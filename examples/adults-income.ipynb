{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Distillation - Binary Classification\n",
    "In this example, we will use the [Adult Census Income](https://www.kaggle.com/uciml/adult-census-income). \n",
    "based on the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "executionInfo": {
     "elapsed": 680,
     "status": "ok",
     "timestamp": 1627202543782,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "I5-jBe2bh-Ug"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../.')\n",
    "sys.path.append('../conformal_pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uZBxFOEivTg"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1627197718603,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "sHXz2EsuifyO",
    "outputId": "5c78e2bf-2b1f-48bd-8157-b4389c0de09c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = Path(r\"C:\\Users\\orrav\\Documents\\Datasets\\Adult Census Income\\adult.csv\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1627197760101,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "bXnywkTLitJF",
    "outputId": "e704e9b8-3ce7-49b0-bd88-d2e84c834a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education.num   32561 non-null  int64 \n",
      " 5   marital.status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital.gain    32561 non-null  int64 \n",
      " 11  capital.loss    32561 non-null  int64 \n",
      " 12  hours.per.week  32561 non-null  int64 \n",
      " 13  native.country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tn7h9q35i8Fo"
   },
   "source": [
    "### Set ? to NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1627197875260,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "uuX7wEtqi2WD"
   },
   "outputs": [],
   "source": [
    "df[df == '?'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1627197911380,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "1rE6ellKjSjQ",
    "outputId": "bf8302c8-cebb-4720-dcd4-ccb5f6ca088b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       30725 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education.num   32561 non-null  int64 \n",
      " 5   marital.status  32561 non-null  object\n",
      " 6   occupation      30718 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital.gain    32561 non-null  int64 \n",
      " 11  capital.loss    32561 non-null  int64 \n",
      " 12  hours.per.week  32561 non-null  int64 \n",
      " 13  native.country  31978 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGR3suExlSoQ"
   },
   "source": [
    "### Fill-out missing values\n",
    "We can see that `workclass`, `occupation` and `native.country` have missing values. These features are categorical and we can therefore fill them out with `mode`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1627198523112,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "fmHuUi2ylXM_"
   },
   "outputs": [],
   "source": [
    "for col in ['workclass', 'occupation', 'native.country']:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1627198545285,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "i8FxGAHll0PH",
    "outputId": "3544b0a4-06bb-48b4-d0a1-1d7e8314400c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education.num   32561 non-null  int64 \n",
      " 5   marital.status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital.gain    32561 non-null  int64 \n",
      " 11  capital.loss    32561 non-null  int64 \n",
      " 12  hours.per.week  32561 non-null  int64 \n",
      " 13  native.country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1627198556472,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "E9qLRbFGl1wY",
    "outputId": "cf6c418f-15b1-4959-8ae0-f56d6ea78bc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education.num     0\n",
       "marital.status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital.gain      0\n",
       "capital.loss      0\n",
       "hours.per.week    0\n",
       "native.country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGmSE6Vu-hpZ"
   },
   "source": [
    "### Setting features and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1627207385650,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "Jmx5__NE-lIo"
   },
   "outputs": [],
   "source": [
    "X = df.drop(['income'], axis=1)\n",
    "\n",
    "y = df['income'].map({'<=50K': 0, '>50K': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPTXDQEW-pSi"
   },
   "source": [
    "### Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1627207388438,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "d0bj4nwM-nhG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1627207400013,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "0D2VJC2KEUDg"
   },
   "outputs": [],
   "source": [
    "pX_train, pX_test = X_train.copy(), X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F47FAN0H-4kS"
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using `LabelEncoder` to encode categorical text features into integers. We also a standard normalization of the tabular features in the form of centering and std scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1627207402436,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "rXOx0Gxx_SfU"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "categorical = X.select_dtypes(include=[\"object\"]).columns\n",
    "label_encoders = []\n",
    "for feature in categorical:\n",
    "        label_enc = preprocessing.LabelEncoder()\n",
    "        pX_train.loc[:, feature] = label_enc.fit_transform(X_train[feature])\n",
    "        pX_test.loc[:, feature] = label_enc.transform(X_test[feature])\n",
    "        label_encoders.append(label_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>321166</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31180</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>94991</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25875</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>44363</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>254202</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15278</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>237620</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education.num  marital.status  \\\n",
       "7872    64          3  321166          9             13               0   \n",
       "31180   31          1   94991         11              9               0   \n",
       "25875   25          3   44363         11              9               4   \n",
       "4345    37          3  254202          9             13               2   \n",
       "15278   63          3  237620         11              9               2   \n",
       "\n",
       "       occupation  relationship  race  sex  capital.gain  capital.loss  \\\n",
       "7872           11             1     4    0             0             0   \n",
       "31180           7             4     0    1             0             0   \n",
       "25875           5             1     4    1             0             0   \n",
       "4345           11             0     4    1             0             0   \n",
       "15278           2             0     4    1             0             0   \n",
       "\n",
       "       hours.per.week  native.country  \n",
       "7872                5              38  \n",
       "31180              40              38  \n",
       "25875              35              38  \n",
       "4345               50              38  \n",
       "15278              30              38  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pX_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1627207405222,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "mZIMYwhYDKiE"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pX_train = pd.DataFrame(scaler.fit_transform(pX_train), columns=X.columns)\n",
    "pX_test = pd.DataFrame(scaler.transform(pX_test), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "9zOYwrjSDQN6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.850713</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>1.246786</td>\n",
       "      <td>-0.332697</td>\n",
       "      <td>1.135385</td>\n",
       "      <td>-1.742386</td>\n",
       "      <td>1.236648</td>\n",
       "      <td>-0.276827</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>-1.434521</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-2.885649</td>\n",
       "      <td>0.260859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.560269</td>\n",
       "      <td>-1.889076</td>\n",
       "      <td>-0.891714</td>\n",
       "      <td>0.185015</td>\n",
       "      <td>-0.421692</td>\n",
       "      <td>-1.742386</td>\n",
       "      <td>0.230318</td>\n",
       "      <td>1.590090</td>\n",
       "      <td>-4.327948</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.042075</td>\n",
       "      <td>0.260859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.998630</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>-1.370405</td>\n",
       "      <td>0.185015</td>\n",
       "      <td>-0.421692</td>\n",
       "      <td>0.921843</td>\n",
       "      <td>-0.272846</td>\n",
       "      <td>-0.276827</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.448300</td>\n",
       "      <td>0.260859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.121909</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>0.613637</td>\n",
       "      <td>-0.332697</td>\n",
       "      <td>1.135385</td>\n",
       "      <td>-0.410272</td>\n",
       "      <td>1.236648</td>\n",
       "      <td>-0.899132</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>0.770375</td>\n",
       "      <td>0.260859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.777653</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>0.456853</td>\n",
       "      <td>0.185015</td>\n",
       "      <td>-0.421692</td>\n",
       "      <td>-0.410272</td>\n",
       "      <td>-1.027593</td>\n",
       "      <td>-0.899132</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.854525</td>\n",
       "      <td>0.260859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education.num  marital.status  \\\n",
       "0  1.850713  -0.088376  1.246786  -0.332697       1.135385       -1.742386   \n",
       "1 -0.560269  -1.889076 -0.891714   0.185015      -0.421692       -1.742386   \n",
       "2 -0.998630  -0.088376 -1.370405   0.185015      -0.421692        0.921843   \n",
       "3 -0.121909  -0.088376  0.613637  -0.332697       1.135385       -0.410272   \n",
       "4  1.777653  -0.088376  0.456853   0.185015      -0.421692       -0.410272   \n",
       "\n",
       "   occupation  relationship      race       sex  capital.gain  capital.loss  \\\n",
       "0    1.236648     -0.276827  0.393160 -1.434521      -0.14426     -0.217063   \n",
       "1    0.230318      1.590090 -4.327948  0.697097      -0.14426     -0.217063   \n",
       "2   -0.272846     -0.276827  0.393160  0.697097      -0.14426     -0.217063   \n",
       "3    1.236648     -0.899132  0.393160  0.697097      -0.14426     -0.217063   \n",
       "4   -1.027593     -0.899132  0.393160  0.697097      -0.14426     -0.217063   \n",
       "\n",
       "   hours.per.week  native.country  \n",
       "0       -2.885649        0.260859  \n",
       "1       -0.042075        0.260859  \n",
       "2       -0.448300        0.260859  \n",
       "3        0.770375        0.260859  \n",
       "4       -0.854525        0.260859  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pX_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1627206648194,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "Irlf2fESDy9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education.num     0\n",
       "marital.status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital.gain      0\n",
       "capital.loss      0\n",
       "hours.per.week    0\n",
       "native.country    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pX_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen by the plot below, the two classes (smaller or larger than a 50k income) are slightly imbalanced. Therefore, we chose a *macro-F1* as our measure of success for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['income'], density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ECjYYqnDZ5a"
   },
   "source": [
    "## Fit Student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's fit a **Random Forest** classifier as our student model. We set `n_estimators` as default of 100 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1627206381584,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "05nP9EUFDZDi"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2059,
     "status": "ok",
     "timestamp": 1627206739142,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "QdKXN9hrDquA",
    "outputId": "d402aa76-8f29-4615-dee2-7d2794be8679"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(pX_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1627206741583,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "BccKvstsEyOw"
   },
   "outputs": [],
   "source": [
    "test_preds = clf.predict(pX_test)\n",
    "test_probas = clf.predict_proba(pX_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "Macro-F1 and ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7885469091492391"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, test_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1627206744112,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "85wrlxJbE70t",
    "outputId": "950350f1-f461-4f07-b61c-625f61656fc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.903020760693811"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, test_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yzcgA9uGfWE"
   },
   "source": [
    "## Fit Teacher (AutoGluon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the teacher model, we'll be using [AutoGluon](https://auto.gluon.ai/stable/index.html), which is an intuitive AutoML framework for multiple applications, including tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1627207235856,
     "user": {
      "displayName": "Orr Avrech",
      "photoUrl": "",
      "userId": "08602400392920330638"
     },
     "user_tz": -180
    },
    "id": "6PHpU7JRGy46",
    "outputId": "12a914ca-db92-496f-8976-2f61245fe781"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.850713</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>1.246786</td>\n",
       "      <td>-0.332697</td>\n",
       "      <td>1.135385</td>\n",
       "      <td>-1.742386</td>\n",
       "      <td>1.236648</td>\n",
       "      <td>-0.276827</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>-1.434521</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-2.885649</td>\n",
       "      <td>0.260859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.560269</td>\n",
       "      <td>-1.889076</td>\n",
       "      <td>-0.891714</td>\n",
       "      <td>0.185015</td>\n",
       "      <td>-0.421692</td>\n",
       "      <td>-1.742386</td>\n",
       "      <td>0.230318</td>\n",
       "      <td>1.590090</td>\n",
       "      <td>-4.327948</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.042075</td>\n",
       "      <td>0.260859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.998630</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>-1.370405</td>\n",
       "      <td>0.185015</td>\n",
       "      <td>-0.421692</td>\n",
       "      <td>0.921843</td>\n",
       "      <td>-0.272846</td>\n",
       "      <td>-0.276827</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.448300</td>\n",
       "      <td>0.260859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.121909</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>0.613637</td>\n",
       "      <td>-0.332697</td>\n",
       "      <td>1.135385</td>\n",
       "      <td>-0.410272</td>\n",
       "      <td>1.236648</td>\n",
       "      <td>-0.899132</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>0.770375</td>\n",
       "      <td>0.260859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.777653</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>0.456853</td>\n",
       "      <td>0.185015</td>\n",
       "      <td>-0.421692</td>\n",
       "      <td>-0.410272</td>\n",
       "      <td>-1.027593</td>\n",
       "      <td>-0.899132</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.854525</td>\n",
       "      <td>0.260859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education.num  marital.status  \\\n",
       "0  1.850713  -0.088376  1.246786  -0.332697       1.135385       -1.742386   \n",
       "1 -0.560269  -1.889076 -0.891714   0.185015      -0.421692       -1.742386   \n",
       "2 -0.998630  -0.088376 -1.370405   0.185015      -0.421692        0.921843   \n",
       "3 -0.121909  -0.088376  0.613637  -0.332697       1.135385       -0.410272   \n",
       "4  1.777653  -0.088376  0.456853   0.185015      -0.421692       -0.410272   \n",
       "\n",
       "   occupation  relationship      race       sex  capital.gain  capital.loss  \\\n",
       "0    1.236648     -0.276827  0.393160 -1.434521      -0.14426     -0.217063   \n",
       "1    0.230318      1.590090 -4.327948  0.697097      -0.14426     -0.217063   \n",
       "2   -0.272846     -0.276827  0.393160  0.697097      -0.14426     -0.217063   \n",
       "3    1.236648     -0.899132  0.393160  0.697097      -0.14426     -0.217063   \n",
       "4   -1.027593     -0.899132  0.393160  0.697097      -0.14426     -0.217063   \n",
       "\n",
       "   hours.per.week  native.country  income  \n",
       "0       -2.885649        0.260859       0  \n",
       "1       -0.042075        0.260859       0  \n",
       "2       -0.448300        0.260859       0  \n",
       "3        0.770375        0.260859       0  \n",
       "4       -0.854525        0.260859       0  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'income'\n",
    "df_train = pX_train.copy()\n",
    "df_train[label] = y_train.reset_index(drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.266233</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>0.805319</td>\n",
       "      <td>-1.109266</td>\n",
       "      <td>-1.978770</td>\n",
       "      <td>2.253958</td>\n",
       "      <td>1.236648</td>\n",
       "      <td>1.590090</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>-1.434521</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.042075</td>\n",
       "      <td>0.260859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.436990</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>0.455293</td>\n",
       "      <td>0.185015</td>\n",
       "      <td>-0.421692</td>\n",
       "      <td>0.921843</td>\n",
       "      <td>-0.272846</td>\n",
       "      <td>0.967785</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>-1.434521</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-1.260750</td>\n",
       "      <td>0.260859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.144750</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>-0.603334</td>\n",
       "      <td>1.220441</td>\n",
       "      <td>-0.032423</td>\n",
       "      <td>0.921843</td>\n",
       "      <td>0.230318</td>\n",
       "      <td>-0.276827</td>\n",
       "      <td>-3.147671</td>\n",
       "      <td>-1.434521</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.448300</td>\n",
       "      <td>0.426445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.121909</td>\n",
       "      <td>-2.789426</td>\n",
       "      <td>-1.328652</td>\n",
       "      <td>-0.332697</td>\n",
       "      <td>1.135385</td>\n",
       "      <td>-0.410272</td>\n",
       "      <td>0.733483</td>\n",
       "      <td>-0.899132</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.042075</td>\n",
       "      <td>0.260859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.754812</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>2.211732</td>\n",
       "      <td>0.443872</td>\n",
       "      <td>1.524654</td>\n",
       "      <td>-0.410272</td>\n",
       "      <td>1.236648</td>\n",
       "      <td>-0.899132</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>0.770375</td>\n",
       "      <td>0.260859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education.num  marital.status  \\\n",
       "0  1.266233  -0.088376  0.805319  -1.109266      -1.978770        2.253958   \n",
       "1 -1.436990  -0.088376  0.455293   0.185015      -0.421692        0.921843   \n",
       "2 -1.144750  -0.088376 -0.603334   1.220441      -0.032423        0.921843   \n",
       "3 -0.121909  -2.789426 -1.328652  -0.332697       1.135385       -0.410272   \n",
       "4  0.754812  -0.088376  2.211732   0.443872       1.524654       -0.410272   \n",
       "\n",
       "   occupation  relationship      race       sex  capital.gain  capital.loss  \\\n",
       "0    1.236648      1.590090  0.393160 -1.434521      -0.14426     -0.217063   \n",
       "1   -0.272846      0.967785  0.393160 -1.434521      -0.14426     -0.217063   \n",
       "2    0.230318     -0.276827 -3.147671 -1.434521      -0.14426     -0.217063   \n",
       "3    0.733483     -0.899132  0.393160  0.697097      -0.14426     -0.217063   \n",
       "4    1.236648     -0.899132  0.393160  0.697097      -0.14426     -0.217063   \n",
       "\n",
       "   hours.per.week  native.country  income  \n",
       "0       -0.042075        0.260859       0  \n",
       "1       -1.260750        0.260859       0  \n",
       "2       -0.448300        0.426445       0  \n",
       "3       -0.042075        0.260859       0  \n",
       "4        0.770375        0.260859       1  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pX_test.copy()\n",
    "df_test[label] = y_test.reset_index(drop=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "tAO4F8YBGiBF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210729_173830\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210729_173830\\\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    16280\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1357.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.82 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['age', 'workclass', 'fnlwgt', 'education', 'education.num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['age', 'workclass', 'fnlwgt', 'education', 'education.num', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.82 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.83s of the 599.89s of remaining time.\n",
      "\t0.7478\t = Validation f1_macro score\n",
      "\t0.4s\t = Training runtime\n",
      "\t2.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 397.08s of the 597.14s of remaining time.\n",
      "\t0.7489\t = Validation f1_macro score\n",
      "\t0.38s\t = Training runtime\n",
      "\t2.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 394.45s of the 594.51s of remaining time.\n",
      "\t0.8112\t = Validation f1_macro score\n",
      "\t150.07s\t = Training runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 243.26s of the 443.32s of remaining time.\n",
      "\t0.8209\t = Validation f1_macro score\n",
      "\t115.18s\t = Training runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 127.32s of the 327.38s of remaining time.\n",
      "\t0.7947\t = Validation f1_macro score\n",
      "\t2.98s\t = Training runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 122.25s of the 322.3s of remaining time.\n",
      "\t0.7935\t = Validation f1_macro score\n",
      "\t3.24s\t = Training runtime\n",
      "\t0.99s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 117.2s of the 317.26s of remaining time.\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 92.73s of the 292.79s of remaining time.\n",
      "\t0.7854\t = Validation f1_macro score\n",
      "\t2.28s\t = Training runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 88.54s of the 288.6s of remaining time.\n",
      "\t0.7874\t = Validation f1_macro score\n",
      "\t1.35s\t = Training runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 85.73s of the 285.79s of remaining time.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\t0.7834\t = Validation f1_macro score\n",
      "\t83.42s\t = Training runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1.01s of the 201.07s of remaining time.\n",
      "\tTime limit exceeded... Skipping XGBoost_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 199.91s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:45:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8209\t = Validation f1_macro score\n",
      "\t12.54s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsUnif_BAG_L2 ... Training model for up to 187.32s of the 187.31s of remaining time.\n",
      "\t0.7833\t = Validation f1_macro score\n",
      "\t0.02s\t = Training runtime\n",
      "\t11.89s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L2 ... Training model for up to 175.1s of the 175.09s of remaining time.\n",
      "\t0.7899\t = Validation f1_macro score\n",
      "\t0.03s\t = Training runtime\n",
      "\t12.28s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 162.15s of the 162.14s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 270. Best iteration is:\n",
      "\t[236]\ttrain_set's binary_logloss: 0.229563\ttrain_set's f1_macro: 0.842545\tvalid_set's binary_logloss: 0.280318\tvalid_set's f1_macro: 0.822384\n",
      "\t0.8212\t = Validation f1_macro score\n",
      "\t103.95s\t = Training runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 57.48s of the 57.47s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 98. Best iteration is:\n",
      "\t[83]\ttrain_set's binary_logloss: 0.237153\ttrain_set's f1_macro: 0.839872\tvalid_set's binary_logloss: 0.280052\tvalid_set's f1_macro: 0.817361\n",
      "\tRan out of time, early stopping on iteration 98. Best iteration is:\n",
      "\t[60]\ttrain_set's binary_logloss: 0.251677\ttrain_set's f1_macro: 0.837629\tvalid_set's binary_logloss: 0.279536\tvalid_set's f1_macro: 0.826709\n",
      "\tRan out of time, early stopping on iteration 102. Best iteration is:\n",
      "\t[80]\ttrain_set's binary_logloss: 0.239493\ttrain_set's f1_macro: 0.837421\tvalid_set's binary_logloss: 0.261477\tvalid_set's f1_macro: 0.827334\n",
      "\tRan out of time, early stopping on iteration 104. Best iteration is:\n",
      "\t[82]\ttrain_set's binary_logloss: 0.234934\ttrain_set's f1_macro: 0.840211\tvalid_set's binary_logloss: 0.287542\tvalid_set's f1_macro: 0.820591\n",
      "\tRan out of time, early stopping on iteration 106. Best iteration is:\n",
      "\t[44]\ttrain_set's binary_logloss: 0.265314\ttrain_set's f1_macro: 0.837386\tvalid_set's binary_logloss: 0.313625\tvalid_set's f1_macro: 0.805888\n",
      "\tRan out of time, early stopping on iteration 112. Best iteration is:\n",
      "\t[95]\ttrain_set's binary_logloss: 0.230433\ttrain_set's f1_macro: 0.845468\tvalid_set's binary_logloss: 0.28376\tvalid_set's f1_macro: 0.828388\n",
      "\tRan out of time, early stopping on iteration 113. Best iteration is:\n",
      "\t[113]\ttrain_set's binary_logloss: 0.222473\ttrain_set's f1_macro: 0.847407\tvalid_set's binary_logloss: 0.284119\tvalid_set's f1_macro: 0.82785\n",
      "\tRan out of time, early stopping on iteration 143. Best iteration is:\n",
      "\t[95]\ttrain_set's binary_logloss: 0.232136\ttrain_set's f1_macro: 0.84033\tvalid_set's binary_logloss: 0.277365\tvalid_set's f1_macro: 0.81699\n",
      "\tRan out of time, early stopping on iteration 163. Best iteration is:\n",
      "\t[129]\ttrain_set's binary_logloss: 0.215415\ttrain_set's f1_macro: 0.854444\tvalid_set's binary_logloss: 0.283725\tvalid_set's f1_macro: 0.823097\n",
      "\t0.8213\t = Validation f1_macro score\n",
      "\t55.22s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 1.62s of the 1.61s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 14.79s compared to 10s of available time.\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L2.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -2.62s of remaining time.\n",
      "\t0.8213\t = Validation f1_macro score\n",
      "\t4.54s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 607.27s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210729_173830\\\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.812143</td>\n",
       "      <td>0.820893</td>\n",
       "      <td>1.269042</td>\n",
       "      <td>0.164297</td>\n",
       "      <td>115.175212</td>\n",
       "      <td>1.269042</td>\n",
       "      <td>0.164297</td>\n",
       "      <td>115.175212</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.812143</td>\n",
       "      <td>0.820893</td>\n",
       "      <td>1.287089</td>\n",
       "      <td>0.190620</td>\n",
       "      <td>127.719201</td>\n",
       "      <td>0.018047</td>\n",
       "      <td>0.026323</td>\n",
       "      <td>12.543988</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.810541</td>\n",
       "      <td>0.821249</td>\n",
       "      <td>17.175383</td>\n",
       "      <td>9.447351</td>\n",
       "      <td>463.249604</td>\n",
       "      <td>0.973044</td>\n",
       "      <td>0.173998</td>\n",
       "      <td>103.950102</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.810262</td>\n",
       "      <td>0.821252</td>\n",
       "      <td>16.838339</td>\n",
       "      <td>9.402344</td>\n",
       "      <td>414.521981</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.128991</td>\n",
       "      <td>55.222479</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.810262</td>\n",
       "      <td>0.821252</td>\n",
       "      <td>16.845339</td>\n",
       "      <td>9.462841</td>\n",
       "      <td>419.063154</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.060496</td>\n",
       "      <td>4.541173</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.806434</td>\n",
       "      <td>0.811167</td>\n",
       "      <td>2.096051</td>\n",
       "      <td>0.256811</td>\n",
       "      <td>150.067877</td>\n",
       "      <td>2.096051</td>\n",
       "      <td>0.256811</td>\n",
       "      <td>150.067877</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.791752</td>\n",
       "      <td>0.793519</td>\n",
       "      <td>0.373015</td>\n",
       "      <td>0.985082</td>\n",
       "      <td>3.244593</td>\n",
       "      <td>0.373015</td>\n",
       "      <td>0.985082</td>\n",
       "      <td>3.244593</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.791192</td>\n",
       "      <td>0.794653</td>\n",
       "      <td>0.369169</td>\n",
       "      <td>1.204760</td>\n",
       "      <td>2.975086</td>\n",
       "      <td>0.369169</td>\n",
       "      <td>1.204760</td>\n",
       "      <td>2.975086</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.786272</td>\n",
       "      <td>0.783351</td>\n",
       "      <td>3.943187</td>\n",
       "      <td>0.759061</td>\n",
       "      <td>83.422577</td>\n",
       "      <td>3.943187</td>\n",
       "      <td>0.759061</td>\n",
       "      <td>83.422577</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.782449</td>\n",
       "      <td>0.785431</td>\n",
       "      <td>0.803378</td>\n",
       "      <td>1.161732</td>\n",
       "      <td>2.279531</td>\n",
       "      <td>0.803378</td>\n",
       "      <td>1.161732</td>\n",
       "      <td>2.279531</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.780859</td>\n",
       "      <td>0.787384</td>\n",
       "      <td>0.843807</td>\n",
       "      <td>0.608155</td>\n",
       "      <td>1.346492</td>\n",
       "      <td>0.843807</td>\n",
       "      <td>0.608155</td>\n",
       "      <td>1.346492</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsUnif_BAG_L2</td>\n",
       "      <td>0.769312</td>\n",
       "      <td>0.783319</td>\n",
       "      <td>29.540497</td>\n",
       "      <td>21.165695</td>\n",
       "      <td>359.318500</td>\n",
       "      <td>13.338158</td>\n",
       "      <td>11.892341</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist_BAG_L2</td>\n",
       "      <td>0.768962</td>\n",
       "      <td>0.789936</td>\n",
       "      <td>27.338913</td>\n",
       "      <td>21.553209</td>\n",
       "      <td>359.327509</td>\n",
       "      <td>11.136575</td>\n",
       "      <td>12.279855</td>\n",
       "      <td>0.028007</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.751422</td>\n",
       "      <td>0.747756</td>\n",
       "      <td>3.314773</td>\n",
       "      <td>2.096978</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>3.314773</td>\n",
       "      <td>2.096978</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.747684</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>3.189917</td>\n",
       "      <td>2.036478</td>\n",
       "      <td>0.383540</td>\n",
       "      <td>3.189917</td>\n",
       "      <td>2.036478</td>\n",
       "      <td>0.383540</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_test  score_val  pred_time_test  \\\n",
       "0           LightGBM_BAG_L1    0.812143   0.820893        1.269042   \n",
       "1       WeightedEnsemble_L2    0.812143   0.820893        1.287089   \n",
       "2         LightGBMXT_BAG_L2    0.810541   0.821249       17.175383   \n",
       "3           LightGBM_BAG_L2    0.810262   0.821252       16.838339   \n",
       "4       WeightedEnsemble_L3    0.810262   0.821252       16.845339   \n",
       "5         LightGBMXT_BAG_L1    0.806434   0.811167        2.096051   \n",
       "6   RandomForestEntr_BAG_L1    0.791752   0.793519        0.373015   \n",
       "7   RandomForestGini_BAG_L1    0.791192   0.794653        0.369169   \n",
       "8    NeuralNetFastAI_BAG_L1    0.786272   0.783351        3.943187   \n",
       "9     ExtraTreesGini_BAG_L1    0.782449   0.785431        0.803378   \n",
       "10    ExtraTreesEntr_BAG_L1    0.780859   0.787384        0.843807   \n",
       "11    KNeighborsUnif_BAG_L2    0.769312   0.783319       29.540497   \n",
       "12    KNeighborsDist_BAG_L2    0.768962   0.789936       27.338913   \n",
       "13    KNeighborsUnif_BAG_L1    0.751422   0.747756        3.314773   \n",
       "14    KNeighborsDist_BAG_L1    0.747684   0.748905        3.189917   \n",
       "\n",
       "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        0.164297  115.175212                 1.269042   \n",
       "1        0.190620  127.719201                 0.018047   \n",
       "2        9.447351  463.249604                 0.973044   \n",
       "3        9.402344  414.521981                 0.636000   \n",
       "4        9.462841  419.063154                 0.007000   \n",
       "5        0.256811  150.067877                 2.096051   \n",
       "6        0.985082    3.244593                 0.373015   \n",
       "7        1.204760    2.975086                 0.369169   \n",
       "8        0.759061   83.422577                 3.943187   \n",
       "9        1.161732    2.279531                 0.803378   \n",
       "10       0.608155    1.346492                 0.843807   \n",
       "11      21.165695  359.318500                13.338158   \n",
       "12      21.553209  359.327509                11.136575   \n",
       "13       2.096978    0.404594                 3.314773   \n",
       "14       2.036478    0.383540                 3.189917   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.164297         115.175212            1       True   \n",
       "1                 0.026323          12.543988            2       True   \n",
       "2                 0.173998         103.950102            2       True   \n",
       "3                 0.128991          55.222479            2       True   \n",
       "4                 0.060496           4.541173            3       True   \n",
       "5                 0.256811         150.067877            1       True   \n",
       "6                 0.985082           3.244593            1       True   \n",
       "7                 1.204760           2.975086            1       True   \n",
       "8                 0.759061          83.422577            1       True   \n",
       "9                 1.161732           2.279531            1       True   \n",
       "10                0.608155           1.346492            1       True   \n",
       "11               11.892341           0.018998            2       True   \n",
       "12               12.279855           0.028007            2       True   \n",
       "13                2.096978           0.404594            1       True   \n",
       "14                2.036478           0.383540            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           4  \n",
       "1          10  \n",
       "2          13  \n",
       "3          14  \n",
       "4          15  \n",
       "5           3  \n",
       "6           6  \n",
       "7           5  \n",
       "8           9  \n",
       "9           7  \n",
       "10          8  \n",
       "11         11  \n",
       "12         12  \n",
       "13          1  \n",
       "14          2  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_limit = 600  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = 'f1_macro'  # specify your evaluation metric here\n",
    "predictor = TabularPredictor(label, eval_metric=metric).fit(df_train, time_limit=time_limit, presets='best_quality', auto_stack=True)\n",
    "predictor.leaderboard(df_test, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment training samples for distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the student on an augmeneted training set, should reduce the approximation error between the teacher and the student, and should therefore lead to better results at the same computational cost. The augmentation procedure is composed of two main stages:\n",
    "1. For all features $i$, estimate the conditional distribution $p(x^i | x^{-i})$ using the training data.\n",
    "2. Sample new features\n",
    "\n",
    "The conditional ditribution estimation is done via a Self-Attention mechanism trained with a pseudolikelihood objective. When sampling, we compare between two methods. The first method, and the one presented in the paper is Gibbs sampling, which aims to estimate $p(x)$ directly. The second method, is simply by using the output of the Self-Attention model, which estimated the conditioal distribution of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models.transformer import CondEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_obj):\n",
    "\n",
    "        # data size\n",
    "        self.N = data_obj.shape[0]\n",
    "        self.data = data_obj.astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset(data_obj=pX_train.to_numpy())\n",
    "train_loader = DataLoader(ds_train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the PL conditionals estimator\n",
    "`CondEncoder` represents the self-attention-based encoder and is trained by minimized the negative log-likelihood of the conditionals. Each conditional is paramterized as a mixture of Gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_enc = CondEncoder(epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train Log likelihood, step 0 in nats: -0.102535\n",
      "Train Log likelihood, step 1 in nats: -0.093035\n",
      "Train Log likelihood, step 50 in nats: -0.095521\n",
      "Train Log likelihood, step 100 in nats: -0.093183\n",
      "Train Log likelihood, step 150 in nats: -0.092472\n",
      "Train epoch average loss: -0.09266250707593539\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "Train Log likelihood, step 200 in nats: -0.093120\n",
      "Train Log likelihood, step 250 in nats: -0.093278\n",
      "Train Log likelihood, step 300 in nats: -0.093106\n",
      "Train epoch average loss: -0.09255757114371738\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "Train Log likelihood, step 350 in nats: -0.091568\n",
      "Train Log likelihood, step 400 in nats: -0.090144\n",
      "Train Log likelihood, step 450 in nats: -0.089954\n",
      "Train epoch average loss: -0.08950587984092112\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "Train Log likelihood, step 500 in nats: -0.088979\n",
      "Train Log likelihood, step 550 in nats: -0.088943\n",
      "Train Log likelihood, step 600 in nats: -0.088255\n",
      "Train Log likelihood, step 650 in nats: -0.087232\n",
      "Train epoch average loss: -0.0872013487242144\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "Train Log likelihood, step 700 in nats: -0.085621\n",
      "Train Log likelihood, step 750 in nats: -0.084604\n",
      "Train Log likelihood, step 800 in nats: -0.083226\n",
      "Train epoch average loss: -0.08303274247456681\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "Train Log likelihood, step 850 in nats: -0.081841\n",
      "Train Log likelihood, step 900 in nats: -0.081742\n",
      "Train Log likelihood, step 950 in nats: -0.080595\n",
      "Train epoch average loss: -0.0799083419511801\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "Train Log likelihood, step 1000 in nats: -0.079479\n",
      "Train Log likelihood, step 1050 in nats: -0.078254\n",
      "Train Log likelihood, step 1100 in nats: -0.077521\n",
      "Train epoch average loss: -0.07650910962828056\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "Train Log likelihood, step 1150 in nats: -0.076021\n",
      "Train Log likelihood, step 1200 in nats: -0.075318\n",
      "Train Log likelihood, step 1250 in nats: -0.074492\n",
      "Train Log likelihood, step 1300 in nats: -0.073738\n",
      "Train epoch average loss: -0.0736162617445079\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "Train Log likelihood, step 1350 in nats: -0.072893\n",
      "Train Log likelihood, step 1400 in nats: -0.072175\n",
      "Train Log likelihood, step 1450 in nats: -0.071901\n",
      "Train epoch average loss: -0.07153377480135731\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "Train Log likelihood, step 1500 in nats: -0.071600\n",
      "Train Log likelihood, step 1550 in nats: -0.071179\n",
      "Train Log likelihood, step 1600 in nats: -0.070629\n",
      "Train epoch average loss: -0.07042435130090693\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "Train Log likelihood, step 1650 in nats: -0.070250\n",
      "Train Log likelihood, step 1700 in nats: -0.069509\n",
      "Train Log likelihood, step 1750 in nats: -0.068644\n",
      "Train epoch average loss: -0.0679198418120461\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "Train Log likelihood, step 1800 in nats: -0.067788\n",
      "Train Log likelihood, step 1850 in nats: -0.067150\n",
      "Train Log likelihood, step 1900 in nats: -0.066742\n",
      "Train Log likelihood, step 1950 in nats: -0.065953\n",
      "Train epoch average loss: -0.06596487236524232\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "Train Log likelihood, step 2000 in nats: -0.065192\n",
      "Train Log likelihood, step 2050 in nats: -0.064631\n",
      "Train Log likelihood, step 2100 in nats: -0.063900\n",
      "Train epoch average loss: -0.06361270267357956\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "Train Log likelihood, step 2150 in nats: -0.063317\n",
      "Train Log likelihood, step 2200 in nats: -0.062981\n",
      "Train Log likelihood, step 2250 in nats: -0.062614\n",
      "Train epoch average loss: -0.0624253094554596\n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "Train Log likelihood, step 2300 in nats: -0.062274\n",
      "Train Log likelihood, step 2350 in nats: -0.061729\n",
      "Train Log likelihood, step 2400 in nats: -0.061009\n",
      "Train epoch average loss: -0.060625922782277956\n",
      "\n",
      "\n",
      "Epoch: 15\n",
      "Train Log likelihood, step 2450 in nats: -0.060552\n",
      "Train Log likelihood, step 2500 in nats: -0.059831\n",
      "Train Log likelihood, step 2550 in nats: -0.059416\n",
      "Train Log likelihood, step 2600 in nats: -0.059035\n",
      "Train epoch average loss: -0.058844925393221705\n",
      "\n",
      "\n",
      "Epoch: 16\n",
      "Train Log likelihood, step 2650 in nats: -0.058593\n",
      "Train Log likelihood, step 2700 in nats: -0.058129\n",
      "Train Log likelihood, step 2750 in nats: -0.057385\n",
      "Train epoch average loss: -0.05732030831117192\n",
      "\n",
      "\n",
      "Epoch: 17\n",
      "Train Log likelihood, step 2800 in nats: -0.057060\n",
      "Train Log likelihood, step 2850 in nats: -0.056646\n",
      "Train Log likelihood, step 2900 in nats: -0.056168\n",
      "Train epoch average loss: -0.05589507948270323\n",
      "\n",
      "\n",
      "Epoch: 18\n",
      "Train Log likelihood, step 2950 in nats: -0.055947\n",
      "Train Log likelihood, step 3000 in nats: -0.055567\n",
      "Train Log likelihood, step 3050 in nats: -0.054997\n",
      "Train epoch average loss: -0.0549661129082823\n",
      "\n",
      "\n",
      "Epoch: 19\n",
      "Train Log likelihood, step 3100 in nats: -0.054899\n",
      "Train Log likelihood, step 3150 in nats: -0.054313\n",
      "Train Log likelihood, step 3200 in nats: -0.053675\n",
      "Train Log likelihood, step 3250 in nats: -0.053137\n",
      "Train epoch average loss: -0.053121266910012274\n",
      "\n",
      "\n",
      "Epoch: 20\n",
      "Train Log likelihood, step 3300 in nats: -0.052725\n",
      "Train Log likelihood, step 3350 in nats: -0.052278\n",
      "Train Log likelihood, step 3400 in nats: -0.051696\n",
      "Train epoch average loss: -0.05138809007334361\n",
      "\n",
      "\n",
      "Epoch: 21\n",
      "Train Log likelihood, step 3450 in nats: -0.051053\n",
      "Train Log likelihood, step 3500 in nats: -0.050458\n",
      "Train Log likelihood, step 3550 in nats: -0.050060\n",
      "Train epoch average loss: -0.049792801059425955\n",
      "\n",
      "\n",
      "Epoch: 22\n",
      "Train Log likelihood, step 3600 in nats: -0.049693\n",
      "Train Log likelihood, step 3650 in nats: -0.049246\n",
      "Train Log likelihood, step 3700 in nats: -0.048935\n",
      "Train epoch average loss: -0.048736928167099576\n",
      "\n",
      "\n",
      "Epoch: 23\n",
      "Train Log likelihood, step 3750 in nats: -0.048717\n",
      "Train Log likelihood, step 3800 in nats: -0.048316\n",
      "Train Log likelihood, step 3850 in nats: -0.048182\n",
      "Train Log likelihood, step 3900 in nats: -0.047808\n",
      "Train epoch average loss: -0.0476759084100594\n",
      "\n",
      "\n",
      "Epoch: 24\n",
      "Train Log likelihood, step 3950 in nats: -0.047516\n",
      "Train Log likelihood, step 4000 in nats: -0.047038\n",
      "Train Log likelihood, step 4050 in nats: -0.046523\n",
      "Train epoch average loss: -0.04648813658010864\n",
      "\n",
      "\n",
      "Epoch: 25\n",
      "Train Log likelihood, step 4100 in nats: -0.046296\n",
      "Train Log likelihood, step 4150 in nats: -0.045850\n",
      "Train Log likelihood, step 4200 in nats: -0.045510\n",
      "Train epoch average loss: -0.04512495476675247\n",
      "\n",
      "\n",
      "Epoch: 26\n",
      "Train Log likelihood, step 4250 in nats: -0.045038\n",
      "Train Log likelihood, step 4300 in nats: -0.044800\n",
      "Train Log likelihood, step 4350 in nats: -0.044618\n",
      "Train Log likelihood, step 4400 in nats: -0.044207\n",
      "Train epoch average loss: -0.04420650157359981\n",
      "\n",
      "\n",
      "Epoch: 27\n",
      "Train Log likelihood, step 4450 in nats: -0.043925\n",
      "Train Log likelihood, step 4500 in nats: -0.043728\n",
      "Train Log likelihood, step 4550 in nats: -0.043250\n",
      "Train epoch average loss: -0.043237319470480644\n",
      "\n",
      "\n",
      "Epoch: 28\n",
      "Train Log likelihood, step 4600 in nats: -0.043182\n",
      "Train Log likelihood, step 4650 in nats: -0.042851\n",
      "Train Log likelihood, step 4700 in nats: -0.042476\n",
      "Train epoch average loss: -0.04250763007331967\n",
      "\n",
      "\n",
      "Epoch: 29\n",
      "Train Log likelihood, step 4750 in nats: -0.042432\n",
      "Train Log likelihood, step 4800 in nats: -0.041906\n",
      "Train Log likelihood, step 4850 in nats: -0.041661\n",
      "Train epoch average loss: -0.04143380338172783\n",
      "\n",
      "\n",
      "Epoch: 30\n",
      "Train Log likelihood, step 4900 in nats: -0.041433\n",
      "Train Log likelihood, step 4950 in nats: -0.041177\n",
      "Train Log likelihood, step 5000 in nats: -0.040861\n",
      "Train Log likelihood, step 5050 in nats: -0.040628\n",
      "Train epoch average loss: -0.040655389833330856\n",
      "\n",
      "\n",
      "Epoch: 31\n",
      "Train Log likelihood, step 5100 in nats: -0.040378\n",
      "Train Log likelihood, step 5150 in nats: -0.040165\n",
      "Train Log likelihood, step 5200 in nats: -0.039994\n",
      "Train epoch average loss: -0.039810008333782274\n",
      "\n",
      "\n",
      "Epoch: 32\n",
      "Train Log likelihood, step 5250 in nats: -0.039577\n",
      "Train Log likelihood, step 5300 in nats: -0.039205\n",
      "Train Log likelihood, step 5350 in nats: -0.038876\n",
      "Train epoch average loss: -0.03874660311999024\n",
      "\n",
      "\n",
      "Epoch: 33\n",
      "Train Log likelihood, step 5400 in nats: -0.038648\n",
      "Train Log likelihood, step 5450 in nats: -0.038381\n",
      "Train Log likelihood, step 5500 in nats: -0.038102\n",
      "Train epoch average loss: -0.03785036527916486\n",
      "\n",
      "\n",
      "Epoch: 34\n",
      "Train Log likelihood, step 5550 in nats: -0.037816\n",
      "Train Log likelihood, step 5600 in nats: -0.037552\n",
      "Train Log likelihood, step 5650 in nats: -0.037161\n",
      "Train Log likelihood, step 5700 in nats: -0.036765\n",
      "Train epoch average loss: -0.0367088496737135\n",
      "\n",
      "\n",
      "Epoch: 35\n",
      "Train Log likelihood, step 5750 in nats: -0.036497\n",
      "Train Log likelihood, step 5800 in nats: -0.036359\n",
      "Train Log likelihood, step 5850 in nats: -0.036130\n",
      "Train epoch average loss: -0.03605485011450616\n",
      "\n",
      "\n",
      "Epoch: 36\n",
      "Train Log likelihood, step 5900 in nats: -0.035833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 5950 in nats: -0.035638\n",
      "Train Log likelihood, step 6000 in nats: -0.035518\n",
      "Train epoch average loss: -0.035174586015483\n",
      "\n",
      "\n",
      "Epoch: 37\n",
      "Train Log likelihood, step 6050 in nats: -0.035070\n",
      "Train Log likelihood, step 6100 in nats: -0.034712\n",
      "Train Log likelihood, step 6150 in nats: -0.034438\n",
      "Train epoch average loss: -0.03419791115572529\n",
      "\n",
      "\n",
      "Epoch: 38\n",
      "Train Log likelihood, step 6200 in nats: -0.034141\n",
      "Train Log likelihood, step 6250 in nats: -0.033829\n",
      "Train Log likelihood, step 6300 in nats: -0.033390\n",
      "Train Log likelihood, step 6350 in nats: -0.033132\n",
      "Train epoch average loss: -0.03302971835849633\n",
      "\n",
      "\n",
      "Epoch: 39\n",
      "Train Log likelihood, step 6400 in nats: -0.032741\n",
      "Train Log likelihood, step 6450 in nats: -0.032594\n",
      "Train Log likelihood, step 6500 in nats: -0.032439\n",
      "Train epoch average loss: -0.03241670292316472\n",
      "\n",
      "\n",
      "Epoch: 40\n",
      "Train Log likelihood, step 6550 in nats: -0.032194\n",
      "Train Log likelihood, step 6600 in nats: -0.031951\n",
      "Train Log likelihood, step 6650 in nats: -0.031862\n",
      "Train epoch average loss: -0.03171244471467254\n",
      "\n",
      "\n",
      "Epoch: 41\n",
      "Train Log likelihood, step 6700 in nats: -0.031568\n",
      "Train Log likelihood, step 6750 in nats: -0.031510\n",
      "Train Log likelihood, step 6800 in nats: -0.031294\n",
      "Train epoch average loss: -0.031181529597465896\n",
      "\n",
      "\n",
      "Epoch: 42\n",
      "Train Log likelihood, step 6850 in nats: -0.031182\n",
      "Train Log likelihood, step 6900 in nats: -0.031045\n",
      "Train Log likelihood, step 6950 in nats: -0.030880\n",
      "Train Log likelihood, step 7000 in nats: -0.030585\n",
      "Train epoch average loss: -0.03048097944615314\n",
      "\n",
      "\n",
      "Epoch: 43\n",
      "Train Log likelihood, step 7050 in nats: -0.030354\n",
      "Train Log likelihood, step 7100 in nats: -0.030184\n",
      "Train Log likelihood, step 7150 in nats: -0.029897\n",
      "Train epoch average loss: -0.029858693265452232\n",
      "\n",
      "\n",
      "Epoch: 44\n",
      "Train Log likelihood, step 7200 in nats: -0.029651\n",
      "Train Log likelihood, step 7250 in nats: -0.029473\n",
      "Train Log likelihood, step 7300 in nats: -0.029185\n",
      "Train epoch average loss: -0.029005071592539827\n",
      "\n",
      "\n",
      "Epoch: 45\n",
      "Train Log likelihood, step 7350 in nats: -0.028934\n",
      "Train Log likelihood, step 7400 in nats: -0.028790\n",
      "Train Log likelihood, step 7450 in nats: -0.028359\n",
      "Train epoch average loss: -0.027907169775529143\n",
      "\n",
      "\n",
      "Epoch: 46\n",
      "Train Log likelihood, step 7500 in nats: -0.027891\n",
      "Train Log likelihood, step 7550 in nats: -0.027687\n",
      "Train Log likelihood, step 7600 in nats: -0.027509\n",
      "Train Log likelihood, step 7650 in nats: -0.027252\n",
      "Train epoch average loss: -0.027266418233090648\n",
      "\n",
      "\n",
      "Epoch: 47\n",
      "Train Log likelihood, step 7700 in nats: -0.027090\n",
      "Train Log likelihood, step 7750 in nats: -0.026922\n",
      "Train Log likelihood, step 7800 in nats: -0.026636\n",
      "Train epoch average loss: -0.026510633048836947\n",
      "\n",
      "\n",
      "Epoch: 48\n",
      "Train Log likelihood, step 7850 in nats: -0.026423\n",
      "Train Log likelihood, step 7900 in nats: -0.026329\n",
      "Train Log likelihood, step 7950 in nats: -0.026066\n",
      "Train epoch average loss: -0.025900151517019156\n",
      "\n",
      "\n",
      "Epoch: 49\n",
      "Train Log likelihood, step 8000 in nats: -0.025883\n",
      "Train Log likelihood, step 8050 in nats: -0.025581\n",
      "Train Log likelihood, step 8100 in nats: -0.025428\n",
      "Train epoch average loss: -0.025169610796542036\n",
      "\n",
      "\n",
      "Epoch: 50\n",
      "Train Log likelihood, step 8150 in nats: -0.025149\n",
      "Train Log likelihood, step 8200 in nats: -0.024853\n",
      "Train Log likelihood, step 8250 in nats: -0.024653\n",
      "Train Log likelihood, step 8300 in nats: -0.024516\n",
      "Train epoch average loss: -0.024474054382442847\n",
      "\n",
      "\n",
      "Epoch: 51\n",
      "Train Log likelihood, step 8350 in nats: -0.024292\n",
      "Train Log likelihood, step 8400 in nats: -0.024025\n",
      "Train Log likelihood, step 8450 in nats: -0.023873\n",
      "Train epoch average loss: -0.023780780444080985\n",
      "\n",
      "\n",
      "Epoch: 52\n",
      "Train Log likelihood, step 8500 in nats: -0.023734\n",
      "Train Log likelihood, step 8550 in nats: -0.023437\n",
      "Train Log likelihood, step 8600 in nats: -0.023306\n",
      "Train epoch average loss: -0.023175113535606664\n",
      "\n",
      "\n",
      "Epoch: 53\n",
      "Train Log likelihood, step 8650 in nats: -0.023163\n",
      "Train Log likelihood, step 8700 in nats: -0.022997\n",
      "Train Log likelihood, step 8750 in nats: -0.022779\n",
      "Train Log likelihood, step 8800 in nats: -0.022566\n",
      "Train epoch average loss: -0.022574249751212777\n",
      "\n",
      "\n",
      "Epoch: 54\n",
      "Train Log likelihood, step 8850 in nats: -0.022288\n",
      "Train Log likelihood, step 8900 in nats: -0.022071\n",
      "Train Log likelihood, step 8950 in nats: -0.021925\n",
      "Train epoch average loss: -0.021896040062350384\n",
      "\n",
      "\n",
      "Epoch: 55\n",
      "Train Log likelihood, step 9000 in nats: -0.021697\n",
      "Train Log likelihood, step 9050 in nats: -0.021581\n",
      "Train Log likelihood, step 9100 in nats: -0.021467\n",
      "Train epoch average loss: -0.02129316413559336\n",
      "\n",
      "\n",
      "Epoch: 56\n",
      "Train Log likelihood, step 9150 in nats: -0.021218\n",
      "Train Log likelihood, step 9200 in nats: -0.021028\n",
      "Train Log likelihood, step 9250 in nats: -0.020840\n",
      "Train epoch average loss: -0.020623545569377223\n",
      "\n",
      "\n",
      "Epoch: 57\n",
      "Train Log likelihood, step 9300 in nats: -0.020543\n",
      "Train Log likelihood, step 9350 in nats: -0.020314\n",
      "Train Log likelihood, step 9400 in nats: -0.020144\n",
      "Train Log likelihood, step 9450 in nats: -0.019989\n",
      "Train epoch average loss: -0.01998723233747531\n",
      "\n",
      "\n",
      "Epoch: 58\n",
      "Train Log likelihood, step 9500 in nats: -0.019801\n",
      "Train Log likelihood, step 9550 in nats: -0.019704\n",
      "Train Log likelihood, step 9600 in nats: -0.019575\n",
      "Train epoch average loss: -0.019494208500669793\n",
      "\n",
      "\n",
      "Epoch: 59\n",
      "Train Log likelihood, step 9650 in nats: -0.019304\n",
      "Train Log likelihood, step 9700 in nats: -0.019008\n",
      "Train Log likelihood, step 9750 in nats: -0.018718\n",
      "Train epoch average loss: -0.018669551412432314\n",
      "\n",
      "\n",
      "Epoch: 60\n",
      "Train Log likelihood, step 9800 in nats: -0.018606\n",
      "Train Log likelihood, step 9850 in nats: -0.018378\n",
      "Train Log likelihood, step 9900 in nats: -0.018201\n",
      "Train epoch average loss: -0.018031647847299513\n",
      "\n",
      "\n",
      "Epoch: 61\n",
      "Train Log likelihood, step 9950 in nats: -0.018044\n",
      "Train Log likelihood, step 10000 in nats: -0.017815\n",
      "Train Log likelihood, step 10050 in nats: -0.017632\n",
      "Train Log likelihood, step 10100 in nats: -0.017507\n",
      "Train epoch average loss: -0.01747788438678149\n",
      "\n",
      "\n",
      "Epoch: 62\n",
      "Train Log likelihood, step 10150 in nats: -0.017292\n",
      "Train Log likelihood, step 10200 in nats: -0.017221\n",
      "Train Log likelihood, step 10250 in nats: -0.017054\n",
      "Train epoch average loss: -0.017010385236393727\n",
      "\n",
      "\n",
      "Epoch: 63\n",
      "Train Log likelihood, step 10300 in nats: -0.016950\n",
      "Train Log likelihood, step 10350 in nats: -0.016776\n",
      "Train Log likelihood, step 10400 in nats: -0.016628\n",
      "Train epoch average loss: -0.01651546013613314\n",
      "\n",
      "\n",
      "Epoch: 64\n",
      "Train Log likelihood, step 10450 in nats: -0.016490\n",
      "Train Log likelihood, step 10500 in nats: -0.016296\n",
      "Train Log likelihood, step 10550 in nats: -0.016127\n",
      "Train epoch average loss: -0.015959807807613784\n",
      "\n",
      "\n",
      "Epoch: 65\n",
      "Train Log likelihood, step 10600 in nats: -0.015953\n",
      "Train Log likelihood, step 10650 in nats: -0.015822\n",
      "Train Log likelihood, step 10700 in nats: -0.015616\n",
      "Train Log likelihood, step 10750 in nats: -0.015417\n",
      "Train epoch average loss: -0.015405530945355824\n",
      "\n",
      "\n",
      "Epoch: 66\n",
      "Train Log likelihood, step 10800 in nats: -0.015196\n",
      "Train Log likelihood, step 10850 in nats: -0.015047\n",
      "Train Log likelihood, step 10900 in nats: -0.014775\n",
      "Train epoch average loss: -0.014734827469578212\n",
      "\n",
      "\n",
      "Epoch: 67\n",
      "Train Log likelihood, step 10950 in nats: -0.014645\n",
      "Train Log likelihood, step 11000 in nats: -0.014438\n",
      "Train Log likelihood, step 11050 in nats: -0.014240\n",
      "Train epoch average loss: -0.014083334834674678\n",
      "\n",
      "\n",
      "Epoch: 68\n",
      "Train Log likelihood, step 11100 in nats: -0.014059\n",
      "Train Log likelihood, step 11150 in nats: -0.013938\n",
      "Train Log likelihood, step 11200 in nats: -0.013842\n",
      "Train epoch average loss: -0.013772677965731494\n",
      "\n",
      "\n",
      "Epoch: 69\n",
      "Train Log likelihood, step 11250 in nats: -0.013787\n",
      "Train Log likelihood, step 11300 in nats: -0.013641\n",
      "Train Log likelihood, step 11350 in nats: -0.013483\n",
      "Train Log likelihood, step 11400 in nats: -0.013290\n",
      "Train epoch average loss: -0.013298614507233126\n",
      "\n",
      "\n",
      "Epoch: 70\n",
      "Train Log likelihood, step 11450 in nats: -0.013201\n",
      "Train Log likelihood, step 11500 in nats: -0.012977\n",
      "Train Log likelihood, step 11550 in nats: -0.012901\n",
      "Train epoch average loss: -0.012864534534756571\n",
      "\n",
      "\n",
      "Epoch: 71\n",
      "Train Log likelihood, step 11600 in nats: -0.012819\n",
      "Train Log likelihood, step 11650 in nats: -0.012625\n",
      "Train Log likelihood, step 11700 in nats: -0.012445\n",
      "Train epoch average loss: -0.012315825800623195\n",
      "\n",
      "\n",
      "Epoch: 72\n",
      "Train Log likelihood, step 11750 in nats: -0.012277\n",
      "Train Log likelihood, step 11800 in nats: -0.012145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 11850 in nats: -0.011979\n",
      "Train epoch average loss: -0.011775642077722748\n",
      "\n",
      "\n",
      "Epoch: 73\n",
      "Train Log likelihood, step 11900 in nats: -0.011774\n",
      "Train Log likelihood, step 11950 in nats: -0.011604\n",
      "Train Log likelihood, step 12000 in nats: -0.011433\n",
      "Train Log likelihood, step 12050 in nats: -0.011337\n",
      "Train epoch average loss: -0.011293036698564284\n",
      "\n",
      "\n",
      "Epoch: 74\n",
      "Train Log likelihood, step 12100 in nats: -0.011151\n",
      "Train Log likelihood, step 12150 in nats: -0.011114\n",
      "Train Log likelihood, step 12200 in nats: -0.010903\n",
      "Train epoch average loss: -0.010841592280482485\n",
      "\n",
      "\n",
      "Epoch: 75\n",
      "Train Log likelihood, step 12250 in nats: -0.010782\n",
      "Train Log likelihood, step 12300 in nats: -0.010636\n",
      "Train Log likelihood, step 12350 in nats: -0.010459\n",
      "Train epoch average loss: -0.010355162697731119\n",
      "\n",
      "\n",
      "Epoch: 76\n",
      "Train Log likelihood, step 12400 in nats: -0.010323\n",
      "Train Log likelihood, step 12450 in nats: -0.010167\n",
      "Train Log likelihood, step 12500 in nats: -0.010011\n",
      "Train Log likelihood, step 12550 in nats: -0.009899\n",
      "Train epoch average loss: -0.009899454511897722\n",
      "\n",
      "\n",
      "Epoch: 77\n",
      "Train Log likelihood, step 12600 in nats: -0.009747\n",
      "Train Log likelihood, step 12650 in nats: -0.009568\n",
      "Train Log likelihood, step 12700 in nats: -0.009433\n",
      "Train epoch average loss: -0.009360975701112415\n",
      "\n",
      "\n",
      "Epoch: 78\n",
      "Train Log likelihood, step 12750 in nats: -0.009256\n",
      "Train Log likelihood, step 12800 in nats: -0.009065\n",
      "Train Log likelihood, step 12850 in nats: -0.008917\n",
      "Train epoch average loss: -0.00884309354813261\n",
      "\n",
      "\n",
      "Epoch: 79\n",
      "Train Log likelihood, step 12900 in nats: -0.008772\n",
      "Train Log likelihood, step 12950 in nats: -0.008711\n",
      "Train Log likelihood, step 13000 in nats: -0.008601\n",
      "Train epoch average loss: -0.008445555809644996\n",
      "\n",
      "\n",
      "Epoch: 80\n",
      "Train Log likelihood, step 13050 in nats: -0.008389\n",
      "Train Log likelihood, step 13100 in nats: -0.008284\n",
      "Train Log likelihood, step 13150 in nats: -0.008193\n",
      "Train Log likelihood, step 13200 in nats: -0.007976\n",
      "Train epoch average loss: -0.007974760969051833\n",
      "\n",
      "\n",
      "Epoch: 81\n",
      "Train Log likelihood, step 13250 in nats: -0.007866\n",
      "Train Log likelihood, step 13300 in nats: -0.007702\n",
      "Train Log likelihood, step 13350 in nats: -0.007542\n",
      "Train epoch average loss: -0.007491342794997776\n",
      "\n",
      "\n",
      "Epoch: 82\n",
      "Train Log likelihood, step 13400 in nats: -0.007427\n",
      "Train Log likelihood, step 13450 in nats: -0.007321\n",
      "Train Log likelihood, step 13500 in nats: -0.007097\n",
      "Train epoch average loss: -0.006989077972062654\n",
      "\n",
      "\n",
      "Epoch: 83\n",
      "Train Log likelihood, step 13550 in nats: -0.006917\n",
      "Train Log likelihood, step 13600 in nats: -0.006758\n",
      "Train Log likelihood, step 13650 in nats: -0.006695\n",
      "Train epoch average loss: -0.006617948833281595\n",
      "\n",
      "\n",
      "Epoch: 84\n",
      "Train Log likelihood, step 13700 in nats: -0.006619\n",
      "Train Log likelihood, step 13750 in nats: -0.006474\n",
      "Train Log likelihood, step 13800 in nats: -0.006319\n",
      "Train Log likelihood, step 13850 in nats: -0.006169\n",
      "Train epoch average loss: -0.006172263217891533\n",
      "\n",
      "\n",
      "Epoch: 85\n",
      "Train Log likelihood, step 13900 in nats: -0.006018\n",
      "Train Log likelihood, step 13950 in nats: -0.005971\n",
      "Train Log likelihood, step 14000 in nats: -0.005816\n",
      "Train epoch average loss: -0.005754482704706728\n",
      "\n",
      "\n",
      "Epoch: 86\n",
      "Train Log likelihood, step 14050 in nats: -0.005616\n",
      "Train Log likelihood, step 14100 in nats: -0.005522\n",
      "Train Log likelihood, step 14150 in nats: -0.005341\n",
      "Train epoch average loss: -0.005267993652839987\n",
      "\n",
      "\n",
      "Epoch: 87\n",
      "Train Log likelihood, step 14200 in nats: -0.005252\n",
      "Train Log likelihood, step 14250 in nats: -0.005149\n",
      "Train Log likelihood, step 14300 in nats: -0.005017\n",
      "Train epoch average loss: -0.004874166424574673\n",
      "\n",
      "\n",
      "Epoch: 88\n",
      "Train Log likelihood, step 14350 in nats: -0.004847\n",
      "Train Log likelihood, step 14400 in nats: -0.004734\n",
      "Train Log likelihood, step 14450 in nats: -0.004611\n",
      "Train Log likelihood, step 14500 in nats: -0.004542\n",
      "Train epoch average loss: -0.0045249741662936336\n",
      "\n",
      "\n",
      "Epoch: 89\n",
      "Train Log likelihood, step 14550 in nats: -0.004401\n",
      "Train Log likelihood, step 14600 in nats: -0.004252\n",
      "Train Log likelihood, step 14650 in nats: -0.004129\n",
      "Train epoch average loss: -0.0040667430907152255\n",
      "\n",
      "\n",
      "Epoch: 90\n",
      "Train Log likelihood, step 14700 in nats: -0.004005\n",
      "Train Log likelihood, step 14750 in nats: -0.003951\n",
      "Train Log likelihood, step 14800 in nats: -0.003824\n",
      "Train epoch average loss: -0.00372218967187044\n",
      "\n",
      "\n",
      "Epoch: 91\n",
      "Train Log likelihood, step 14850 in nats: -0.003680\n",
      "Train Log likelihood, step 14900 in nats: -0.003565\n",
      "Train Log likelihood, step 14950 in nats: -0.003393\n",
      "Train epoch average loss: -0.0032301793914051896\n",
      "\n",
      "\n",
      "Epoch: 92\n",
      "Train Log likelihood, step 15000 in nats: -0.003214\n",
      "Train Log likelihood, step 15050 in nats: -0.003116\n",
      "Train Log likelihood, step 15100 in nats: -0.002923\n",
      "Train Log likelihood, step 15150 in nats: -0.002742\n",
      "Train epoch average loss: -0.002716854820565566\n",
      "\n",
      "\n",
      "Epoch: 93\n",
      "Train Log likelihood, step 15200 in nats: -0.002582\n",
      "Train Log likelihood, step 15250 in nats: -0.002422\n",
      "Train Log likelihood, step 15300 in nats: -0.002317\n",
      "Train epoch average loss: -0.0023096673084506006\n",
      "\n",
      "\n",
      "Epoch: 94\n",
      "Train Log likelihood, step 15350 in nats: -0.002318\n",
      "Train Log likelihood, step 15400 in nats: -0.002211\n",
      "Train Log likelihood, step 15450 in nats: -0.002108\n",
      "Train epoch average loss: -0.001957763666676069\n",
      "\n",
      "\n",
      "Epoch: 95\n",
      "Train Log likelihood, step 15500 in nats: -0.001889\n",
      "Train Log likelihood, step 15550 in nats: -0.001772\n",
      "Train Log likelihood, step 15600 in nats: -0.001600\n",
      "Train epoch average loss: -0.001408746584162595\n",
      "\n",
      "\n",
      "Epoch: 96\n",
      "Train Log likelihood, step 15650 in nats: -0.001417\n",
      "Train Log likelihood, step 15700 in nats: -0.001323\n",
      "Train Log likelihood, step 15750 in nats: -0.001172\n",
      "Train Log likelihood, step 15800 in nats: -0.000989\n",
      "Train epoch average loss: -0.0009847824014886546\n",
      "\n",
      "\n",
      "Epoch: 97\n",
      "Train Log likelihood, step 15850 in nats: -0.000884\n",
      "Train Log likelihood, step 15900 in nats: -0.000803\n",
      "Train Log likelihood, step 15950 in nats: -0.000685\n",
      "Train epoch average loss: -0.0006335459123916398\n",
      "\n",
      "\n",
      "Epoch: 98\n",
      "Train Log likelihood, step 16000 in nats: -0.000552\n",
      "Train Log likelihood, step 16050 in nats: -0.000431\n",
      "Train Log likelihood, step 16100 in nats: -0.000331\n",
      "Train epoch average loss: -0.0002594129827433911\n",
      "\n",
      "\n",
      "Epoch: 99\n",
      "Train Log likelihood, step 16150 in nats: -0.000240\n",
      "Train Log likelihood, step 16200 in nats: -0.000103\n",
      "Train Log likelihood, step 16250 in nats: 0.000036\n",
      "Train epoch average loss: 0.0001483377889073305\n",
      "\n",
      "\n",
      "Epoch: 100\n",
      "Train Log likelihood, step 16300 in nats: 0.000157\n",
      "Train Log likelihood, step 16350 in nats: 0.000239\n",
      "Train Log likelihood, step 16400 in nats: 0.000428\n",
      "Train Log likelihood, step 16450 in nats: 0.000620\n",
      "Train epoch average loss: 0.000658202379571106\n",
      "\n",
      "\n",
      "Epoch: 101\n",
      "Train Log likelihood, step 16500 in nats: 0.000734\n",
      "Train Log likelihood, step 16550 in nats: 0.000878\n",
      "Train Log likelihood, step 16600 in nats: 0.001052\n",
      "Train epoch average loss: 0.0010745554225678221\n",
      "\n",
      "\n",
      "Epoch: 102\n",
      "Train Log likelihood, step 16650 in nats: 0.001091\n",
      "Train Log likelihood, step 16700 in nats: 0.001243\n",
      "Train Log likelihood, step 16750 in nats: 0.001325\n",
      "Train epoch average loss: 0.0013633328447859665\n",
      "\n",
      "\n",
      "Epoch: 103\n",
      "Train Log likelihood, step 16800 in nats: 0.001392\n",
      "Train Log likelihood, step 16850 in nats: 0.001484\n",
      "Train Log likelihood, step 16900 in nats: 0.001582\n",
      "Train Log likelihood, step 16950 in nats: 0.001703\n",
      "Train epoch average loss: 0.0017090125675873799\n",
      "\n",
      "\n",
      "Epoch: 104\n",
      "Train Log likelihood, step 17000 in nats: 0.001844\n",
      "Train Log likelihood, step 17050 in nats: 0.001980\n",
      "Train Log likelihood, step 17100 in nats: 0.002135\n",
      "Train epoch average loss: 0.0021479187116708563\n",
      "\n",
      "\n",
      "Epoch: 105\n",
      "Train Log likelihood, step 17150 in nats: 0.002256\n",
      "Train Log likelihood, step 17200 in nats: 0.002362\n",
      "Train Log likelihood, step 17250 in nats: 0.002432\n",
      "Train epoch average loss: 0.0024693537692931722\n",
      "\n",
      "\n",
      "Epoch: 106\n",
      "Train Log likelihood, step 17300 in nats: 0.002511\n",
      "Train Log likelihood, step 17350 in nats: 0.002585\n",
      "Train Log likelihood, step 17400 in nats: 0.002666\n",
      "Train epoch average loss: 0.002684439742264593\n",
      "\n",
      "\n",
      "Epoch: 107\n",
      "Train Log likelihood, step 17450 in nats: 0.002706\n",
      "Train Log likelihood, step 17500 in nats: 0.002807\n",
      "Train Log likelihood, step 17550 in nats: 0.002885\n",
      "Train Log likelihood, step 17600 in nats: 0.002983\n",
      "Train epoch average loss: 0.0029835584232411937\n",
      "\n",
      "\n",
      "Epoch: 108\n",
      "Train Log likelihood, step 17650 in nats: 0.003068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 17700 in nats: 0.003162\n",
      "Train Log likelihood, step 17750 in nats: 0.003277\n",
      "Train epoch average loss: 0.003345023765283334\n",
      "\n",
      "\n",
      "Epoch: 109\n",
      "Train Log likelihood, step 17800 in nats: 0.003411\n",
      "Train Log likelihood, step 17850 in nats: 0.003498\n",
      "Train Log likelihood, step 17900 in nats: 0.003595\n",
      "Train epoch average loss: 0.0036723539462616356\n",
      "\n",
      "\n",
      "Epoch: 110\n",
      "Train Log likelihood, step 17950 in nats: 0.003691\n",
      "Train Log likelihood, step 18000 in nats: 0.003765\n",
      "Train Log likelihood, step 18050 in nats: 0.003858\n",
      "Train epoch average loss: 0.003955204404202327\n",
      "\n",
      "\n",
      "Epoch: 111\n",
      "Train Log likelihood, step 18100 in nats: 0.003986\n",
      "Train Log likelihood, step 18150 in nats: 0.004124\n",
      "Train Log likelihood, step 18200 in nats: 0.004206\n",
      "Train Log likelihood, step 18250 in nats: 0.004358\n",
      "Train epoch average loss: 0.004366010484403661\n",
      "\n",
      "\n",
      "Epoch: 112\n",
      "Train Log likelihood, step 18300 in nats: 0.004407\n",
      "Train Log likelihood, step 18350 in nats: 0.004489\n",
      "Train Log likelihood, step 18400 in nats: 0.004583\n",
      "Train epoch average loss: 0.004634800332117792\n",
      "\n",
      "\n",
      "Epoch: 113\n",
      "Train Log likelihood, step 18450 in nats: 0.004663\n",
      "Train Log likelihood, step 18500 in nats: 0.004759\n",
      "Train Log likelihood, step 18550 in nats: 0.004868\n",
      "Train epoch average loss: 0.004929299516135822\n",
      "\n",
      "\n",
      "Epoch: 114\n",
      "Train Log likelihood, step 18600 in nats: 0.004957\n",
      "Train Log likelihood, step 18650 in nats: 0.005092\n",
      "Train Log likelihood, step 18700 in nats: 0.005183\n",
      "Train epoch average loss: 0.005311786883150795\n",
      "\n",
      "\n",
      "Epoch: 115\n",
      "Train Log likelihood, step 18750 in nats: 0.005331\n",
      "Train Log likelihood, step 18800 in nats: 0.005431\n",
      "Train Log likelihood, step 18850 in nats: 0.005548\n",
      "Train Log likelihood, step 18900 in nats: 0.005638\n",
      "Train epoch average loss: 0.005643889555254024\n",
      "\n",
      "\n",
      "Epoch: 116\n",
      "Train Log likelihood, step 18950 in nats: 0.005802\n",
      "Train Log likelihood, step 19000 in nats: 0.005945\n",
      "Train Log likelihood, step 19050 in nats: 0.006036\n",
      "Train epoch average loss: 0.006060765294939822\n",
      "\n",
      "\n",
      "Epoch: 117\n",
      "Train Log likelihood, step 19100 in nats: 0.006103\n",
      "Train Log likelihood, step 19150 in nats: 0.006231\n",
      "Train Log likelihood, step 19200 in nats: 0.006332\n",
      "Train epoch average loss: 0.006400463325815245\n",
      "\n",
      "\n",
      "Epoch: 118\n",
      "Train Log likelihood, step 19250 in nats: 0.006474\n",
      "Train Log likelihood, step 19300 in nats: 0.006546\n",
      "Train Log likelihood, step 19350 in nats: 0.006629\n",
      "Train epoch average loss: 0.0067500397036295845\n",
      "\n",
      "\n",
      "Epoch: 119\n",
      "Train Log likelihood, step 19400 in nats: 0.006750\n",
      "Train Log likelihood, step 19450 in nats: 0.006901\n",
      "Train Log likelihood, step 19500 in nats: 0.007000\n",
      "Train Log likelihood, step 19550 in nats: 0.007102\n",
      "Train epoch average loss: 0.007084183894287731\n",
      "\n",
      "\n",
      "Epoch: 120\n",
      "Train Log likelihood, step 19600 in nats: 0.007143\n",
      "Train Log likelihood, step 19650 in nats: 0.007187\n",
      "Train Log likelihood, step 19700 in nats: 0.007248\n",
      "Train epoch average loss: 0.007243289233036501\n",
      "\n",
      "\n",
      "Epoch: 121\n",
      "Train Log likelihood, step 19750 in nats: 0.007287\n",
      "Train Log likelihood, step 19800 in nats: 0.007454\n",
      "Train Log likelihood, step 19850 in nats: 0.007556\n",
      "Train epoch average loss: 0.007579002833526467\n",
      "\n",
      "\n",
      "Epoch: 122\n",
      "Train Log likelihood, step 19900 in nats: 0.007578\n",
      "Train Log likelihood, step 19950 in nats: 0.007650\n",
      "Train Log likelihood, step 20000 in nats: 0.007696\n",
      "Train epoch average loss: 0.007766068230850294\n",
      "\n",
      "\n",
      "Epoch: 123\n",
      "Train Log likelihood, step 20050 in nats: 0.007770\n",
      "Train Log likelihood, step 20100 in nats: 0.007838\n",
      "Train Log likelihood, step 20150 in nats: 0.007937\n",
      "Train Log likelihood, step 20200 in nats: 0.008034\n",
      "Train epoch average loss: 0.008068149409683452\n",
      "\n",
      "\n",
      "Epoch: 124\n",
      "Train Log likelihood, step 20250 in nats: 0.008156\n",
      "Train Log likelihood, step 20300 in nats: 0.008189\n",
      "Train Log likelihood, step 20350 in nats: 0.008268\n",
      "Train epoch average loss: 0.008293003330590245\n",
      "\n",
      "\n",
      "Epoch: 125\n",
      "Train Log likelihood, step 20400 in nats: 0.008319\n",
      "Train Log likelihood, step 20450 in nats: 0.008392\n",
      "Train Log likelihood, step 20500 in nats: 0.008528\n",
      "Train epoch average loss: 0.0086642808719723\n",
      "\n",
      "\n",
      "Epoch: 126\n",
      "Train Log likelihood, step 20550 in nats: 0.008675\n",
      "Train Log likelihood, step 20600 in nats: 0.008776\n",
      "Train Log likelihood, step 20650 in nats: 0.008840\n",
      "Train Log likelihood, step 20700 in nats: 0.009007\n",
      "Train epoch average loss: 0.009006815149944248\n",
      "\n",
      "\n",
      "Epoch: 127\n",
      "Train Log likelihood, step 20750 in nats: 0.009144\n",
      "Train Log likelihood, step 20800 in nats: 0.009292\n",
      "Train Log likelihood, step 20850 in nats: 0.009378\n",
      "Train epoch average loss: 0.009398816234458048\n",
      "\n",
      "\n",
      "Epoch: 128\n",
      "Train Log likelihood, step 20900 in nats: 0.009475\n",
      "Train Log likelihood, step 20950 in nats: 0.009562\n",
      "Train Log likelihood, step 21000 in nats: 0.009661\n",
      "Train epoch average loss: 0.009688777806239788\n",
      "\n",
      "\n",
      "Epoch: 129\n",
      "Train Log likelihood, step 21050 in nats: 0.009722\n",
      "Train Log likelihood, step 21100 in nats: 0.009830\n",
      "Train Log likelihood, step 21150 in nats: 0.009906\n",
      "Train epoch average loss: 0.010023358554204923\n",
      "\n",
      "\n",
      "Epoch: 130\n",
      "Train Log likelihood, step 21200 in nats: 0.010064\n",
      "Train Log likelihood, step 21250 in nats: 0.010178\n",
      "Train Log likelihood, step 21300 in nats: 0.010251\n",
      "Train Log likelihood, step 21350 in nats: 0.010405\n",
      "Train epoch average loss: 0.01040342421860737\n",
      "\n",
      "\n",
      "Epoch: 131\n",
      "Train Log likelihood, step 21400 in nats: 0.010504\n",
      "Train Log likelihood, step 21450 in nats: 0.010545\n",
      "Train Log likelihood, step 21500 in nats: 0.010679\n",
      "Train epoch average loss: 0.010713273704843294\n",
      "\n",
      "\n",
      "Epoch: 132\n",
      "Train Log likelihood, step 21550 in nats: 0.010760\n",
      "Train Log likelihood, step 21600 in nats: 0.010893\n",
      "Train Log likelihood, step 21650 in nats: 0.010982\n",
      "Train epoch average loss: 0.011022618917676037\n",
      "\n",
      "\n",
      "Epoch: 133\n",
      "Train Log likelihood, step 21700 in nats: 0.011096\n",
      "Train Log likelihood, step 21750 in nats: 0.011239\n",
      "Train Log likelihood, step 21800 in nats: 0.011308\n",
      "Train epoch average loss: 0.011387862809190378\n",
      "\n",
      "\n",
      "Epoch: 134\n",
      "Train Log likelihood, step 21850 in nats: 0.011415\n",
      "Train Log likelihood, step 21900 in nats: 0.011487\n",
      "Train Log likelihood, step 21950 in nats: 0.011576\n",
      "Train Log likelihood, step 22000 in nats: 0.011697\n",
      "Train epoch average loss: 0.011717506155279457\n",
      "\n",
      "\n",
      "Epoch: 135\n",
      "Train Log likelihood, step 22050 in nats: 0.011771\n",
      "Train Log likelihood, step 22100 in nats: 0.011913\n",
      "Train Log likelihood, step 22150 in nats: 0.011998\n",
      "Train epoch average loss: 0.012007581594555306\n",
      "\n",
      "\n",
      "Epoch: 136\n",
      "Train Log likelihood, step 22200 in nats: 0.012039\n",
      "Train Log likelihood, step 22250 in nats: 0.012161\n",
      "Train Log likelihood, step 22300 in nats: 0.012241\n",
      "Train epoch average loss: 0.012232361473853298\n",
      "\n",
      "\n",
      "Epoch: 137\n",
      "Train Log likelihood, step 22350 in nats: 0.012233\n",
      "Train Log likelihood, step 22400 in nats: 0.012263\n",
      "Train Log likelihood, step 22450 in nats: 0.012361\n",
      "Train epoch average loss: 0.012467636818081693\n",
      "\n",
      "\n",
      "Epoch: 138\n",
      "Train Log likelihood, step 22500 in nats: 0.012470\n",
      "Train Log likelihood, step 22550 in nats: 0.012617\n",
      "Train Log likelihood, step 22600 in nats: 0.012713\n",
      "Train Log likelihood, step 22650 in nats: 0.012781\n",
      "Train epoch average loss: 0.012789600648865945\n",
      "\n",
      "\n",
      "Epoch: 139\n",
      "Train Log likelihood, step 22700 in nats: 0.012895\n",
      "Train Log likelihood, step 22750 in nats: 0.012989\n",
      "Train Log likelihood, step 22800 in nats: 0.013042\n",
      "Train epoch average loss: 0.0130519714240683\n",
      "\n",
      "\n",
      "Epoch: 140\n",
      "Train Log likelihood, step 22850 in nats: 0.013131\n",
      "Train Log likelihood, step 22900 in nats: 0.013202\n",
      "Train Log likelihood, step 22950 in nats: 0.013303\n",
      "Train epoch average loss: 0.01337697669719719\n",
      "\n",
      "\n",
      "Epoch: 141\n",
      "Train Log likelihood, step 23000 in nats: 0.013418\n",
      "Train Log likelihood, step 23050 in nats: 0.013551\n",
      "Train Log likelihood, step 23100 in nats: 0.013674\n",
      "Train epoch average loss: 0.013754522083439653\n",
      "\n",
      "\n",
      "Epoch: 142\n",
      "Train Log likelihood, step 23150 in nats: 0.013750\n",
      "Train Log likelihood, step 23200 in nats: 0.013860\n",
      "Train Log likelihood, step 23250 in nats: 0.013969\n",
      "Train Log likelihood, step 23300 in nats: 0.014062\n",
      "Train epoch average loss: 0.014071857340579976\n",
      "\n",
      "\n",
      "Epoch: 143\n",
      "Train Log likelihood, step 23350 in nats: 0.014131\n",
      "Train Log likelihood, step 23400 in nats: 0.014191\n",
      "Train Log likelihood, step 23450 in nats: 0.014331\n",
      "Train epoch average loss: 0.014376480153081937\n",
      "\n",
      "\n",
      "Epoch: 144\n",
      "Train Log likelihood, step 23500 in nats: 0.014427\n",
      "Train Log likelihood, step 23550 in nats: 0.014469\n",
      "Train Log likelihood, step 23600 in nats: 0.014507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch average loss: 0.01456858817135405\n",
      "\n",
      "\n",
      "Epoch: 145\n",
      "Train Log likelihood, step 23650 in nats: 0.014575\n",
      "Train Log likelihood, step 23700 in nats: 0.014632\n",
      "Train Log likelihood, step 23750 in nats: 0.014673\n",
      "Train epoch average loss: 0.014772140180386077\n",
      "\n",
      "\n",
      "Epoch: 146\n",
      "Train Log likelihood, step 23800 in nats: 0.014777\n",
      "Train Log likelihood, step 23850 in nats: 0.014877\n",
      "Train Log likelihood, step 23900 in nats: 0.014947\n",
      "Train Log likelihood, step 23950 in nats: 0.015048\n",
      "Train epoch average loss: 0.015068170346664503\n",
      "\n",
      "\n",
      "Epoch: 147\n",
      "Train Log likelihood, step 24000 in nats: 0.015177\n",
      "Train Log likelihood, step 24050 in nats: 0.015275\n",
      "Train Log likelihood, step 24100 in nats: 0.015390\n",
      "Train epoch average loss: 0.015398665522868697\n",
      "\n",
      "\n",
      "Epoch: 148\n",
      "Train Log likelihood, step 24150 in nats: 0.015435\n",
      "Train Log likelihood, step 24200 in nats: 0.015502\n",
      "Train Log likelihood, step 24250 in nats: 0.015599\n",
      "Train epoch average loss: 0.01564628575290514\n",
      "\n",
      "\n",
      "Epoch: 149\n",
      "Train Log likelihood, step 24300 in nats: 0.015678\n",
      "Train Log likelihood, step 24350 in nats: 0.015734\n",
      "Train Log likelihood, step 24400 in nats: 0.015815\n",
      "Train epoch average loss: 0.015886829893764515\n",
      "\n",
      "\n",
      "Epoch: 150\n",
      "Train Log likelihood, step 24450 in nats: 0.015888\n",
      "Train Log likelihood, step 24500 in nats: 0.015956\n",
      "Train Log likelihood, step 24550 in nats: 0.016046\n",
      "Train Log likelihood, step 24600 in nats: 0.016111\n",
      "Train epoch average loss: 0.01612302872247148\n",
      "\n",
      "\n",
      "Epoch: 151\n",
      "Train Log likelihood, step 24650 in nats: 0.016149\n",
      "Train Log likelihood, step 24700 in nats: 0.016252\n",
      "Train Log likelihood, step 24750 in nats: 0.016374\n",
      "Train epoch average loss: 0.01639186289045465\n",
      "\n",
      "\n",
      "Epoch: 152\n",
      "Train Log likelihood, step 24800 in nats: 0.016430\n",
      "Train Log likelihood, step 24850 in nats: 0.016518\n",
      "Train Log likelihood, step 24900 in nats: 0.016584\n",
      "Train epoch average loss: 0.016622388533968736\n",
      "\n",
      "\n",
      "Epoch: 153\n",
      "Train Log likelihood, step 24950 in nats: 0.016653\n",
      "Train Log likelihood, step 25000 in nats: 0.016723\n",
      "Train Log likelihood, step 25050 in nats: 0.016822\n",
      "Train Log likelihood, step 25100 in nats: 0.016936\n",
      "Train epoch average loss: 0.016936317327420417\n",
      "\n",
      "\n",
      "Epoch: 154\n",
      "Train Log likelihood, step 25150 in nats: 0.016967\n",
      "Train Log likelihood, step 25200 in nats: 0.017022\n",
      "Train Log likelihood, step 25250 in nats: 0.017083\n",
      "Train epoch average loss: 0.01709281568504853\n",
      "\n",
      "\n",
      "Epoch: 155\n",
      "Train Log likelihood, step 25300 in nats: 0.017112\n",
      "Train Log likelihood, step 25350 in nats: 0.017168\n",
      "Train Log likelihood, step 25400 in nats: 0.017227\n",
      "Train epoch average loss: 0.017257586946454073\n",
      "\n",
      "\n",
      "Epoch: 156\n",
      "Train Log likelihood, step 25450 in nats: 0.017299\n",
      "Train Log likelihood, step 25500 in nats: 0.017369\n",
      "Train Log likelihood, step 25550 in nats: 0.017400\n",
      "Train epoch average loss: 0.017415391768912176\n",
      "\n",
      "\n",
      "Epoch: 157\n",
      "Train Log likelihood, step 25600 in nats: 0.017419\n",
      "Train Log likelihood, step 25650 in nats: 0.017512\n",
      "Train Log likelihood, step 25700 in nats: 0.017586\n",
      "Train Log likelihood, step 25750 in nats: 0.017618\n",
      "Train epoch average loss: 0.017626027821000128\n",
      "\n",
      "\n",
      "Epoch: 158\n",
      "Train Log likelihood, step 25800 in nats: 0.017681\n",
      "Train Log likelihood, step 25850 in nats: 0.017787\n",
      "Train Log likelihood, step 25900 in nats: 0.017842\n",
      "Train epoch average loss: 0.017855856040912284\n",
      "\n",
      "\n",
      "Epoch: 159\n",
      "Train Log likelihood, step 25950 in nats: 0.017907\n",
      "Train Log likelihood, step 26000 in nats: 0.018021\n",
      "Train Log likelihood, step 26050 in nats: 0.018090\n",
      "Train epoch average loss: 0.01814616026109112\n",
      "\n",
      "\n",
      "Epoch: 160\n",
      "Train Log likelihood, step 26100 in nats: 0.018165\n",
      "Train Log likelihood, step 26150 in nats: 0.018286\n",
      "Train Log likelihood, step 26200 in nats: 0.018335\n",
      "Train epoch average loss: 0.018381346984383345\n",
      "\n",
      "\n",
      "Epoch: 161\n",
      "Train Log likelihood, step 26250 in nats: 0.018388\n",
      "Train Log likelihood, step 26300 in nats: 0.018433\n",
      "Train Log likelihood, step 26350 in nats: 0.018518\n",
      "Train Log likelihood, step 26400 in nats: 0.018597\n",
      "Train epoch average loss: 0.018602178933566565\n",
      "\n",
      "\n",
      "Epoch: 162\n",
      "Train Log likelihood, step 26450 in nats: 0.018700\n",
      "Train Log likelihood, step 26500 in nats: 0.018742\n",
      "Train Log likelihood, step 26550 in nats: 0.018819\n",
      "Train epoch average loss: 0.018877816143170533\n",
      "\n",
      "\n",
      "Epoch: 163\n",
      "Train Log likelihood, step 26600 in nats: 0.018955\n",
      "Train Log likelihood, step 26650 in nats: 0.019053\n",
      "Train Log likelihood, step 26700 in nats: 0.019130\n",
      "Train epoch average loss: 0.019170641475183263\n",
      "\n",
      "\n",
      "Epoch: 164\n",
      "Train Log likelihood, step 26750 in nats: 0.019177\n",
      "Train Log likelihood, step 26800 in nats: 0.019267\n",
      "Train Log likelihood, step 26850 in nats: 0.019336\n",
      "Train epoch average loss: 0.019384662695825387\n",
      "\n",
      "\n",
      "Epoch: 165\n",
      "Train Log likelihood, step 26900 in nats: 0.019397\n",
      "Train Log likelihood, step 26950 in nats: 0.019467\n",
      "Train Log likelihood, step 27000 in nats: 0.019542\n",
      "Train Log likelihood, step 27050 in nats: 0.019638\n",
      "Train epoch average loss: 0.019659955282680566\n",
      "\n",
      "\n",
      "Epoch: 166\n",
      "Train Log likelihood, step 27100 in nats: 0.019721\n",
      "Train Log likelihood, step 27150 in nats: 0.019802\n",
      "Train Log likelihood, step 27200 in nats: 0.019837\n",
      "Train epoch average loss: 0.019856376882065537\n",
      "\n",
      "\n",
      "Epoch: 167\n",
      "Train Log likelihood, step 27250 in nats: 0.019890\n",
      "Train Log likelihood, step 27300 in nats: 0.019952\n",
      "Train Log likelihood, step 27350 in nats: 0.020005\n",
      "Train epoch average loss: 0.020028390942829637\n",
      "\n",
      "\n",
      "Epoch: 168\n",
      "Train Log likelihood, step 27400 in nats: 0.020093\n",
      "Train Log likelihood, step 27450 in nats: 0.020177\n",
      "Train Log likelihood, step 27500 in nats: 0.020273\n",
      "Train epoch average loss: 0.020312837569019398\n",
      "\n",
      "\n",
      "Epoch: 169\n",
      "Train Log likelihood, step 27550 in nats: 0.020310\n",
      "Train Log likelihood, step 27600 in nats: 0.020361\n",
      "Train Log likelihood, step 27650 in nats: 0.020430\n",
      "Train Log likelihood, step 27700 in nats: 0.020506\n",
      "Train epoch average loss: 0.02052593572172648\n",
      "\n",
      "\n",
      "Epoch: 170\n",
      "Train Log likelihood, step 27750 in nats: 0.020601\n",
      "Train Log likelihood, step 27800 in nats: 0.020593\n",
      "Train Log likelihood, step 27850 in nats: 0.020642\n",
      "Train epoch average loss: 0.0206531125346286\n",
      "\n",
      "\n",
      "Epoch: 171\n",
      "Train Log likelihood, step 27900 in nats: 0.020679\n",
      "Train Log likelihood, step 27950 in nats: 0.020683\n",
      "Train Log likelihood, step 28000 in nats: 0.020781\n",
      "Train epoch average loss: 0.020792577460895238\n",
      "\n",
      "\n",
      "Epoch: 172\n",
      "Train Log likelihood, step 28050 in nats: 0.020815\n",
      "Train Log likelihood, step 28100 in nats: 0.020876\n",
      "Train Log likelihood, step 28150 in nats: 0.020897\n",
      "Train epoch average loss: 0.020957234438661494\n",
      "\n",
      "\n",
      "Epoch: 173\n",
      "Train Log likelihood, step 28200 in nats: 0.020960\n",
      "Train Log likelihood, step 28250 in nats: 0.021051\n",
      "Train Log likelihood, step 28300 in nats: 0.021151\n",
      "Train Log likelihood, step 28350 in nats: 0.021225\n",
      "Train epoch average loss: 0.02124311665218276\n",
      "\n",
      "\n",
      "Epoch: 174\n",
      "Train Log likelihood, step 28400 in nats: 0.021327\n",
      "Train Log likelihood, step 28450 in nats: 0.021399\n",
      "Train Log likelihood, step 28500 in nats: 0.021478\n",
      "Train epoch average loss: 0.021495023758385676\n",
      "\n",
      "\n",
      "Epoch: 175\n",
      "Train Log likelihood, step 28550 in nats: 0.021540\n",
      "Train Log likelihood, step 28600 in nats: 0.021608\n",
      "Train Log likelihood, step 28650 in nats: 0.021630\n",
      "Train epoch average loss: 0.02164719782656619\n",
      "\n",
      "\n",
      "Epoch: 176\n",
      "Train Log likelihood, step 28700 in nats: 0.021658\n",
      "Train Log likelihood, step 28750 in nats: 0.021688\n",
      "Train Log likelihood, step 28800 in nats: 0.021725\n",
      "Train Log likelihood, step 28850 in nats: 0.021766\n",
      "Train epoch average loss: 0.02176622759158987\n",
      "\n",
      "\n",
      "Epoch: 177\n",
      "Train Log likelihood, step 28900 in nats: 0.021810\n",
      "Train Log likelihood, step 28950 in nats: 0.021881\n",
      "Train Log likelihood, step 29000 in nats: 0.021949\n",
      "Train epoch average loss: 0.02199016766213295\n",
      "\n",
      "\n",
      "Epoch: 178\n",
      "Train Log likelihood, step 29050 in nats: 0.022065\n",
      "Train Log likelihood, step 29100 in nats: 0.022157\n",
      "Train Log likelihood, step 29150 in nats: 0.022247\n",
      "Train epoch average loss: 0.022299002031050463\n",
      "\n",
      "\n",
      "Epoch: 179\n",
      "Train Log likelihood, step 29200 in nats: 0.022331\n",
      "Train Log likelihood, step 29250 in nats: 0.022358\n",
      "Train Log likelihood, step 29300 in nats: 0.022436\n",
      "Train epoch average loss: 0.022522363252424207\n",
      "\n",
      "\n",
      "Epoch: 180\n",
      "Train Log likelihood, step 29350 in nats: 0.022554\n",
      "Train Log likelihood, step 29400 in nats: 0.022644\n",
      "Train Log likelihood, step 29450 in nats: 0.022680\n",
      "Train Log likelihood, step 29500 in nats: 0.022697\n",
      "Train epoch average loss: 0.022699156900855454\n",
      "\n",
      "\n",
      "Epoch: 181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 29550 in nats: 0.022714\n",
      "Train Log likelihood, step 29600 in nats: 0.022774\n",
      "Train Log likelihood, step 29650 in nats: 0.022844\n",
      "Train epoch average loss: 0.022861871417141813\n",
      "\n",
      "\n",
      "Epoch: 182\n",
      "Train Log likelihood, step 29700 in nats: 0.022904\n",
      "Train Log likelihood, step 29750 in nats: 0.022986\n",
      "Train Log likelihood, step 29800 in nats: 0.023015\n",
      "Train epoch average loss: 0.02306591235686918\n",
      "\n",
      "\n",
      "Epoch: 183\n",
      "Train Log likelihood, step 29850 in nats: 0.023076\n",
      "Train Log likelihood, step 29900 in nats: 0.023122\n",
      "Train Log likelihood, step 29950 in nats: 0.023222\n",
      "Train epoch average loss: 0.02322168433756208\n",
      "\n",
      "\n",
      "Epoch: 184\n",
      "Train Log likelihood, step 30000 in nats: 0.023241\n",
      "Train Log likelihood, step 30050 in nats: 0.023328\n",
      "Train Log likelihood, step 30100 in nats: 0.023386\n",
      "Train Log likelihood, step 30150 in nats: 0.023452\n",
      "Train epoch average loss: 0.023452662961910394\n",
      "\n",
      "\n",
      "Epoch: 185\n",
      "Train Log likelihood, step 30200 in nats: 0.023503\n",
      "Train Log likelihood, step 30250 in nats: 0.023522\n",
      "Train Log likelihood, step 30300 in nats: 0.023574\n",
      "Train epoch average loss: 0.023585635720219014\n",
      "\n",
      "\n",
      "Epoch: 186\n",
      "Train Log likelihood, step 30350 in nats: 0.023612\n",
      "Train Log likelihood, step 30400 in nats: 0.023651\n",
      "Train Log likelihood, step 30450 in nats: 0.023701\n",
      "Train epoch average loss: 0.023735693225453013\n",
      "\n",
      "\n",
      "Epoch: 187\n",
      "Train Log likelihood, step 30500 in nats: 0.023768\n",
      "Train Log likelihood, step 30550 in nats: 0.023839\n",
      "Train Log likelihood, step 30600 in nats: 0.023860\n",
      "Train epoch average loss: 0.023876948916798816\n",
      "\n",
      "\n",
      "Epoch: 188\n",
      "Train Log likelihood, step 30650 in nats: 0.023883\n",
      "Train Log likelihood, step 30700 in nats: 0.023962\n",
      "Train Log likelihood, step 30750 in nats: 0.024046\n",
      "Train Log likelihood, step 30800 in nats: 0.024101\n",
      "Train epoch average loss: 0.024100253483967236\n",
      "\n",
      "\n",
      "Epoch: 189\n",
      "Train Log likelihood, step 30850 in nats: 0.024196\n",
      "Train Log likelihood, step 30900 in nats: 0.024270\n",
      "Train Log likelihood, step 30950 in nats: 0.024294\n",
      "Train epoch average loss: 0.024332494792567834\n",
      "\n",
      "\n",
      "Epoch: 190\n",
      "Train Log likelihood, step 31000 in nats: 0.024374\n",
      "Train Log likelihood, step 31050 in nats: 0.024438\n",
      "Train Log likelihood, step 31100 in nats: 0.024511\n",
      "Train epoch average loss: 0.02456680157888912\n",
      "\n",
      "\n",
      "Epoch: 191\n",
      "Train Log likelihood, step 31150 in nats: 0.024576\n",
      "Train Log likelihood, step 31200 in nats: 0.024622\n",
      "Train Log likelihood, step 31250 in nats: 0.024656\n",
      "Train epoch average loss: 0.02465157012968022\n",
      "\n",
      "\n",
      "Epoch: 192\n",
      "Train Log likelihood, step 31300 in nats: 0.024662\n",
      "Train Log likelihood, step 31350 in nats: 0.024714\n",
      "Train Log likelihood, step 31400 in nats: 0.024779\n",
      "Train Log likelihood, step 31450 in nats: 0.024853\n",
      "Train epoch average loss: 0.02485945079798796\n",
      "\n",
      "\n",
      "Epoch: 193\n",
      "Train Log likelihood, step 31500 in nats: 0.024866\n",
      "Train Log likelihood, step 31550 in nats: 0.024901\n",
      "Train Log likelihood, step 31600 in nats: 0.024958\n",
      "Train epoch average loss: 0.02500000423192091\n",
      "\n",
      "\n",
      "Epoch: 194\n",
      "Train Log likelihood, step 31650 in nats: 0.025071\n",
      "Train Log likelihood, step 31700 in nats: 0.025107\n",
      "Train Log likelihood, step 31750 in nats: 0.025124\n",
      "Train epoch average loss: 0.02512871802150654\n",
      "\n",
      "\n",
      "Epoch: 195\n",
      "Train Log likelihood, step 31800 in nats: 0.025166\n",
      "Train Log likelihood, step 31850 in nats: 0.025219\n",
      "Train Log likelihood, step 31900 in nats: 0.025254\n",
      "Train epoch average loss: 0.02532960743199724\n",
      "\n",
      "\n",
      "Epoch: 196\n",
      "Train Log likelihood, step 31950 in nats: 0.025328\n",
      "Train Log likelihood, step 32000 in nats: 0.025392\n",
      "Train Log likelihood, step 32050 in nats: 0.025464\n",
      "Train Log likelihood, step 32100 in nats: 0.025521\n",
      "Train epoch average loss: 0.02552112336947523\n",
      "\n",
      "\n",
      "Epoch: 197\n",
      "Train Log likelihood, step 32150 in nats: 0.025548\n",
      "Train Log likelihood, step 32200 in nats: 0.025599\n",
      "Train Log likelihood, step 32250 in nats: 0.025678\n",
      "Train epoch average loss: 0.025710489907582863\n",
      "\n",
      "\n",
      "Epoch: 198\n",
      "Train Log likelihood, step 32300 in nats: 0.025724\n",
      "Train Log likelihood, step 32350 in nats: 0.025723\n",
      "Train Log likelihood, step 32400 in nats: 0.025781\n",
      "Train epoch average loss: 0.025818887985031486\n",
      "\n",
      "\n",
      "Epoch: 199\n",
      "Train Log likelihood, step 32450 in nats: 0.025842\n",
      "Train Log likelihood, step 32500 in nats: 0.025940\n",
      "Train Log likelihood, step 32550 in nats: 0.026029\n",
      "Train epoch average loss: 0.02611340557092215\n",
      "\n",
      "\n",
      "Epoch: 200\n",
      "Train Log likelihood, step 32600 in nats: 0.026113\n",
      "Train Log likelihood, step 32650 in nats: 0.026158\n",
      "Train Log likelihood, step 32700 in nats: 0.026174\n",
      "Train Log likelihood, step 32750 in nats: 0.026207\n",
      "Train epoch average loss: 0.026228651003863252\n",
      "\n",
      "\n",
      "Epoch: 201\n",
      "Train Log likelihood, step 32800 in nats: 0.026257\n",
      "Train Log likelihood, step 32850 in nats: 0.026281\n",
      "Train Log likelihood, step 32900 in nats: 0.026404\n",
      "Train epoch average loss: 0.026453766252762922\n",
      "\n",
      "\n",
      "Epoch: 202\n",
      "Train Log likelihood, step 32950 in nats: 0.026479\n",
      "Train Log likelihood, step 33000 in nats: 0.026556\n",
      "Train Log likelihood, step 33050 in nats: 0.026627\n",
      "Train epoch average loss: 0.026662381580751786\n",
      "\n",
      "\n",
      "Epoch: 203\n",
      "Train Log likelihood, step 33100 in nats: 0.026681\n",
      "Train Log likelihood, step 33150 in nats: 0.026729\n",
      "Train Log likelihood, step 33200 in nats: 0.026789\n",
      "Train Log likelihood, step 33250 in nats: 0.026861\n",
      "Train epoch average loss: 0.026861402272037156\n",
      "\n",
      "\n",
      "Epoch: 204\n",
      "Train Log likelihood, step 33300 in nats: 0.026925\n",
      "Train Log likelihood, step 33350 in nats: 0.026947\n",
      "Train Log likelihood, step 33400 in nats: 0.026986\n",
      "Train epoch average loss: 0.02699304371202792\n",
      "\n",
      "\n",
      "Epoch: 205\n",
      "Train Log likelihood, step 33450 in nats: 0.027013\n",
      "Train Log likelihood, step 33500 in nats: 0.027048\n",
      "Train Log likelihood, step 33550 in nats: 0.027148\n",
      "Train epoch average loss: 0.027193166180866923\n",
      "\n",
      "\n",
      "Epoch: 206\n",
      "Train Log likelihood, step 33600 in nats: 0.027237\n",
      "Train Log likelihood, step 33650 in nats: 0.027263\n",
      "Train Log likelihood, step 33700 in nats: 0.027324\n",
      "Train epoch average loss: 0.027384522672528416\n",
      "\n",
      "\n",
      "Epoch: 207\n",
      "Train Log likelihood, step 33750 in nats: 0.027397\n",
      "Train Log likelihood, step 33800 in nats: 0.027450\n",
      "Train Log likelihood, step 33850 in nats: 0.027486\n",
      "Train Log likelihood, step 33900 in nats: 0.027554\n",
      "Train epoch average loss: 0.027552974796115334\n",
      "\n",
      "\n",
      "Epoch: 208\n",
      "Train Log likelihood, step 33950 in nats: 0.027600\n",
      "Train Log likelihood, step 34000 in nats: 0.027657\n",
      "Train Log likelihood, step 34050 in nats: 0.027674\n",
      "Train epoch average loss: 0.027699858909913066\n",
      "\n",
      "\n",
      "Epoch: 209\n",
      "Train Log likelihood, step 34100 in nats: 0.027773\n",
      "Train Log likelihood, step 34150 in nats: 0.027825\n",
      "Train Log likelihood, step 34200 in nats: 0.027880\n",
      "Train epoch average loss: 0.027926757677776512\n",
      "\n",
      "\n",
      "Epoch: 210\n",
      "Train Log likelihood, step 34250 in nats: 0.027950\n",
      "Train Log likelihood, step 34300 in nats: 0.027992\n",
      "Train Log likelihood, step 34350 in nats: 0.028058\n",
      "Train epoch average loss: 0.028132641003188377\n",
      "\n",
      "\n",
      "Epoch: 211\n",
      "Train Log likelihood, step 34400 in nats: 0.028139\n",
      "Train Log likelihood, step 34450 in nats: 0.028138\n",
      "Train Log likelihood, step 34500 in nats: 0.028187\n",
      "Train Log likelihood, step 34550 in nats: 0.028236\n",
      "Train epoch average loss: 0.02823898732833238\n",
      "\n",
      "\n",
      "Epoch: 212\n",
      "Train Log likelihood, step 34600 in nats: 0.028252\n",
      "Train Log likelihood, step 34650 in nats: 0.028315\n",
      "Train Log likelihood, step 34700 in nats: 0.028343\n",
      "Train epoch average loss: 0.02837573055440508\n",
      "\n",
      "\n",
      "Epoch: 213\n",
      "Train Log likelihood, step 34750 in nats: 0.028425\n",
      "Train Log likelihood, step 34800 in nats: 0.028486\n",
      "Train Log likelihood, step 34850 in nats: 0.028554\n",
      "Train epoch average loss: 0.02857773695256025\n",
      "\n",
      "\n",
      "Epoch: 214\n",
      "Train Log likelihood, step 34900 in nats: 0.028598\n",
      "Train Log likelihood, step 34950 in nats: 0.028652\n",
      "Train Log likelihood, step 35000 in nats: 0.028682\n",
      "Train epoch average loss: 0.028754274873015608\n",
      "\n",
      "\n",
      "Epoch: 215\n",
      "Train Log likelihood, step 35050 in nats: 0.028755\n",
      "Train Log likelihood, step 35100 in nats: 0.028815\n",
      "Train Log likelihood, step 35150 in nats: 0.028826\n",
      "Train Log likelihood, step 35200 in nats: 0.028877\n",
      "Train epoch average loss: 0.02889030654619216\n",
      "\n",
      "\n",
      "Epoch: 216\n",
      "Train Log likelihood, step 35250 in nats: 0.028930\n",
      "Train Log likelihood, step 35300 in nats: 0.028990\n",
      "Train Log likelihood, step 35350 in nats: 0.029046\n",
      "Train epoch average loss: 0.029070813872839336\n",
      "\n",
      "\n",
      "Epoch: 217\n",
      "Train Log likelihood, step 35400 in nats: 0.029108\n",
      "Train Log likelihood, step 35450 in nats: 0.029133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 35500 in nats: 0.029186\n",
      "Train epoch average loss: 0.02920877882034255\n",
      "\n",
      "\n",
      "Epoch: 218\n",
      "Train Log likelihood, step 35550 in nats: 0.029208\n",
      "Train Log likelihood, step 35600 in nats: 0.029272\n",
      "Train Log likelihood, step 35650 in nats: 0.029312\n",
      "Train epoch average loss: 0.029368256156429035\n",
      "\n",
      "\n",
      "Epoch: 219\n",
      "Train Log likelihood, step 35700 in nats: 0.029369\n",
      "Train Log likelihood, step 35750 in nats: 0.029417\n",
      "Train Log likelihood, step 35800 in nats: 0.029471\n",
      "Train Log likelihood, step 35850 in nats: 0.029537\n",
      "Train epoch average loss: 0.02955326299535983\n",
      "\n",
      "\n",
      "Epoch: 220\n",
      "Train Log likelihood, step 35900 in nats: 0.029586\n",
      "Train Log likelihood, step 35950 in nats: 0.029659\n",
      "Train Log likelihood, step 36000 in nats: 0.029699\n",
      "Train epoch average loss: 0.029730407549398524\n",
      "\n",
      "\n",
      "Epoch: 221\n",
      "Train Log likelihood, step 36050 in nats: 0.029758\n",
      "Train Log likelihood, step 36100 in nats: 0.029827\n",
      "Train Log likelihood, step 36150 in nats: 0.029886\n",
      "Train epoch average loss: 0.029967944556218457\n",
      "\n",
      "\n",
      "Epoch: 222\n",
      "Train Log likelihood, step 36200 in nats: 0.029982\n",
      "Train Log likelihood, step 36250 in nats: 0.030043\n",
      "Train Log likelihood, step 36300 in nats: 0.030063\n",
      "Train epoch average loss: 0.030064164360959936\n",
      "\n",
      "\n",
      "Epoch: 223\n",
      "Train Log likelihood, step 36350 in nats: 0.030060\n",
      "Train Log likelihood, step 36400 in nats: 0.030085\n",
      "Train Log likelihood, step 36450 in nats: 0.030148\n",
      "Train Log likelihood, step 36500 in nats: 0.030156\n",
      "Train epoch average loss: 0.030179813122450147\n",
      "\n",
      "\n",
      "Epoch: 224\n",
      "Train Log likelihood, step 36550 in nats: 0.030207\n",
      "Train Log likelihood, step 36600 in nats: 0.030297\n",
      "Train Log likelihood, step 36650 in nats: 0.030384\n",
      "Train epoch average loss: 0.03039850299048039\n",
      "\n",
      "\n",
      "Epoch: 225\n",
      "Train Log likelihood, step 36700 in nats: 0.030455\n",
      "Train Log likelihood, step 36750 in nats: 0.030499\n",
      "Train Log likelihood, step 36800 in nats: 0.030559\n",
      "Train epoch average loss: 0.030582616829510634\n",
      "\n",
      "\n",
      "Epoch: 226\n",
      "Train Log likelihood, step 36850 in nats: 0.030605\n",
      "Train Log likelihood, step 36900 in nats: 0.030633\n",
      "Train Log likelihood, step 36950 in nats: 0.030708\n",
      "Train Log likelihood, step 37000 in nats: 0.030768\n",
      "Train epoch average loss: 0.03076806943230679\n",
      "\n",
      "\n",
      "Epoch: 227\n",
      "Train Log likelihood, step 37050 in nats: 0.030813\n",
      "Train Log likelihood, step 37100 in nats: 0.030859\n",
      "Train Log likelihood, step 37150 in nats: 0.030908\n",
      "Train epoch average loss: 0.030916569490932765\n",
      "\n",
      "\n",
      "Epoch: 228\n",
      "Train Log likelihood, step 37200 in nats: 0.030960\n",
      "Train Log likelihood, step 37250 in nats: 0.030989\n",
      "Train Log likelihood, step 37300 in nats: 0.031032\n",
      "Train epoch average loss: 0.031062604714060773\n",
      "\n",
      "\n",
      "Epoch: 229\n",
      "Train Log likelihood, step 37350 in nats: 0.031089\n",
      "Train Log likelihood, step 37400 in nats: 0.031144\n",
      "Train Log likelihood, step 37450 in nats: 0.031204\n",
      "Train epoch average loss: 0.031241348128684836\n",
      "\n",
      "\n",
      "Epoch: 230\n",
      "Train Log likelihood, step 37500 in nats: 0.031237\n",
      "Train Log likelihood, step 37550 in nats: 0.031289\n",
      "Train Log likelihood, step 37600 in nats: 0.031302\n",
      "Train Log likelihood, step 37650 in nats: 0.031363\n",
      "Train epoch average loss: 0.03135663241725845\n",
      "\n",
      "\n",
      "Epoch: 231\n",
      "Train Log likelihood, step 37700 in nats: 0.031402\n",
      "Train Log likelihood, step 37750 in nats: 0.031471\n",
      "Train Log likelihood, step 37800 in nats: 0.031540\n",
      "Train epoch average loss: 0.03155057465950312\n",
      "\n",
      "\n",
      "Epoch: 232\n",
      "Train Log likelihood, step 37850 in nats: 0.031576\n",
      "Train Log likelihood, step 37900 in nats: 0.031586\n",
      "Train Log likelihood, step 37950 in nats: 0.031620\n",
      "Train epoch average loss: 0.03162565655323334\n",
      "\n",
      "\n",
      "Epoch: 233\n",
      "Train Log likelihood, step 38000 in nats: 0.031630\n",
      "Train Log likelihood, step 38050 in nats: 0.031706\n",
      "Train Log likelihood, step 38100 in nats: 0.031745\n",
      "Train epoch average loss: 0.031807270253025675\n",
      "\n",
      "\n",
      "Epoch: 234\n",
      "Train Log likelihood, step 38150 in nats: 0.031818\n",
      "Train Log likelihood, step 38200 in nats: 0.031889\n",
      "Train Log likelihood, step 38250 in nats: 0.031988\n",
      "Train Log likelihood, step 38300 in nats: 0.032022\n",
      "Train epoch average loss: 0.03202778207682885\n",
      "\n",
      "\n",
      "Epoch: 235\n",
      "Train Log likelihood, step 38350 in nats: 0.032086\n",
      "Train Log likelihood, step 38400 in nats: 0.032133\n",
      "Train Log likelihood, step 38450 in nats: 0.032142\n",
      "Train epoch average loss: 0.032146226410708335\n",
      "\n",
      "\n",
      "Epoch: 236\n",
      "Train Log likelihood, step 38500 in nats: 0.032199\n",
      "Train Log likelihood, step 38550 in nats: 0.032257\n",
      "Train Log likelihood, step 38600 in nats: 0.032307\n",
      "Train epoch average loss: 0.03230788167593578\n",
      "\n",
      "\n",
      "Epoch: 237\n",
      "Train Log likelihood, step 38650 in nats: 0.032321\n",
      "Train Log likelihood, step 38700 in nats: 0.032369\n",
      "Train Log likelihood, step 38750 in nats: 0.032398\n",
      "Train epoch average loss: 0.03244744269258176\n",
      "\n",
      "\n",
      "Epoch: 238\n",
      "Train Log likelihood, step 38800 in nats: 0.032466\n",
      "Train Log likelihood, step 38850 in nats: 0.032509\n",
      "Train Log likelihood, step 38900 in nats: 0.032583\n",
      "Train Log likelihood, step 38950 in nats: 0.032629\n",
      "Train epoch average loss: 0.032639444711674355\n",
      "\n",
      "\n",
      "Epoch: 239\n",
      "Train Log likelihood, step 39000 in nats: 0.032685\n",
      "Train Log likelihood, step 39050 in nats: 0.032731\n",
      "Train Log likelihood, step 39100 in nats: 0.032814\n",
      "Train epoch average loss: 0.03280736173513684\n",
      "\n",
      "\n",
      "Epoch: 240\n",
      "Train Log likelihood, step 39150 in nats: 0.032842\n",
      "Train Log likelihood, step 39200 in nats: 0.032932\n",
      "Train Log likelihood, step 39250 in nats: 0.032939\n",
      "Train epoch average loss: 0.03297000917266301\n",
      "\n",
      "\n",
      "Epoch: 241\n",
      "Train Log likelihood, step 39300 in nats: 0.032997\n",
      "Train Log likelihood, step 39350 in nats: 0.033060\n",
      "Train Log likelihood, step 39400 in nats: 0.033100\n",
      "Train epoch average loss: 0.033154638909732345\n",
      "\n",
      "\n",
      "Epoch: 242\n",
      "Train Log likelihood, step 39450 in nats: 0.033155\n",
      "Train Log likelihood, step 39500 in nats: 0.033198\n",
      "Train Log likelihood, step 39550 in nats: 0.033247\n",
      "Train Log likelihood, step 39600 in nats: 0.033294\n",
      "Train epoch average loss: 0.033301157442496586\n",
      "\n",
      "\n",
      "Epoch: 243\n",
      "Train Log likelihood, step 39650 in nats: 0.033344\n",
      "Train Log likelihood, step 39700 in nats: 0.033350\n",
      "Train Log likelihood, step 39750 in nats: 0.033396\n",
      "Train epoch average loss: 0.03341640329355811\n",
      "\n",
      "\n",
      "Epoch: 244\n",
      "Train Log likelihood, step 39800 in nats: 0.033443\n",
      "Train Log likelihood, step 39850 in nats: 0.033514\n",
      "Train Log likelihood, step 39900 in nats: 0.033545\n",
      "Train epoch average loss: 0.03356597727800296\n",
      "\n",
      "\n",
      "Epoch: 245\n",
      "Train Log likelihood, step 39950 in nats: 0.033591\n",
      "Train Log likelihood, step 40000 in nats: 0.033635\n",
      "Train Log likelihood, step 40050 in nats: 0.033690\n",
      "Train epoch average loss: 0.033727993104851584\n",
      "\n",
      "\n",
      "Epoch: 246\n",
      "Train Log likelihood, step 40100 in nats: 0.033733\n",
      "Train Log likelihood, step 40150 in nats: 0.033759\n",
      "Train Log likelihood, step 40200 in nats: 0.033799\n",
      "Train Log likelihood, step 40250 in nats: 0.033871\n",
      "Train epoch average loss: 0.03387141603939005\n",
      "\n",
      "\n",
      "Epoch: 247\n",
      "Train Log likelihood, step 40300 in nats: 0.033927\n",
      "Train Log likelihood, step 40350 in nats: 0.033957\n",
      "Train Log likelihood, step 40400 in nats: 0.033990\n",
      "Train epoch average loss: 0.034029928334326574\n",
      "\n",
      "\n",
      "Epoch: 248\n",
      "Train Log likelihood, step 40450 in nats: 0.034070\n",
      "Train Log likelihood, step 40500 in nats: 0.034140\n",
      "Train Log likelihood, step 40550 in nats: 0.034184\n",
      "Train epoch average loss: 0.03420296171724939\n",
      "\n",
      "\n",
      "Epoch: 249\n",
      "Train Log likelihood, step 40600 in nats: 0.034220\n",
      "Train Log likelihood, step 40650 in nats: 0.034279\n",
      "Train Log likelihood, step 40700 in nats: 0.034313\n",
      "Train epoch average loss: 0.0343689858776849\n",
      "\n",
      "\n",
      "Epoch: 250\n",
      "Train Log likelihood, step 40750 in nats: 0.034366\n",
      "Train Log likelihood, step 40800 in nats: 0.034399\n",
      "Train Log likelihood, step 40850 in nats: 0.034441\n",
      "Train Log likelihood, step 40900 in nats: 0.034467\n",
      "Train epoch average loss: 0.034485616909099216\n",
      "\n",
      "\n",
      "Epoch: 251\n",
      "Train Log likelihood, step 40950 in nats: 0.034542\n",
      "Train Log likelihood, step 41000 in nats: 0.034606\n",
      "Train Log likelihood, step 41050 in nats: 0.034707\n",
      "Train epoch average loss: 0.03475042133128551\n",
      "\n",
      "\n",
      "Epoch: 252\n",
      "Train Log likelihood, step 41100 in nats: 0.034784\n",
      "Train Log likelihood, step 41150 in nats: 0.034851\n",
      "Train Log likelihood, step 41200 in nats: 0.034943\n",
      "Train epoch average loss: 0.03497502466057121\n",
      "\n",
      "\n",
      "Epoch: 253\n",
      "Train Log likelihood, step 41250 in nats: 0.034982\n",
      "Train Log likelihood, step 41300 in nats: 0.035036\n",
      "Train Log likelihood, step 41350 in nats: 0.035104\n",
      "Train Log likelihood, step 41400 in nats: 0.035153\n",
      "Train epoch average loss: 0.03515476026403388\n",
      "\n",
      "\n",
      "Epoch: 254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 41450 in nats: 0.035225\n",
      "Train Log likelihood, step 41500 in nats: 0.035285\n",
      "Train Log likelihood, step 41550 in nats: 0.035281\n",
      "Train epoch average loss: 0.03529216676645264\n",
      "\n",
      "\n",
      "Epoch: 255\n",
      "Train Log likelihood, step 41600 in nats: 0.035333\n",
      "Train Log likelihood, step 41650 in nats: 0.035402\n",
      "Train Log likelihood, step 41700 in nats: 0.035465\n",
      "Train epoch average loss: 0.03549057930752606\n",
      "\n",
      "\n",
      "Epoch: 256\n",
      "Train Log likelihood, step 41750 in nats: 0.035502\n",
      "Train Log likelihood, step 41800 in nats: 0.035545\n",
      "Train Log likelihood, step 41850 in nats: 0.035582\n",
      "Train epoch average loss: 0.03561429176312989\n",
      "\n",
      "\n",
      "Epoch: 257\n",
      "Train Log likelihood, step 41900 in nats: 0.035637\n",
      "Train Log likelihood, step 41950 in nats: 0.035675\n",
      "Train Log likelihood, step 42000 in nats: 0.035677\n",
      "Train Log likelihood, step 42050 in nats: 0.035716\n",
      "Train epoch average loss: 0.03570995877267611\n",
      "\n",
      "\n",
      "Epoch: 258\n",
      "Train Log likelihood, step 42100 in nats: 0.035749\n",
      "Train Log likelihood, step 42150 in nats: 0.035779\n",
      "Train Log likelihood, step 42200 in nats: 0.035790\n",
      "Train epoch average loss: 0.03579408356053314\n",
      "\n",
      "\n",
      "Epoch: 259\n",
      "Train Log likelihood, step 42250 in nats: 0.035831\n",
      "Train Log likelihood, step 42300 in nats: 0.035899\n",
      "Train Log likelihood, step 42350 in nats: 0.035984\n",
      "Train epoch average loss: 0.03600552137724529\n",
      "\n",
      "\n",
      "Epoch: 260\n",
      "Train Log likelihood, step 42400 in nats: 0.036035\n",
      "Train Log likelihood, step 42450 in nats: 0.036102\n",
      "Train Log likelihood, step 42500 in nats: 0.036153\n",
      "Train epoch average loss: 0.036178165200449086\n",
      "\n",
      "\n",
      "Epoch: 261\n",
      "Train Log likelihood, step 42550 in nats: 0.036188\n",
      "Train Log likelihood, step 42600 in nats: 0.036240\n",
      "Train Log likelihood, step 42650 in nats: 0.036319\n",
      "Train Log likelihood, step 42700 in nats: 0.036366\n",
      "Train epoch average loss: 0.036353373858702104\n",
      "\n",
      "\n",
      "Epoch: 262\n",
      "Train Log likelihood, step 42750 in nats: 0.036390\n",
      "Train Log likelihood, step 42800 in nats: 0.036416\n",
      "Train Log likelihood, step 42850 in nats: 0.036478\n",
      "Train epoch average loss: 0.03648247232129496\n",
      "\n",
      "\n",
      "Epoch: 263\n",
      "Train Log likelihood, step 42900 in nats: 0.036533\n",
      "Train Log likelihood, step 42950 in nats: 0.036581\n",
      "Train Log likelihood, step 43000 in nats: 0.036629\n",
      "Train epoch average loss: 0.036669080791909885\n",
      "\n",
      "\n",
      "Epoch: 264\n",
      "Train Log likelihood, step 43050 in nats: 0.036684\n",
      "Train Log likelihood, step 43100 in nats: 0.036703\n",
      "Train Log likelihood, step 43150 in nats: 0.036744\n",
      "Train epoch average loss: 0.036756612824055984\n",
      "\n",
      "\n",
      "Epoch: 265\n",
      "Train Log likelihood, step 43200 in nats: 0.036761\n",
      "Train Log likelihood, step 43250 in nats: 0.036807\n",
      "Train Log likelihood, step 43300 in nats: 0.036826\n",
      "Train Log likelihood, step 43350 in nats: 0.036831\n",
      "Train epoch average loss: 0.036830685051681515\n",
      "\n",
      "\n",
      "Epoch: 266\n",
      "Train Log likelihood, step 43400 in nats: 0.036868\n",
      "Train Log likelihood, step 43450 in nats: 0.036911\n",
      "Train Log likelihood, step 43500 in nats: 0.036950\n",
      "Train epoch average loss: 0.03698227365199869\n",
      "\n",
      "\n",
      "Epoch: 267\n",
      "Train Log likelihood, step 43550 in nats: 0.037011\n",
      "Train Log likelihood, step 43600 in nats: 0.037047\n",
      "Train Log likelihood, step 43650 in nats: 0.037085\n",
      "Train epoch average loss: 0.037123342279238476\n",
      "\n",
      "\n",
      "Epoch: 268\n",
      "Train Log likelihood, step 43700 in nats: 0.037135\n",
      "Train Log likelihood, step 43750 in nats: 0.037175\n",
      "Train Log likelihood, step 43800 in nats: 0.037211\n",
      "Train epoch average loss: 0.03724386039748815\n",
      "\n",
      "\n",
      "Epoch: 269\n",
      "Train Log likelihood, step 43850 in nats: 0.037247\n",
      "Train Log likelihood, step 43900 in nats: 0.037331\n",
      "Train Log likelihood, step 43950 in nats: 0.037375\n",
      "Train Log likelihood, step 44000 in nats: 0.037416\n",
      "Train epoch average loss: 0.037422872318598324\n",
      "\n",
      "\n",
      "Epoch: 270\n",
      "Train Log likelihood, step 44050 in nats: 0.037477\n",
      "Train Log likelihood, step 44100 in nats: 0.037495\n",
      "Train Log likelihood, step 44150 in nats: 0.037561\n",
      "Train epoch average loss: 0.03759227284976831\n",
      "\n",
      "\n",
      "Epoch: 271\n",
      "Train Log likelihood, step 44200 in nats: 0.037643\n",
      "Train Log likelihood, step 44250 in nats: 0.037706\n",
      "Train Log likelihood, step 44300 in nats: 0.037764\n",
      "Train epoch average loss: 0.03780441461989327\n",
      "\n",
      "\n",
      "Epoch: 272\n",
      "Train Log likelihood, step 44350 in nats: 0.037802\n",
      "Train Log likelihood, step 44400 in nats: 0.037832\n",
      "Train Log likelihood, step 44450 in nats: 0.037843\n",
      "Train epoch average loss: 0.03789185069191789\n",
      "\n",
      "\n",
      "Epoch: 273\n",
      "Train Log likelihood, step 44500 in nats: 0.037891\n",
      "Train Log likelihood, step 44550 in nats: 0.037957\n",
      "Train Log likelihood, step 44600 in nats: 0.037986\n",
      "Train Log likelihood, step 44650 in nats: 0.038046\n",
      "Train epoch average loss: 0.038044641375590695\n",
      "\n",
      "\n",
      "Epoch: 274\n",
      "Train Log likelihood, step 44700 in nats: 0.038075\n",
      "Train Log likelihood, step 44750 in nats: 0.038145\n",
      "Train Log likelihood, step 44800 in nats: 0.038193\n",
      "Train epoch average loss: 0.03821548446463303\n",
      "\n",
      "\n",
      "Epoch: 275\n",
      "Train Log likelihood, step 44850 in nats: 0.038236\n",
      "Train Log likelihood, step 44900 in nats: 0.038267\n",
      "Train Log likelihood, step 44950 in nats: 0.038321\n",
      "Train epoch average loss: 0.03834465483639013\n",
      "\n",
      "\n",
      "Epoch: 276\n",
      "Train Log likelihood, step 45000 in nats: 0.038349\n",
      "Train Log likelihood, step 45050 in nats: 0.038403\n",
      "Train Log likelihood, step 45100 in nats: 0.038430\n",
      "Train Log likelihood, step 45150 in nats: 0.038497\n",
      "Train epoch average loss: 0.038496737363789515\n",
      "\n",
      "\n",
      "Epoch: 277\n",
      "Train Log likelihood, step 45200 in nats: 0.038536\n",
      "Train Log likelihood, step 45250 in nats: 0.038577\n",
      "Train Log likelihood, step 45300 in nats: 0.038647\n",
      "Train epoch average loss: 0.03866040936495775\n",
      "\n",
      "\n",
      "Epoch: 278\n",
      "Train Log likelihood, step 45350 in nats: 0.038692\n",
      "Train Log likelihood, step 45400 in nats: 0.038715\n",
      "Train Log likelihood, step 45450 in nats: 0.038749\n",
      "Train epoch average loss: 0.03875869226007481\n",
      "\n",
      "\n",
      "Epoch: 279\n",
      "Train Log likelihood, step 45500 in nats: 0.038758\n",
      "Train Log likelihood, step 45550 in nats: 0.038779\n",
      "Train Log likelihood, step 45600 in nats: 0.038793\n",
      "Train epoch average loss: 0.03881440476314585\n",
      "\n",
      "\n",
      "Epoch: 280\n",
      "Train Log likelihood, step 45650 in nats: 0.038823\n",
      "Train Log likelihood, step 45700 in nats: 0.038870\n",
      "Train Log likelihood, step 45750 in nats: 0.038914\n",
      "Train Log likelihood, step 45800 in nats: 0.038944\n",
      "Train epoch average loss: 0.03894472211462852\n",
      "\n",
      "\n",
      "Epoch: 281\n",
      "Train Log likelihood, step 45850 in nats: 0.038996\n",
      "Train Log likelihood, step 45900 in nats: 0.039048\n",
      "Train Log likelihood, step 45950 in nats: 0.039100\n",
      "Train epoch average loss: 0.039096934015033495\n",
      "\n",
      "\n",
      "Epoch: 282\n",
      "Train Log likelihood, step 46000 in nats: 0.039129\n",
      "Train Log likelihood, step 46050 in nats: 0.039151\n",
      "Train Log likelihood, step 46100 in nats: 0.039197\n",
      "Train epoch average loss: 0.039206921595677006\n",
      "\n",
      "\n",
      "Epoch: 283\n",
      "Train Log likelihood, step 46150 in nats: 0.039221\n",
      "Train Log likelihood, step 46200 in nats: 0.039286\n",
      "Train Log likelihood, step 46250 in nats: 0.039341\n",
      "Train epoch average loss: 0.03936843376071427\n",
      "\n",
      "\n",
      "Epoch: 284\n",
      "Train Log likelihood, step 46300 in nats: 0.039375\n",
      "Train Log likelihood, step 46350 in nats: 0.039403\n",
      "Train Log likelihood, step 46400 in nats: 0.039445\n",
      "Train Log likelihood, step 46450 in nats: 0.039488\n",
      "Train epoch average loss: 0.0394951975434083\n",
      "\n",
      "\n",
      "Epoch: 285\n",
      "Train Log likelihood, step 46500 in nats: 0.039514\n",
      "Train Log likelihood, step 46550 in nats: 0.039579\n",
      "Train Log likelihood, step 46600 in nats: 0.039595\n",
      "Train epoch average loss: 0.03960376329008755\n",
      "\n",
      "\n",
      "Epoch: 286\n",
      "Train Log likelihood, step 46650 in nats: 0.039623\n",
      "Train Log likelihood, step 46700 in nats: 0.039654\n",
      "Train Log likelihood, step 46750 in nats: 0.039664\n",
      "Train epoch average loss: 0.03968254320141219\n",
      "\n",
      "\n",
      "Epoch: 287\n",
      "Train Log likelihood, step 46800 in nats: 0.039685\n",
      "Train Log likelihood, step 46850 in nats: 0.039745\n",
      "Train Log likelihood, step 46900 in nats: 0.039789\n",
      "Train epoch average loss: 0.039853807755362756\n",
      "\n",
      "\n",
      "Epoch: 288\n",
      "Train Log likelihood, step 46950 in nats: 0.039869\n",
      "Train Log likelihood, step 47000 in nats: 0.039909\n",
      "Train Log likelihood, step 47050 in nats: 0.039959\n",
      "Train Log likelihood, step 47100 in nats: 0.039976\n",
      "Train epoch average loss: 0.03997951770444182\n",
      "\n",
      "\n",
      "Epoch: 289\n",
      "Train Log likelihood, step 47150 in nats: 0.040009\n",
      "Train Log likelihood, step 47200 in nats: 0.040082\n",
      "Train Log likelihood, step 47250 in nats: 0.040128\n",
      "Train epoch average loss: 0.04013853753835962\n",
      "\n",
      "\n",
      "Epoch: 290\n",
      "Train Log likelihood, step 47300 in nats: 0.040165\n",
      "Train Log likelihood, step 47350 in nats: 0.040223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 47400 in nats: 0.040281\n",
      "Train epoch average loss: 0.04030805324941959\n",
      "\n",
      "\n",
      "Epoch: 291\n",
      "Train Log likelihood, step 47450 in nats: 0.040330\n",
      "Train Log likelihood, step 47500 in nats: 0.040374\n",
      "Train Log likelihood, step 47550 in nats: 0.040417\n",
      "Train epoch average loss: 0.040461487190595335\n",
      "\n",
      "\n",
      "Epoch: 292\n",
      "Train Log likelihood, step 47600 in nats: 0.040472\n",
      "Train Log likelihood, step 47650 in nats: 0.040525\n",
      "Train Log likelihood, step 47700 in nats: 0.040580\n",
      "Train Log likelihood, step 47750 in nats: 0.040630\n",
      "Train epoch average loss: 0.04063450420039351\n",
      "\n",
      "\n",
      "Epoch: 293\n",
      "Train Log likelihood, step 47800 in nats: 0.040652\n",
      "Train Log likelihood, step 47850 in nats: 0.040715\n",
      "Train Log likelihood, step 47900 in nats: 0.040758\n",
      "Train epoch average loss: 0.040760350934904425\n",
      "\n",
      "\n",
      "Epoch: 294\n",
      "Train Log likelihood, step 47950 in nats: 0.040794\n",
      "Train Log likelihood, step 48000 in nats: 0.040802\n",
      "Train Log likelihood, step 48050 in nats: 0.040864\n",
      "Train epoch average loss: 0.04088299087339459\n",
      "\n",
      "\n",
      "Epoch: 295\n",
      "Train Log likelihood, step 48100 in nats: 0.040891\n",
      "Train Log likelihood, step 48150 in nats: 0.040928\n",
      "Train Log likelihood, step 48200 in nats: 0.040988\n",
      "Train epoch average loss: 0.04102327538792911\n",
      "\n",
      "\n",
      "Epoch: 296\n",
      "Train Log likelihood, step 48250 in nats: 0.041026\n",
      "Train Log likelihood, step 48300 in nats: 0.041086\n",
      "Train Log likelihood, step 48350 in nats: 0.041131\n",
      "Train Log likelihood, step 48400 in nats: 0.041178\n",
      "Train epoch average loss: 0.04119612436498141\n",
      "\n",
      "\n",
      "Epoch: 297\n",
      "Train Log likelihood, step 48450 in nats: 0.041235\n",
      "Train Log likelihood, step 48500 in nats: 0.041278\n",
      "Train Log likelihood, step 48550 in nats: 0.041322\n",
      "Train epoch average loss: 0.04133065598017535\n",
      "\n",
      "\n",
      "Epoch: 298\n",
      "Train Log likelihood, step 48600 in nats: 0.041350\n",
      "Train Log likelihood, step 48650 in nats: 0.041369\n",
      "Train Log likelihood, step 48700 in nats: 0.041411\n",
      "Train epoch average loss: 0.04142566255625462\n",
      "\n",
      "\n",
      "Epoch: 299\n",
      "Train Log likelihood, step 48750 in nats: 0.041444\n",
      "Train Log likelihood, step 48800 in nats: 0.041472\n",
      "Train Log likelihood, step 48850 in nats: 0.041523\n",
      "Train epoch average loss: 0.04156078372360493\n",
      "\n",
      "\n",
      "Epoch: 300\n",
      "Train Log likelihood, step 48900 in nats: 0.041564\n",
      "Train Log likelihood, step 48950 in nats: 0.041588\n",
      "Train Log likelihood, step 49000 in nats: 0.041664\n",
      "Train Log likelihood, step 49050 in nats: 0.041710\n",
      "Train epoch average loss: 0.04171742008327807\n",
      "\n",
      "\n",
      "Epoch: 301\n",
      "Train Log likelihood, step 49100 in nats: 0.041733\n",
      "Train Log likelihood, step 49150 in nats: 0.041757\n",
      "Train Log likelihood, step 49200 in nats: 0.041787\n",
      "Train epoch average loss: 0.041798926483063895\n",
      "\n",
      "\n",
      "Epoch: 302\n",
      "Train Log likelihood, step 49250 in nats: 0.041823\n",
      "Train Log likelihood, step 49300 in nats: 0.041880\n",
      "Train Log likelihood, step 49350 in nats: 0.041895\n",
      "Train epoch average loss: 0.04188811168231433\n",
      "\n",
      "\n",
      "Epoch: 303\n",
      "Train Log likelihood, step 49400 in nats: 0.041894\n",
      "Train Log likelihood, step 49450 in nats: 0.041944\n",
      "Train Log likelihood, step 49500 in nats: 0.041994\n",
      "Train Log likelihood, step 49550 in nats: 0.042032\n",
      "Train epoch average loss: 0.042031259447787434\n",
      "\n",
      "\n",
      "Epoch: 304\n",
      "Train Log likelihood, step 49600 in nats: 0.042082\n",
      "Train Log likelihood, step 49650 in nats: 0.042128\n",
      "Train Log likelihood, step 49700 in nats: 0.042187\n",
      "Train epoch average loss: 0.042195052497519404\n",
      "\n",
      "\n",
      "Epoch: 305\n",
      "Train Log likelihood, step 49750 in nats: 0.042181\n",
      "Train Log likelihood, step 49800 in nats: 0.042208\n",
      "Train Log likelihood, step 49850 in nats: 0.042236\n",
      "Train epoch average loss: 0.042268812908867415\n",
      "\n",
      "\n",
      "Epoch: 306\n",
      "Train Log likelihood, step 49900 in nats: 0.042302\n",
      "Train Log likelihood, step 49950 in nats: 0.042368\n",
      "Train Log likelihood, step 50000 in nats: 0.042413\n",
      "Train epoch average loss: 0.042443001206213166\n",
      "\n",
      "\n",
      "Epoch: 307\n",
      "Train Log likelihood, step 50050 in nats: 0.042462\n",
      "Train Log likelihood, step 50100 in nats: 0.042520\n",
      "Train Log likelihood, step 50150 in nats: 0.042553\n",
      "Train Log likelihood, step 50200 in nats: 0.042593\n",
      "Train epoch average loss: 0.042595374024622136\n",
      "\n",
      "\n",
      "Epoch: 308\n",
      "Train Log likelihood, step 50250 in nats: 0.042618\n",
      "Train Log likelihood, step 50300 in nats: 0.042657\n",
      "Train Log likelihood, step 50350 in nats: 0.042655\n",
      "Train epoch average loss: 0.042667763305740784\n",
      "\n",
      "\n",
      "Epoch: 309\n",
      "Train Log likelihood, step 50400 in nats: 0.042701\n",
      "Train Log likelihood, step 50450 in nats: 0.042697\n",
      "Train Log likelihood, step 50500 in nats: 0.042735\n",
      "Train epoch average loss: 0.04278642064190514\n",
      "\n",
      "\n",
      "Epoch: 310\n",
      "Train Log likelihood, step 50550 in nats: 0.042809\n",
      "Train Log likelihood, step 50600 in nats: 0.042847\n",
      "Train Log likelihood, step 50650 in nats: 0.042882\n",
      "Train epoch average loss: 0.04291265700550224\n",
      "\n",
      "\n",
      "Epoch: 311\n",
      "Train Log likelihood, step 50700 in nats: 0.042915\n",
      "Train Log likelihood, step 50750 in nats: 0.042938\n",
      "Train Log likelihood, step 50800 in nats: 0.042956\n",
      "Train Log likelihood, step 50850 in nats: 0.043010\n",
      "Train epoch average loss: 0.043025287145416265\n",
      "\n",
      "\n",
      "Epoch: 312\n",
      "Train Log likelihood, step 50900 in nats: 0.043052\n",
      "Train Log likelihood, step 50950 in nats: 0.043091\n",
      "Train Log likelihood, step 51000 in nats: 0.043144\n",
      "Train epoch average loss: 0.04315976023139026\n",
      "\n",
      "\n",
      "Epoch: 313\n",
      "Train Log likelihood, step 51050 in nats: 0.043167\n",
      "Train Log likelihood, step 51100 in nats: 0.043202\n",
      "Train Log likelihood, step 51150 in nats: 0.043252\n",
      "Train epoch average loss: 0.04327813186278453\n",
      "\n",
      "\n",
      "Epoch: 314\n",
      "Train Log likelihood, step 51200 in nats: 0.043270\n",
      "Train Log likelihood, step 51250 in nats: 0.043310\n",
      "Train Log likelihood, step 51300 in nats: 0.043318\n",
      "Train epoch average loss: 0.04336455916266411\n",
      "\n",
      "\n",
      "Epoch: 315\n",
      "Train Log likelihood, step 51350 in nats: 0.043365\n",
      "Train Log likelihood, step 51400 in nats: 0.043394\n",
      "Train Log likelihood, step 51450 in nats: 0.043432\n",
      "Train Log likelihood, step 51500 in nats: 0.043456\n",
      "Train epoch average loss: 0.04345172290036771\n",
      "\n",
      "\n",
      "Epoch: 316\n",
      "Train Log likelihood, step 51550 in nats: 0.043517\n",
      "Train Log likelihood, step 51600 in nats: 0.043562\n",
      "Train Log likelihood, step 51650 in nats: 0.043607\n",
      "Train epoch average loss: 0.04361489037959623\n",
      "\n",
      "\n",
      "Epoch: 317\n",
      "Train Log likelihood, step 51700 in nats: 0.043637\n",
      "Train Log likelihood, step 51750 in nats: 0.043703\n",
      "Train Log likelihood, step 51800 in nats: 0.043731\n",
      "Train epoch average loss: 0.043768734532637056\n",
      "\n",
      "\n",
      "Epoch: 318\n",
      "Train Log likelihood, step 51850 in nats: 0.043791\n",
      "Train Log likelihood, step 51900 in nats: 0.043824\n",
      "Train Log likelihood, step 51950 in nats: 0.043886\n",
      "Train epoch average loss: 0.04393318357065703\n",
      "\n",
      "\n",
      "Epoch: 319\n",
      "Train Log likelihood, step 52000 in nats: 0.043935\n",
      "Train Log likelihood, step 52050 in nats: 0.043985\n",
      "Train Log likelihood, step 52100 in nats: 0.044041\n",
      "Train Log likelihood, step 52150 in nats: 0.044053\n",
      "Train epoch average loss: 0.04405907231171147\n",
      "\n",
      "\n",
      "Epoch: 320\n",
      "Train Log likelihood, step 52200 in nats: 0.044081\n",
      "Train Log likelihood, step 52250 in nats: 0.044130\n",
      "Train Log likelihood, step 52300 in nats: 0.044175\n",
      "Train epoch average loss: 0.0441929547976112\n",
      "\n",
      "\n",
      "Epoch: 321\n",
      "Train Log likelihood, step 52350 in nats: 0.044235\n",
      "Train Log likelihood, step 52400 in nats: 0.044251\n",
      "Train Log likelihood, step 52450 in nats: 0.044311\n",
      "Train epoch average loss: 0.04433919876423221\n",
      "\n",
      "\n",
      "Epoch: 322\n",
      "Train Log likelihood, step 52500 in nats: 0.044357\n",
      "Train Log likelihood, step 52550 in nats: 0.044398\n",
      "Train Log likelihood, step 52600 in nats: 0.044440\n",
      "Train epoch average loss: 0.044472400998600156\n",
      "\n",
      "\n",
      "Epoch: 323\n",
      "Train Log likelihood, step 52650 in nats: 0.044476\n",
      "Train Log likelihood, step 52700 in nats: 0.044482\n",
      "Train Log likelihood, step 52750 in nats: 0.044521\n",
      "Train Log likelihood, step 52800 in nats: 0.044557\n",
      "Train epoch average loss: 0.04455393441793307\n",
      "\n",
      "\n",
      "Epoch: 324\n",
      "Train Log likelihood, step 52850 in nats: 0.044563\n",
      "Train Log likelihood, step 52900 in nats: 0.044572\n",
      "Train Log likelihood, step 52950 in nats: 0.044610\n",
      "Train epoch average loss: 0.04464889604521328\n",
      "\n",
      "\n",
      "Epoch: 325\n",
      "Train Log likelihood, step 53000 in nats: 0.044666\n",
      "Train Log likelihood, step 53050 in nats: 0.044718\n",
      "Train Log likelihood, step 53100 in nats: 0.044770\n",
      "Train epoch average loss: 0.04479917436039153\n",
      "\n",
      "\n",
      "Epoch: 326\n",
      "Train Log likelihood, step 53150 in nats: 0.044810\n",
      "Train Log likelihood, step 53200 in nats: 0.044867\n",
      "Train Log likelihood, step 53250 in nats: 0.044908\n",
      "Train Log likelihood, step 53300 in nats: 0.044943\n",
      "Train epoch average loss: 0.0449434221060535\n",
      "\n",
      "\n",
      "Epoch: 327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 53350 in nats: 0.044984\n",
      "Train Log likelihood, step 53400 in nats: 0.045018\n",
      "Train Log likelihood, step 53450 in nats: 0.045059\n",
      "Train epoch average loss: 0.0450602077708292\n",
      "\n",
      "\n",
      "Epoch: 328\n",
      "Train Log likelihood, step 53500 in nats: 0.045083\n",
      "Train Log likelihood, step 53550 in nats: 0.045132\n",
      "Train Log likelihood, step 53600 in nats: 0.045167\n",
      "Train epoch average loss: 0.045161167027942914\n",
      "\n",
      "\n",
      "Epoch: 329\n",
      "Train Log likelihood, step 53650 in nats: 0.045172\n",
      "Train Log likelihood, step 53700 in nats: 0.045190\n",
      "Train Log likelihood, step 53750 in nats: 0.045219\n",
      "Train epoch average loss: 0.045239548276672044\n",
      "\n",
      "\n",
      "Epoch: 330\n",
      "Train Log likelihood, step 53800 in nats: 0.045252\n",
      "Train Log likelihood, step 53850 in nats: 0.045277\n",
      "Train Log likelihood, step 53900 in nats: 0.045293\n",
      "Train Log likelihood, step 53950 in nats: 0.045351\n",
      "Train epoch average loss: 0.04534760983062689\n",
      "\n",
      "\n",
      "Epoch: 331\n",
      "Train Log likelihood, step 54000 in nats: 0.045353\n",
      "Train Log likelihood, step 54050 in nats: 0.045385\n",
      "Train Log likelihood, step 54100 in nats: 0.045425\n",
      "Train epoch average loss: 0.045443142385050865\n",
      "\n",
      "\n",
      "Epoch: 332\n",
      "Train Log likelihood, step 54150 in nats: 0.045466\n",
      "Train Log likelihood, step 54200 in nats: 0.045510\n",
      "Train Log likelihood, step 54250 in nats: 0.045563\n",
      "Train epoch average loss: 0.04558968714972973\n",
      "\n",
      "\n",
      "Epoch: 333\n",
      "Train Log likelihood, step 54300 in nats: 0.045614\n",
      "Train Log likelihood, step 54350 in nats: 0.045631\n",
      "Train Log likelihood, step 54400 in nats: 0.045672\n",
      "Train epoch average loss: 0.045717496095519485\n",
      "\n",
      "\n",
      "Epoch: 334\n",
      "Train Log likelihood, step 54450 in nats: 0.045719\n",
      "Train Log likelihood, step 54500 in nats: 0.045723\n",
      "Train Log likelihood, step 54550 in nats: 0.045754\n",
      "Train Log likelihood, step 54600 in nats: 0.045807\n",
      "Train epoch average loss: 0.045816428147915804\n",
      "\n",
      "\n",
      "Epoch: 335\n",
      "Train Log likelihood, step 54650 in nats: 0.045879\n",
      "Train Log likelihood, step 54700 in nats: 0.045894\n",
      "Train Log likelihood, step 54750 in nats: 0.045943\n",
      "Train epoch average loss: 0.04595928161481207\n",
      "\n",
      "\n",
      "Epoch: 336\n",
      "Train Log likelihood, step 54800 in nats: 0.046003\n",
      "Train Log likelihood, step 54850 in nats: 0.046048\n",
      "Train Log likelihood, step 54900 in nats: 0.046055\n",
      "Train epoch average loss: 0.04603940985701417\n",
      "\n",
      "\n",
      "Epoch: 337\n",
      "Train Log likelihood, step 54950 in nats: 0.046056\n",
      "Train Log likelihood, step 55000 in nats: 0.046091\n",
      "Train Log likelihood, step 55050 in nats: 0.046140\n",
      "Train epoch average loss: 0.04616120221796389\n",
      "\n",
      "\n",
      "Epoch: 338\n",
      "Train Log likelihood, step 55100 in nats: 0.046172\n",
      "Train Log likelihood, step 55150 in nats: 0.046196\n",
      "Train Log likelihood, step 55200 in nats: 0.046234\n",
      "Train Log likelihood, step 55250 in nats: 0.046281\n",
      "Train epoch average loss: 0.04628297623357163\n",
      "\n",
      "\n",
      "Epoch: 339\n",
      "Train Log likelihood, step 55300 in nats: 0.046306\n",
      "Train Log likelihood, step 55350 in nats: 0.046371\n",
      "Train Log likelihood, step 55400 in nats: 0.046421\n",
      "Train epoch average loss: 0.046439947594635725\n",
      "\n",
      "\n",
      "Epoch: 340\n",
      "Train Log likelihood, step 55450 in nats: 0.046484\n",
      "Train Log likelihood, step 55500 in nats: 0.046524\n",
      "Train Log likelihood, step 55550 in nats: 0.046543\n",
      "Train epoch average loss: 0.04657567555443941\n",
      "\n",
      "\n",
      "Epoch: 341\n",
      "Train Log likelihood, step 55600 in nats: 0.046585\n",
      "Train Log likelihood, step 55650 in nats: 0.046619\n",
      "Train Log likelihood, step 55700 in nats: 0.046660\n",
      "Train epoch average loss: 0.04668866200954611\n",
      "\n",
      "\n",
      "Epoch: 342\n",
      "Train Log likelihood, step 55750 in nats: 0.046693\n",
      "Train Log likelihood, step 55800 in nats: 0.046728\n",
      "Train Log likelihood, step 55850 in nats: 0.046757\n",
      "Train Log likelihood, step 55900 in nats: 0.046802\n",
      "Train epoch average loss: 0.04681644421741082\n",
      "\n",
      "\n",
      "Epoch: 343\n",
      "Train Log likelihood, step 55950 in nats: 0.046856\n",
      "Train Log likelihood, step 56000 in nats: 0.046881\n",
      "Train Log likelihood, step 56050 in nats: 0.046934\n",
      "Train epoch average loss: 0.04694739464836465\n",
      "\n",
      "\n",
      "Epoch: 344\n",
      "Train Log likelihood, step 56100 in nats: 0.046971\n",
      "Train Log likelihood, step 56150 in nats: 0.046989\n",
      "Train Log likelihood, step 56200 in nats: 0.047032\n",
      "Train epoch average loss: 0.04705030256093158\n",
      "\n",
      "\n",
      "Epoch: 345\n",
      "Train Log likelihood, step 56250 in nats: 0.047045\n",
      "Train Log likelihood, step 56300 in nats: 0.047063\n",
      "Train Log likelihood, step 56350 in nats: 0.047097\n",
      "Train epoch average loss: 0.04709922627790089\n",
      "\n",
      "\n",
      "Epoch: 346\n",
      "Train Log likelihood, step 56400 in nats: 0.047095\n",
      "Train Log likelihood, step 56450 in nats: 0.047134\n",
      "Train Log likelihood, step 56500 in nats: 0.047171\n",
      "Train Log likelihood, step 56550 in nats: 0.047188\n",
      "Train epoch average loss: 0.04717149987379878\n",
      "\n",
      "\n",
      "Epoch: 347\n",
      "Train Log likelihood, step 56600 in nats: 0.047174\n",
      "Train Log likelihood, step 56650 in nats: 0.047199\n",
      "Train Log likelihood, step 56700 in nats: 0.047232\n",
      "Train epoch average loss: 0.047251252464576676\n",
      "\n",
      "\n",
      "Epoch: 348\n",
      "Train Log likelihood, step 56750 in nats: 0.047269\n",
      "Train Log likelihood, step 56800 in nats: 0.047320\n",
      "Train Log likelihood, step 56850 in nats: 0.047374\n",
      "Train epoch average loss: 0.047386983492126285\n",
      "\n",
      "\n",
      "Epoch: 349\n",
      "Train Log likelihood, step 56900 in nats: 0.047408\n",
      "Train Log likelihood, step 56950 in nats: 0.047445\n",
      "Train Log likelihood, step 57000 in nats: 0.047492\n",
      "Train epoch average loss: 0.047525153238953295\n",
      "\n",
      "\n",
      "Epoch: 350\n",
      "Train Log likelihood, step 57050 in nats: 0.047523\n",
      "Train Log likelihood, step 57100 in nats: 0.047548\n",
      "Train Log likelihood, step 57150 in nats: 0.047571\n",
      "Train Log likelihood, step 57200 in nats: 0.047574\n",
      "Train epoch average loss: 0.04758655310711249\n",
      "\n",
      "\n",
      "Epoch: 351\n",
      "Train Log likelihood, step 57250 in nats: 0.047596\n",
      "Train Log likelihood, step 57300 in nats: 0.047633\n",
      "Train Log likelihood, step 57350 in nats: 0.047684\n",
      "Train epoch average loss: 0.047696836412813075\n",
      "\n",
      "\n",
      "Epoch: 352\n",
      "Train Log likelihood, step 57400 in nats: 0.047715\n",
      "Train Log likelihood, step 57450 in nats: 0.047767\n",
      "Train Log likelihood, step 57500 in nats: 0.047779\n",
      "Train epoch average loss: 0.04778597016758814\n",
      "\n",
      "\n",
      "Epoch: 353\n",
      "Train Log likelihood, step 57550 in nats: 0.047790\n",
      "Train Log likelihood, step 57600 in nats: 0.047822\n",
      "Train Log likelihood, step 57650 in nats: 0.047863\n",
      "Train Log likelihood, step 57700 in nats: 0.047914\n",
      "Train epoch average loss: 0.04791248248098317\n",
      "\n",
      "\n",
      "Epoch: 354\n",
      "Train Log likelihood, step 57750 in nats: 0.047937\n",
      "Train Log likelihood, step 57800 in nats: 0.047951\n",
      "Train Log likelihood, step 57850 in nats: 0.047961\n",
      "Train epoch average loss: 0.04796843276276667\n",
      "\n",
      "\n",
      "Epoch: 355\n",
      "Train Log likelihood, step 57900 in nats: 0.047985\n",
      "Train Log likelihood, step 57950 in nats: 0.048027\n",
      "Train Log likelihood, step 58000 in nats: 0.048045\n",
      "Train epoch average loss: 0.04804799477724216\n",
      "\n",
      "\n",
      "Epoch: 356\n",
      "Train Log likelihood, step 58050 in nats: 0.048056\n",
      "Train Log likelihood, step 58100 in nats: 0.048095\n",
      "Train Log likelihood, step 58150 in nats: 0.048104\n",
      "Train epoch average loss: 0.0481283722539508\n",
      "\n",
      "\n",
      "Epoch: 357\n",
      "Train Log likelihood, step 58200 in nats: 0.048130\n",
      "Train Log likelihood, step 58250 in nats: 0.048146\n",
      "Train Log likelihood, step 58300 in nats: 0.048165\n",
      "Train Log likelihood, step 58350 in nats: 0.048200\n",
      "Train epoch average loss: 0.048200774172842735\n",
      "\n",
      "\n",
      "Epoch: 358\n",
      "Train Log likelihood, step 58400 in nats: 0.048206\n",
      "Train Log likelihood, step 58450 in nats: 0.048255\n",
      "Train Log likelihood, step 58500 in nats: 0.048300\n",
      "Train epoch average loss: 0.04831284747427437\n",
      "\n",
      "\n",
      "Epoch: 359\n",
      "Train Log likelihood, step 58550 in nats: 0.048340\n",
      "Train Log likelihood, step 58600 in nats: 0.048374\n",
      "Train Log likelihood, step 58650 in nats: 0.048407\n",
      "Train epoch average loss: 0.04842660269547758\n",
      "\n",
      "\n",
      "Epoch: 360\n",
      "Train Log likelihood, step 58700 in nats: 0.048437\n",
      "Train Log likelihood, step 58750 in nats: 0.048453\n",
      "Train Log likelihood, step 58800 in nats: 0.048465\n",
      "Train epoch average loss: 0.04848721831868883\n",
      "\n",
      "\n",
      "Epoch: 361\n",
      "Train Log likelihood, step 58850 in nats: 0.048485\n",
      "Train Log likelihood, step 58900 in nats: 0.048493\n",
      "Train Log likelihood, step 58950 in nats: 0.048523\n",
      "Train Log likelihood, step 59000 in nats: 0.048549\n",
      "Train epoch average loss: 0.04855150218409801\n",
      "\n",
      "\n",
      "Epoch: 362\n",
      "Train Log likelihood, step 59050 in nats: 0.048580\n",
      "Train Log likelihood, step 59100 in nats: 0.048580\n",
      "Train Log likelihood, step 59150 in nats: 0.048605\n",
      "Train epoch average loss: 0.04860804095901576\n",
      "\n",
      "\n",
      "Epoch: 363\n",
      "Train Log likelihood, step 59200 in nats: 0.048622\n",
      "Train Log likelihood, step 59250 in nats: 0.048670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 59300 in nats: 0.048695\n",
      "Train epoch average loss: 0.048711250614050926\n",
      "\n",
      "\n",
      "Epoch: 364\n",
      "Train Log likelihood, step 59350 in nats: 0.048718\n",
      "Train Log likelihood, step 59400 in nats: 0.048740\n",
      "Train Log likelihood, step 59450 in nats: 0.048766\n",
      "Train epoch average loss: 0.04877627053580766\n",
      "\n",
      "\n",
      "Epoch: 365\n",
      "Train Log likelihood, step 59500 in nats: 0.048776\n",
      "Train Log likelihood, step 59550 in nats: 0.048815\n",
      "Train Log likelihood, step 59600 in nats: 0.048834\n",
      "Train Log likelihood, step 59650 in nats: 0.048875\n",
      "Train epoch average loss: 0.04887513869176307\n",
      "\n",
      "\n",
      "Epoch: 366\n",
      "Train Log likelihood, step 59700 in nats: 0.048910\n",
      "Train Log likelihood, step 59750 in nats: 0.048934\n",
      "Train Log likelihood, step 59800 in nats: 0.048943\n",
      "Train epoch average loss: 0.048950215193149064\n",
      "\n",
      "\n",
      "Epoch: 367\n",
      "Train Log likelihood, step 59850 in nats: 0.048959\n",
      "Train Log likelihood, step 59900 in nats: 0.048979\n",
      "Train Log likelihood, step 59950 in nats: 0.049019\n",
      "Train epoch average loss: 0.04905169808710586\n",
      "\n",
      "\n",
      "Epoch: 368\n",
      "Train Log likelihood, step 60000 in nats: 0.049070\n",
      "Train Log likelihood, step 60050 in nats: 0.049096\n",
      "Train Log likelihood, step 60100 in nats: 0.049101\n",
      "Train epoch average loss: 0.04912987063176482\n",
      "\n",
      "\n",
      "Epoch: 369\n",
      "Train Log likelihood, step 60150 in nats: 0.049134\n",
      "Train Log likelihood, step 60200 in nats: 0.049184\n",
      "Train Log likelihood, step 60250 in nats: 0.049210\n",
      "Train Log likelihood, step 60300 in nats: 0.049236\n",
      "Train epoch average loss: 0.04924157423816386\n",
      "\n",
      "\n",
      "Epoch: 370\n",
      "Train Log likelihood, step 60350 in nats: 0.049284\n",
      "Train Log likelihood, step 60400 in nats: 0.049325\n",
      "Train Log likelihood, step 60450 in nats: 0.049349\n",
      "Train epoch average loss: 0.04936081485319897\n",
      "\n",
      "\n",
      "Epoch: 371\n",
      "Train Log likelihood, step 60500 in nats: 0.049377\n",
      "Train Log likelihood, step 60550 in nats: 0.049403\n",
      "Train Log likelihood, step 60600 in nats: 0.049431\n",
      "Train epoch average loss: 0.04945414454053102\n",
      "\n",
      "\n",
      "Epoch: 372\n",
      "Train Log likelihood, step 60650 in nats: 0.049471\n",
      "Train Log likelihood, step 60700 in nats: 0.049487\n",
      "Train Log likelihood, step 60750 in nats: 0.049498\n",
      "Train epoch average loss: 0.049534260367001925\n",
      "\n",
      "\n",
      "Epoch: 373\n",
      "Train Log likelihood, step 60800 in nats: 0.049537\n",
      "Train Log likelihood, step 60850 in nats: 0.049554\n",
      "Train Log likelihood, step 60900 in nats: 0.049579\n",
      "Train Log likelihood, step 60950 in nats: 0.049604\n",
      "Train epoch average loss: 0.049618222729943616\n",
      "\n",
      "\n",
      "Epoch: 374\n",
      "Train Log likelihood, step 61000 in nats: 0.049655\n",
      "Train Log likelihood, step 61050 in nats: 0.049676\n",
      "Train Log likelihood, step 61100 in nats: 0.049728\n",
      "Train epoch average loss: 0.04975283381288763\n",
      "\n",
      "\n",
      "Epoch: 375\n",
      "Train Log likelihood, step 61150 in nats: 0.049774\n",
      "Train Log likelihood, step 61200 in nats: 0.049790\n",
      "Train Log likelihood, step 61250 in nats: 0.049805\n",
      "Train epoch average loss: 0.049832920006522376\n",
      "\n",
      "\n",
      "Epoch: 376\n",
      "Train Log likelihood, step 61300 in nats: 0.049832\n",
      "Train Log likelihood, step 61350 in nats: 0.049865\n",
      "Train Log likelihood, step 61400 in nats: 0.049913\n",
      "Train Log likelihood, step 61450 in nats: 0.049934\n",
      "Train epoch average loss: 0.04993378086907968\n",
      "\n",
      "\n",
      "Epoch: 377\n",
      "Train Log likelihood, step 61500 in nats: 0.049971\n",
      "Train Log likelihood, step 61550 in nats: 0.050016\n",
      "Train Log likelihood, step 61600 in nats: 0.050032\n",
      "Train epoch average loss: 0.05003410260119777\n",
      "\n",
      "\n",
      "Epoch: 378\n",
      "Train Log likelihood, step 61650 in nats: 0.050036\n",
      "Train Log likelihood, step 61700 in nats: 0.050029\n",
      "Train Log likelihood, step 61750 in nats: 0.050048\n",
      "Train epoch average loss: 0.0500644860436069\n",
      "\n",
      "\n",
      "Epoch: 379\n",
      "Train Log likelihood, step 61800 in nats: 0.050087\n",
      "Train Log likelihood, step 61850 in nats: 0.050122\n",
      "Train Log likelihood, step 61900 in nats: 0.050152\n",
      "Train epoch average loss: 0.05016904765492724\n",
      "\n",
      "\n",
      "Epoch: 380\n",
      "Train Log likelihood, step 61950 in nats: 0.050168\n",
      "Train Log likelihood, step 62000 in nats: 0.050170\n",
      "Train Log likelihood, step 62050 in nats: 0.050180\n",
      "Train Log likelihood, step 62100 in nats: 0.050194\n",
      "Train epoch average loss: 0.05019466909719421\n",
      "\n",
      "\n",
      "Epoch: 381\n",
      "Train Log likelihood, step 62150 in nats: 0.050233\n",
      "Train Log likelihood, step 62200 in nats: 0.050282\n",
      "Train Log likelihood, step 62250 in nats: 0.050307\n",
      "Train epoch average loss: 0.05032529127537157\n",
      "\n",
      "\n",
      "Epoch: 382\n",
      "Train Log likelihood, step 62300 in nats: 0.050346\n",
      "Train Log likelihood, step 62350 in nats: 0.050377\n",
      "Train Log likelihood, step 62400 in nats: 0.050410\n",
      "Train epoch average loss: 0.0504325527733189\n",
      "\n",
      "\n",
      "Epoch: 383\n",
      "Train Log likelihood, step 62450 in nats: 0.050445\n",
      "Train Log likelihood, step 62500 in nats: 0.050471\n",
      "Train Log likelihood, step 62550 in nats: 0.050486\n",
      "Train epoch average loss: 0.050532746149589115\n",
      "\n",
      "\n",
      "Epoch: 384\n",
      "Train Log likelihood, step 62600 in nats: 0.050534\n",
      "Train Log likelihood, step 62650 in nats: 0.050553\n",
      "Train Log likelihood, step 62700 in nats: 0.050579\n",
      "Train Log likelihood, step 62750 in nats: 0.050586\n",
      "Train epoch average loss: 0.05059124501798155\n",
      "\n",
      "\n",
      "Epoch: 385\n",
      "Train Log likelihood, step 62800 in nats: 0.050640\n",
      "Train Log likelihood, step 62850 in nats: 0.050672\n",
      "Train Log likelihood, step 62900 in nats: 0.050713\n",
      "Train epoch average loss: 0.050724844132850486\n",
      "\n",
      "\n",
      "Epoch: 386\n",
      "Train Log likelihood, step 62950 in nats: 0.050754\n",
      "Train Log likelihood, step 63000 in nats: 0.050770\n",
      "Train Log likelihood, step 63050 in nats: 0.050804\n",
      "Train epoch average loss: 0.050819896565472304\n",
      "\n",
      "\n",
      "Epoch: 387\n",
      "Train Log likelihood, step 63100 in nats: 0.050832\n",
      "Train Log likelihood, step 63150 in nats: 0.050871\n",
      "Train Log likelihood, step 63200 in nats: 0.050907\n",
      "Train epoch average loss: 0.050945657699429235\n",
      "\n",
      "\n",
      "Epoch: 388\n",
      "Train Log likelihood, step 63250 in nats: 0.050949\n",
      "Train Log likelihood, step 63300 in nats: 0.050989\n",
      "Train Log likelihood, step 63350 in nats: 0.051018\n",
      "Train Log likelihood, step 63400 in nats: 0.051060\n",
      "Train epoch average loss: 0.051066011459075786\n",
      "\n",
      "\n",
      "Epoch: 389\n",
      "Train Log likelihood, step 63450 in nats: 0.051110\n",
      "Train Log likelihood, step 63500 in nats: 0.051143\n",
      "Train Log likelihood, step 63550 in nats: 0.051183\n",
      "Train epoch average loss: 0.05119589577921149\n",
      "\n",
      "\n",
      "Epoch: 390\n",
      "Train Log likelihood, step 63600 in nats: 0.051215\n",
      "Train Log likelihood, step 63650 in nats: 0.051216\n",
      "Train Log likelihood, step 63700 in nats: 0.051225\n",
      "Train epoch average loss: 0.05124792270960427\n",
      "\n",
      "\n",
      "Epoch: 391\n",
      "Train Log likelihood, step 63750 in nats: 0.051256\n",
      "Train Log likelihood, step 63800 in nats: 0.051294\n",
      "Train Log likelihood, step 63850 in nats: 0.051326\n",
      "Train epoch average loss: 0.05134296614964977\n",
      "\n",
      "\n",
      "Epoch: 392\n",
      "Train Log likelihood, step 63900 in nats: 0.051342\n",
      "Train Log likelihood, step 63950 in nats: 0.051382\n",
      "Train Log likelihood, step 64000 in nats: 0.051426\n",
      "Train Log likelihood, step 64050 in nats: 0.051453\n",
      "Train epoch average loss: 0.051459882344327225\n",
      "\n",
      "\n",
      "Epoch: 393\n",
      "Train Log likelihood, step 64100 in nats: 0.051485\n",
      "Train Log likelihood, step 64150 in nats: 0.051534\n",
      "Train Log likelihood, step 64200 in nats: 0.051543\n",
      "Train epoch average loss: 0.05155942276689568\n",
      "\n",
      "\n",
      "Epoch: 394\n",
      "Train Log likelihood, step 64250 in nats: 0.051584\n",
      "Train Log likelihood, step 64300 in nats: 0.051612\n",
      "Train Log likelihood, step 64350 in nats: 0.051617\n",
      "Train epoch average loss: 0.05163265508566008\n",
      "\n",
      "\n",
      "Epoch: 395\n",
      "Train Log likelihood, step 64400 in nats: 0.051636\n",
      "Train Log likelihood, step 64450 in nats: 0.051654\n",
      "Train Log likelihood, step 64500 in nats: 0.051667\n",
      "Train epoch average loss: 0.0516777334403664\n",
      "\n",
      "\n",
      "Epoch: 396\n",
      "Train Log likelihood, step 64550 in nats: 0.051683\n",
      "Train Log likelihood, step 64600 in nats: 0.051713\n",
      "Train Log likelihood, step 64650 in nats: 0.051759\n",
      "Train Log likelihood, step 64700 in nats: 0.051785\n",
      "Train epoch average loss: 0.0517917960266875\n",
      "\n",
      "\n",
      "Epoch: 397\n",
      "Train Log likelihood, step 64750 in nats: 0.051813\n",
      "Train Log likelihood, step 64800 in nats: 0.051861\n",
      "Train Log likelihood, step 64850 in nats: 0.051893\n",
      "Train epoch average loss: 0.051911072957187915\n",
      "\n",
      "\n",
      "Epoch: 398\n",
      "Train Log likelihood, step 64900 in nats: 0.051924\n",
      "Train Log likelihood, step 64950 in nats: 0.051944\n",
      "Train Log likelihood, step 65000 in nats: 0.051959\n",
      "Train epoch average loss: 0.05198277659204393\n",
      "\n",
      "\n",
      "Epoch: 399\n",
      "Train Log likelihood, step 65050 in nats: 0.051985\n",
      "Train Log likelihood, step 65100 in nats: 0.052025\n",
      "Train Log likelihood, step 65150 in nats: 0.052072\n",
      "Train epoch average loss: 0.052073126405682894\n",
      "\n",
      "\n",
      "Epoch: 400\n",
      "Train Log likelihood, step 65200 in nats: 0.052071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 65250 in nats: 0.052083\n",
      "Train Log likelihood, step 65300 in nats: 0.052086\n",
      "Train Log likelihood, step 65350 in nats: 0.052092\n",
      "Train epoch average loss: 0.05208971128375738\n",
      "\n",
      "\n",
      "Epoch: 401\n",
      "Train Log likelihood, step 65400 in nats: 0.052115\n",
      "Train Log likelihood, step 65450 in nats: 0.052148\n",
      "Train Log likelihood, step 65500 in nats: 0.052195\n",
      "Train epoch average loss: 0.05221892695191357\n",
      "\n",
      "\n",
      "Epoch: 402\n",
      "Train Log likelihood, step 65550 in nats: 0.052224\n",
      "Train Log likelihood, step 65600 in nats: 0.052245\n",
      "Train Log likelihood, step 65650 in nats: 0.052275\n",
      "Train epoch average loss: 0.052284568023057774\n",
      "\n",
      "\n",
      "Epoch: 403\n",
      "Train Log likelihood, step 65700 in nats: 0.052296\n",
      "Train Log likelihood, step 65750 in nats: 0.052335\n",
      "Train Log likelihood, step 65800 in nats: 0.052358\n",
      "Train Log likelihood, step 65850 in nats: 0.052378\n",
      "Train epoch average loss: 0.05237852376802848\n",
      "\n",
      "\n",
      "Epoch: 404\n",
      "Train Log likelihood, step 65900 in nats: 0.052412\n",
      "Train Log likelihood, step 65950 in nats: 0.052450\n",
      "Train Log likelihood, step 66000 in nats: 0.052489\n",
      "Train epoch average loss: 0.05249268238351204\n",
      "\n",
      "\n",
      "Epoch: 405\n",
      "Train Log likelihood, step 66050 in nats: 0.052518\n",
      "Train Log likelihood, step 66100 in nats: 0.052549\n",
      "Train Log likelihood, step 66150 in nats: 0.052565\n",
      "Train epoch average loss: 0.05257898950728657\n",
      "\n",
      "\n",
      "Epoch: 406\n",
      "Train Log likelihood, step 66200 in nats: 0.052599\n",
      "Train Log likelihood, step 66250 in nats: 0.052612\n",
      "Train Log likelihood, step 66300 in nats: 0.052621\n",
      "Train epoch average loss: 0.052641538309915935\n",
      "\n",
      "\n",
      "Epoch: 407\n",
      "Train Log likelihood, step 66350 in nats: 0.052647\n",
      "Train Log likelihood, step 66400 in nats: 0.052671\n",
      "Train Log likelihood, step 66450 in nats: 0.052701\n",
      "Train Log likelihood, step 66500 in nats: 0.052733\n",
      "Train epoch average loss: 0.05273509004359692\n",
      "\n",
      "\n",
      "Epoch: 408\n",
      "Train Log likelihood, step 66550 in nats: 0.052761\n",
      "Train Log likelihood, step 66600 in nats: 0.052788\n",
      "Train Log likelihood, step 66650 in nats: 0.052830\n",
      "Train epoch average loss: 0.05282583419655641\n",
      "\n",
      "\n",
      "Epoch: 409\n",
      "Train Log likelihood, step 66700 in nats: 0.052852\n",
      "Train Log likelihood, step 66750 in nats: 0.052850\n",
      "Train Log likelihood, step 66800 in nats: 0.052869\n",
      "Train epoch average loss: 0.05289330724422678\n",
      "\n",
      "\n",
      "Epoch: 410\n",
      "Train Log likelihood, step 66850 in nats: 0.052907\n",
      "Train Log likelihood, step 66900 in nats: 0.052955\n",
      "Train Log likelihood, step 66950 in nats: 0.052976\n",
      "Train epoch average loss: 0.0530107442245468\n",
      "\n",
      "\n",
      "Epoch: 411\n",
      "Train Log likelihood, step 67000 in nats: 0.053017\n",
      "Train Log likelihood, step 67050 in nats: 0.053048\n",
      "Train Log likelihood, step 67100 in nats: 0.053066\n",
      "Train Log likelihood, step 67150 in nats: 0.053092\n",
      "Train epoch average loss: 0.05309061888013552\n",
      "\n",
      "\n",
      "Epoch: 412\n",
      "Train Log likelihood, step 67200 in nats: 0.053105\n",
      "Train Log likelihood, step 67250 in nats: 0.053130\n",
      "Train Log likelihood, step 67300 in nats: 0.053152\n",
      "Train epoch average loss: 0.05315073800521807\n",
      "\n",
      "\n",
      "Epoch: 413\n",
      "Train Log likelihood, step 67350 in nats: 0.053159\n",
      "Train Log likelihood, step 67400 in nats: 0.053198\n",
      "Train Log likelihood, step 67450 in nats: 0.053236\n",
      "Train epoch average loss: 0.05325117383688462\n",
      "\n",
      "\n",
      "Epoch: 414\n",
      "Train Log likelihood, step 67500 in nats: 0.053267\n",
      "Train Log likelihood, step 67550 in nats: 0.053292\n",
      "Train Log likelihood, step 67600 in nats: 0.053330\n",
      "Train epoch average loss: 0.05334414035970426\n",
      "\n",
      "\n",
      "Epoch: 415\n",
      "Train Log likelihood, step 67650 in nats: 0.053346\n",
      "Train Log likelihood, step 67700 in nats: 0.053360\n",
      "Train Log likelihood, step 67750 in nats: 0.053402\n",
      "Train Log likelihood, step 67800 in nats: 0.053441\n",
      "Train epoch average loss: 0.05344287897153172\n",
      "\n",
      "\n",
      "Epoch: 416\n",
      "Train Log likelihood, step 67850 in nats: 0.053476\n",
      "Train Log likelihood, step 67900 in nats: 0.053485\n",
      "Train Log likelihood, step 67950 in nats: 0.053502\n",
      "Train epoch average loss: 0.05352150485455199\n",
      "\n",
      "\n",
      "Epoch: 417\n",
      "Train Log likelihood, step 68000 in nats: 0.053543\n",
      "Train Log likelihood, step 68050 in nats: 0.053556\n",
      "Train Log likelihood, step 68100 in nats: 0.053558\n",
      "Train epoch average loss: 0.053573340817348804\n",
      "\n",
      "\n",
      "Epoch: 418\n",
      "Train Log likelihood, step 68150 in nats: 0.053578\n",
      "Train Log likelihood, step 68200 in nats: 0.053625\n",
      "Train Log likelihood, step 68250 in nats: 0.053658\n",
      "Train epoch average loss: 0.05366437589447097\n",
      "\n",
      "\n",
      "Epoch: 419\n",
      "Train Log likelihood, step 68300 in nats: 0.053665\n",
      "Train Log likelihood, step 68350 in nats: 0.053699\n",
      "Train Log likelihood, step 68400 in nats: 0.053742\n",
      "Train Log likelihood, step 68450 in nats: 0.053795\n",
      "Train epoch average loss: 0.05379758445658428\n",
      "\n",
      "\n",
      "Epoch: 420\n",
      "Train Log likelihood, step 68500 in nats: 0.053825\n",
      "Train Log likelihood, step 68550 in nats: 0.053856\n",
      "Train Log likelihood, step 68600 in nats: 0.053892\n",
      "Train epoch average loss: 0.053899730368013196\n",
      "\n",
      "\n",
      "Epoch: 421\n",
      "Train Log likelihood, step 68650 in nats: 0.053911\n",
      "Train Log likelihood, step 68700 in nats: 0.053928\n",
      "Train Log likelihood, step 68750 in nats: 0.053942\n",
      "Train epoch average loss: 0.053961275652498454\n",
      "\n",
      "\n",
      "Epoch: 422\n",
      "Train Log likelihood, step 68800 in nats: 0.053956\n",
      "Train Log likelihood, step 68850 in nats: 0.053973\n",
      "Train Log likelihood, step 68900 in nats: 0.054000\n",
      "Train epoch average loss: 0.05400173826181532\n",
      "\n",
      "\n",
      "Epoch: 423\n",
      "Train Log likelihood, step 68950 in nats: 0.054003\n",
      "Train Log likelihood, step 69000 in nats: 0.054034\n",
      "Train Log likelihood, step 69050 in nats: 0.054027\n",
      "Train Log likelihood, step 69100 in nats: 0.054056\n",
      "Train epoch average loss: 0.054061838539978924\n",
      "\n",
      "\n",
      "Epoch: 424\n",
      "Train Log likelihood, step 69150 in nats: 0.054091\n",
      "Train Log likelihood, step 69200 in nats: 0.054139\n",
      "Train Log likelihood, step 69250 in nats: 0.054174\n",
      "Train epoch average loss: 0.054171512372008374\n",
      "\n",
      "\n",
      "Epoch: 425\n",
      "Train Log likelihood, step 69300 in nats: 0.054192\n",
      "Train Log likelihood, step 69350 in nats: 0.054232\n",
      "Train Log likelihood, step 69400 in nats: 0.054262\n",
      "Train epoch average loss: 0.054288570185959055\n",
      "\n",
      "\n",
      "Epoch: 426\n",
      "Train Log likelihood, step 69450 in nats: 0.054291\n",
      "Train Log likelihood, step 69500 in nats: 0.054328\n",
      "Train Log likelihood, step 69550 in nats: 0.054329\n",
      "Train Log likelihood, step 69600 in nats: 0.054330\n",
      "Train epoch average loss: 0.054329924923449444\n",
      "\n",
      "\n",
      "Epoch: 427\n",
      "Train Log likelihood, step 69650 in nats: 0.054350\n",
      "Train Log likelihood, step 69700 in nats: 0.054373\n",
      "Train Log likelihood, step 69750 in nats: 0.054391\n",
      "Train epoch average loss: 0.0544047357225661\n",
      "\n",
      "\n",
      "Epoch: 428\n",
      "Train Log likelihood, step 69800 in nats: 0.054436\n",
      "Train Log likelihood, step 69850 in nats: 0.054477\n",
      "Train Log likelihood, step 69900 in nats: 0.054505\n",
      "Train epoch average loss: 0.054528690326003396\n",
      "\n",
      "\n",
      "Epoch: 429\n",
      "Train Log likelihood, step 69950 in nats: 0.054540\n",
      "Train Log likelihood, step 70000 in nats: 0.054547\n",
      "Train Log likelihood, step 70050 in nats: 0.054584\n",
      "Train epoch average loss: 0.054608080839079656\n",
      "\n",
      "\n",
      "Epoch: 430\n",
      "Train Log likelihood, step 70100 in nats: 0.054615\n",
      "Train Log likelihood, step 70150 in nats: 0.054640\n",
      "Train Log likelihood, step 70200 in nats: 0.054670\n",
      "Train Log likelihood, step 70250 in nats: 0.054682\n",
      "Train epoch average loss: 0.054680427921853424\n",
      "\n",
      "\n",
      "Epoch: 431\n",
      "Train Log likelihood, step 70300 in nats: 0.054722\n",
      "Train Log likelihood, step 70350 in nats: 0.054743\n",
      "Train Log likelihood, step 70400 in nats: 0.054776\n",
      "Train epoch average loss: 0.05478035633715376\n",
      "\n",
      "\n",
      "Epoch: 432\n",
      "Train Log likelihood, step 70450 in nats: 0.054798\n",
      "Train Log likelihood, step 70500 in nats: 0.054813\n",
      "Train Log likelihood, step 70550 in nats: 0.054829\n",
      "Train epoch average loss: 0.054839502678419104\n",
      "\n",
      "\n",
      "Epoch: 433\n",
      "Train Log likelihood, step 70600 in nats: 0.054845\n",
      "Train Log likelihood, step 70650 in nats: 0.054876\n",
      "Train Log likelihood, step 70700 in nats: 0.054908\n",
      "Train epoch average loss: 0.054933269256823763\n",
      "\n",
      "\n",
      "Epoch: 434\n",
      "Train Log likelihood, step 70750 in nats: 0.054944\n",
      "Train Log likelihood, step 70800 in nats: 0.054956\n",
      "Train Log likelihood, step 70850 in nats: 0.054976\n",
      "Train Log likelihood, step 70900 in nats: 0.054987\n",
      "Train epoch average loss: 0.05498402781089692\n",
      "\n",
      "\n",
      "Epoch: 435\n",
      "Train Log likelihood, step 70950 in nats: 0.054994\n",
      "Train Log likelihood, step 71000 in nats: 0.055011\n",
      "Train Log likelihood, step 71050 in nats: 0.055027\n",
      "Train epoch average loss: 0.05503163453475673\n",
      "\n",
      "\n",
      "Epoch: 436\n",
      "Train Log likelihood, step 71100 in nats: 0.055033\n",
      "Train Log likelihood, step 71150 in nats: 0.055065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 71200 in nats: 0.055083\n",
      "Train epoch average loss: 0.05509772473599026\n",
      "\n",
      "\n",
      "Epoch: 437\n",
      "Train Log likelihood, step 71250 in nats: 0.055095\n",
      "Train Log likelihood, step 71300 in nats: 0.055100\n",
      "Train Log likelihood, step 71350 in nats: 0.055131\n",
      "Train epoch average loss: 0.0551454696806683\n",
      "\n",
      "\n",
      "Epoch: 438\n",
      "Train Log likelihood, step 71400 in nats: 0.055155\n",
      "Train Log likelihood, step 71450 in nats: 0.055193\n",
      "Train Log likelihood, step 71500 in nats: 0.055222\n",
      "Train Log likelihood, step 71550 in nats: 0.055226\n",
      "Train epoch average loss: 0.05522876783330653\n",
      "\n",
      "\n",
      "Epoch: 439\n",
      "Train Log likelihood, step 71600 in nats: 0.055253\n",
      "Train Log likelihood, step 71650 in nats: 0.055276\n",
      "Train Log likelihood, step 71700 in nats: 0.055293\n",
      "Train epoch average loss: 0.05529915952260113\n",
      "\n",
      "\n",
      "Epoch: 440\n",
      "Train Log likelihood, step 71750 in nats: 0.055314\n",
      "Train Log likelihood, step 71800 in nats: 0.055324\n",
      "Train Log likelihood, step 71850 in nats: 0.055347\n",
      "Train epoch average loss: 0.05536468129353886\n",
      "\n",
      "\n",
      "Epoch: 441\n",
      "Train Log likelihood, step 71900 in nats: 0.055373\n",
      "Train Log likelihood, step 71950 in nats: 0.055397\n",
      "Train Log likelihood, step 72000 in nats: 0.055408\n",
      "Train epoch average loss: 0.05542669915313564\n",
      "\n",
      "\n",
      "Epoch: 442\n",
      "Train Log likelihood, step 72050 in nats: 0.055432\n",
      "Train Log likelihood, step 72100 in nats: 0.055428\n",
      "Train Log likelihood, step 72150 in nats: 0.055444\n",
      "Train Log likelihood, step 72200 in nats: 0.055475\n",
      "Train epoch average loss: 0.05548087843082672\n",
      "\n",
      "\n",
      "Epoch: 443\n",
      "Train Log likelihood, step 72250 in nats: 0.055508\n",
      "Train Log likelihood, step 72300 in nats: 0.055532\n",
      "Train Log likelihood, step 72350 in nats: 0.055566\n",
      "Train epoch average loss: 0.05559304141030383\n",
      "\n",
      "\n",
      "Epoch: 444\n",
      "Train Log likelihood, step 72400 in nats: 0.055603\n",
      "Train Log likelihood, step 72450 in nats: 0.055641\n",
      "Train Log likelihood, step 72500 in nats: 0.055657\n",
      "Train epoch average loss: 0.05567439719635311\n",
      "\n",
      "\n",
      "Epoch: 445\n",
      "Train Log likelihood, step 72550 in nats: 0.055680\n",
      "Train Log likelihood, step 72600 in nats: 0.055699\n",
      "Train Log likelihood, step 72650 in nats: 0.055724\n",
      "Train epoch average loss: 0.05574422432971814\n",
      "\n",
      "\n",
      "Epoch: 446\n",
      "Train Log likelihood, step 72700 in nats: 0.055749\n",
      "Train Log likelihood, step 72750 in nats: 0.055776\n",
      "Train Log likelihood, step 72800 in nats: 0.055806\n",
      "Train Log likelihood, step 72850 in nats: 0.055814\n",
      "Train epoch average loss: 0.05582008598905367\n",
      "\n",
      "\n",
      "Epoch: 447\n",
      "Train Log likelihood, step 72900 in nats: 0.055815\n",
      "Train Log likelihood, step 72950 in nats: 0.055851\n",
      "Train Log likelihood, step 73000 in nats: 0.055890\n",
      "Train epoch average loss: 0.055891136490884556\n",
      "\n",
      "\n",
      "Epoch: 448\n",
      "Train Log likelihood, step 73050 in nats: 0.055896\n",
      "Train Log likelihood, step 73100 in nats: 0.055944\n",
      "Train Log likelihood, step 73150 in nats: 0.055976\n",
      "Train epoch average loss: 0.055995008661764344\n",
      "\n",
      "\n",
      "Epoch: 449\n",
      "Train Log likelihood, step 73200 in nats: 0.056011\n",
      "Train Log likelihood, step 73250 in nats: 0.056042\n",
      "Train Log likelihood, step 73300 in nats: 0.056054\n",
      "Train epoch average loss: 0.056076605893364884\n",
      "\n",
      "\n",
      "Epoch: 450\n",
      "Train Log likelihood, step 73350 in nats: 0.056076\n",
      "Train Log likelihood, step 73400 in nats: 0.056089\n",
      "Train Log likelihood, step 73450 in nats: 0.056101\n",
      "Train Log likelihood, step 73500 in nats: 0.056124\n",
      "Train epoch average loss: 0.05613166374938958\n",
      "\n",
      "\n",
      "Epoch: 451\n",
      "Train Log likelihood, step 73550 in nats: 0.056131\n",
      "Train Log likelihood, step 73600 in nats: 0.056157\n",
      "Train Log likelihood, step 73650 in nats: 0.056174\n",
      "Train epoch average loss: 0.05617943449502889\n",
      "\n",
      "\n",
      "Epoch: 452\n",
      "Train Log likelihood, step 73700 in nats: 0.056189\n",
      "Train Log likelihood, step 73750 in nats: 0.056210\n",
      "Train Log likelihood, step 73800 in nats: 0.056242\n",
      "Train epoch average loss: 0.05625433063053891\n",
      "\n",
      "\n",
      "Epoch: 453\n",
      "Train Log likelihood, step 73850 in nats: 0.056254\n",
      "Train Log likelihood, step 73900 in nats: 0.056282\n",
      "Train Log likelihood, step 73950 in nats: 0.056281\n",
      "Train Log likelihood, step 74000 in nats: 0.056321\n",
      "Train epoch average loss: 0.05632120181637357\n",
      "\n",
      "\n",
      "Epoch: 454\n",
      "Train Log likelihood, step 74050 in nats: 0.056348\n",
      "Train Log likelihood, step 74100 in nats: 0.056360\n",
      "Train Log likelihood, step 74150 in nats: 0.056395\n",
      "Train epoch average loss: 0.056400078998351394\n",
      "\n",
      "\n",
      "Epoch: 455\n",
      "Train Log likelihood, step 74200 in nats: 0.056417\n",
      "Train Log likelihood, step 74250 in nats: 0.056443\n",
      "Train Log likelihood, step 74300 in nats: 0.056468\n",
      "Train epoch average loss: 0.0564922456293807\n",
      "\n",
      "\n",
      "Epoch: 456\n",
      "Train Log likelihood, step 74350 in nats: 0.056506\n",
      "Train Log likelihood, step 74400 in nats: 0.056535\n",
      "Train Log likelihood, step 74450 in nats: 0.056547\n",
      "Train epoch average loss: 0.05657165794108626\n",
      "\n",
      "\n",
      "Epoch: 457\n",
      "Train Log likelihood, step 74500 in nats: 0.056564\n",
      "Train Log likelihood, step 74550 in nats: 0.056558\n",
      "Train Log likelihood, step 74600 in nats: 0.056585\n",
      "Train Log likelihood, step 74650 in nats: 0.056608\n",
      "Train epoch average loss: 0.05661155868472353\n",
      "\n",
      "\n",
      "Epoch: 458\n",
      "Train Log likelihood, step 74700 in nats: 0.056625\n",
      "Train Log likelihood, step 74750 in nats: 0.056665\n",
      "Train Log likelihood, step 74800 in nats: 0.056706\n",
      "Train epoch average loss: 0.05671238412568062\n",
      "\n",
      "\n",
      "Epoch: 459\n",
      "Train Log likelihood, step 74850 in nats: 0.056730\n",
      "Train Log likelihood, step 74900 in nats: 0.056758\n",
      "Train Log likelihood, step 74950 in nats: 0.056780\n",
      "Train epoch average loss: 0.056790438874404\n",
      "\n",
      "\n",
      "Epoch: 460\n",
      "Train Log likelihood, step 75000 in nats: 0.056793\n",
      "Train Log likelihood, step 75050 in nats: 0.056822\n",
      "Train Log likelihood, step 75100 in nats: 0.056851\n",
      "Train epoch average loss: 0.05685583568043368\n",
      "\n",
      "\n",
      "Epoch: 461\n",
      "Train Log likelihood, step 75150 in nats: 0.056864\n",
      "Train Log likelihood, step 75200 in nats: 0.056904\n",
      "Train Log likelihood, step 75250 in nats: 0.056931\n",
      "Train Log likelihood, step 75300 in nats: 0.056954\n",
      "Train epoch average loss: 0.05695717007152863\n",
      "\n",
      "\n",
      "Epoch: 462\n",
      "Train Log likelihood, step 75350 in nats: 0.056974\n",
      "Train Log likelihood, step 75400 in nats: 0.057004\n",
      "Train Log likelihood, step 75450 in nats: 0.057045\n",
      "Train epoch average loss: 0.05705769812540972\n",
      "\n",
      "\n",
      "Epoch: 463\n",
      "Train Log likelihood, step 75500 in nats: 0.057086\n",
      "Train Log likelihood, step 75550 in nats: 0.057118\n",
      "Train Log likelihood, step 75600 in nats: 0.057128\n",
      "Train epoch average loss: 0.057145609051501504\n",
      "\n",
      "\n",
      "Epoch: 464\n",
      "Train Log likelihood, step 75650 in nats: 0.057150\n",
      "Train Log likelihood, step 75700 in nats: 0.057167\n",
      "Train Log likelihood, step 75750 in nats: 0.057200\n",
      "Train epoch average loss: 0.05723645472745446\n",
      "\n",
      "\n",
      "Epoch: 465\n",
      "Train Log likelihood, step 75800 in nats: 0.057235\n",
      "Train Log likelihood, step 75850 in nats: 0.057263\n",
      "Train Log likelihood, step 75900 in nats: 0.057290\n",
      "Train Log likelihood, step 75950 in nats: 0.057306\n",
      "Train epoch average loss: 0.0573124989036645\n",
      "\n",
      "\n",
      "Epoch: 466\n",
      "Train Log likelihood, step 76000 in nats: 0.057345\n",
      "Train Log likelihood, step 76050 in nats: 0.057354\n",
      "Train Log likelihood, step 76100 in nats: 0.057379\n",
      "Train epoch average loss: 0.057387093634713025\n",
      "\n",
      "\n",
      "Epoch: 467\n",
      "Train Log likelihood, step 76150 in nats: 0.057410\n",
      "Train Log likelihood, step 76200 in nats: 0.057444\n",
      "Train Log likelihood, step 76250 in nats: 0.057487\n",
      "Train epoch average loss: 0.0574959663318836\n",
      "\n",
      "\n",
      "Epoch: 468\n",
      "Train Log likelihood, step 76300 in nats: 0.057512\n",
      "Train Log likelihood, step 76350 in nats: 0.057549\n",
      "Train Log likelihood, step 76400 in nats: 0.057581\n",
      "Train epoch average loss: 0.0575950349697551\n",
      "\n",
      "\n",
      "Epoch: 469\n",
      "Train Log likelihood, step 76450 in nats: 0.057594\n",
      "Train Log likelihood, step 76500 in nats: 0.057611\n",
      "Train Log likelihood, step 76550 in nats: 0.057621\n",
      "Train Log likelihood, step 76600 in nats: 0.057663\n",
      "Train epoch average loss: 0.05767662473468175\n",
      "\n",
      "\n",
      "Epoch: 470\n",
      "Train Log likelihood, step 76650 in nats: 0.057696\n",
      "Train Log likelihood, step 76700 in nats: 0.057717\n",
      "Train Log likelihood, step 76750 in nats: 0.057740\n",
      "Train epoch average loss: 0.05774378965428819\n",
      "\n",
      "\n",
      "Epoch: 471\n",
      "Train Log likelihood, step 76800 in nats: 0.057769\n",
      "Train Log likelihood, step 76850 in nats: 0.057807\n",
      "Train Log likelihood, step 76900 in nats: 0.057833\n",
      "Train epoch average loss: 0.057847245256015374\n",
      "\n",
      "\n",
      "Epoch: 472\n",
      "Train Log likelihood, step 76950 in nats: 0.057847\n",
      "Train Log likelihood, step 77000 in nats: 0.057868\n",
      "Train Log likelihood, step 77050 in nats: 0.057901\n",
      "Train epoch average loss: 0.05792972836221169\n",
      "\n",
      "\n",
      "Epoch: 473\n",
      "Train Log likelihood, step 77100 in nats: 0.057933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 77150 in nats: 0.057934\n",
      "Train Log likelihood, step 77200 in nats: 0.057939\n",
      "Train Log likelihood, step 77250 in nats: 0.057983\n",
      "Train epoch average loss: 0.05799354842601088\n",
      "\n",
      "\n",
      "Epoch: 474\n",
      "Train Log likelihood, step 77300 in nats: 0.058025\n",
      "Train Log likelihood, step 77350 in nats: 0.058053\n",
      "Train Log likelihood, step 77400 in nats: 0.058099\n",
      "Train epoch average loss: 0.058111038045001194\n",
      "\n",
      "\n",
      "Epoch: 475\n",
      "Train Log likelihood, step 77450 in nats: 0.058123\n",
      "Train Log likelihood, step 77500 in nats: 0.058155\n",
      "Train Log likelihood, step 77550 in nats: 0.058192\n",
      "Train epoch average loss: 0.058204598867997365\n",
      "\n",
      "\n",
      "Epoch: 476\n",
      "Train Log likelihood, step 77600 in nats: 0.058208\n",
      "Train Log likelihood, step 77650 in nats: 0.058239\n",
      "Train Log likelihood, step 77700 in nats: 0.058276\n",
      "Train Log likelihood, step 77750 in nats: 0.058303\n",
      "Train epoch average loss: 0.058302879472667025\n",
      "\n",
      "\n",
      "Epoch: 477\n",
      "Train Log likelihood, step 77800 in nats: 0.058313\n",
      "Train Log likelihood, step 77850 in nats: 0.058331\n",
      "Train Log likelihood, step 77900 in nats: 0.058350\n",
      "Train epoch average loss: 0.05834849068769741\n",
      "\n",
      "\n",
      "Epoch: 478\n",
      "Train Log likelihood, step 77950 in nats: 0.058366\n",
      "Train Log likelihood, step 78000 in nats: 0.058370\n",
      "Train Log likelihood, step 78050 in nats: 0.058393\n",
      "Train epoch average loss: 0.05840189873952394\n",
      "\n",
      "\n",
      "Epoch: 479\n",
      "Train Log likelihood, step 78100 in nats: 0.058414\n",
      "Train Log likelihood, step 78150 in nats: 0.058447\n",
      "Train Log likelihood, step 78200 in nats: 0.058485\n",
      "Train epoch average loss: 0.05851111970686712\n",
      "\n",
      "\n",
      "Epoch: 480\n",
      "Train Log likelihood, step 78250 in nats: 0.058514\n",
      "Train Log likelihood, step 78300 in nats: 0.058550\n",
      "Train Log likelihood, step 78350 in nats: 0.058587\n",
      "Train Log likelihood, step 78400 in nats: 0.058616\n",
      "Train epoch average loss: 0.05861801738525435\n",
      "\n",
      "\n",
      "Epoch: 481\n",
      "Train Log likelihood, step 78450 in nats: 0.058640\n",
      "Train Log likelihood, step 78500 in nats: 0.058673\n",
      "Train Log likelihood, step 78550 in nats: 0.058682\n",
      "Train epoch average loss: 0.05868805272336429\n",
      "\n",
      "\n",
      "Epoch: 482\n",
      "Train Log likelihood, step 78600 in nats: 0.058703\n",
      "Train Log likelihood, step 78650 in nats: 0.058718\n",
      "Train Log likelihood, step 78700 in nats: 0.058746\n",
      "Train epoch average loss: 0.05876336438603917\n",
      "\n",
      "\n",
      "Epoch: 483\n",
      "Train Log likelihood, step 78750 in nats: 0.058764\n",
      "Train Log likelihood, step 78800 in nats: 0.058790\n",
      "Train Log likelihood, step 78850 in nats: 0.058795\n",
      "Train epoch average loss: 0.058803230772623664\n",
      "\n",
      "\n",
      "Epoch: 484\n",
      "Train Log likelihood, step 78900 in nats: 0.058806\n",
      "Train Log likelihood, step 78950 in nats: 0.058821\n",
      "Train Log likelihood, step 79000 in nats: 0.058827\n",
      "Train Log likelihood, step 79050 in nats: 0.058833\n",
      "Train epoch average loss: 0.0588341648562241\n",
      "\n",
      "\n",
      "Epoch: 485\n",
      "Train Log likelihood, step 79100 in nats: 0.058864\n",
      "Train Log likelihood, step 79150 in nats: 0.058893\n",
      "Train Log likelihood, step 79200 in nats: 0.058909\n",
      "Train epoch average loss: 0.05892822090465401\n",
      "\n",
      "\n",
      "Epoch: 486\n",
      "Train Log likelihood, step 79250 in nats: 0.058932\n",
      "Train Log likelihood, step 79300 in nats: 0.058957\n",
      "Train Log likelihood, step 79350 in nats: 0.058981\n",
      "Train epoch average loss: 0.058990439873036156\n",
      "\n",
      "\n",
      "Epoch: 487\n",
      "Train Log likelihood, step 79400 in nats: 0.058991\n",
      "Train Log likelihood, step 79450 in nats: 0.059010\n",
      "Train Log likelihood, step 79500 in nats: 0.059035\n",
      "Train epoch average loss: 0.05904575116120594\n",
      "\n",
      "\n",
      "Epoch: 488\n",
      "Train Log likelihood, step 79550 in nats: 0.059050\n",
      "Train Log likelihood, step 79600 in nats: 0.059067\n",
      "Train Log likelihood, step 79650 in nats: 0.059078\n",
      "Train Log likelihood, step 79700 in nats: 0.059103\n",
      "Train epoch average loss: 0.0591096062505467\n",
      "\n",
      "\n",
      "Epoch: 489\n",
      "Train Log likelihood, step 79750 in nats: 0.059114\n",
      "Train Log likelihood, step 79800 in nats: 0.059150\n",
      "Train Log likelihood, step 79850 in nats: 0.059180\n",
      "Train epoch average loss: 0.059187144527735006\n",
      "\n",
      "\n",
      "Epoch: 490\n",
      "Train Log likelihood, step 79900 in nats: 0.059207\n",
      "Train Log likelihood, step 79950 in nats: 0.059228\n",
      "Train Log likelihood, step 80000 in nats: 0.059258\n",
      "Train epoch average loss: 0.0592819347552166\n",
      "\n",
      "\n",
      "Epoch: 491\n",
      "Train Log likelihood, step 80050 in nats: 0.059291\n",
      "Train Log likelihood, step 80100 in nats: 0.059303\n",
      "Train Log likelihood, step 80150 in nats: 0.059297\n",
      "Train epoch average loss: 0.059320521676595135\n",
      "\n",
      "\n",
      "Epoch: 492\n",
      "Train Log likelihood, step 80200 in nats: 0.059327\n",
      "Train Log likelihood, step 80250 in nats: 0.059346\n",
      "Train Log likelihood, step 80300 in nats: 0.059363\n",
      "Train Log likelihood, step 80350 in nats: 0.059379\n",
      "Train epoch average loss: 0.059379332259165425\n",
      "\n",
      "\n",
      "Epoch: 493\n",
      "Train Log likelihood, step 80400 in nats: 0.059387\n",
      "Train Log likelihood, step 80450 in nats: 0.059393\n",
      "Train Log likelihood, step 80500 in nats: 0.059411\n",
      "Train epoch average loss: 0.05942113138605271\n",
      "\n",
      "\n",
      "Epoch: 494\n",
      "Train Log likelihood, step 80550 in nats: 0.059432\n",
      "Train Log likelihood, step 80600 in nats: 0.059453\n",
      "Train Log likelihood, step 80650 in nats: 0.059492\n",
      "Train epoch average loss: 0.05951911927905661\n",
      "\n",
      "\n",
      "Epoch: 495\n",
      "Train Log likelihood, step 80700 in nats: 0.059521\n",
      "Train Log likelihood, step 80750 in nats: 0.059546\n",
      "Train Log likelihood, step 80800 in nats: 0.059568\n",
      "Train epoch average loss: 0.05959919071227466\n",
      "\n",
      "\n",
      "Epoch: 496\n",
      "Train Log likelihood, step 80850 in nats: 0.059602\n",
      "Train Log likelihood, step 80900 in nats: 0.059611\n",
      "Train Log likelihood, step 80950 in nats: 0.059638\n",
      "Train Log likelihood, step 81000 in nats: 0.059654\n",
      "Train epoch average loss: 0.059658851160845204\n",
      "\n",
      "\n",
      "Epoch: 497\n",
      "Train Log likelihood, step 81050 in nats: 0.059682\n",
      "Train Log likelihood, step 81100 in nats: 0.059705\n",
      "Train Log likelihood, step 81150 in nats: 0.059750\n",
      "Train epoch average loss: 0.059770099597115\n",
      "\n",
      "\n",
      "Epoch: 498\n",
      "Train Log likelihood, step 81200 in nats: 0.059780\n",
      "Train Log likelihood, step 81250 in nats: 0.059794\n",
      "Train Log likelihood, step 81300 in nats: 0.059823\n",
      "Train epoch average loss: 0.05984189290951911\n",
      "\n",
      "\n",
      "Epoch: 499\n",
      "Train Log likelihood, step 81350 in nats: 0.059845\n",
      "Train Log likelihood, step 81400 in nats: 0.059867\n",
      "Train Log likelihood, step 81450 in nats: 0.059893\n",
      "Train epoch average loss: 0.05991596257062057\n",
      "\n",
      "\n",
      "Epoch: 500\n",
      "Train Log likelihood, step 81500 in nats: 0.059916\n",
      "Train Log likelihood, step 81550 in nats: 0.059929\n",
      "Train Log likelihood, step 81600 in nats: 0.059952\n",
      "Train Log likelihood, step 81650 in nats: 0.059959\n",
      "Train epoch average loss: 0.059973106176258444\n",
      "\n",
      "\n",
      "Epoch: 501\n",
      "Train Log likelihood, step 81700 in nats: 0.059995\n",
      "Train Log likelihood, step 81750 in nats: 0.060041\n",
      "Train Log likelihood, step 81800 in nats: 0.060064\n",
      "Train epoch average loss: 0.06008343426251006\n",
      "\n",
      "\n",
      "Epoch: 502\n",
      "Train Log likelihood, step 81850 in nats: 0.060096\n",
      "Train Log likelihood, step 81900 in nats: 0.060119\n",
      "Train Log likelihood, step 81950 in nats: 0.060149\n",
      "Train epoch average loss: 0.06018581794471571\n",
      "\n",
      "\n",
      "Epoch: 503\n",
      "Train Log likelihood, step 82000 in nats: 0.060195\n",
      "Train Log likelihood, step 82050 in nats: 0.060211\n",
      "Train Log likelihood, step 82100 in nats: 0.060236\n",
      "Train Log likelihood, step 82150 in nats: 0.060259\n",
      "Train epoch average loss: 0.06026091977566877\n",
      "\n",
      "\n",
      "Epoch: 504\n",
      "Train Log likelihood, step 82200 in nats: 0.060294\n",
      "Train Log likelihood, step 82250 in nats: 0.060329\n",
      "Train Log likelihood, step 82300 in nats: 0.060367\n",
      "Train epoch average loss: 0.060373144993135265\n",
      "\n",
      "\n",
      "Epoch: 505\n",
      "Train Log likelihood, step 82350 in nats: 0.060372\n",
      "Train Log likelihood, step 82400 in nats: 0.060391\n",
      "Train Log likelihood, step 82450 in nats: 0.060420\n",
      "Train epoch average loss: 0.06043152581518942\n",
      "\n",
      "\n",
      "Epoch: 506\n",
      "Train Log likelihood, step 82500 in nats: 0.060429\n",
      "Train Log likelihood, step 82550 in nats: 0.060453\n",
      "Train Log likelihood, step 82600 in nats: 0.060480\n",
      "Train epoch average loss: 0.060494981196310915\n",
      "\n",
      "\n",
      "Epoch: 507\n",
      "Train Log likelihood, step 82650 in nats: 0.060500\n",
      "Train Log likelihood, step 82700 in nats: 0.060497\n",
      "Train Log likelihood, step 82750 in nats: 0.060530\n",
      "Train Log likelihood, step 82800 in nats: 0.060521\n",
      "Train epoch average loss: 0.06052054767726926\n",
      "\n",
      "\n",
      "Epoch: 508\n",
      "Train Log likelihood, step 82850 in nats: 0.060539\n",
      "Train Log likelihood, step 82900 in nats: 0.060567\n",
      "Train Log likelihood, step 82950 in nats: 0.060585\n",
      "Train epoch average loss: 0.06059888616887063\n",
      "\n",
      "\n",
      "Epoch: 509\n",
      "Train Log likelihood, step 83000 in nats: 0.060613\n",
      "Train Log likelihood, step 83050 in nats: 0.060646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 83100 in nats: 0.060648\n",
      "Train epoch average loss: 0.06067140344444422\n",
      "\n",
      "\n",
      "Epoch: 510\n",
      "Train Log likelihood, step 83150 in nats: 0.060683\n",
      "Train Log likelihood, step 83200 in nats: 0.060717\n",
      "Train Log likelihood, step 83250 in nats: 0.060735\n",
      "Train epoch average loss: 0.060763265372263536\n",
      "\n",
      "\n",
      "Epoch: 511\n",
      "Train Log likelihood, step 83300 in nats: 0.060772\n",
      "Train Log likelihood, step 83350 in nats: 0.060804\n",
      "Train Log likelihood, step 83400 in nats: 0.060818\n",
      "Train Log likelihood, step 83450 in nats: 0.060841\n",
      "Train epoch average loss: 0.06084457642585241\n",
      "\n",
      "\n",
      "Epoch: 512\n",
      "Train Log likelihood, step 83500 in nats: 0.060871\n",
      "Train Log likelihood, step 83550 in nats: 0.060900\n",
      "Train Log likelihood, step 83600 in nats: 0.060921\n",
      "Train epoch average loss: 0.0609219027863519\n",
      "\n",
      "\n",
      "Epoch: 513\n",
      "Train Log likelihood, step 83650 in nats: 0.060930\n",
      "Train Log likelihood, step 83700 in nats: 0.060953\n",
      "Train Log likelihood, step 83750 in nats: 0.060960\n",
      "Train epoch average loss: 0.060977102979496135\n",
      "\n",
      "\n",
      "Epoch: 514\n",
      "Train Log likelihood, step 83800 in nats: 0.060989\n",
      "Train Log likelihood, step 83850 in nats: 0.061008\n",
      "Train Log likelihood, step 83900 in nats: 0.061035\n",
      "Train epoch average loss: 0.06105260698578065\n",
      "\n",
      "\n",
      "Epoch: 515\n",
      "Train Log likelihood, step 83950 in nats: 0.061058\n",
      "Train Log likelihood, step 84000 in nats: 0.061097\n",
      "Train Log likelihood, step 84050 in nats: 0.061116\n",
      "Train Log likelihood, step 84100 in nats: 0.061115\n",
      "Train epoch average loss: 0.06111730096937224\n",
      "\n",
      "\n",
      "Epoch: 516\n",
      "Train Log likelihood, step 84150 in nats: 0.061137\n",
      "Train Log likelihood, step 84200 in nats: 0.061162\n",
      "Train Log likelihood, step 84250 in nats: 0.061196\n",
      "Train epoch average loss: 0.06120753730896297\n",
      "\n",
      "\n",
      "Epoch: 517\n",
      "Train Log likelihood, step 84300 in nats: 0.061218\n",
      "Train Log likelihood, step 84350 in nats: 0.061225\n",
      "Train Log likelihood, step 84400 in nats: 0.061232\n",
      "Train epoch average loss: 0.06123731417832697\n",
      "\n",
      "\n",
      "Epoch: 518\n",
      "Train Log likelihood, step 84450 in nats: 0.061246\n",
      "Train Log likelihood, step 84500 in nats: 0.061266\n",
      "Train Log likelihood, step 84550 in nats: 0.061286\n",
      "Train epoch average loss: 0.06129916673233499\n",
      "\n",
      "\n",
      "Epoch: 519\n",
      "Train Log likelihood, step 84600 in nats: 0.061301\n",
      "Train Log likelihood, step 84650 in nats: 0.061313\n",
      "Train Log likelihood, step 84700 in nats: 0.061319\n",
      "Train Log likelihood, step 84750 in nats: 0.061344\n",
      "Train epoch average loss: 0.06134800285399511\n",
      "\n",
      "\n",
      "Epoch: 520\n",
      "Train Log likelihood, step 84800 in nats: 0.061354\n",
      "Train Log likelihood, step 84850 in nats: 0.061379\n",
      "Train Log likelihood, step 84900 in nats: 0.061411\n",
      "Train epoch average loss: 0.06143170034041276\n",
      "\n",
      "\n",
      "Epoch: 521\n",
      "Train Log likelihood, step 84950 in nats: 0.061442\n",
      "Train Log likelihood, step 85000 in nats: 0.061455\n",
      "Train Log likelihood, step 85050 in nats: 0.061470\n",
      "Train epoch average loss: 0.06148082117335767\n",
      "\n",
      "\n",
      "Epoch: 522\n",
      "Train Log likelihood, step 85100 in nats: 0.061487\n",
      "Train Log likelihood, step 85150 in nats: 0.061515\n",
      "Train Log likelihood, step 85200 in nats: 0.061533\n",
      "Train epoch average loss: 0.06155838826651817\n",
      "\n",
      "\n",
      "Epoch: 523\n",
      "Train Log likelihood, step 85250 in nats: 0.061560\n",
      "Train Log likelihood, step 85300 in nats: 0.061584\n",
      "Train Log likelihood, step 85350 in nats: 0.061603\n",
      "Train Log likelihood, step 85400 in nats: 0.061611\n",
      "Train epoch average loss: 0.06161513913141358\n",
      "\n",
      "\n",
      "Epoch: 524\n",
      "Train Log likelihood, step 85450 in nats: 0.061630\n",
      "Train Log likelihood, step 85500 in nats: 0.061667\n",
      "Train Log likelihood, step 85550 in nats: 0.061682\n",
      "Train epoch average loss: 0.06169787877348666\n",
      "\n",
      "\n",
      "Epoch: 525\n",
      "Train Log likelihood, step 85600 in nats: 0.061715\n",
      "Train Log likelihood, step 85650 in nats: 0.061742\n",
      "Train Log likelihood, step 85700 in nats: 0.061769\n",
      "Train epoch average loss: 0.06176174140529013\n",
      "\n",
      "\n",
      "Epoch: 526\n",
      "Train Log likelihood, step 85750 in nats: 0.061757\n",
      "Train Log likelihood, step 85800 in nats: 0.061768\n",
      "Train Log likelihood, step 85850 in nats: 0.061792\n",
      "Train Log likelihood, step 85900 in nats: 0.061826\n",
      "Train epoch average loss: 0.06182633786532497\n",
      "\n",
      "\n",
      "Epoch: 527\n",
      "Train Log likelihood, step 85950 in nats: 0.061834\n",
      "Train Log likelihood, step 86000 in nats: 0.061849\n",
      "Train Log likelihood, step 86050 in nats: 0.061875\n",
      "Train epoch average loss: 0.06187923196845042\n",
      "\n",
      "\n",
      "Epoch: 528\n",
      "Train Log likelihood, step 86100 in nats: 0.061891\n",
      "Train Log likelihood, step 86150 in nats: 0.061924\n",
      "Train Log likelihood, step 86200 in nats: 0.061942\n",
      "Train epoch average loss: 0.06195982632644541\n",
      "\n",
      "\n",
      "Epoch: 529\n",
      "Train Log likelihood, step 86250 in nats: 0.061967\n",
      "Train Log likelihood, step 86300 in nats: 0.061986\n",
      "Train Log likelihood, step 86350 in nats: 0.062014\n",
      "Train epoch average loss: 0.06202581446642408\n",
      "\n",
      "\n",
      "Epoch: 530\n",
      "Train Log likelihood, step 86400 in nats: 0.062030\n",
      "Train Log likelihood, step 86450 in nats: 0.062069\n",
      "Train Log likelihood, step 86500 in nats: 0.062104\n",
      "Train Log likelihood, step 86550 in nats: 0.062122\n",
      "Train epoch average loss: 0.06212383110954459\n",
      "\n",
      "\n",
      "Epoch: 531\n",
      "Train Log likelihood, step 86600 in nats: 0.062153\n",
      "Train Log likelihood, step 86650 in nats: 0.062179\n",
      "Train Log likelihood, step 86700 in nats: 0.062218\n",
      "Train epoch average loss: 0.062226133860435934\n",
      "\n",
      "\n",
      "Epoch: 532\n",
      "Train Log likelihood, step 86750 in nats: 0.062255\n",
      "Train Log likelihood, step 86800 in nats: 0.062291\n",
      "Train Log likelihood, step 86850 in nats: 0.062306\n",
      "Train epoch average loss: 0.06230476954720137\n",
      "\n",
      "\n",
      "Epoch: 533\n",
      "Train Log likelihood, step 86900 in nats: 0.062311\n",
      "Train Log likelihood, step 86950 in nats: 0.062330\n",
      "Train Log likelihood, step 87000 in nats: 0.062356\n",
      "Train epoch average loss: 0.062369609043037316\n",
      "\n",
      "\n",
      "Epoch: 534\n",
      "Train Log likelihood, step 87050 in nats: 0.062374\n",
      "Train Log likelihood, step 87100 in nats: 0.062415\n",
      "Train Log likelihood, step 87150 in nats: 0.062440\n",
      "Train Log likelihood, step 87200 in nats: 0.062465\n",
      "Train epoch average loss: 0.06246600034141369\n",
      "\n",
      "\n",
      "Epoch: 535\n",
      "Train Log likelihood, step 87250 in nats: 0.062483\n",
      "Train Log likelihood, step 87300 in nats: 0.062502\n",
      "Train Log likelihood, step 87350 in nats: 0.062534\n",
      "Train epoch average loss: 0.06254895041033037\n",
      "\n",
      "\n",
      "Epoch: 536\n",
      "Train Log likelihood, step 87400 in nats: 0.062571\n",
      "Train Log likelihood, step 87450 in nats: 0.062591\n",
      "Train Log likelihood, step 87500 in nats: 0.062609\n",
      "Train epoch average loss: 0.06262865567012735\n",
      "\n",
      "\n",
      "Epoch: 537\n",
      "Train Log likelihood, step 87550 in nats: 0.062628\n",
      "Train Log likelihood, step 87600 in nats: 0.062659\n",
      "Train Log likelihood, step 87650 in nats: 0.062697\n",
      "Train epoch average loss: 0.06272010652172748\n",
      "\n",
      "\n",
      "Epoch: 538\n",
      "Train Log likelihood, step 87700 in nats: 0.062722\n",
      "Train Log likelihood, step 87750 in nats: 0.062766\n",
      "Train Log likelihood, step 87800 in nats: 0.062793\n",
      "Train Log likelihood, step 87850 in nats: 0.062816\n",
      "Train epoch average loss: 0.06281947716854107\n",
      "\n",
      "\n",
      "Epoch: 539\n",
      "Train Log likelihood, step 87900 in nats: 0.062829\n",
      "Train Log likelihood, step 87950 in nats: 0.062855\n",
      "Train Log likelihood, step 88000 in nats: 0.062886\n",
      "Train epoch average loss: 0.0628980779504349\n",
      "\n",
      "\n",
      "Epoch: 540\n",
      "Train Log likelihood, step 88050 in nats: 0.062910\n",
      "Train Log likelihood, step 88100 in nats: 0.062924\n",
      "Train Log likelihood, step 88150 in nats: 0.062928\n",
      "Train epoch average loss: 0.06295201293943815\n",
      "\n",
      "\n",
      "Epoch: 541\n",
      "Train Log likelihood, step 88200 in nats: 0.062959\n",
      "Train Log likelihood, step 88250 in nats: 0.062963\n",
      "Train Log likelihood, step 88300 in nats: 0.062993\n",
      "Train epoch average loss: 0.06301542375320825\n",
      "\n",
      "\n",
      "Epoch: 542\n",
      "Train Log likelihood, step 88350 in nats: 0.063018\n",
      "Train Log likelihood, step 88400 in nats: 0.063040\n",
      "Train Log likelihood, step 88450 in nats: 0.063072\n",
      "Train Log likelihood, step 88500 in nats: 0.063111\n",
      "Train epoch average loss: 0.06311204817296245\n",
      "\n",
      "\n",
      "Epoch: 543\n",
      "Train Log likelihood, step 88550 in nats: 0.063130\n",
      "Train Log likelihood, step 88600 in nats: 0.063137\n",
      "Train Log likelihood, step 88650 in nats: 0.063137\n",
      "Train epoch average loss: 0.06315010093913043\n",
      "\n",
      "\n",
      "Epoch: 544\n",
      "Train Log likelihood, step 88700 in nats: 0.063147\n",
      "Train Log likelihood, step 88750 in nats: 0.063165\n",
      "Train Log likelihood, step 88800 in nats: 0.063195\n",
      "Train epoch average loss: 0.06320843424823508\n",
      "\n",
      "\n",
      "Epoch: 545\n",
      "Train Log likelihood, step 88850 in nats: 0.063218\n",
      "Train Log likelihood, step 88900 in nats: 0.063242\n",
      "Train Log likelihood, step 88950 in nats: 0.063254\n",
      "Train epoch average loss: 0.06326094962674277\n",
      "\n",
      "\n",
      "Epoch: 546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 89000 in nats: 0.063263\n",
      "Train Log likelihood, step 89050 in nats: 0.063284\n",
      "Train Log likelihood, step 89100 in nats: 0.063306\n",
      "Train Log likelihood, step 89150 in nats: 0.063315\n",
      "Train epoch average loss: 0.06332224789678428\n",
      "\n",
      "\n",
      "Epoch: 547\n",
      "Train Log likelihood, step 89200 in nats: 0.063327\n",
      "Train Log likelihood, step 89250 in nats: 0.063337\n",
      "Train Log likelihood, step 89300 in nats: 0.063359\n",
      "Train epoch average loss: 0.06336559880729256\n",
      "\n",
      "\n",
      "Epoch: 548\n",
      "Train Log likelihood, step 89350 in nats: 0.063373\n",
      "Train Log likelihood, step 89400 in nats: 0.063380\n",
      "Train Log likelihood, step 89450 in nats: 0.063399\n",
      "Train epoch average loss: 0.06341108152425057\n",
      "\n",
      "\n",
      "Epoch: 549\n",
      "Train Log likelihood, step 89500 in nats: 0.063409\n",
      "Train Log likelihood, step 89550 in nats: 0.063424\n",
      "Train Log likelihood, step 89600 in nats: 0.063434\n",
      "Train epoch average loss: 0.06344493054280752\n",
      "\n",
      "\n",
      "Epoch: 550\n",
      "Train Log likelihood, step 89650 in nats: 0.063446\n",
      "Train Log likelihood, step 89700 in nats: 0.063461\n",
      "Train Log likelihood, step 89750 in nats: 0.063487\n",
      "Train Log likelihood, step 89800 in nats: 0.063522\n",
      "Train epoch average loss: 0.06352779284240448\n",
      "\n",
      "\n",
      "Epoch: 551\n",
      "Train Log likelihood, step 89850 in nats: 0.063538\n",
      "Train Log likelihood, step 89900 in nats: 0.063565\n",
      "Train Log likelihood, step 89950 in nats: 0.063597\n",
      "Train epoch average loss: 0.0636084781220333\n",
      "\n",
      "\n",
      "Epoch: 552\n",
      "Train Log likelihood, step 90000 in nats: 0.063614\n",
      "Train Log likelihood, step 90050 in nats: 0.063643\n",
      "Train Log likelihood, step 90100 in nats: 0.063667\n",
      "Train epoch average loss: 0.06368806010951367\n",
      "\n",
      "\n",
      "Epoch: 553\n",
      "Train Log likelihood, step 90150 in nats: 0.063694\n",
      "Train Log likelihood, step 90200 in nats: 0.063697\n",
      "Train Log likelihood, step 90250 in nats: 0.063699\n",
      "Train Log likelihood, step 90300 in nats: 0.063725\n",
      "Train epoch average loss: 0.06372409646466413\n",
      "\n",
      "\n",
      "Epoch: 554\n",
      "Train Log likelihood, step 90350 in nats: 0.063747\n",
      "Train Log likelihood, step 90400 in nats: 0.063752\n",
      "Train Log likelihood, step 90450 in nats: 0.063778\n",
      "Train epoch average loss: 0.0637828002799089\n",
      "\n",
      "\n",
      "Epoch: 555\n",
      "Train Log likelihood, step 90500 in nats: 0.063792\n",
      "Train Log likelihood, step 90550 in nats: 0.063807\n",
      "Train Log likelihood, step 90600 in nats: 0.063835\n",
      "Train epoch average loss: 0.06384792787795522\n",
      "\n",
      "\n",
      "Epoch: 556\n",
      "Train Log likelihood, step 90650 in nats: 0.063860\n",
      "Train Log likelihood, step 90700 in nats: 0.063896\n",
      "Train Log likelihood, step 90750 in nats: 0.063924\n",
      "Train epoch average loss: 0.06393375616951863\n",
      "\n",
      "\n",
      "Epoch: 557\n",
      "Train Log likelihood, step 90800 in nats: 0.063942\n",
      "Train Log likelihood, step 90850 in nats: 0.063970\n",
      "Train Log likelihood, step 90900 in nats: 0.063999\n",
      "Train Log likelihood, step 90950 in nats: 0.064022\n",
      "Train epoch average loss: 0.06402300363084173\n",
      "\n",
      "\n",
      "Epoch: 558\n",
      "Train Log likelihood, step 91000 in nats: 0.064034\n",
      "Train Log likelihood, step 91050 in nats: 0.064054\n",
      "Train Log likelihood, step 91100 in nats: 0.064082\n",
      "Train epoch average loss: 0.06409170987532467\n",
      "\n",
      "\n",
      "Epoch: 559\n",
      "Train Log likelihood, step 91150 in nats: 0.064115\n",
      "Train Log likelihood, step 91200 in nats: 0.064142\n",
      "Train Log likelihood, step 91250 in nats: 0.064170\n",
      "Train epoch average loss: 0.06418848992141364\n",
      "\n",
      "\n",
      "Epoch: 560\n",
      "Train Log likelihood, step 91300 in nats: 0.064206\n",
      "Train Log likelihood, step 91350 in nats: 0.064226\n",
      "Train Log likelihood, step 91400 in nats: 0.064257\n",
      "Train epoch average loss: 0.06426766049883968\n",
      "\n",
      "\n",
      "Epoch: 561\n",
      "Train Log likelihood, step 91450 in nats: 0.064265\n",
      "Train Log likelihood, step 91500 in nats: 0.064289\n",
      "Train Log likelihood, step 91550 in nats: 0.064309\n",
      "Train Log likelihood, step 91600 in nats: 0.064335\n",
      "Train epoch average loss: 0.06433290551869082\n",
      "\n",
      "\n",
      "Epoch: 562\n",
      "Train Log likelihood, step 91650 in nats: 0.064351\n",
      "Train Log likelihood, step 91700 in nats: 0.064383\n",
      "Train Log likelihood, step 91750 in nats: 0.064418\n",
      "Train epoch average loss: 0.06443690150134498\n",
      "\n",
      "\n",
      "Epoch: 563\n",
      "Train Log likelihood, step 91800 in nats: 0.064450\n",
      "Train Log likelihood, step 91850 in nats: 0.064467\n",
      "Train Log likelihood, step 91900 in nats: 0.064489\n",
      "Train epoch average loss: 0.06450597921633794\n",
      "\n",
      "\n",
      "Epoch: 564\n",
      "Train Log likelihood, step 91950 in nats: 0.064500\n",
      "Train Log likelihood, step 92000 in nats: 0.064513\n",
      "Train Log likelihood, step 92050 in nats: 0.064540\n",
      "Train epoch average loss: 0.0645637130840649\n",
      "\n",
      "\n",
      "Epoch: 565\n",
      "Train Log likelihood, step 92100 in nats: 0.064570\n",
      "Train Log likelihood, step 92150 in nats: 0.064605\n",
      "Train Log likelihood, step 92200 in nats: 0.064635\n",
      "Train Log likelihood, step 92250 in nats: 0.064666\n",
      "Train epoch average loss: 0.0646665121261678\n",
      "\n",
      "\n",
      "Epoch: 566\n",
      "Train Log likelihood, step 92300 in nats: 0.064692\n",
      "Train Log likelihood, step 92350 in nats: 0.064717\n",
      "Train Log likelihood, step 92400 in nats: 0.064743\n",
      "Train epoch average loss: 0.06475572371841334\n",
      "\n",
      "\n",
      "Epoch: 567\n",
      "Train Log likelihood, step 92450 in nats: 0.064756\n",
      "Train Log likelihood, step 92500 in nats: 0.064751\n",
      "Train Log likelihood, step 92550 in nats: 0.064791\n",
      "Train epoch average loss: 0.06480382929403218\n",
      "\n",
      "\n",
      "Epoch: 568\n",
      "Train Log likelihood, step 92600 in nats: 0.064803\n",
      "Train Log likelihood, step 92650 in nats: 0.064823\n",
      "Train Log likelihood, step 92700 in nats: 0.064841\n",
      "Train epoch average loss: 0.06485790609056319\n",
      "\n",
      "\n",
      "Epoch: 569\n",
      "Train Log likelihood, step 92750 in nats: 0.064862\n",
      "Train Log likelihood, step 92800 in nats: 0.064879\n",
      "Train Log likelihood, step 92850 in nats: 0.064902\n",
      "Train Log likelihood, step 92900 in nats: 0.064901\n",
      "Train epoch average loss: 0.06490681382941473\n",
      "\n",
      "\n",
      "Epoch: 570\n",
      "Train Log likelihood, step 92950 in nats: 0.064906\n",
      "Train Log likelihood, step 93000 in nats: 0.064915\n",
      "Train Log likelihood, step 93050 in nats: 0.064935\n",
      "Train epoch average loss: 0.06494538428531034\n",
      "\n",
      "\n",
      "Epoch: 571\n",
      "Train Log likelihood, step 93100 in nats: 0.064943\n",
      "Train Log likelihood, step 93150 in nats: 0.064951\n",
      "Train Log likelihood, step 93200 in nats: 0.064980\n",
      "Train epoch average loss: 0.06500485122159749\n",
      "\n",
      "\n",
      "Epoch: 572\n",
      "Train Log likelihood, step 93250 in nats: 0.065010\n",
      "Train Log likelihood, step 93300 in nats: 0.065019\n",
      "Train Log likelihood, step 93350 in nats: 0.065040\n",
      "Train epoch average loss: 0.06505281842351761\n",
      "\n",
      "\n",
      "Epoch: 573\n",
      "Train Log likelihood, step 93400 in nats: 0.065051\n",
      "Train Log likelihood, step 93450 in nats: 0.065059\n",
      "Train Log likelihood, step 93500 in nats: 0.065090\n",
      "Train Log likelihood, step 93550 in nats: 0.065117\n",
      "Train epoch average loss: 0.06511775072513802\n",
      "\n",
      "\n",
      "Epoch: 574\n",
      "Train Log likelihood, step 93600 in nats: 0.065142\n",
      "Train Log likelihood, step 93650 in nats: 0.065173\n",
      "Train Log likelihood, step 93700 in nats: 0.065192\n",
      "Train epoch average loss: 0.06520321307759726\n",
      "\n",
      "\n",
      "Epoch: 575\n",
      "Train Log likelihood, step 93750 in nats: 0.065204\n",
      "Train Log likelihood, step 93800 in nats: 0.065230\n",
      "Train Log likelihood, step 93850 in nats: 0.065259\n",
      "Train epoch average loss: 0.06527596745864249\n",
      "\n",
      "\n",
      "Epoch: 576\n",
      "Train Log likelihood, step 93900 in nats: 0.065282\n",
      "Train Log likelihood, step 93950 in nats: 0.065302\n",
      "Train Log likelihood, step 94000 in nats: 0.065316\n",
      "Train Log likelihood, step 94050 in nats: 0.065334\n",
      "Train epoch average loss: 0.06533446899648941\n",
      "\n",
      "\n",
      "Epoch: 577\n",
      "Train Log likelihood, step 94100 in nats: 0.065342\n",
      "Train Log likelihood, step 94150 in nats: 0.065361\n",
      "Train Log likelihood, step 94200 in nats: 0.065369\n",
      "Train epoch average loss: 0.06537054165300549\n",
      "\n",
      "\n",
      "Epoch: 578\n",
      "Train Log likelihood, step 94250 in nats: 0.065369\n",
      "Train Log likelihood, step 94300 in nats: 0.065384\n",
      "Train Log likelihood, step 94350 in nats: 0.065400\n",
      "Train epoch average loss: 0.06542088108492607\n",
      "\n",
      "\n",
      "Epoch: 579\n",
      "Train Log likelihood, step 94400 in nats: 0.065435\n",
      "Train Log likelihood, step 94450 in nats: 0.065451\n",
      "Train Log likelihood, step 94500 in nats: 0.065482\n",
      "Train epoch average loss: 0.06550476708935206\n",
      "\n",
      "\n",
      "Epoch: 580\n",
      "Train Log likelihood, step 94550 in nats: 0.065510\n",
      "Train Log likelihood, step 94600 in nats: 0.065529\n",
      "Train Log likelihood, step 94650 in nats: 0.065547\n",
      "Train Log likelihood, step 94700 in nats: 0.065567\n",
      "Train epoch average loss: 0.0655648599499117\n",
      "\n",
      "\n",
      "Epoch: 581\n",
      "Train Log likelihood, step 94750 in nats: 0.065591\n",
      "Train Log likelihood, step 94800 in nats: 0.065604\n",
      "Train Log likelihood, step 94850 in nats: 0.065623\n",
      "Train epoch average loss: 0.06563409832335537\n",
      "\n",
      "\n",
      "Epoch: 582\n",
      "Train Log likelihood, step 94900 in nats: 0.065647\n",
      "Train Log likelihood, step 94950 in nats: 0.065666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 95000 in nats: 0.065687\n",
      "Train epoch average loss: 0.06569882550785638\n",
      "\n",
      "\n",
      "Epoch: 583\n",
      "Train Log likelihood, step 95050 in nats: 0.065707\n",
      "Train Log likelihood, step 95100 in nats: 0.065726\n",
      "Train Log likelihood, step 95150 in nats: 0.065748\n",
      "Train epoch average loss: 0.0657597679985347\n",
      "\n",
      "\n",
      "Epoch: 584\n",
      "Train Log likelihood, step 95200 in nats: 0.065763\n",
      "Train Log likelihood, step 95250 in nats: 0.065768\n",
      "Train Log likelihood, step 95300 in nats: 0.065800\n",
      "Train Log likelihood, step 95350 in nats: 0.065828\n",
      "Train epoch average loss: 0.06583125722486581\n",
      "\n",
      "\n",
      "Epoch: 585\n",
      "Train Log likelihood, step 95400 in nats: 0.065838\n",
      "Train Log likelihood, step 95450 in nats: 0.065858\n",
      "Train Log likelihood, step 95500 in nats: 0.065900\n",
      "Train epoch average loss: 0.06590700681622265\n",
      "\n",
      "\n",
      "Epoch: 586\n",
      "Train Log likelihood, step 95550 in nats: 0.065930\n",
      "Train Log likelihood, step 95600 in nats: 0.065956\n",
      "Train Log likelihood, step 95650 in nats: 0.065985\n",
      "Train epoch average loss: 0.06600469423680366\n",
      "\n",
      "\n",
      "Epoch: 587\n",
      "Train Log likelihood, step 95700 in nats: 0.066018\n",
      "Train Log likelihood, step 95750 in nats: 0.066034\n",
      "Train Log likelihood, step 95800 in nats: 0.066051\n",
      "Train epoch average loss: 0.06607619171842428\n",
      "\n",
      "\n",
      "Epoch: 588\n",
      "Train Log likelihood, step 95850 in nats: 0.066081\n",
      "Train Log likelihood, step 95900 in nats: 0.066108\n",
      "Train Log likelihood, step 95950 in nats: 0.066141\n",
      "Train Log likelihood, step 96000 in nats: 0.066170\n",
      "Train epoch average loss: 0.06617210412044353\n",
      "\n",
      "\n",
      "Epoch: 589\n",
      "Train Log likelihood, step 96050 in nats: 0.066178\n",
      "Train Log likelihood, step 96100 in nats: 0.066206\n",
      "Train Log likelihood, step 96150 in nats: 0.066223\n",
      "Train epoch average loss: 0.06623037122966417\n",
      "\n",
      "\n",
      "Epoch: 590\n",
      "Train Log likelihood, step 96200 in nats: 0.066244\n",
      "Train Log likelihood, step 96250 in nats: 0.066259\n",
      "Train Log likelihood, step 96300 in nats: 0.066283\n",
      "Train epoch average loss: 0.06630051442708168\n",
      "\n",
      "\n",
      "Epoch: 591\n",
      "Train Log likelihood, step 96350 in nats: 0.066299\n",
      "Train Log likelihood, step 96400 in nats: 0.066328\n",
      "Train Log likelihood, step 96450 in nats: 0.066357\n",
      "Train epoch average loss: 0.06637160553850532\n",
      "\n",
      "\n",
      "Epoch: 592\n",
      "Train Log likelihood, step 96500 in nats: 0.066374\n",
      "Train Log likelihood, step 96550 in nats: 0.066386\n",
      "Train Log likelihood, step 96600 in nats: 0.066388\n",
      "Train Log likelihood, step 96650 in nats: 0.066418\n",
      "Train epoch average loss: 0.06641409131147372\n",
      "\n",
      "\n",
      "Epoch: 593\n",
      "Train Log likelihood, step 96700 in nats: 0.066432\n",
      "Train Log likelihood, step 96750 in nats: 0.066445\n",
      "Train Log likelihood, step 96800 in nats: 0.066467\n",
      "Train epoch average loss: 0.06646834746095906\n",
      "\n",
      "\n",
      "Epoch: 594\n",
      "Train Log likelihood, step 96850 in nats: 0.066483\n",
      "Train Log likelihood, step 96900 in nats: 0.066506\n",
      "Train Log likelihood, step 96950 in nats: 0.066523\n",
      "Train epoch average loss: 0.06653764366111163\n",
      "\n",
      "\n",
      "Epoch: 595\n",
      "Train Log likelihood, step 97000 in nats: 0.066546\n",
      "Train Log likelihood, step 97050 in nats: 0.066574\n",
      "Train Log likelihood, step 97100 in nats: 0.066601\n",
      "Train epoch average loss: 0.06660929494106982\n",
      "\n",
      "\n",
      "Epoch: 596\n",
      "Train Log likelihood, step 97150 in nats: 0.066609\n",
      "Train Log likelihood, step 97200 in nats: 0.066623\n",
      "Train Log likelihood, step 97250 in nats: 0.066648\n",
      "Train Log likelihood, step 97300 in nats: 0.066662\n",
      "Train epoch average loss: 0.06666140019331332\n",
      "\n",
      "\n",
      "Epoch: 597\n",
      "Train Log likelihood, step 97350 in nats: 0.066680\n",
      "Train Log likelihood, step 97400 in nats: 0.066678\n",
      "Train Log likelihood, step 97450 in nats: 0.066701\n",
      "Train epoch average loss: 0.06671703908098099\n",
      "\n",
      "\n",
      "Epoch: 598\n",
      "Train Log likelihood, step 97500 in nats: 0.066731\n",
      "Train Log likelihood, step 97550 in nats: 0.066751\n",
      "Train Log likelihood, step 97600 in nats: 0.066780\n",
      "Train epoch average loss: 0.06680815606617675\n",
      "\n",
      "\n",
      "Epoch: 599\n",
      "Train Log likelihood, step 97650 in nats: 0.066814\n",
      "Train Log likelihood, step 97700 in nats: 0.066840\n",
      "Train Log likelihood, step 97750 in nats: 0.066873\n",
      "Train epoch average loss: 0.06689843958647186\n",
      "\n",
      "\n",
      "Epoch: 600\n",
      "Train Log likelihood, step 97800 in nats: 0.066900\n",
      "Train Log likelihood, step 97850 in nats: 0.066927\n",
      "Train Log likelihood, step 97900 in nats: 0.066940\n",
      "Train Log likelihood, step 97950 in nats: 0.066959\n",
      "Train epoch average loss: 0.06696494250876363\n",
      "\n",
      "\n",
      "Epoch: 601\n",
      "Train Log likelihood, step 98000 in nats: 0.066984\n",
      "Train Log likelihood, step 98050 in nats: 0.067006\n",
      "Train Log likelihood, step 98100 in nats: 0.067047\n",
      "Train epoch average loss: 0.06706052916639474\n",
      "\n",
      "\n",
      "Epoch: 602\n",
      "Train Log likelihood, step 98150 in nats: 0.067069\n",
      "Train Log likelihood, step 98200 in nats: 0.067094\n",
      "Train Log likelihood, step 98250 in nats: 0.067104\n",
      "Train epoch average loss: 0.06711756809745485\n",
      "\n",
      "\n",
      "Epoch: 603\n",
      "Train Log likelihood, step 98300 in nats: 0.067117\n",
      "Train Log likelihood, step 98350 in nats: 0.067128\n",
      "Train Log likelihood, step 98400 in nats: 0.067143\n",
      "Train Log likelihood, step 98450 in nats: 0.067166\n",
      "Train epoch average loss: 0.06716630037301638\n",
      "\n",
      "\n",
      "Epoch: 604\n",
      "Train Log likelihood, step 98500 in nats: 0.067193\n",
      "Train Log likelihood, step 98550 in nats: 0.067210\n",
      "Train Log likelihood, step 98600 in nats: 0.067238\n",
      "Train epoch average loss: 0.06724418494819723\n",
      "\n",
      "\n",
      "Epoch: 605\n",
      "Train Log likelihood, step 98650 in nats: 0.067263\n",
      "Train Log likelihood, step 98700 in nats: 0.067300\n",
      "Train Log likelihood, step 98750 in nats: 0.067314\n",
      "Train epoch average loss: 0.06732913106490324\n",
      "\n",
      "\n",
      "Epoch: 606\n",
      "Train Log likelihood, step 98800 in nats: 0.067349\n",
      "Train Log likelihood, step 98850 in nats: 0.067360\n",
      "Train Log likelihood, step 98900 in nats: 0.067400\n",
      "Train epoch average loss: 0.06741162648015288\n",
      "\n",
      "\n",
      "Epoch: 607\n",
      "Train Log likelihood, step 98950 in nats: 0.067421\n",
      "Train Log likelihood, step 99000 in nats: 0.067449\n",
      "Train Log likelihood, step 99050 in nats: 0.067476\n",
      "Train Log likelihood, step 99100 in nats: 0.067500\n",
      "Train epoch average loss: 0.06750207832877637\n",
      "\n",
      "\n",
      "Epoch: 608\n",
      "Train Log likelihood, step 99150 in nats: 0.067510\n",
      "Train Log likelihood, step 99200 in nats: 0.067521\n",
      "Train Log likelihood, step 99250 in nats: 0.067546\n",
      "Train epoch average loss: 0.06755592748518513\n",
      "\n",
      "\n",
      "Epoch: 609\n",
      "Train Log likelihood, step 99300 in nats: 0.067575\n",
      "Train Log likelihood, step 99350 in nats: 0.067592\n",
      "Train Log likelihood, step 99400 in nats: 0.067611\n",
      "Train epoch average loss: 0.06762599740957465\n",
      "\n",
      "\n",
      "Epoch: 610\n",
      "Train Log likelihood, step 99450 in nats: 0.067634\n",
      "Train Log likelihood, step 99500 in nats: 0.067667\n",
      "Train Log likelihood, step 99550 in nats: 0.067680\n",
      "Train epoch average loss: 0.06769868411846401\n",
      "\n",
      "\n",
      "Epoch: 611\n",
      "Train Log likelihood, step 99600 in nats: 0.067701\n",
      "Train Log likelihood, step 99650 in nats: 0.067723\n",
      "Train Log likelihood, step 99700 in nats: 0.067753\n",
      "Train Log likelihood, step 99750 in nats: 0.067766\n",
      "Train epoch average loss: 0.06776808407845596\n",
      "\n",
      "\n",
      "Epoch: 612\n",
      "Train Log likelihood, step 99800 in nats: 0.067788\n",
      "Train Log likelihood, step 99850 in nats: 0.067808\n",
      "Train Log likelihood, step 99900 in nats: 0.067843\n",
      "Train epoch average loss: 0.06785298229188917\n",
      "\n",
      "\n",
      "Epoch: 613\n",
      "Train Log likelihood, step 99950 in nats: 0.067872\n",
      "Train Log likelihood, step 100000 in nats: 0.067876\n",
      "Train Log likelihood, step 100050 in nats: 0.067901\n",
      "Train epoch average loss: 0.06790795089754204\n",
      "\n",
      "\n",
      "Epoch: 614\n",
      "Train Log likelihood, step 100100 in nats: 0.067914\n",
      "Train Log likelihood, step 100150 in nats: 0.067929\n",
      "Train Log likelihood, step 100200 in nats: 0.067956\n",
      "Train epoch average loss: 0.06797459890667389\n",
      "\n",
      "\n",
      "Epoch: 615\n",
      "Train Log likelihood, step 100250 in nats: 0.067979\n",
      "Train Log likelihood, step 100300 in nats: 0.068002\n",
      "Train Log likelihood, step 100350 in nats: 0.068024\n",
      "Train Log likelihood, step 100400 in nats: 0.068057\n",
      "Train epoch average loss: 0.06805760006607588\n",
      "\n",
      "\n",
      "Epoch: 616\n",
      "Train Log likelihood, step 100450 in nats: 0.068079\n",
      "Train Log likelihood, step 100500 in nats: 0.068105\n",
      "Train Log likelihood, step 100550 in nats: 0.068129\n",
      "Train epoch average loss: 0.06814272095045983\n",
      "\n",
      "\n",
      "Epoch: 617\n",
      "Train Log likelihood, step 100600 in nats: 0.068156\n",
      "Train Log likelihood, step 100650 in nats: 0.068192\n",
      "Train Log likelihood, step 100700 in nats: 0.068224\n",
      "Train epoch average loss: 0.06824474017899279\n",
      "\n",
      "\n",
      "Epoch: 618\n",
      "Train Log likelihood, step 100750 in nats: 0.068245\n",
      "Train Log likelihood, step 100800 in nats: 0.068259\n",
      "Train Log likelihood, step 100850 in nats: 0.068286\n",
      "Train epoch average loss: 0.06827839020854946\n",
      "\n",
      "\n",
      "Epoch: 619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 100900 in nats: 0.068280\n",
      "Train Log likelihood, step 100950 in nats: 0.068300\n",
      "Train Log likelihood, step 101000 in nats: 0.068319\n",
      "Train Log likelihood, step 101050 in nats: 0.068330\n",
      "Train epoch average loss: 0.06832736707972738\n",
      "\n",
      "\n",
      "Epoch: 620\n",
      "Train Log likelihood, step 101100 in nats: 0.068347\n",
      "Train Log likelihood, step 101150 in nats: 0.068365\n",
      "Train Log likelihood, step 101200 in nats: 0.068390\n",
      "Train epoch average loss: 0.06840489063472757\n",
      "\n",
      "\n",
      "Epoch: 621\n",
      "Train Log likelihood, step 101250 in nats: 0.068409\n",
      "Train Log likelihood, step 101300 in nats: 0.068416\n",
      "Train Log likelihood, step 101350 in nats: 0.068437\n",
      "Train epoch average loss: 0.0684485702753224\n",
      "\n",
      "\n",
      "Epoch: 622\n",
      "Train Log likelihood, step 101400 in nats: 0.068450\n",
      "Train Log likelihood, step 101450 in nats: 0.068467\n",
      "Train Log likelihood, step 101500 in nats: 0.068496\n",
      "Train epoch average loss: 0.06851326303786225\n",
      "\n",
      "\n",
      "Epoch: 623\n",
      "Train Log likelihood, step 101550 in nats: 0.068516\n",
      "Train Log likelihood, step 101600 in nats: 0.068536\n",
      "Train Log likelihood, step 101650 in nats: 0.068571\n",
      "Train Log likelihood, step 101700 in nats: 0.068593\n",
      "Train epoch average loss: 0.06860235964663718\n",
      "\n",
      "\n",
      "Epoch: 624\n",
      "Train Log likelihood, step 101750 in nats: 0.068630\n",
      "Train Log likelihood, step 101800 in nats: 0.068659\n",
      "Train Log likelihood, step 101850 in nats: 0.068693\n",
      "Train epoch average loss: 0.06870454663052789\n",
      "\n",
      "\n",
      "Epoch: 625\n",
      "Train Log likelihood, step 101900 in nats: 0.068711\n",
      "Train Log likelihood, step 101950 in nats: 0.068730\n",
      "Train Log likelihood, step 102000 in nats: 0.068743\n",
      "Train epoch average loss: 0.06875734273325892\n",
      "\n",
      "\n",
      "Epoch: 626\n",
      "Train Log likelihood, step 102050 in nats: 0.068763\n",
      "Train Log likelihood, step 102100 in nats: 0.068781\n",
      "Train Log likelihood, step 102150 in nats: 0.068794\n",
      "Train Log likelihood, step 102200 in nats: 0.068803\n",
      "Train epoch average loss: 0.06880319166158119\n",
      "\n",
      "\n",
      "Epoch: 627\n",
      "Train Log likelihood, step 102250 in nats: 0.068825\n",
      "Train Log likelihood, step 102300 in nats: 0.068846\n",
      "Train Log likelihood, step 102350 in nats: 0.068860\n",
      "Train epoch average loss: 0.06886612534064286\n",
      "\n",
      "\n",
      "Epoch: 628\n",
      "Train Log likelihood, step 102400 in nats: 0.068871\n",
      "Train Log likelihood, step 102450 in nats: 0.068903\n",
      "Train Log likelihood, step 102500 in nats: 0.068928\n",
      "Train epoch average loss: 0.06893694466887235\n",
      "\n",
      "\n",
      "Epoch: 629\n",
      "Train Log likelihood, step 102550 in nats: 0.068947\n",
      "Train Log likelihood, step 102600 in nats: 0.068972\n",
      "Train Log likelihood, step 102650 in nats: 0.069001\n",
      "Train epoch average loss: 0.06901899941213607\n",
      "\n",
      "\n",
      "Epoch: 630\n",
      "Train Log likelihood, step 102700 in nats: 0.069015\n",
      "Train Log likelihood, step 102750 in nats: 0.069013\n",
      "Train Log likelihood, step 102800 in nats: 0.069028\n",
      "Train Log likelihood, step 102850 in nats: 0.069042\n",
      "Train epoch average loss: 0.06904170586226634\n",
      "\n",
      "\n",
      "Epoch: 631\n",
      "Train Log likelihood, step 102900 in nats: 0.069068\n",
      "Train Log likelihood, step 102950 in nats: 0.069084\n",
      "Train Log likelihood, step 103000 in nats: 0.069088\n",
      "Train epoch average loss: 0.06908593526943654\n",
      "\n",
      "\n",
      "Epoch: 632\n",
      "Train Log likelihood, step 103050 in nats: 0.069106\n",
      "Train Log likelihood, step 103100 in nats: 0.069135\n",
      "Train Log likelihood, step 103150 in nats: 0.069150\n",
      "Train epoch average loss: 0.06916816998183592\n",
      "\n",
      "\n",
      "Epoch: 633\n",
      "Train Log likelihood, step 103200 in nats: 0.069169\n",
      "Train Log likelihood, step 103250 in nats: 0.069188\n",
      "Train Log likelihood, step 103300 in nats: 0.069188\n",
      "Train epoch average loss: 0.06919407887127973\n",
      "\n",
      "\n",
      "Epoch: 634\n",
      "Train Log likelihood, step 103350 in nats: 0.069200\n",
      "Train Log likelihood, step 103400 in nats: 0.069223\n",
      "Train Log likelihood, step 103450 in nats: 0.069238\n",
      "Train Log likelihood, step 103500 in nats: 0.069256\n",
      "Train epoch average loss: 0.0692614765398064\n",
      "\n",
      "\n",
      "Epoch: 635\n",
      "Train Log likelihood, step 103550 in nats: 0.069285\n",
      "Train Log likelihood, step 103600 in nats: 0.069301\n",
      "Train Log likelihood, step 103650 in nats: 0.069324\n",
      "Train epoch average loss: 0.0693294539514182\n",
      "\n",
      "\n",
      "Epoch: 636\n",
      "Train Log likelihood, step 103700 in nats: 0.069344\n",
      "Train Log likelihood, step 103750 in nats: 0.069348\n",
      "Train Log likelihood, step 103800 in nats: 0.069357\n",
      "Train epoch average loss: 0.06936902608540789\n",
      "\n",
      "\n",
      "Epoch: 637\n",
      "Train Log likelihood, step 103850 in nats: 0.069379\n",
      "Train Log likelihood, step 103900 in nats: 0.069417\n",
      "Train Log likelihood, step 103950 in nats: 0.069441\n",
      "Train epoch average loss: 0.06947067568872133\n",
      "\n",
      "\n",
      "Epoch: 638\n",
      "Train Log likelihood, step 104000 in nats: 0.069476\n",
      "Train Log likelihood, step 104050 in nats: 0.069489\n",
      "Train Log likelihood, step 104100 in nats: 0.069519\n",
      "Train Log likelihood, step 104150 in nats: 0.069543\n",
      "Train epoch average loss: 0.06954452575398695\n",
      "\n",
      "\n",
      "Epoch: 639\n",
      "Train Log likelihood, step 104200 in nats: 0.069565\n",
      "Train Log likelihood, step 104250 in nats: 0.069590\n",
      "Train Log likelihood, step 104300 in nats: 0.069611\n",
      "Train epoch average loss: 0.06961757781939143\n",
      "\n",
      "\n",
      "Epoch: 640\n",
      "Train Log likelihood, step 104350 in nats: 0.069635\n",
      "Train Log likelihood, step 104400 in nats: 0.069640\n",
      "Train Log likelihood, step 104450 in nats: 0.069648\n",
      "Train epoch average loss: 0.06965882922049667\n",
      "\n",
      "\n",
      "Epoch: 641\n",
      "Train Log likelihood, step 104500 in nats: 0.069666\n",
      "Train Log likelihood, step 104550 in nats: 0.069682\n",
      "Train Log likelihood, step 104600 in nats: 0.069690\n",
      "Train epoch average loss: 0.0697030108804505\n",
      "\n",
      "\n",
      "Epoch: 642\n",
      "Train Log likelihood, step 104650 in nats: 0.069706\n",
      "Train Log likelihood, step 104700 in nats: 0.069728\n",
      "Train Log likelihood, step 104750 in nats: 0.069752\n",
      "Train Log likelihood, step 104800 in nats: 0.069774\n",
      "Train epoch average loss: 0.0697776526259301\n",
      "\n",
      "\n",
      "Epoch: 643\n",
      "Train Log likelihood, step 104850 in nats: 0.069798\n",
      "Train Log likelihood, step 104900 in nats: 0.069825\n",
      "Train Log likelihood, step 104950 in nats: 0.069849\n",
      "Train epoch average loss: 0.06986268341884082\n",
      "\n",
      "\n",
      "Epoch: 644\n",
      "Train Log likelihood, step 105000 in nats: 0.069868\n",
      "Train Log likelihood, step 105050 in nats: 0.069879\n",
      "Train Log likelihood, step 105100 in nats: 0.069895\n",
      "Train epoch average loss: 0.06991814222699055\n",
      "\n",
      "\n",
      "Epoch: 645\n",
      "Train Log likelihood, step 105150 in nats: 0.069927\n",
      "Train Log likelihood, step 105200 in nats: 0.069955\n",
      "Train Log likelihood, step 105250 in nats: 0.069982\n",
      "Train epoch average loss: 0.06999636982038857\n",
      "\n",
      "\n",
      "Epoch: 646\n",
      "Train Log likelihood, step 105300 in nats: 0.069998\n",
      "Train Log likelihood, step 105350 in nats: 0.070008\n",
      "Train Log likelihood, step 105400 in nats: 0.070031\n",
      "Train Log likelihood, step 105450 in nats: 0.070051\n",
      "Train epoch average loss: 0.07005539774796343\n",
      "\n",
      "\n",
      "Epoch: 647\n",
      "Train Log likelihood, step 105500 in nats: 0.070055\n",
      "Train Log likelihood, step 105550 in nats: 0.070069\n",
      "Train Log likelihood, step 105600 in nats: 0.070100\n",
      "Train epoch average loss: 0.07010649676703475\n",
      "\n",
      "\n",
      "Epoch: 648\n",
      "Train Log likelihood, step 105650 in nats: 0.070122\n",
      "Train Log likelihood, step 105700 in nats: 0.070154\n",
      "Train Log likelihood, step 105750 in nats: 0.070157\n",
      "Train epoch average loss: 0.07015781045608922\n",
      "\n",
      "\n",
      "Epoch: 649\n",
      "Train Log likelihood, step 105800 in nats: 0.070159\n",
      "Train Log likelihood, step 105850 in nats: 0.070191\n",
      "Train Log likelihood, step 105900 in nats: 0.070206\n",
      "Train epoch average loss: 0.07022230442272483\n",
      "\n",
      "\n",
      "Epoch: 650\n",
      "Train Log likelihood, step 105950 in nats: 0.070221\n",
      "Train Log likelihood, step 106000 in nats: 0.070237\n",
      "Train Log likelihood, step 106050 in nats: 0.070263\n",
      "Train Log likelihood, step 106100 in nats: 0.070297\n",
      "Train epoch average loss: 0.07030145557143536\n",
      "\n",
      "\n",
      "Epoch: 651\n",
      "Train Log likelihood, step 106150 in nats: 0.070313\n",
      "Train Log likelihood, step 106200 in nats: 0.070346\n",
      "Train Log likelihood, step 106250 in nats: 0.070355\n",
      "Train epoch average loss: 0.07036242912654897\n",
      "\n",
      "\n",
      "Epoch: 652\n",
      "Train Log likelihood, step 106300 in nats: 0.070374\n",
      "Train Log likelihood, step 106350 in nats: 0.070385\n",
      "Train Log likelihood, step 106400 in nats: 0.070405\n",
      "Train epoch average loss: 0.07041295056896574\n",
      "\n",
      "\n",
      "Epoch: 653\n",
      "Train Log likelihood, step 106450 in nats: 0.070419\n",
      "Train Log likelihood, step 106500 in nats: 0.070438\n",
      "Train Log likelihood, step 106550 in nats: 0.070466\n",
      "Train Log likelihood, step 106600 in nats: 0.070477\n",
      "Train epoch average loss: 0.07047708370989836\n",
      "\n",
      "\n",
      "Epoch: 654\n",
      "Train Log likelihood, step 106650 in nats: 0.070498\n",
      "Train Log likelihood, step 106700 in nats: 0.070491\n",
      "Train Log likelihood, step 106750 in nats: 0.070493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch average loss: 0.07049553688799005\n",
      "\n",
      "\n",
      "Epoch: 655\n",
      "Train Log likelihood, step 106800 in nats: 0.070507\n",
      "Train Log likelihood, step 106850 in nats: 0.070517\n",
      "Train Log likelihood, step 106900 in nats: 0.070536\n",
      "Train epoch average loss: 0.07054939012741634\n",
      "\n",
      "\n",
      "Epoch: 656\n",
      "Train Log likelihood, step 106950 in nats: 0.070555\n",
      "Train Log likelihood, step 107000 in nats: 0.070563\n",
      "Train Log likelihood, step 107050 in nats: 0.070590\n",
      "Train epoch average loss: 0.07060334490002378\n",
      "\n",
      "\n",
      "Epoch: 657\n",
      "Train Log likelihood, step 107100 in nats: 0.070612\n",
      "Train Log likelihood, step 107150 in nats: 0.070632\n",
      "Train Log likelihood, step 107200 in nats: 0.070653\n",
      "Train Log likelihood, step 107250 in nats: 0.070665\n",
      "Train epoch average loss: 0.07066690634770345\n",
      "\n",
      "\n",
      "Epoch: 658\n",
      "Train Log likelihood, step 107300 in nats: 0.070693\n",
      "Train Log likelihood, step 107350 in nats: 0.070717\n",
      "Train Log likelihood, step 107400 in nats: 0.070739\n",
      "Train epoch average loss: 0.07073943807994049\n",
      "\n",
      "\n",
      "Epoch: 659\n",
      "Train Log likelihood, step 107450 in nats: 0.070748\n",
      "Train Log likelihood, step 107500 in nats: 0.070753\n",
      "Train Log likelihood, step 107550 in nats: 0.070767\n",
      "Train epoch average loss: 0.07077075702706392\n",
      "\n",
      "\n",
      "Epoch: 660\n",
      "Train Log likelihood, step 107600 in nats: 0.070782\n",
      "Train Log likelihood, step 107650 in nats: 0.070815\n",
      "Train Log likelihood, step 107700 in nats: 0.070842\n",
      "Train epoch average loss: 0.07085527570966128\n",
      "\n",
      "\n",
      "Epoch: 661\n",
      "Train Log likelihood, step 107750 in nats: 0.070861\n",
      "Train Log likelihood, step 107800 in nats: 0.070865\n",
      "Train Log likelihood, step 107850 in nats: 0.070885\n",
      "Train Log likelihood, step 107900 in nats: 0.070890\n",
      "Train epoch average loss: 0.07089312528298627\n",
      "\n",
      "\n",
      "Epoch: 662\n",
      "Train Log likelihood, step 107950 in nats: 0.070904\n",
      "Train Log likelihood, step 108000 in nats: 0.070916\n",
      "Train Log likelihood, step 108050 in nats: 0.070919\n",
      "Train epoch average loss: 0.07092484295029773\n",
      "\n",
      "\n",
      "Epoch: 663\n",
      "Train Log likelihood, step 108100 in nats: 0.070940\n",
      "Train Log likelihood, step 108150 in nats: 0.070945\n",
      "Train Log likelihood, step 108200 in nats: 0.070945\n",
      "Train epoch average loss: 0.0709467633119778\n",
      "\n",
      "\n",
      "Epoch: 664\n",
      "Train Log likelihood, step 108250 in nats: 0.070957\n",
      "Train Log likelihood, step 108300 in nats: 0.070969\n",
      "Train Log likelihood, step 108350 in nats: 0.070999\n",
      "Train epoch average loss: 0.07101715529326859\n",
      "\n",
      "\n",
      "Epoch: 665\n",
      "Train Log likelihood, step 108400 in nats: 0.071020\n",
      "Train Log likelihood, step 108450 in nats: 0.071047\n",
      "Train Log likelihood, step 108500 in nats: 0.071054\n",
      "Train Log likelihood, step 108550 in nats: 0.071077\n",
      "Train epoch average loss: 0.07107992251014625\n",
      "\n",
      "\n",
      "Epoch: 666\n",
      "Train Log likelihood, step 108600 in nats: 0.071090\n",
      "Train Log likelihood, step 108650 in nats: 0.071114\n",
      "Train Log likelihood, step 108700 in nats: 0.071119\n",
      "Train epoch average loss: 0.07111938896074389\n",
      "\n",
      "\n",
      "Epoch: 667\n",
      "Train Log likelihood, step 108750 in nats: 0.071135\n",
      "Train Log likelihood, step 108800 in nats: 0.071144\n",
      "Train Log likelihood, step 108850 in nats: 0.071151\n",
      "Train epoch average loss: 0.07115825198568428\n",
      "\n",
      "\n",
      "Epoch: 668\n",
      "Train Log likelihood, step 108900 in nats: 0.071165\n",
      "Train Log likelihood, step 108950 in nats: 0.071163\n",
      "Train Log likelihood, step 109000 in nats: 0.071186\n",
      "Train epoch average loss: 0.07120881427953474\n",
      "\n",
      "\n",
      "Epoch: 669\n",
      "Train Log likelihood, step 109050 in nats: 0.071214\n",
      "Train Log likelihood, step 109100 in nats: 0.071236\n",
      "Train Log likelihood, step 109150 in nats: 0.071246\n",
      "Train Log likelihood, step 109200 in nats: 0.071279\n",
      "Train epoch average loss: 0.07128781625156701\n",
      "\n",
      "\n",
      "Epoch: 670\n",
      "Train Log likelihood, step 109250 in nats: 0.071307\n",
      "Train Log likelihood, step 109300 in nats: 0.071327\n",
      "Train Log likelihood, step 109350 in nats: 0.071343\n",
      "Train epoch average loss: 0.0713669491745908\n",
      "\n",
      "\n",
      "Epoch: 671\n",
      "Train Log likelihood, step 109400 in nats: 0.071379\n",
      "Train Log likelihood, step 109450 in nats: 0.071397\n",
      "Train Log likelihood, step 109500 in nats: 0.071410\n",
      "Train epoch average loss: 0.0714334885485012\n",
      "\n",
      "\n",
      "Epoch: 672\n",
      "Train Log likelihood, step 109550 in nats: 0.071437\n",
      "Train Log likelihood, step 109600 in nats: 0.071454\n",
      "Train Log likelihood, step 109650 in nats: 0.071474\n",
      "Train epoch average loss: 0.0714919649142692\n",
      "\n",
      "\n",
      "Epoch: 673\n",
      "Train Log likelihood, step 109700 in nats: 0.071491\n",
      "Train Log likelihood, step 109750 in nats: 0.071514\n",
      "Train Log likelihood, step 109800 in nats: 0.071529\n",
      "Train Log likelihood, step 109850 in nats: 0.071552\n",
      "Train epoch average loss: 0.07155970207905957\n",
      "\n",
      "\n",
      "Epoch: 674\n",
      "Train Log likelihood, step 109900 in nats: 0.071567\n",
      "Train Log likelihood, step 109950 in nats: 0.071583\n",
      "Train Log likelihood, step 110000 in nats: 0.071602\n",
      "Train epoch average loss: 0.07160889681920461\n",
      "\n",
      "\n",
      "Epoch: 675\n",
      "Train Log likelihood, step 110050 in nats: 0.071622\n",
      "Train Log likelihood, step 110100 in nats: 0.071634\n",
      "Train Log likelihood, step 110150 in nats: 0.071637\n",
      "Train epoch average loss: 0.07164090853746677\n",
      "\n",
      "\n",
      "Epoch: 676\n",
      "Train Log likelihood, step 110200 in nats: 0.071646\n",
      "Train Log likelihood, step 110250 in nats: 0.071657\n",
      "Train Log likelihood, step 110300 in nats: 0.071674\n",
      "Train Log likelihood, step 110350 in nats: 0.071706\n",
      "Train epoch average loss: 0.0717055303743933\n",
      "\n",
      "\n",
      "Epoch: 677\n",
      "Train Log likelihood, step 110400 in nats: 0.071728\n",
      "Train Log likelihood, step 110450 in nats: 0.071744\n",
      "Train Log likelihood, step 110500 in nats: 0.071761\n",
      "Train epoch average loss: 0.07176259636102504\n",
      "\n",
      "\n",
      "Epoch: 678\n",
      "Train Log likelihood, step 110550 in nats: 0.071776\n",
      "Train Log likelihood, step 110600 in nats: 0.071797\n",
      "Train Log likelihood, step 110650 in nats: 0.071810\n",
      "Train epoch average loss: 0.07182106675106935\n",
      "\n",
      "\n",
      "Epoch: 679\n",
      "Train Log likelihood, step 110700 in nats: 0.071831\n",
      "Train Log likelihood, step 110750 in nats: 0.071844\n",
      "Train Log likelihood, step 110800 in nats: 0.071852\n",
      "Train epoch average loss: 0.07187746563536695\n",
      "\n",
      "\n",
      "Epoch: 680\n",
      "Train Log likelihood, step 110850 in nats: 0.071881\n",
      "Train Log likelihood, step 110900 in nats: 0.071913\n",
      "Train Log likelihood, step 110950 in nats: 0.071929\n",
      "Train Log likelihood, step 111000 in nats: 0.071951\n",
      "Train epoch average loss: 0.07195242543949558\n",
      "\n",
      "\n",
      "Epoch: 681\n",
      "Train Log likelihood, step 111050 in nats: 0.071966\n",
      "Train Log likelihood, step 111100 in nats: 0.071973\n",
      "Train Log likelihood, step 111150 in nats: 0.071986\n",
      "Train epoch average loss: 0.07198884765114749\n",
      "\n",
      "\n",
      "Epoch: 682\n",
      "Train Log likelihood, step 111200 in nats: 0.071999\n",
      "Train Log likelihood, step 111250 in nats: 0.072014\n",
      "Train Log likelihood, step 111300 in nats: 0.072043\n",
      "Train epoch average loss: 0.0720570451985409\n",
      "\n",
      "\n",
      "Epoch: 683\n",
      "Train Log likelihood, step 111350 in nats: 0.072054\n",
      "Train Log likelihood, step 111400 in nats: 0.072068\n",
      "Train Log likelihood, step 111450 in nats: 0.072086\n",
      "Train epoch average loss: 0.07210932648432362\n",
      "\n",
      "\n",
      "Epoch: 684\n",
      "Train Log likelihood, step 111500 in nats: 0.072110\n",
      "Train Log likelihood, step 111550 in nats: 0.072113\n",
      "Train Log likelihood, step 111600 in nats: 0.072132\n",
      "Train Log likelihood, step 111650 in nats: 0.072143\n",
      "Train epoch average loss: 0.07214411717279784\n",
      "\n",
      "\n",
      "Epoch: 685\n",
      "Train Log likelihood, step 111700 in nats: 0.072156\n",
      "Train Log likelihood, step 111750 in nats: 0.072176\n",
      "Train Log likelihood, step 111800 in nats: 0.072183\n",
      "Train epoch average loss: 0.07218693282368965\n",
      "\n",
      "\n",
      "Epoch: 686\n",
      "Train Log likelihood, step 111850 in nats: 0.072197\n",
      "Train Log likelihood, step 111900 in nats: 0.072228\n",
      "Train Log likelihood, step 111950 in nats: 0.072255\n",
      "Train epoch average loss: 0.0722711187277568\n",
      "\n",
      "\n",
      "Epoch: 687\n",
      "Train Log likelihood, step 112000 in nats: 0.072277\n",
      "Train Log likelihood, step 112050 in nats: 0.072296\n",
      "Train Log likelihood, step 112100 in nats: 0.072317\n",
      "Train epoch average loss: 0.0723385424268919\n",
      "\n",
      "\n",
      "Epoch: 688\n",
      "Train Log likelihood, step 112150 in nats: 0.072337\n",
      "Train Log likelihood, step 112200 in nats: 0.072351\n",
      "Train Log likelihood, step 112250 in nats: 0.072379\n",
      "Train Log likelihood, step 112300 in nats: 0.072401\n",
      "Train epoch average loss: 0.07239902081854539\n",
      "\n",
      "\n",
      "Epoch: 689\n",
      "Train Log likelihood, step 112350 in nats: 0.072426\n",
      "Train Log likelihood, step 112400 in nats: 0.072448\n",
      "Train Log likelihood, step 112450 in nats: 0.072469\n",
      "Train epoch average loss: 0.07247233656909115\n",
      "\n",
      "\n",
      "Epoch: 690\n",
      "Train Log likelihood, step 112500 in nats: 0.072474\n",
      "Train Log likelihood, step 112550 in nats: 0.072492\n",
      "Train Log likelihood, step 112600 in nats: 0.072505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch average loss: 0.07251978727719907\n",
      "\n",
      "\n",
      "Epoch: 691\n",
      "Train Log likelihood, step 112650 in nats: 0.072527\n",
      "Train Log likelihood, step 112700 in nats: 0.072544\n",
      "Train Log likelihood, step 112750 in nats: 0.072551\n",
      "Train epoch average loss: 0.07256624066031235\n",
      "\n",
      "\n",
      "Epoch: 692\n",
      "Train Log likelihood, step 112800 in nats: 0.072570\n",
      "Train Log likelihood, step 112850 in nats: 0.072599\n",
      "Train Log likelihood, step 112900 in nats: 0.072604\n",
      "Train Log likelihood, step 112950 in nats: 0.072622\n",
      "Train epoch average loss: 0.07262472349209491\n",
      "\n",
      "\n",
      "Epoch: 693\n",
      "Train Log likelihood, step 113000 in nats: 0.072649\n",
      "Train Log likelihood, step 113050 in nats: 0.072666\n",
      "Train Log likelihood, step 113100 in nats: 0.072682\n",
      "Train epoch average loss: 0.07268489579733661\n",
      "\n",
      "\n",
      "Epoch: 694\n",
      "Train Log likelihood, step 113150 in nats: 0.072694\n",
      "Train Log likelihood, step 113200 in nats: 0.072700\n",
      "Train Log likelihood, step 113250 in nats: 0.072717\n",
      "Train epoch average loss: 0.07272300582739924\n",
      "\n",
      "\n",
      "Epoch: 695\n",
      "Train Log likelihood, step 113300 in nats: 0.072730\n",
      "Train Log likelihood, step 113350 in nats: 0.072723\n",
      "Train Log likelihood, step 113400 in nats: 0.072752\n",
      "Train epoch average loss: 0.07275166944861589\n",
      "\n",
      "\n",
      "Epoch: 696\n",
      "Train Log likelihood, step 113450 in nats: 0.072753\n",
      "Train Log likelihood, step 113500 in nats: 0.072770\n",
      "Train Log likelihood, step 113550 in nats: 0.072795\n",
      "Train Log likelihood, step 113600 in nats: 0.072805\n",
      "Train epoch average loss: 0.0728106401534136\n",
      "\n",
      "\n",
      "Epoch: 697\n",
      "Train Log likelihood, step 113650 in nats: 0.072816\n",
      "Train Log likelihood, step 113700 in nats: 0.072819\n",
      "Train Log likelihood, step 113750 in nats: 0.072821\n",
      "Train epoch average loss: 0.07282095039580676\n",
      "\n",
      "\n",
      "Epoch: 698\n",
      "Train Log likelihood, step 113800 in nats: 0.072828\n",
      "Train Log likelihood, step 113850 in nats: 0.072839\n",
      "Train Log likelihood, step 113900 in nats: 0.072840\n",
      "Train epoch average loss: 0.07285588502242235\n",
      "\n",
      "\n",
      "Epoch: 699\n",
      "Train Log likelihood, step 113950 in nats: 0.072864\n",
      "Train Log likelihood, step 114000 in nats: 0.072878\n",
      "Train Log likelihood, step 114050 in nats: 0.072882\n",
      "Train epoch average loss: 0.07290295372782167\n",
      "\n",
      "\n",
      "Epoch: 700\n",
      "Train Log likelihood, step 114100 in nats: 0.072904\n",
      "Train Log likelihood, step 114150 in nats: 0.072910\n",
      "Train Log likelihood, step 114200 in nats: 0.072918\n",
      "Train Log likelihood, step 114250 in nats: 0.072920\n",
      "Train epoch average loss: 0.0729224716319392\n",
      "\n",
      "\n",
      "Epoch: 701\n",
      "Train Log likelihood, step 114300 in nats: 0.072933\n",
      "Train Log likelihood, step 114350 in nats: 0.072935\n",
      "Train Log likelihood, step 114400 in nats: 0.072943\n",
      "Train epoch average loss: 0.07293999958133059\n",
      "\n",
      "\n",
      "Epoch: 702\n",
      "Train Log likelihood, step 114450 in nats: 0.072952\n",
      "Train Log likelihood, step 114500 in nats: 0.072972\n",
      "Train Log likelihood, step 114550 in nats: 0.072970\n",
      "Train epoch average loss: 0.07297592587687768\n",
      "\n",
      "\n",
      "Epoch: 703\n",
      "Train Log likelihood, step 114600 in nats: 0.072978\n",
      "Train Log likelihood, step 114650 in nats: 0.072999\n",
      "Train Log likelihood, step 114700 in nats: 0.073026\n",
      "Train Log likelihood, step 114750 in nats: 0.073034\n",
      "Train epoch average loss: 0.07303531659295864\n",
      "\n",
      "\n",
      "Epoch: 704\n",
      "Train Log likelihood, step 114800 in nats: 0.073059\n",
      "Train Log likelihood, step 114850 in nats: 0.073075\n",
      "Train Log likelihood, step 114900 in nats: 0.073097\n",
      "Train epoch average loss: 0.0731066758715025\n",
      "\n",
      "\n",
      "Epoch: 705\n",
      "Train Log likelihood, step 114950 in nats: 0.073115\n",
      "Train Log likelihood, step 115000 in nats: 0.073141\n",
      "Train Log likelihood, step 115050 in nats: 0.073163\n",
      "Train epoch average loss: 0.07317705688670038\n",
      "\n",
      "\n",
      "Epoch: 706\n",
      "Train Log likelihood, step 115100 in nats: 0.073186\n",
      "Train Log likelihood, step 115150 in nats: 0.073203\n",
      "Train Log likelihood, step 115200 in nats: 0.073219\n",
      "Train epoch average loss: 0.07323489186613481\n",
      "\n",
      "\n",
      "Epoch: 707\n",
      "Train Log likelihood, step 115250 in nats: 0.073240\n",
      "Train Log likelihood, step 115300 in nats: 0.073259\n",
      "Train Log likelihood, step 115350 in nats: 0.073277\n",
      "Train Log likelihood, step 115400 in nats: 0.073277\n",
      "Train epoch average loss: 0.07327945270283584\n",
      "\n",
      "\n",
      "Epoch: 708\n",
      "Train Log likelihood, step 115450 in nats: 0.073289\n",
      "Train Log likelihood, step 115500 in nats: 0.073306\n",
      "Train Log likelihood, step 115550 in nats: 0.073311\n",
      "Train epoch average loss: 0.07331792151021263\n",
      "\n",
      "\n",
      "Epoch: 709\n",
      "Train Log likelihood, step 115600 in nats: 0.073336\n",
      "Train Log likelihood, step 115650 in nats: 0.073340\n",
      "Train Log likelihood, step 115700 in nats: 0.073348\n",
      "Train epoch average loss: 0.07334350890742262\n",
      "\n",
      "\n",
      "Epoch: 710\n",
      "Train Log likelihood, step 115750 in nats: 0.073339\n",
      "Train Log likelihood, step 115800 in nats: 0.073336\n",
      "Train Log likelihood, step 115850 in nats: 0.073339\n",
      "Train epoch average loss: 0.07335564274668441\n",
      "\n",
      "\n",
      "Epoch: 711\n",
      "Train Log likelihood, step 115900 in nats: 0.073358\n",
      "Train Log likelihood, step 115950 in nats: 0.073368\n",
      "Train Log likelihood, step 116000 in nats: 0.073372\n",
      "Train Log likelihood, step 116050 in nats: 0.073390\n",
      "Train epoch average loss: 0.07339470410231606\n",
      "\n",
      "\n",
      "Epoch: 712\n",
      "Train Log likelihood, step 116100 in nats: 0.073394\n",
      "Train Log likelihood, step 116150 in nats: 0.073411\n",
      "Train Log likelihood, step 116200 in nats: 0.073437\n",
      "Train epoch average loss: 0.0734476304355459\n",
      "\n",
      "\n",
      "Epoch: 713\n",
      "Train Log likelihood, step 116250 in nats: 0.073452\n",
      "Train Log likelihood, step 116300 in nats: 0.073482\n",
      "Train Log likelihood, step 116350 in nats: 0.073517\n",
      "Train epoch average loss: 0.07353675131508444\n",
      "\n",
      "\n",
      "Epoch: 714\n",
      "Train Log likelihood, step 116400 in nats: 0.073541\n",
      "Train Log likelihood, step 116450 in nats: 0.073569\n",
      "Train Log likelihood, step 116500 in nats: 0.073586\n",
      "Train epoch average loss: 0.07357997489276955\n",
      "\n",
      "\n",
      "Epoch: 715\n",
      "Train Log likelihood, step 116550 in nats: 0.073587\n",
      "Train Log likelihood, step 116600 in nats: 0.073608\n",
      "Train Log likelihood, step 116650 in nats: 0.073621\n",
      "Train Log likelihood, step 116700 in nats: 0.073629\n",
      "Train epoch average loss: 0.07363460458371131\n",
      "\n",
      "\n",
      "Epoch: 716\n",
      "Train Log likelihood, step 116750 in nats: 0.073632\n",
      "Train Log likelihood, step 116800 in nats: 0.073649\n",
      "Train Log likelihood, step 116850 in nats: 0.073663\n",
      "Train epoch average loss: 0.07367205262657836\n",
      "\n",
      "\n",
      "Epoch: 717\n",
      "Train Log likelihood, step 116900 in nats: 0.073666\n",
      "Train Log likelihood, step 116950 in nats: 0.073678\n",
      "Train Log likelihood, step 117000 in nats: 0.073705\n",
      "Train epoch average loss: 0.07371673642455298\n",
      "\n",
      "\n",
      "Epoch: 718\n",
      "Train Log likelihood, step 117050 in nats: 0.073720\n",
      "Train Log likelihood, step 117100 in nats: 0.073746\n",
      "Train Log likelihood, step 117150 in nats: 0.073756\n",
      "Train epoch average loss: 0.07377213974595125\n",
      "\n",
      "\n",
      "Epoch: 719\n",
      "Train Log likelihood, step 117200 in nats: 0.073776\n",
      "Train Log likelihood, step 117250 in nats: 0.073785\n",
      "Train Log likelihood, step 117300 in nats: 0.073800\n",
      "Train Log likelihood, step 117350 in nats: 0.073816\n",
      "Train epoch average loss: 0.07381912256779709\n",
      "\n",
      "\n",
      "Epoch: 720\n",
      "Train Log likelihood, step 117400 in nats: 0.073829\n",
      "Train Log likelihood, step 117450 in nats: 0.073853\n",
      "Train Log likelihood, step 117500 in nats: 0.073870\n",
      "Train epoch average loss: 0.07387727880503799\n",
      "\n",
      "\n",
      "Epoch: 721\n",
      "Train Log likelihood, step 117550 in nats: 0.073890\n",
      "Train Log likelihood, step 117600 in nats: 0.073921\n",
      "Train Log likelihood, step 117650 in nats: 0.073943\n",
      "Train epoch average loss: 0.07394129636329347\n",
      "\n",
      "\n",
      "Epoch: 722\n",
      "Train Log likelihood, step 117700 in nats: 0.073947\n",
      "Train Log likelihood, step 117750 in nats: 0.073956\n",
      "Train Log likelihood, step 117800 in nats: 0.073978\n",
      "Train epoch average loss: 0.0739960869073473\n",
      "\n",
      "\n",
      "Epoch: 723\n",
      "Train Log likelihood, step 117850 in nats: 0.073996\n",
      "Train Log likelihood, step 117900 in nats: 0.074031\n",
      "Train Log likelihood, step 117950 in nats: 0.074045\n",
      "Train Log likelihood, step 118000 in nats: 0.074060\n",
      "Train epoch average loss: 0.07406561080103975\n",
      "\n",
      "\n",
      "Epoch: 724\n",
      "Train Log likelihood, step 118050 in nats: 0.074074\n",
      "Train Log likelihood, step 118100 in nats: 0.074090\n",
      "Train Log likelihood, step 118150 in nats: 0.074097\n",
      "Train epoch average loss: 0.07410376735417452\n",
      "\n",
      "\n",
      "Epoch: 725\n",
      "Train Log likelihood, step 118200 in nats: 0.074106\n",
      "Train Log likelihood, step 118250 in nats: 0.074133\n",
      "Train Log likelihood, step 118300 in nats: 0.074139\n",
      "Train epoch average loss: 0.07414039559889939\n",
      "\n",
      "\n",
      "Epoch: 726\n",
      "Train Log likelihood, step 118350 in nats: 0.074148\n",
      "Train Log likelihood, step 118400 in nats: 0.074169\n",
      "Train Log likelihood, step 118450 in nats: 0.074194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 118500 in nats: 0.074208\n",
      "Train epoch average loss: 0.07420799924464204\n",
      "\n",
      "\n",
      "Epoch: 727\n",
      "Train Log likelihood, step 118550 in nats: 0.074217\n",
      "Train Log likelihood, step 118600 in nats: 0.074228\n",
      "Train Log likelihood, step 118650 in nats: 0.074245\n",
      "Train epoch average loss: 0.07424539732895423\n",
      "\n",
      "\n",
      "Epoch: 728\n",
      "Train Log likelihood, step 118700 in nats: 0.074263\n",
      "Train Log likelihood, step 118750 in nats: 0.074272\n",
      "Train Log likelihood, step 118800 in nats: 0.074283\n",
      "Train epoch average loss: 0.07429456929734383\n",
      "\n",
      "\n",
      "Epoch: 729\n",
      "Train Log likelihood, step 118850 in nats: 0.074303\n",
      "Train Log likelihood, step 118900 in nats: 0.074312\n",
      "Train Log likelihood, step 118950 in nats: 0.074334\n",
      "Train epoch average loss: 0.07435258149307433\n",
      "\n",
      "\n",
      "Epoch: 730\n",
      "Train Log likelihood, step 119000 in nats: 0.074359\n",
      "Train Log likelihood, step 119050 in nats: 0.074367\n",
      "Train Log likelihood, step 119100 in nats: 0.074388\n",
      "Train Log likelihood, step 119150 in nats: 0.074402\n",
      "Train epoch average loss: 0.0744033745018595\n",
      "\n",
      "\n",
      "Epoch: 731\n",
      "Train Log likelihood, step 119200 in nats: 0.074423\n",
      "Train Log likelihood, step 119250 in nats: 0.074437\n",
      "Train Log likelihood, step 119300 in nats: 0.074456\n",
      "Train epoch average loss: 0.07446392888729819\n",
      "\n",
      "\n",
      "Epoch: 732\n",
      "Train Log likelihood, step 119350 in nats: 0.074469\n",
      "Train Log likelihood, step 119400 in nats: 0.074480\n",
      "Train Log likelihood, step 119450 in nats: 0.074484\n",
      "Train epoch average loss: 0.07448915187108085\n",
      "\n",
      "\n",
      "Epoch: 733\n",
      "Train Log likelihood, step 119500 in nats: 0.074492\n",
      "Train Log likelihood, step 119550 in nats: 0.074502\n",
      "Train Log likelihood, step 119600 in nats: 0.074522\n",
      "Train epoch average loss: 0.07453105969613408\n",
      "\n",
      "\n",
      "Epoch: 734\n",
      "Train Log likelihood, step 119650 in nats: 0.074532\n",
      "Train Log likelihood, step 119700 in nats: 0.074534\n",
      "Train Log likelihood, step 119750 in nats: 0.074560\n",
      "Train Log likelihood, step 119800 in nats: 0.074576\n",
      "Train epoch average loss: 0.07457724614475647\n",
      "\n",
      "\n",
      "Epoch: 735\n",
      "Train Log likelihood, step 119850 in nats: 0.074589\n",
      "Train Log likelihood, step 119900 in nats: 0.074597\n",
      "Train Log likelihood, step 119950 in nats: 0.074606\n",
      "Train epoch average loss: 0.07461132096764211\n",
      "\n",
      "\n",
      "Epoch: 736\n",
      "Train Log likelihood, step 120000 in nats: 0.074629\n",
      "Train Log likelihood, step 120050 in nats: 0.074646\n",
      "Train Log likelihood, step 120100 in nats: 0.074657\n",
      "Train epoch average loss: 0.07467460322695285\n",
      "\n",
      "\n",
      "Epoch: 737\n",
      "Train Log likelihood, step 120150 in nats: 0.074678\n",
      "Train Log likelihood, step 120200 in nats: 0.074684\n",
      "Train Log likelihood, step 120250 in nats: 0.074694\n",
      "Train epoch average loss: 0.07470332572070085\n",
      "\n",
      "\n",
      "Epoch: 738\n",
      "Train Log likelihood, step 120300 in nats: 0.074706\n",
      "Train Log likelihood, step 120350 in nats: 0.074720\n",
      "Train Log likelihood, step 120400 in nats: 0.074730\n",
      "Train Log likelihood, step 120450 in nats: 0.074759\n",
      "Train epoch average loss: 0.07475999633544335\n",
      "\n",
      "\n",
      "Epoch: 739\n",
      "Train Log likelihood, step 120500 in nats: 0.074766\n",
      "Train Log likelihood, step 120550 in nats: 0.074772\n",
      "Train Log likelihood, step 120600 in nats: 0.074780\n",
      "Train epoch average loss: 0.07477943443515818\n",
      "\n",
      "\n",
      "Epoch: 740\n",
      "Train Log likelihood, step 120650 in nats: 0.074777\n",
      "Train Log likelihood, step 120700 in nats: 0.074778\n",
      "Train Log likelihood, step 120750 in nats: 0.074788\n",
      "Train epoch average loss: 0.07479735946677968\n",
      "\n",
      "\n",
      "Epoch: 741\n",
      "Train Log likelihood, step 120800 in nats: 0.074804\n",
      "Train Log likelihood, step 120850 in nats: 0.074820\n",
      "Train Log likelihood, step 120900 in nats: 0.074839\n",
      "Train epoch average loss: 0.07485871233156342\n",
      "\n",
      "\n",
      "Epoch: 742\n",
      "Train Log likelihood, step 120950 in nats: 0.074862\n",
      "Train Log likelihood, step 121000 in nats: 0.074868\n",
      "Train Log likelihood, step 121050 in nats: 0.074886\n",
      "Train Log likelihood, step 121100 in nats: 0.074904\n",
      "Train epoch average loss: 0.07490396158528323\n",
      "\n",
      "\n",
      "Epoch: 743\n",
      "Train Log likelihood, step 121150 in nats: 0.074920\n",
      "Train Log likelihood, step 121200 in nats: 0.074942\n",
      "Train Log likelihood, step 121250 in nats: 0.074963\n",
      "Train epoch average loss: 0.07496624957580166\n",
      "\n",
      "\n",
      "Epoch: 744\n",
      "Train Log likelihood, step 121300 in nats: 0.074973\n",
      "Train Log likelihood, step 121350 in nats: 0.074986\n",
      "Train Log likelihood, step 121400 in nats: 0.075014\n",
      "Train epoch average loss: 0.07502353706804503\n",
      "\n",
      "\n",
      "Epoch: 745\n",
      "Train Log likelihood, step 121450 in nats: 0.075030\n",
      "Train Log likelihood, step 121500 in nats: 0.075039\n",
      "Train Log likelihood, step 121550 in nats: 0.075052\n",
      "Train epoch average loss: 0.07506482018097418\n",
      "\n",
      "\n",
      "Epoch: 746\n",
      "Train Log likelihood, step 121600 in nats: 0.075068\n",
      "Train Log likelihood, step 121650 in nats: 0.075085\n",
      "Train Log likelihood, step 121700 in nats: 0.075110\n",
      "Train Log likelihood, step 121750 in nats: 0.075122\n",
      "Train epoch average loss: 0.07512209173818774\n",
      "\n",
      "\n",
      "Epoch: 747\n",
      "Train Log likelihood, step 121800 in nats: 0.075122\n",
      "Train Log likelihood, step 121850 in nats: 0.075150\n",
      "Train Log likelihood, step 121900 in nats: 0.075175\n",
      "Train epoch average loss: 0.07517525209356762\n",
      "\n",
      "\n",
      "Epoch: 748\n",
      "Train Log likelihood, step 121950 in nats: 0.075187\n",
      "Train Log likelihood, step 122000 in nats: 0.075213\n",
      "Train Log likelihood, step 122050 in nats: 0.075220\n",
      "Train epoch average loss: 0.07523088535627162\n",
      "\n",
      "\n",
      "Epoch: 749\n",
      "Train Log likelihood, step 122100 in nats: 0.075232\n",
      "Train Log likelihood, step 122150 in nats: 0.075258\n",
      "Train Log likelihood, step 122200 in nats: 0.075284\n",
      "Train epoch average loss: 0.07531541871004672\n",
      "\n",
      "\n",
      "Epoch: 750\n",
      "Train Log likelihood, step 122250 in nats: 0.075317\n",
      "Train Log likelihood, step 122300 in nats: 0.075336\n",
      "Train Log likelihood, step 122350 in nats: 0.075339\n",
      "Train Log likelihood, step 122400 in nats: 0.075358\n",
      "Train epoch average loss: 0.07535883604679802\n",
      "\n",
      "\n",
      "Epoch: 751\n",
      "Train Log likelihood, step 122450 in nats: 0.075368\n",
      "Train Log likelihood, step 122500 in nats: 0.075384\n",
      "Train Log likelihood, step 122550 in nats: 0.075406\n",
      "Train epoch average loss: 0.07542307919645956\n",
      "\n",
      "\n",
      "Epoch: 752\n",
      "Train Log likelihood, step 122600 in nats: 0.075429\n",
      "Train Log likelihood, step 122650 in nats: 0.075451\n",
      "Train Log likelihood, step 122700 in nats: 0.075463\n",
      "Train epoch average loss: 0.0754792725027261\n",
      "\n",
      "\n",
      "Epoch: 753\n",
      "Train Log likelihood, step 122750 in nats: 0.075484\n",
      "Train Log likelihood, step 122800 in nats: 0.075504\n",
      "Train Log likelihood, step 122850 in nats: 0.075530\n",
      "Train Log likelihood, step 122900 in nats: 0.075551\n",
      "Train epoch average loss: 0.07555151533583654\n",
      "\n",
      "\n",
      "Epoch: 754\n",
      "Train Log likelihood, step 122950 in nats: 0.075571\n",
      "Train Log likelihood, step 123000 in nats: 0.075572\n",
      "Train Log likelihood, step 123050 in nats: 0.075578\n",
      "Train epoch average loss: 0.07558005468641645\n",
      "\n",
      "\n",
      "Epoch: 755\n",
      "Train Log likelihood, step 123100 in nats: 0.075589\n",
      "Train Log likelihood, step 123150 in nats: 0.075608\n",
      "Train Log likelihood, step 123200 in nats: 0.075630\n",
      "Train epoch average loss: 0.0756450082437703\n",
      "\n",
      "\n",
      "Epoch: 756\n",
      "Train Log likelihood, step 123250 in nats: 0.075649\n",
      "Train Log likelihood, step 123300 in nats: 0.075670\n",
      "Train Log likelihood, step 123350 in nats: 0.075684\n",
      "Train epoch average loss: 0.07568423571985633\n",
      "\n",
      "\n",
      "Epoch: 757\n",
      "Train Log likelihood, step 123400 in nats: 0.075687\n",
      "Train Log likelihood, step 123450 in nats: 0.075693\n",
      "Train Log likelihood, step 123500 in nats: 0.075703\n",
      "Train Log likelihood, step 123550 in nats: 0.075715\n",
      "Train epoch average loss: 0.07571411165289547\n",
      "\n",
      "\n",
      "Epoch: 758\n",
      "Train Log likelihood, step 123600 in nats: 0.075729\n",
      "Train Log likelihood, step 123650 in nats: 0.075750\n",
      "Train Log likelihood, step 123700 in nats: 0.075763\n",
      "Train epoch average loss: 0.07576199200598883\n",
      "\n",
      "\n",
      "Epoch: 759\n",
      "Train Log likelihood, step 123750 in nats: 0.075780\n",
      "Train Log likelihood, step 123800 in nats: 0.075792\n",
      "Train Log likelihood, step 123850 in nats: 0.075799\n",
      "Train epoch average loss: 0.0758064165163861\n",
      "\n",
      "\n",
      "Epoch: 760\n",
      "Train Log likelihood, step 123900 in nats: 0.075822\n",
      "Train Log likelihood, step 123950 in nats: 0.075852\n",
      "Train Log likelihood, step 124000 in nats: 0.075875\n",
      "Train epoch average loss: 0.07589752243570766\n",
      "\n",
      "\n",
      "Epoch: 761\n",
      "Train Log likelihood, step 124050 in nats: 0.075901\n",
      "Train Log likelihood, step 124100 in nats: 0.075932\n",
      "Train Log likelihood, step 124150 in nats: 0.075951\n",
      "Train Log likelihood, step 124200 in nats: 0.075961\n",
      "Train epoch average loss: 0.07596382411356123\n",
      "\n",
      "\n",
      "Epoch: 762\n",
      "Train Log likelihood, step 124250 in nats: 0.075967\n",
      "Train Log likelihood, step 124300 in nats: 0.075975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 124350 in nats: 0.075984\n",
      "Train epoch average loss: 0.07598876024314925\n",
      "\n",
      "\n",
      "Epoch: 763\n",
      "Train Log likelihood, step 124400 in nats: 0.076004\n",
      "Train Log likelihood, step 124450 in nats: 0.076020\n",
      "Train Log likelihood, step 124500 in nats: 0.076042\n",
      "Train epoch average loss: 0.07605443788004565\n",
      "\n",
      "\n",
      "Epoch: 764\n",
      "Train Log likelihood, step 124550 in nats: 0.076063\n",
      "Train Log likelihood, step 124600 in nats: 0.076084\n",
      "Train Log likelihood, step 124650 in nats: 0.076089\n",
      "Train epoch average loss: 0.07609202598898193\n",
      "\n",
      "\n",
      "Epoch: 765\n",
      "Train Log likelihood, step 124700 in nats: 0.076093\n",
      "Train Log likelihood, step 124750 in nats: 0.076115\n",
      "Train Log likelihood, step 124800 in nats: 0.076129\n",
      "Train Log likelihood, step 124850 in nats: 0.076151\n",
      "Train epoch average loss: 0.07615732202305547\n",
      "\n",
      "\n",
      "Epoch: 766\n",
      "Train Log likelihood, step 124900 in nats: 0.076163\n",
      "Train Log likelihood, step 124950 in nats: 0.076189\n",
      "Train Log likelihood, step 125000 in nats: 0.076194\n",
      "Train epoch average loss: 0.07620019539732\n",
      "\n",
      "\n",
      "Epoch: 767\n",
      "Train Log likelihood, step 125050 in nats: 0.076212\n",
      "Train Log likelihood, step 125100 in nats: 0.076222\n",
      "Train Log likelihood, step 125150 in nats: 0.076248\n",
      "Train epoch average loss: 0.07626052113989275\n",
      "\n",
      "\n",
      "Epoch: 768\n",
      "Train Log likelihood, step 125200 in nats: 0.076269\n",
      "Train Log likelihood, step 125250 in nats: 0.076280\n",
      "Train Log likelihood, step 125300 in nats: 0.076302\n",
      "Train epoch average loss: 0.076324515300194\n",
      "\n",
      "\n",
      "Epoch: 769\n",
      "Train Log likelihood, step 125350 in nats: 0.076325\n",
      "Train Log likelihood, step 125400 in nats: 0.076332\n",
      "Train Log likelihood, step 125450 in nats: 0.076346\n",
      "Train Log likelihood, step 125500 in nats: 0.076358\n",
      "Train epoch average loss: 0.07636191572349149\n",
      "\n",
      "\n",
      "Epoch: 770\n",
      "Train Log likelihood, step 125550 in nats: 0.076374\n",
      "Train Log likelihood, step 125600 in nats: 0.076366\n",
      "Train Log likelihood, step 125650 in nats: 0.076385\n",
      "Train epoch average loss: 0.07638762184965348\n",
      "\n",
      "\n",
      "Epoch: 771\n",
      "Train Log likelihood, step 125700 in nats: 0.076398\n",
      "Train Log likelihood, step 125750 in nats: 0.076418\n",
      "Train Log likelihood, step 125800 in nats: 0.076435\n",
      "Train epoch average loss: 0.0764551990771292\n",
      "\n",
      "\n",
      "Epoch: 772\n",
      "Train Log likelihood, step 125850 in nats: 0.076458\n",
      "Train Log likelihood, step 125900 in nats: 0.076475\n",
      "Train Log likelihood, step 125950 in nats: 0.076485\n",
      "Train epoch average loss: 0.0764990982566905\n",
      "\n",
      "\n",
      "Epoch: 773\n",
      "Train Log likelihood, step 126000 in nats: 0.076500\n",
      "Train Log likelihood, step 126050 in nats: 0.076519\n",
      "Train Log likelihood, step 126100 in nats: 0.076545\n",
      "Train Log likelihood, step 126150 in nats: 0.076563\n",
      "Train epoch average loss: 0.07656650210738761\n",
      "\n",
      "\n",
      "Epoch: 774\n",
      "Train Log likelihood, step 126200 in nats: 0.076563\n",
      "Train Log likelihood, step 126250 in nats: 0.076582\n",
      "Train Log likelihood, step 126300 in nats: 0.076608\n",
      "Train epoch average loss: 0.07660733189386423\n",
      "\n",
      "\n",
      "Epoch: 775\n",
      "Train Log likelihood, step 126350 in nats: 0.076618\n",
      "Train Log likelihood, step 126400 in nats: 0.076629\n",
      "Train Log likelihood, step 126450 in nats: 0.076638\n",
      "Train epoch average loss: 0.07665521302622481\n",
      "\n",
      "\n",
      "Epoch: 776\n",
      "Train Log likelihood, step 126500 in nats: 0.076662\n",
      "Train Log likelihood, step 126550 in nats: 0.076675\n",
      "Train Log likelihood, step 126600 in nats: 0.076689\n",
      "Train Log likelihood, step 126650 in nats: 0.076717\n",
      "Train epoch average loss: 0.076717321148512\n",
      "\n",
      "\n",
      "Epoch: 777\n",
      "Train Log likelihood, step 126700 in nats: 0.076730\n",
      "Train Log likelihood, step 126750 in nats: 0.076749\n",
      "Train Log likelihood, step 126800 in nats: 0.076763\n",
      "Train epoch average loss: 0.07676764496718978\n",
      "\n",
      "\n",
      "Epoch: 778\n",
      "Train Log likelihood, step 126850 in nats: 0.076778\n",
      "Train Log likelihood, step 126900 in nats: 0.076787\n",
      "Train Log likelihood, step 126950 in nats: 0.076806\n",
      "Train epoch average loss: 0.07681269353435671\n",
      "\n",
      "\n",
      "Epoch: 779\n",
      "Train Log likelihood, step 127000 in nats: 0.076825\n",
      "Train Log likelihood, step 127050 in nats: 0.076843\n",
      "Train Log likelihood, step 127100 in nats: 0.076868\n",
      "Train epoch average loss: 0.07689260614453763\n",
      "\n",
      "\n",
      "Epoch: 780\n",
      "Train Log likelihood, step 127150 in nats: 0.076888\n",
      "Train Log likelihood, step 127200 in nats: 0.076915\n",
      "Train Log likelihood, step 127250 in nats: 0.076938\n",
      "Train Log likelihood, step 127300 in nats: 0.076947\n",
      "Train epoch average loss: 0.07694835104977064\n",
      "\n",
      "\n",
      "Epoch: 781\n",
      "Train Log likelihood, step 127350 in nats: 0.076948\n",
      "Train Log likelihood, step 127400 in nats: 0.076953\n",
      "Train Log likelihood, step 127450 in nats: 0.076969\n",
      "Train epoch average loss: 0.07696853885471097\n",
      "\n",
      "\n",
      "Epoch: 782\n",
      "Train Log likelihood, step 127500 in nats: 0.076983\n",
      "Train Log likelihood, step 127550 in nats: 0.076992\n",
      "Train Log likelihood, step 127600 in nats: 0.077005\n",
      "Train epoch average loss: 0.07701173976522134\n",
      "\n",
      "\n",
      "Epoch: 783\n",
      "Train Log likelihood, step 127650 in nats: 0.077021\n",
      "Train Log likelihood, step 127700 in nats: 0.077039\n",
      "Train Log likelihood, step 127750 in nats: 0.077065\n",
      "Train epoch average loss: 0.07707276212997012\n",
      "\n",
      "\n",
      "Epoch: 784\n",
      "Train Log likelihood, step 127800 in nats: 0.077076\n",
      "Train Log likelihood, step 127850 in nats: 0.077086\n",
      "Train Log likelihood, step 127900 in nats: 0.077105\n",
      "Train Log likelihood, step 127950 in nats: 0.077122\n",
      "Train epoch average loss: 0.07712065670956164\n",
      "\n",
      "\n",
      "Epoch: 785\n",
      "Train Log likelihood, step 128000 in nats: 0.077137\n",
      "Train Log likelihood, step 128050 in nats: 0.077161\n",
      "Train Log likelihood, step 128100 in nats: 0.077193\n",
      "Train epoch average loss: 0.07719752993931477\n",
      "\n",
      "\n",
      "Epoch: 786\n",
      "Train Log likelihood, step 128150 in nats: 0.077214\n",
      "Train Log likelihood, step 128200 in nats: 0.077224\n",
      "Train Log likelihood, step 128250 in nats: 0.077233\n",
      "Train epoch average loss: 0.07724536358387664\n",
      "\n",
      "\n",
      "Epoch: 787\n",
      "Train Log likelihood, step 128300 in nats: 0.077259\n",
      "Train Log likelihood, step 128350 in nats: 0.077267\n",
      "Train Log likelihood, step 128400 in nats: 0.077274\n",
      "Train epoch average loss: 0.07728929074388258\n",
      "\n",
      "\n",
      "Epoch: 788\n",
      "Train Log likelihood, step 128450 in nats: 0.077291\n",
      "Train Log likelihood, step 128500 in nats: 0.077305\n",
      "Train Log likelihood, step 128550 in nats: 0.077317\n",
      "Train Log likelihood, step 128600 in nats: 0.077327\n",
      "Train epoch average loss: 0.07732889478579821\n",
      "\n",
      "\n",
      "Epoch: 789\n",
      "Train Log likelihood, step 128650 in nats: 0.077342\n",
      "Train Log likelihood, step 128700 in nats: 0.077346\n",
      "Train Log likelihood, step 128750 in nats: 0.077371\n",
      "Train epoch average loss: 0.07737986876540254\n",
      "\n",
      "\n",
      "Epoch: 790\n",
      "Train Log likelihood, step 128800 in nats: 0.077396\n",
      "Train Log likelihood, step 128850 in nats: 0.077419\n",
      "Train Log likelihood, step 128900 in nats: 0.077432\n",
      "Train epoch average loss: 0.07743802817698577\n",
      "\n",
      "\n",
      "Epoch: 791\n",
      "Train Log likelihood, step 128950 in nats: 0.077438\n",
      "Train Log likelihood, step 129000 in nats: 0.077456\n",
      "Train Log likelihood, step 129050 in nats: 0.077472\n",
      "Train epoch average loss: 0.0774953732725521\n",
      "\n",
      "\n",
      "Epoch: 792\n",
      "Train Log likelihood, step 129100 in nats: 0.077496\n",
      "Train Log likelihood, step 129150 in nats: 0.077518\n",
      "Train Log likelihood, step 129200 in nats: 0.077538\n",
      "Train Log likelihood, step 129250 in nats: 0.077559\n",
      "Train epoch average loss: 0.07755975571545924\n",
      "\n",
      "\n",
      "Epoch: 793\n",
      "Train Log likelihood, step 129300 in nats: 0.077573\n",
      "Train Log likelihood, step 129350 in nats: 0.077585\n",
      "Train Log likelihood, step 129400 in nats: 0.077594\n",
      "Train epoch average loss: 0.07760265154385294\n",
      "\n",
      "\n",
      "Epoch: 794\n",
      "Train Log likelihood, step 129450 in nats: 0.077614\n",
      "Train Log likelihood, step 129500 in nats: 0.077616\n",
      "Train Log likelihood, step 129550 in nats: 0.077616\n",
      "Train epoch average loss: 0.07761862192476188\n",
      "\n",
      "\n",
      "Epoch: 795\n",
      "Train Log likelihood, step 129600 in nats: 0.077624\n",
      "Train Log likelihood, step 129650 in nats: 0.077643\n",
      "Train Log likelihood, step 129700 in nats: 0.077655\n",
      "Train epoch average loss: 0.07766991535568463\n",
      "\n",
      "\n",
      "Epoch: 796\n",
      "Train Log likelihood, step 129750 in nats: 0.077671\n",
      "Train Log likelihood, step 129800 in nats: 0.077695\n",
      "Train Log likelihood, step 129850 in nats: 0.077711\n",
      "Train Log likelihood, step 129900 in nats: 0.077725\n",
      "Train epoch average loss: 0.07773077018567782\n",
      "\n",
      "\n",
      "Epoch: 797\n",
      "Train Log likelihood, step 129950 in nats: 0.077741\n",
      "Train Log likelihood, step 130000 in nats: 0.077752\n",
      "Train Log likelihood, step 130050 in nats: 0.077762\n",
      "Train epoch average loss: 0.07776480780910933\n",
      "\n",
      "\n",
      "Epoch: 798\n",
      "Train Log likelihood, step 130100 in nats: 0.077774\n",
      "Train Log likelihood, step 130150 in nats: 0.077790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 130200 in nats: 0.077803\n",
      "Train epoch average loss: 0.07780877629890616\n",
      "\n",
      "\n",
      "Epoch: 799\n",
      "Train Log likelihood, step 130250 in nats: 0.077818\n",
      "Train Log likelihood, step 130300 in nats: 0.077850\n",
      "Train Log likelihood, step 130350 in nats: 0.077864\n",
      "Train epoch average loss: 0.07787470104657851\n",
      "\n",
      "\n",
      "Epoch: 800\n",
      "Train Log likelihood, step 130400 in nats: 0.077875\n",
      "Train Log likelihood, step 130450 in nats: 0.077889\n",
      "Train Log likelihood, step 130500 in nats: 0.077908\n",
      "Train Log likelihood, step 130550 in nats: 0.077925\n",
      "Train epoch average loss: 0.0779323464999208\n",
      "\n",
      "\n",
      "Epoch: 801\n",
      "Train Log likelihood, step 130600 in nats: 0.077945\n",
      "Train Log likelihood, step 130650 in nats: 0.077953\n",
      "Train Log likelihood, step 130700 in nats: 0.077975\n",
      "Train epoch average loss: 0.0779784202331533\n",
      "\n",
      "\n",
      "Epoch: 802\n",
      "Train Log likelihood, step 130750 in nats: 0.077990\n",
      "Train Log likelihood, step 130800 in nats: 0.077993\n",
      "Train Log likelihood, step 130850 in nats: 0.078002\n",
      "Train epoch average loss: 0.07801571391003434\n",
      "\n",
      "\n",
      "Epoch: 803\n",
      "Train Log likelihood, step 130900 in nats: 0.078022\n",
      "Train Log likelihood, step 130950 in nats: 0.078042\n",
      "Train Log likelihood, step 131000 in nats: 0.078050\n",
      "Train Log likelihood, step 131050 in nats: 0.078067\n",
      "Train epoch average loss: 0.07806758459478429\n",
      "\n",
      "\n",
      "Epoch: 804\n",
      "Train Log likelihood, step 131100 in nats: 0.078079\n",
      "Train Log likelihood, step 131150 in nats: 0.078081\n",
      "Train Log likelihood, step 131200 in nats: 0.078108\n",
      "Train epoch average loss: 0.07810949817007543\n",
      "\n",
      "\n",
      "Epoch: 805\n",
      "Train Log likelihood, step 131250 in nats: 0.078127\n",
      "Train Log likelihood, step 131300 in nats: 0.078157\n",
      "Train Log likelihood, step 131350 in nats: 0.078175\n",
      "Train epoch average loss: 0.07818001952396096\n",
      "\n",
      "\n",
      "Epoch: 806\n",
      "Train Log likelihood, step 131400 in nats: 0.078184\n",
      "Train Log likelihood, step 131450 in nats: 0.078186\n",
      "Train Log likelihood, step 131500 in nats: 0.078198\n",
      "Train epoch average loss: 0.07821230520822876\n",
      "\n",
      "\n",
      "Epoch: 807\n",
      "Train Log likelihood, step 131550 in nats: 0.078218\n",
      "Train Log likelihood, step 131600 in nats: 0.078238\n",
      "Train Log likelihood, step 131650 in nats: 0.078259\n",
      "Train Log likelihood, step 131700 in nats: 0.078281\n",
      "Train epoch average loss: 0.07828265671343448\n",
      "\n",
      "\n",
      "Epoch: 808\n",
      "Train Log likelihood, step 131750 in nats: 0.078293\n",
      "Train Log likelihood, step 131800 in nats: 0.078302\n",
      "Train Log likelihood, step 131850 in nats: 0.078319\n",
      "Train epoch average loss: 0.0783176793595505\n",
      "\n",
      "\n",
      "Epoch: 809\n",
      "Train Log likelihood, step 131900 in nats: 0.078326\n",
      "Train Log likelihood, step 131950 in nats: 0.078343\n",
      "Train Log likelihood, step 132000 in nats: 0.078363\n",
      "Train epoch average loss: 0.07837289833004664\n",
      "\n",
      "\n",
      "Epoch: 810\n",
      "Train Log likelihood, step 132050 in nats: 0.078375\n",
      "Train Log likelihood, step 132100 in nats: 0.078395\n",
      "Train Log likelihood, step 132150 in nats: 0.078402\n",
      "Train epoch average loss: 0.07840662593913683\n",
      "\n",
      "\n",
      "Epoch: 811\n",
      "Train Log likelihood, step 132200 in nats: 0.078410\n",
      "Train Log likelihood, step 132250 in nats: 0.078424\n",
      "Train Log likelihood, step 132300 in nats: 0.078422\n",
      "Train Log likelihood, step 132350 in nats: 0.078431\n",
      "Train epoch average loss: 0.07843368796638508\n",
      "\n",
      "\n",
      "Epoch: 812\n",
      "Train Log likelihood, step 132400 in nats: 0.078449\n",
      "Train Log likelihood, step 132450 in nats: 0.078453\n",
      "Train Log likelihood, step 132500 in nats: 0.078466\n",
      "Train epoch average loss: 0.07846693224454107\n",
      "\n",
      "\n",
      "Epoch: 813\n",
      "Train Log likelihood, step 132550 in nats: 0.078472\n",
      "Train Log likelihood, step 132600 in nats: 0.078484\n",
      "Train Log likelihood, step 132650 in nats: 0.078500\n",
      "Train epoch average loss: 0.07849885434346929\n",
      "\n",
      "\n",
      "Epoch: 814\n",
      "Train Log likelihood, step 132700 in nats: 0.078504\n",
      "Train Log likelihood, step 132750 in nats: 0.078513\n",
      "Train Log likelihood, step 132800 in nats: 0.078534\n",
      "Train epoch average loss: 0.07854343604266431\n",
      "\n",
      "\n",
      "Epoch: 815\n",
      "Train Log likelihood, step 132850 in nats: 0.078541\n",
      "Train Log likelihood, step 132900 in nats: 0.078556\n",
      "Train Log likelihood, step 132950 in nats: 0.078570\n",
      "Train Log likelihood, step 133000 in nats: 0.078566\n",
      "Train epoch average loss: 0.07856634176457086\n",
      "\n",
      "\n",
      "Epoch: 816\n",
      "Train Log likelihood, step 133050 in nats: 0.078575\n",
      "Train Log likelihood, step 133100 in nats: 0.078583\n",
      "Train Log likelihood, step 133150 in nats: 0.078593\n",
      "Train epoch average loss: 0.07859203675702049\n",
      "\n",
      "\n",
      "Epoch: 817\n",
      "Train Log likelihood, step 133200 in nats: 0.078601\n",
      "Train Log likelihood, step 133250 in nats: 0.078616\n",
      "Train Log likelihood, step 133300 in nats: 0.078627\n",
      "Train epoch average loss: 0.07864345095939243\n",
      "\n",
      "\n",
      "Epoch: 818\n",
      "Train Log likelihood, step 133350 in nats: 0.078652\n",
      "Train Log likelihood, step 133400 in nats: 0.078666\n",
      "Train Log likelihood, step 133450 in nats: 0.078677\n",
      "Train epoch average loss: 0.07868962378724337\n",
      "\n",
      "\n",
      "Epoch: 819\n",
      "Train Log likelihood, step 133500 in nats: 0.078691\n",
      "Train Log likelihood, step 133550 in nats: 0.078712\n",
      "Train Log likelihood, step 133600 in nats: 0.078729\n",
      "Train Log likelihood, step 133650 in nats: 0.078752\n",
      "Train epoch average loss: 0.07875405975464853\n",
      "\n",
      "\n",
      "Epoch: 820\n",
      "Train Log likelihood, step 133700 in nats: 0.078765\n",
      "Train Log likelihood, step 133750 in nats: 0.078774\n",
      "Train Log likelihood, step 133800 in nats: 0.078793\n",
      "Train epoch average loss: 0.07879426322167644\n",
      "\n",
      "\n",
      "Epoch: 821\n",
      "Train Log likelihood, step 133850 in nats: 0.078801\n",
      "Train Log likelihood, step 133900 in nats: 0.078810\n",
      "Train Log likelihood, step 133950 in nats: 0.078821\n",
      "Train epoch average loss: 0.07882043195875033\n",
      "\n",
      "\n",
      "Epoch: 822\n",
      "Train Log likelihood, step 134000 in nats: 0.078826\n",
      "Train Log likelihood, step 134050 in nats: 0.078844\n",
      "Train Log likelihood, step 134100 in nats: 0.078870\n",
      "Train epoch average loss: 0.07888990386987878\n",
      "\n",
      "\n",
      "Epoch: 823\n",
      "Train Log likelihood, step 134150 in nats: 0.078892\n",
      "Train Log likelihood, step 134200 in nats: 0.078912\n",
      "Train Log likelihood, step 134250 in nats: 0.078933\n",
      "Train Log likelihood, step 134300 in nats: 0.078941\n",
      "Train epoch average loss: 0.07894392891482815\n",
      "\n",
      "\n",
      "Epoch: 824\n",
      "Train Log likelihood, step 134350 in nats: 0.078961\n",
      "Train Log likelihood, step 134400 in nats: 0.078982\n",
      "Train Log likelihood, step 134450 in nats: 0.078995\n",
      "Train epoch average loss: 0.07900492273420334\n",
      "\n",
      "\n",
      "Epoch: 825\n",
      "Train Log likelihood, step 134500 in nats: 0.079015\n",
      "Train Log likelihood, step 134550 in nats: 0.079021\n",
      "Train Log likelihood, step 134600 in nats: 0.079025\n",
      "Train epoch average loss: 0.07902977633936004\n",
      "\n",
      "\n",
      "Epoch: 826\n",
      "Train Log likelihood, step 134650 in nats: 0.079030\n",
      "Train Log likelihood, step 134700 in nats: 0.079046\n",
      "Train Log likelihood, step 134750 in nats: 0.079065\n",
      "Train Log likelihood, step 134800 in nats: 0.079091\n",
      "Train epoch average loss: 0.0790914741832241\n",
      "\n",
      "\n",
      "Epoch: 827\n",
      "Train Log likelihood, step 134850 in nats: 0.079112\n",
      "Train Log likelihood, step 134900 in nats: 0.079124\n",
      "Train Log likelihood, step 134950 in nats: 0.079148\n",
      "Train epoch average loss: 0.07915184453044367\n",
      "\n",
      "\n",
      "Epoch: 828\n",
      "Train Log likelihood, step 135000 in nats: 0.079166\n",
      "Train Log likelihood, step 135050 in nats: 0.079177\n",
      "Train Log likelihood, step 135100 in nats: 0.079182\n",
      "Train epoch average loss: 0.07919217275775796\n",
      "\n",
      "\n",
      "Epoch: 829\n",
      "Train Log likelihood, step 135150 in nats: 0.079202\n",
      "Train Log likelihood, step 135200 in nats: 0.079212\n",
      "Train Log likelihood, step 135250 in nats: 0.079229\n",
      "Train epoch average loss: 0.07924175489008312\n",
      "\n",
      "\n",
      "Epoch: 830\n",
      "Train Log likelihood, step 135300 in nats: 0.079241\n",
      "Train Log likelihood, step 135350 in nats: 0.079248\n",
      "Train Log likelihood, step 135400 in nats: 0.079273\n",
      "Train Log likelihood, step 135450 in nats: 0.079295\n",
      "Train epoch average loss: 0.07929470357164387\n",
      "\n",
      "\n",
      "Epoch: 831\n",
      "Train Log likelihood, step 135500 in nats: 0.079307\n",
      "Train Log likelihood, step 135550 in nats: 0.079324\n",
      "Train Log likelihood, step 135600 in nats: 0.079345\n",
      "Train epoch average loss: 0.07935171890903103\n",
      "\n",
      "\n",
      "Epoch: 832\n",
      "Train Log likelihood, step 135650 in nats: 0.079355\n",
      "Train Log likelihood, step 135700 in nats: 0.079364\n",
      "Train Log likelihood, step 135750 in nats: 0.079396\n",
      "Train epoch average loss: 0.07940212982814598\n",
      "\n",
      "\n",
      "Epoch: 833\n",
      "Train Log likelihood, step 135800 in nats: 0.079410\n",
      "Train Log likelihood, step 135850 in nats: 0.079428\n",
      "Train Log likelihood, step 135900 in nats: 0.079437\n",
      "Train epoch average loss: 0.07945004326350658\n",
      "\n",
      "\n",
      "Epoch: 834\n",
      "Train Log likelihood, step 135950 in nats: 0.079453\n",
      "Train Log likelihood, step 136000 in nats: 0.079469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 136050 in nats: 0.079479\n",
      "Train Log likelihood, step 136100 in nats: 0.079481\n",
      "Train epoch average loss: 0.07948347798537389\n",
      "\n",
      "\n",
      "Epoch: 835\n",
      "Train Log likelihood, step 136150 in nats: 0.079494\n",
      "Train Log likelihood, step 136200 in nats: 0.079511\n",
      "Train Log likelihood, step 136250 in nats: 0.079522\n",
      "Train epoch average loss: 0.07952848182484232\n",
      "\n",
      "\n",
      "Epoch: 836\n",
      "Train Log likelihood, step 136300 in nats: 0.079531\n",
      "Train Log likelihood, step 136350 in nats: 0.079543\n",
      "Train Log likelihood, step 136400 in nats: 0.079554\n",
      "Train epoch average loss: 0.07955497985825609\n",
      "\n",
      "\n",
      "Epoch: 837\n",
      "Train Log likelihood, step 136450 in nats: 0.079559\n",
      "Train Log likelihood, step 136500 in nats: 0.079579\n",
      "Train Log likelihood, step 136550 in nats: 0.079595\n",
      "Train epoch average loss: 0.07959718352825937\n",
      "\n",
      "\n",
      "Epoch: 838\n",
      "Train Log likelihood, step 136600 in nats: 0.079595\n",
      "Train Log likelihood, step 136650 in nats: 0.079599\n",
      "Train Log likelihood, step 136700 in nats: 0.079612\n",
      "Train Log likelihood, step 136750 in nats: 0.079623\n",
      "Train epoch average loss: 0.07962704067062754\n",
      "\n",
      "\n",
      "Epoch: 839\n",
      "Train Log likelihood, step 136800 in nats: 0.079624\n",
      "Train Log likelihood, step 136850 in nats: 0.079630\n",
      "Train Log likelihood, step 136900 in nats: 0.079642\n",
      "Train epoch average loss: 0.07964939611329235\n",
      "\n",
      "\n",
      "Epoch: 840\n",
      "Train Log likelihood, step 136950 in nats: 0.079657\n",
      "Train Log likelihood, step 137000 in nats: 0.079668\n",
      "Train Log likelihood, step 137050 in nats: 0.079677\n",
      "Train epoch average loss: 0.07968285197484931\n",
      "\n",
      "\n",
      "Epoch: 841\n",
      "Train Log likelihood, step 137100 in nats: 0.079685\n",
      "Train Log likelihood, step 137150 in nats: 0.079697\n",
      "Train Log likelihood, step 137200 in nats: 0.079701\n",
      "Train epoch average loss: 0.07971714838723007\n",
      "\n",
      "\n",
      "Epoch: 842\n",
      "Train Log likelihood, step 137250 in nats: 0.079718\n",
      "Train Log likelihood, step 137300 in nats: 0.079727\n",
      "Train Log likelihood, step 137350 in nats: 0.079736\n",
      "Train Log likelihood, step 137400 in nats: 0.079745\n",
      "Train epoch average loss: 0.07974020471711388\n",
      "\n",
      "\n",
      "Epoch: 843\n",
      "Train Log likelihood, step 137450 in nats: 0.079747\n",
      "Train Log likelihood, step 137500 in nats: 0.079746\n",
      "Train Log likelihood, step 137550 in nats: 0.079746\n",
      "Train epoch average loss: 0.07974877720027229\n",
      "\n",
      "\n",
      "Epoch: 844\n",
      "Train Log likelihood, step 137600 in nats: 0.079758\n",
      "Train Log likelihood, step 137650 in nats: 0.079769\n",
      "Train Log likelihood, step 137700 in nats: 0.079790\n",
      "Train epoch average loss: 0.07979283785717411\n",
      "\n",
      "\n",
      "Epoch: 845\n",
      "Train Log likelihood, step 137750 in nats: 0.079791\n",
      "Train Log likelihood, step 137800 in nats: 0.079797\n",
      "Train Log likelihood, step 137850 in nats: 0.079816\n",
      "Train epoch average loss: 0.07983594727908545\n",
      "\n",
      "\n",
      "Epoch: 846\n",
      "Train Log likelihood, step 137900 in nats: 0.079836\n",
      "Train Log likelihood, step 137950 in nats: 0.079852\n",
      "Train Log likelihood, step 138000 in nats: 0.079865\n",
      "Train Log likelihood, step 138050 in nats: 0.079880\n",
      "Train epoch average loss: 0.07988332621569101\n",
      "\n",
      "\n",
      "Epoch: 847\n",
      "Train Log likelihood, step 138100 in nats: 0.079898\n",
      "Train Log likelihood, step 138150 in nats: 0.079914\n",
      "Train Log likelihood, step 138200 in nats: 0.079938\n",
      "Train epoch average loss: 0.07993887243513424\n",
      "\n",
      "\n",
      "Epoch: 848\n",
      "Train Log likelihood, step 138250 in nats: 0.079941\n",
      "Train Log likelihood, step 138300 in nats: 0.079957\n",
      "Train Log likelihood, step 138350 in nats: 0.079981\n",
      "Train epoch average loss: 0.07998683752801496\n",
      "\n",
      "\n",
      "Epoch: 849\n",
      "Train Log likelihood, step 138400 in nats: 0.079992\n",
      "Train Log likelihood, step 138450 in nats: 0.080006\n",
      "Train Log likelihood, step 138500 in nats: 0.080032\n",
      "Train epoch average loss: 0.08004551015182773\n",
      "\n",
      "\n",
      "Epoch: 850\n",
      "Train Log likelihood, step 138550 in nats: 0.080046\n",
      "Train Log likelihood, step 138600 in nats: 0.080055\n",
      "Train Log likelihood, step 138650 in nats: 0.080061\n",
      "Train Log likelihood, step 138700 in nats: 0.080083\n",
      "Train epoch average loss: 0.08008274272846386\n",
      "\n",
      "\n",
      "Epoch: 851\n",
      "Train Log likelihood, step 138750 in nats: 0.080092\n",
      "Train Log likelihood, step 138800 in nats: 0.080092\n",
      "Train Log likelihood, step 138850 in nats: 0.080102\n",
      "Train epoch average loss: 0.08010511629628327\n",
      "\n",
      "\n",
      "Epoch: 852\n",
      "Train Log likelihood, step 138900 in nats: 0.080106\n",
      "Train Log likelihood, step 138950 in nats: 0.080128\n",
      "Train Log likelihood, step 139000 in nats: 0.080139\n",
      "Train epoch average loss: 0.08015034446213597\n",
      "\n",
      "\n",
      "Epoch: 853\n",
      "Train Log likelihood, step 139050 in nats: 0.080154\n",
      "Train Log likelihood, step 139100 in nats: 0.080164\n",
      "Train Log likelihood, step 139150 in nats: 0.080178\n",
      "Train Log likelihood, step 139200 in nats: 0.080179\n",
      "Train epoch average loss: 0.08017951372202517\n",
      "\n",
      "\n",
      "Epoch: 854\n",
      "Train Log likelihood, step 139250 in nats: 0.080191\n",
      "Train Log likelihood, step 139300 in nats: 0.080206\n",
      "Train Log likelihood, step 139350 in nats: 0.080215\n",
      "Train epoch average loss: 0.08021900336491422\n",
      "\n",
      "\n",
      "Epoch: 855\n",
      "Train Log likelihood, step 139400 in nats: 0.080240\n",
      "Train Log likelihood, step 139450 in nats: 0.080255\n",
      "Train Log likelihood, step 139500 in nats: 0.080277\n",
      "Train epoch average loss: 0.0802803334169149\n",
      "\n",
      "\n",
      "Epoch: 856\n",
      "Train Log likelihood, step 139550 in nats: 0.080280\n",
      "Train Log likelihood, step 139600 in nats: 0.080292\n",
      "Train Log likelihood, step 139650 in nats: 0.080304\n",
      "Train epoch average loss: 0.08030952865248962\n",
      "\n",
      "\n",
      "Epoch: 857\n",
      "Train Log likelihood, step 139700 in nats: 0.080314\n",
      "Train Log likelihood, step 139750 in nats: 0.080330\n",
      "Train Log likelihood, step 139800 in nats: 0.080332\n",
      "Train Log likelihood, step 139850 in nats: 0.080342\n",
      "Train epoch average loss: 0.08034199338111939\n",
      "\n",
      "\n",
      "Epoch: 858\n",
      "Train Log likelihood, step 139900 in nats: 0.080354\n",
      "Train Log likelihood, step 139950 in nats: 0.080350\n",
      "Train Log likelihood, step 140000 in nats: 0.080366\n",
      "Train epoch average loss: 0.08037163093086441\n",
      "\n",
      "\n",
      "Epoch: 859\n",
      "Train Log likelihood, step 140050 in nats: 0.080393\n",
      "Train Log likelihood, step 140100 in nats: 0.080413\n",
      "Train Log likelihood, step 140150 in nats: 0.080423\n",
      "Train epoch average loss: 0.08043579065464611\n",
      "\n",
      "\n",
      "Epoch: 860\n",
      "Train Log likelihood, step 140200 in nats: 0.080443\n",
      "Train Log likelihood, step 140250 in nats: 0.080461\n",
      "Train Log likelihood, step 140300 in nats: 0.080464\n",
      "Train epoch average loss: 0.08048650589911881\n",
      "\n",
      "\n",
      "Epoch: 861\n",
      "Train Log likelihood, step 140350 in nats: 0.080491\n",
      "Train Log likelihood, step 140400 in nats: 0.080508\n",
      "Train Log likelihood, step 140450 in nats: 0.080523\n",
      "Train Log likelihood, step 140500 in nats: 0.080524\n",
      "Train epoch average loss: 0.08052754850228888\n",
      "\n",
      "\n",
      "Epoch: 862\n",
      "Train Log likelihood, step 140550 in nats: 0.080527\n",
      "Train Log likelihood, step 140600 in nats: 0.080540\n",
      "Train Log likelihood, step 140650 in nats: 0.080538\n",
      "Train epoch average loss: 0.08053632701758848\n",
      "\n",
      "\n",
      "Epoch: 863\n",
      "Train Log likelihood, step 140700 in nats: 0.080546\n",
      "Train Log likelihood, step 140750 in nats: 0.080549\n",
      "Train Log likelihood, step 140800 in nats: 0.080553\n",
      "Train epoch average loss: 0.08056439287205303\n",
      "\n",
      "\n",
      "Epoch: 864\n",
      "Train Log likelihood, step 140850 in nats: 0.080567\n",
      "Train Log likelihood, step 140900 in nats: 0.080577\n",
      "Train Log likelihood, step 140950 in nats: 0.080588\n",
      "Train epoch average loss: 0.08059422492576027\n",
      "\n",
      "\n",
      "Epoch: 865\n",
      "Train Log likelihood, step 141000 in nats: 0.080594\n",
      "Train Log likelihood, step 141050 in nats: 0.080608\n",
      "Train Log likelihood, step 141100 in nats: 0.080609\n",
      "Train Log likelihood, step 141150 in nats: 0.080619\n",
      "Train epoch average loss: 0.08062244014321178\n",
      "\n",
      "\n",
      "Epoch: 866\n",
      "Train Log likelihood, step 141200 in nats: 0.080627\n",
      "Train Log likelihood, step 141250 in nats: 0.080632\n",
      "Train Log likelihood, step 141300 in nats: 0.080643\n",
      "Train epoch average loss: 0.0806477947488335\n",
      "\n",
      "\n",
      "Epoch: 867\n",
      "Train Log likelihood, step 141350 in nats: 0.080661\n",
      "Train Log likelihood, step 141400 in nats: 0.080671\n",
      "Train Log likelihood, step 141450 in nats: 0.080681\n",
      "Train epoch average loss: 0.08069374718334588\n",
      "\n",
      "\n",
      "Epoch: 868\n",
      "Train Log likelihood, step 141500 in nats: 0.080693\n",
      "Train Log likelihood, step 141550 in nats: 0.080699\n",
      "Train Log likelihood, step 141600 in nats: 0.080720\n",
      "Train epoch average loss: 0.08073453894227439\n",
      "\n",
      "\n",
      "Epoch: 869\n",
      "Train Log likelihood, step 141650 in nats: 0.080733\n",
      "Train Log likelihood, step 141700 in nats: 0.080728\n",
      "Train Log likelihood, step 141750 in nats: 0.080732\n",
      "Train Log likelihood, step 141800 in nats: 0.080739\n",
      "Train epoch average loss: 0.08074380114103423\n",
      "\n",
      "\n",
      "Epoch: 870\n",
      "Train Log likelihood, step 141850 in nats: 0.080755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 141900 in nats: 0.080777\n",
      "Train Log likelihood, step 141950 in nats: 0.080781\n",
      "Train epoch average loss: 0.08078973662315724\n",
      "\n",
      "\n",
      "Epoch: 871\n",
      "Train Log likelihood, step 142000 in nats: 0.080792\n",
      "Train Log likelihood, step 142050 in nats: 0.080813\n",
      "Train Log likelihood, step 142100 in nats: 0.080830\n",
      "Train epoch average loss: 0.080837789327311\n",
      "\n",
      "\n",
      "Epoch: 872\n",
      "Train Log likelihood, step 142150 in nats: 0.080843\n",
      "Train Log likelihood, step 142200 in nats: 0.080848\n",
      "Train Log likelihood, step 142250 in nats: 0.080858\n",
      "Train epoch average loss: 0.08086591183149931\n",
      "\n",
      "\n",
      "Epoch: 873\n",
      "Train Log likelihood, step 142300 in nats: 0.080867\n",
      "Train Log likelihood, step 142350 in nats: 0.080885\n",
      "Train Log likelihood, step 142400 in nats: 0.080904\n",
      "Train Log likelihood, step 142450 in nats: 0.080916\n",
      "Train epoch average loss: 0.08091071764990321\n",
      "\n",
      "\n",
      "Epoch: 874\n",
      "Train Log likelihood, step 142500 in nats: 0.080925\n",
      "Train Log likelihood, step 142550 in nats: 0.080943\n",
      "Train Log likelihood, step 142600 in nats: 0.080946\n",
      "Train epoch average loss: 0.08095625063706857\n",
      "\n",
      "\n",
      "Epoch: 875\n",
      "Train Log likelihood, step 142650 in nats: 0.080965\n",
      "Train Log likelihood, step 142700 in nats: 0.080976\n",
      "Train Log likelihood, step 142750 in nats: 0.080991\n",
      "Train epoch average loss: 0.0810025845412764\n",
      "\n",
      "\n",
      "Epoch: 876\n",
      "Train Log likelihood, step 142800 in nats: 0.081008\n",
      "Train Log likelihood, step 142850 in nats: 0.081022\n",
      "Train Log likelihood, step 142900 in nats: 0.081033\n",
      "Train Log likelihood, step 142950 in nats: 0.081044\n",
      "Train epoch average loss: 0.08104449085975195\n",
      "\n",
      "\n",
      "Epoch: 877\n",
      "Train Log likelihood, step 143000 in nats: 0.081045\n",
      "Train Log likelihood, step 143050 in nats: 0.081066\n",
      "Train Log likelihood, step 143100 in nats: 0.081093\n",
      "Train epoch average loss: 0.08109816070163037\n",
      "\n",
      "\n",
      "Epoch: 878\n",
      "Train Log likelihood, step 143150 in nats: 0.081107\n",
      "Train Log likelihood, step 143200 in nats: 0.081135\n",
      "Train Log likelihood, step 143250 in nats: 0.081139\n",
      "Train epoch average loss: 0.0811446034904989\n",
      "\n",
      "\n",
      "Epoch: 879\n",
      "Train Log likelihood, step 143300 in nats: 0.081150\n",
      "Train Log likelihood, step 143350 in nats: 0.081167\n",
      "Train Log likelihood, step 143400 in nats: 0.081187\n",
      "Train epoch average loss: 0.08119972777459265\n",
      "\n",
      "\n",
      "Epoch: 880\n",
      "Train Log likelihood, step 143450 in nats: 0.081199\n",
      "Train Log likelihood, step 143500 in nats: 0.081207\n",
      "Train Log likelihood, step 143550 in nats: 0.081223\n",
      "Train Log likelihood, step 143600 in nats: 0.081238\n",
      "Train epoch average loss: 0.08123903076209621\n",
      "\n",
      "\n",
      "Epoch: 881\n",
      "Train Log likelihood, step 143650 in nats: 0.081242\n",
      "Train Log likelihood, step 143700 in nats: 0.081245\n",
      "Train Log likelihood, step 143750 in nats: 0.081268\n",
      "Train epoch average loss: 0.08127628077284112\n",
      "\n",
      "\n",
      "Epoch: 882\n",
      "Train Log likelihood, step 143800 in nats: 0.081293\n",
      "Train Log likelihood, step 143850 in nats: 0.081297\n",
      "Train Log likelihood, step 143900 in nats: 0.081316\n",
      "Train epoch average loss: 0.08133015940344872\n",
      "\n",
      "\n",
      "Epoch: 883\n",
      "Train Log likelihood, step 143950 in nats: 0.081333\n",
      "Train Log likelihood, step 144000 in nats: 0.081341\n",
      "Train Log likelihood, step 144050 in nats: 0.081356\n",
      "Train epoch average loss: 0.08136470038820669\n",
      "\n",
      "\n",
      "Epoch: 884\n",
      "Train Log likelihood, step 144100 in nats: 0.081364\n",
      "Train Log likelihood, step 144150 in nats: 0.081374\n",
      "Train Log likelihood, step 144200 in nats: 0.081388\n",
      "Train Log likelihood, step 144250 in nats: 0.081399\n",
      "Train epoch average loss: 0.08139915266433109\n",
      "\n",
      "\n",
      "Epoch: 885\n",
      "Train Log likelihood, step 144300 in nats: 0.081410\n",
      "Train Log likelihood, step 144350 in nats: 0.081408\n",
      "Train Log likelihood, step 144400 in nats: 0.081427\n",
      "Train epoch average loss: 0.08143696634654667\n",
      "\n",
      "\n",
      "Epoch: 886\n",
      "Train Log likelihood, step 144450 in nats: 0.081448\n",
      "Train Log likelihood, step 144500 in nats: 0.081451\n",
      "Train Log likelihood, step 144550 in nats: 0.081462\n",
      "Train epoch average loss: 0.08146841477265641\n",
      "\n",
      "\n",
      "Epoch: 887\n",
      "Train Log likelihood, step 144600 in nats: 0.081484\n",
      "Train Log likelihood, step 144650 in nats: 0.081507\n",
      "Train Log likelihood, step 144700 in nats: 0.081510\n",
      "Train epoch average loss: 0.08152125755179268\n",
      "\n",
      "\n",
      "Epoch: 888\n",
      "Train Log likelihood, step 144750 in nats: 0.081522\n",
      "Train Log likelihood, step 144800 in nats: 0.081540\n",
      "Train Log likelihood, step 144850 in nats: 0.081550\n",
      "Train Log likelihood, step 144900 in nats: 0.081567\n",
      "Train epoch average loss: 0.08156991396732552\n",
      "\n",
      "\n",
      "Epoch: 889\n",
      "Train Log likelihood, step 144950 in nats: 0.081587\n",
      "Train Log likelihood, step 145000 in nats: 0.081604\n",
      "Train Log likelihood, step 145050 in nats: 0.081616\n",
      "Train epoch average loss: 0.081616137967462\n",
      "\n",
      "\n",
      "Epoch: 890\n",
      "Train Log likelihood, step 145100 in nats: 0.081622\n",
      "Train Log likelihood, step 145150 in nats: 0.081630\n",
      "Train Log likelihood, step 145200 in nats: 0.081655\n",
      "Train epoch average loss: 0.08166371199041937\n",
      "\n",
      "\n",
      "Epoch: 891\n",
      "Train Log likelihood, step 145250 in nats: 0.081662\n",
      "Train Log likelihood, step 145300 in nats: 0.081678\n",
      "Train Log likelihood, step 145350 in nats: 0.081699\n",
      "Train epoch average loss: 0.08171178490411518\n",
      "\n",
      "\n",
      "Epoch: 892\n",
      "Train Log likelihood, step 145400 in nats: 0.081712\n",
      "Train Log likelihood, step 145450 in nats: 0.081720\n",
      "Train Log likelihood, step 145500 in nats: 0.081725\n",
      "Train Log likelihood, step 145550 in nats: 0.081748\n",
      "Train epoch average loss: 0.08175379269428822\n",
      "\n",
      "\n",
      "Epoch: 893\n",
      "Train Log likelihood, step 145600 in nats: 0.081755\n",
      "Train Log likelihood, step 145650 in nats: 0.081769\n",
      "Train Log likelihood, step 145700 in nats: 0.081777\n",
      "Train epoch average loss: 0.08178956830127002\n",
      "\n",
      "\n",
      "Epoch: 894\n",
      "Train Log likelihood, step 145750 in nats: 0.081804\n",
      "Train Log likelihood, step 145800 in nats: 0.081814\n",
      "Train Log likelihood, step 145850 in nats: 0.081818\n",
      "Train epoch average loss: 0.08182384956104699\n",
      "\n",
      "\n",
      "Epoch: 895\n",
      "Train Log likelihood, step 145900 in nats: 0.081820\n",
      "Train Log likelihood, step 145950 in nats: 0.081832\n",
      "Train Log likelihood, step 146000 in nats: 0.081846\n",
      "Train epoch average loss: 0.08186310255920043\n",
      "\n",
      "\n",
      "Epoch: 896\n",
      "Train Log likelihood, step 146050 in nats: 0.081863\n",
      "Train Log likelihood, step 146100 in nats: 0.081878\n",
      "Train Log likelihood, step 146150 in nats: 0.081896\n",
      "Train Log likelihood, step 146200 in nats: 0.081898\n",
      "Train epoch average loss: 0.08190356707950713\n",
      "\n",
      "\n",
      "Epoch: 897\n",
      "Train Log likelihood, step 146250 in nats: 0.081904\n",
      "Train Log likelihood, step 146300 in nats: 0.081913\n",
      "Train Log likelihood, step 146350 in nats: 0.081934\n",
      "Train epoch average loss: 0.08194106568559963\n",
      "\n",
      "\n",
      "Epoch: 898\n",
      "Train Log likelihood, step 146400 in nats: 0.081952\n",
      "Train Log likelihood, step 146450 in nats: 0.081963\n",
      "Train Log likelihood, step 146500 in nats: 0.081974\n",
      "Train epoch average loss: 0.08199452851325699\n",
      "\n",
      "\n",
      "Epoch: 899\n",
      "Train Log likelihood, step 146550 in nats: 0.082003\n",
      "Train Log likelihood, step 146600 in nats: 0.082018\n",
      "Train Log likelihood, step 146650 in nats: 0.082036\n",
      "Train epoch average loss: 0.08204764121197394\n",
      "\n",
      "\n",
      "Epoch: 900\n",
      "Train Log likelihood, step 146700 in nats: 0.082047\n",
      "Train Log likelihood, step 146750 in nats: 0.082057\n",
      "Train Log likelihood, step 146800 in nats: 0.082073\n",
      "Train Log likelihood, step 146850 in nats: 0.082093\n",
      "Train epoch average loss: 0.0820899802281546\n",
      "\n",
      "\n",
      "Epoch: 901\n",
      "Train Log likelihood, step 146900 in nats: 0.082107\n",
      "Train Log likelihood, step 146950 in nats: 0.082126\n",
      "Train Log likelihood, step 147000 in nats: 0.082125\n",
      "Train epoch average loss: 0.08212728077529237\n",
      "\n",
      "\n",
      "Epoch: 902\n",
      "Train Log likelihood, step 147050 in nats: 0.082131\n",
      "Train Log likelihood, step 147100 in nats: 0.082147\n",
      "Train Log likelihood, step 147150 in nats: 0.082155\n",
      "Train epoch average loss: 0.08216723539751382\n",
      "\n",
      "\n",
      "Epoch: 903\n",
      "Train Log likelihood, step 147200 in nats: 0.082170\n",
      "Train Log likelihood, step 147250 in nats: 0.082157\n",
      "Train Log likelihood, step 147300 in nats: 0.082183\n",
      "Train Log likelihood, step 147350 in nats: 0.082197\n",
      "Train epoch average loss: 0.08219738622992967\n",
      "\n",
      "\n",
      "Epoch: 904\n",
      "Train Log likelihood, step 147400 in nats: 0.082207\n",
      "Train Log likelihood, step 147450 in nats: 0.082223\n",
      "Train Log likelihood, step 147500 in nats: 0.082227\n",
      "Train epoch average loss: 0.0822311716188223\n",
      "\n",
      "\n",
      "Epoch: 905\n",
      "Train Log likelihood, step 147550 in nats: 0.082243\n",
      "Train Log likelihood, step 147600 in nats: 0.082248\n",
      "Train Log likelihood, step 147650 in nats: 0.082277\n",
      "Train epoch average loss: 0.08228507034929348\n",
      "\n",
      "\n",
      "Epoch: 906\n",
      "Train Log likelihood, step 147700 in nats: 0.082294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 147750 in nats: 0.082309\n",
      "Train Log likelihood, step 147800 in nats: 0.082318\n",
      "Train epoch average loss: 0.08233837365875911\n",
      "\n",
      "\n",
      "Epoch: 907\n",
      "Train Log likelihood, step 147850 in nats: 0.082342\n",
      "Train Log likelihood, step 147900 in nats: 0.082358\n",
      "Train Log likelihood, step 147950 in nats: 0.082374\n",
      "Train Log likelihood, step 148000 in nats: 0.082383\n",
      "Train epoch average loss: 0.0823839297712402\n",
      "\n",
      "\n",
      "Epoch: 908\n",
      "Train Log likelihood, step 148050 in nats: 0.082393\n",
      "Train Log likelihood, step 148100 in nats: 0.082404\n",
      "Train Log likelihood, step 148150 in nats: 0.082411\n",
      "Train epoch average loss: 0.0824142694736175\n",
      "\n",
      "\n",
      "Epoch: 909\n",
      "Train Log likelihood, step 148200 in nats: 0.082415\n",
      "Train Log likelihood, step 148250 in nats: 0.082411\n",
      "Train Log likelihood, step 148300 in nats: 0.082427\n",
      "Train epoch average loss: 0.08243741006181506\n",
      "\n",
      "\n",
      "Epoch: 910\n",
      "Train Log likelihood, step 148350 in nats: 0.082437\n",
      "Train Log likelihood, step 148400 in nats: 0.082445\n",
      "Train Log likelihood, step 148450 in nats: 0.082462\n",
      "Train epoch average loss: 0.08247818148266013\n",
      "\n",
      "\n",
      "Epoch: 911\n",
      "Train Log likelihood, step 148500 in nats: 0.082482\n",
      "Train Log likelihood, step 148550 in nats: 0.082501\n",
      "Train Log likelihood, step 148600 in nats: 0.082505\n",
      "Train Log likelihood, step 148650 in nats: 0.082516\n",
      "Train epoch average loss: 0.0825192383309828\n",
      "\n",
      "\n",
      "Epoch: 912\n",
      "Train Log likelihood, step 148700 in nats: 0.082524\n",
      "Train Log likelihood, step 148750 in nats: 0.082530\n",
      "Train Log likelihood, step 148800 in nats: 0.082554\n",
      "Train epoch average loss: 0.08255607390598309\n",
      "\n",
      "\n",
      "Epoch: 913\n",
      "Train Log likelihood, step 148850 in nats: 0.082559\n",
      "Train Log likelihood, step 148900 in nats: 0.082573\n",
      "Train Log likelihood, step 148950 in nats: 0.082593\n",
      "Train epoch average loss: 0.08260853460869812\n",
      "\n",
      "\n",
      "Epoch: 914\n",
      "Train Log likelihood, step 149000 in nats: 0.082614\n",
      "Train Log likelihood, step 149050 in nats: 0.082636\n",
      "Train Log likelihood, step 149100 in nats: 0.082648\n",
      "Train epoch average loss: 0.08265917008096775\n",
      "\n",
      "\n",
      "Epoch: 915\n",
      "Train Log likelihood, step 149150 in nats: 0.082665\n",
      "Train Log likelihood, step 149200 in nats: 0.082671\n",
      "Train Log likelihood, step 149250 in nats: 0.082685\n",
      "Train Log likelihood, step 149300 in nats: 0.082705\n",
      "Train epoch average loss: 0.0827098857036372\n",
      "\n",
      "\n",
      "Epoch: 916\n",
      "Train Log likelihood, step 149350 in nats: 0.082731\n",
      "Train Log likelihood, step 149400 in nats: 0.082742\n",
      "Train Log likelihood, step 149450 in nats: 0.082755\n",
      "Train epoch average loss: 0.08276016731743678\n",
      "\n",
      "\n",
      "Epoch: 917\n",
      "Train Log likelihood, step 149500 in nats: 0.082774\n",
      "Train Log likelihood, step 149550 in nats: 0.082774\n",
      "Train Log likelihood, step 149600 in nats: 0.082788\n",
      "Train epoch average loss: 0.0827945214980823\n",
      "\n",
      "\n",
      "Epoch: 918\n",
      "Train Log likelihood, step 149650 in nats: 0.082794\n",
      "Train Log likelihood, step 149700 in nats: 0.082810\n",
      "Train Log likelihood, step 149750 in nats: 0.082818\n",
      "Train epoch average loss: 0.0828302212520295\n",
      "\n",
      "\n",
      "Epoch: 919\n",
      "Train Log likelihood, step 149800 in nats: 0.082831\n",
      "Train Log likelihood, step 149850 in nats: 0.082843\n",
      "Train Log likelihood, step 149900 in nats: 0.082847\n",
      "Train Log likelihood, step 149950 in nats: 0.082873\n",
      "Train epoch average loss: 0.08287563711103521\n",
      "\n",
      "\n",
      "Epoch: 920\n",
      "Train Log likelihood, step 150000 in nats: 0.082891\n",
      "Train Log likelihood, step 150050 in nats: 0.082898\n",
      "Train Log likelihood, step 150100 in nats: 0.082917\n",
      "Train epoch average loss: 0.08292595534526397\n",
      "\n",
      "\n",
      "Epoch: 921\n",
      "Train Log likelihood, step 150150 in nats: 0.082925\n",
      "Train Log likelihood, step 150200 in nats: 0.082921\n",
      "Train Log likelihood, step 150250 in nats: 0.082933\n",
      "Train epoch average loss: 0.08293690829964696\n",
      "\n",
      "\n",
      "Epoch: 922\n",
      "Train Log likelihood, step 150300 in nats: 0.082944\n",
      "Train Log likelihood, step 150350 in nats: 0.082957\n",
      "Train Log likelihood, step 150400 in nats: 0.082973\n",
      "Train epoch average loss: 0.08298915908177436\n",
      "\n",
      "\n",
      "Epoch: 923\n",
      "Train Log likelihood, step 150450 in nats: 0.082987\n",
      "Train Log likelihood, step 150500 in nats: 0.083004\n",
      "Train Log likelihood, step 150550 in nats: 0.083016\n",
      "Train Log likelihood, step 150600 in nats: 0.083032\n",
      "Train epoch average loss: 0.0830373877912226\n",
      "\n",
      "\n",
      "Epoch: 924\n",
      "Train Log likelihood, step 150650 in nats: 0.083048\n",
      "Train Log likelihood, step 150700 in nats: 0.083067\n",
      "Train Log likelihood, step 150750 in nats: 0.083084\n",
      "Train epoch average loss: 0.08309493993793839\n",
      "\n",
      "\n",
      "Epoch: 925\n",
      "Train Log likelihood, step 150800 in nats: 0.083096\n",
      "Train Log likelihood, step 150850 in nats: 0.083112\n",
      "Train Log likelihood, step 150900 in nats: 0.083118\n",
      "Train epoch average loss: 0.08311899497033011\n",
      "\n",
      "\n",
      "Epoch: 926\n",
      "Train Log likelihood, step 150950 in nats: 0.083119\n",
      "Train Log likelihood, step 151000 in nats: 0.083139\n",
      "Train Log likelihood, step 151050 in nats: 0.083161\n",
      "Train Log likelihood, step 151100 in nats: 0.083168\n",
      "Train epoch average loss: 0.08316785139627557\n",
      "\n",
      "\n",
      "Epoch: 927\n",
      "Train Log likelihood, step 151150 in nats: 0.083185\n",
      "Train Log likelihood, step 151200 in nats: 0.083202\n",
      "Train Log likelihood, step 151250 in nats: 0.083214\n",
      "Train epoch average loss: 0.08322347696606858\n",
      "\n",
      "\n",
      "Epoch: 928\n",
      "Train Log likelihood, step 151300 in nats: 0.083233\n",
      "Train Log likelihood, step 151350 in nats: 0.083236\n",
      "Train Log likelihood, step 151400 in nats: 0.083255\n",
      "Train epoch average loss: 0.08326823022858774\n",
      "\n",
      "\n",
      "Epoch: 929\n",
      "Train Log likelihood, step 151450 in nats: 0.083267\n",
      "Train Log likelihood, step 151500 in nats: 0.083274\n",
      "Train Log likelihood, step 151550 in nats: 0.083289\n",
      "Train epoch average loss: 0.08329709824247054\n",
      "\n",
      "\n",
      "Epoch: 930\n",
      "Train Log likelihood, step 151600 in nats: 0.083299\n",
      "Train Log likelihood, step 151650 in nats: 0.083312\n",
      "Train Log likelihood, step 151700 in nats: 0.083321\n",
      "Train Log likelihood, step 151750 in nats: 0.083322\n",
      "Train epoch average loss: 0.08332278779388316\n",
      "\n",
      "\n",
      "Epoch: 931\n",
      "Train Log likelihood, step 151800 in nats: 0.083333\n",
      "Train Log likelihood, step 151850 in nats: 0.083341\n",
      "Train Log likelihood, step 151900 in nats: 0.083359\n",
      "Train epoch average loss: 0.08336411792576762\n",
      "\n",
      "\n",
      "Epoch: 932\n",
      "Train Log likelihood, step 151950 in nats: 0.083373\n",
      "Train Log likelihood, step 152000 in nats: 0.083386\n",
      "Train Log likelihood, step 152050 in nats: 0.083392\n",
      "Train epoch average loss: 0.08339428316551568\n",
      "\n",
      "\n",
      "Epoch: 933\n",
      "Train Log likelihood, step 152100 in nats: 0.083400\n",
      "Train Log likelihood, step 152150 in nats: 0.083412\n",
      "Train Log likelihood, step 152200 in nats: 0.083427\n",
      "Train epoch average loss: 0.08344056550354939\n",
      "\n",
      "\n",
      "Epoch: 934\n",
      "Train Log likelihood, step 152250 in nats: 0.083442\n",
      "Train Log likelihood, step 152300 in nats: 0.083454\n",
      "Train Log likelihood, step 152350 in nats: 0.083475\n",
      "Train Log likelihood, step 152400 in nats: 0.083478\n",
      "Train epoch average loss: 0.08348124525833937\n",
      "\n",
      "\n",
      "Epoch: 935\n",
      "Train Log likelihood, step 152450 in nats: 0.083486\n",
      "Train Log likelihood, step 152500 in nats: 0.083496\n",
      "Train Log likelihood, step 152550 in nats: 0.083496\n",
      "Train epoch average loss: 0.08349773750150348\n",
      "\n",
      "\n",
      "Epoch: 936\n",
      "Train Log likelihood, step 152600 in nats: 0.083509\n",
      "Train Log likelihood, step 152650 in nats: 0.083517\n",
      "Train Log likelihood, step 152700 in nats: 0.083530\n",
      "Train epoch average loss: 0.0835367134488736\n",
      "\n",
      "\n",
      "Epoch: 937\n",
      "Train Log likelihood, step 152750 in nats: 0.083540\n",
      "Train Log likelihood, step 152800 in nats: 0.083550\n",
      "Train Log likelihood, step 152850 in nats: 0.083544\n",
      "Train epoch average loss: 0.08356540984176102\n",
      "\n",
      "\n",
      "Epoch: 938\n",
      "Train Log likelihood, step 152900 in nats: 0.083569\n",
      "Train Log likelihood, step 152950 in nats: 0.083585\n",
      "Train Log likelihood, step 153000 in nats: 0.083594\n",
      "Train Log likelihood, step 153050 in nats: 0.083589\n",
      "Train epoch average loss: 0.08359133968841694\n",
      "\n",
      "\n",
      "Epoch: 939\n",
      "Train Log likelihood, step 153100 in nats: 0.083607\n",
      "Train Log likelihood, step 153150 in nats: 0.083622\n",
      "Train Log likelihood, step 153200 in nats: 0.083636\n",
      "Train epoch average loss: 0.08363346270315951\n",
      "\n",
      "\n",
      "Epoch: 940\n",
      "Train Log likelihood, step 153250 in nats: 0.083640\n",
      "Train Log likelihood, step 153300 in nats: 0.083657\n",
      "Train Log likelihood, step 153350 in nats: 0.083670\n",
      "Train epoch average loss: 0.08367445945125603\n",
      "\n",
      "\n",
      "Epoch: 941\n",
      "Train Log likelihood, step 153400 in nats: 0.083680\n",
      "Train Log likelihood, step 153450 in nats: 0.083692\n",
      "Train Log likelihood, step 153500 in nats: 0.083698\n",
      "Train epoch average loss: 0.08371010959454495\n",
      "\n",
      "\n",
      "Epoch: 942\n",
      "Train Log likelihood, step 153550 in nats: 0.083711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 153600 in nats: 0.083717\n",
      "Train Log likelihood, step 153650 in nats: 0.083729\n",
      "Train Log likelihood, step 153700 in nats: 0.083732\n",
      "Train epoch average loss: 0.0837367011596503\n",
      "\n",
      "\n",
      "Epoch: 943\n",
      "Train Log likelihood, step 153750 in nats: 0.083746\n",
      "Train Log likelihood, step 153800 in nats: 0.083764\n",
      "Train Log likelihood, step 153850 in nats: 0.083778\n",
      "Train epoch average loss: 0.08377970393792405\n",
      "\n",
      "\n",
      "Epoch: 944\n",
      "Train Log likelihood, step 153900 in nats: 0.083789\n",
      "Train Log likelihood, step 153950 in nats: 0.083807\n",
      "Train Log likelihood, step 154000 in nats: 0.083810\n",
      "Train epoch average loss: 0.08381658908749866\n",
      "\n",
      "\n",
      "Epoch: 945\n",
      "Train Log likelihood, step 154050 in nats: 0.083824\n",
      "Train Log likelihood, step 154100 in nats: 0.083844\n",
      "Train Log likelihood, step 154150 in nats: 0.083857\n",
      "Train epoch average loss: 0.08386629746772341\n",
      "\n",
      "\n",
      "Epoch: 946\n",
      "Train Log likelihood, step 154200 in nats: 0.083869\n",
      "Train Log likelihood, step 154250 in nats: 0.083882\n",
      "Train Log likelihood, step 154300 in nats: 0.083901\n",
      "Train Log likelihood, step 154350 in nats: 0.083910\n",
      "Train epoch average loss: 0.08391266545748363\n",
      "\n",
      "\n",
      "Epoch: 947\n",
      "Train Log likelihood, step 154400 in nats: 0.083918\n",
      "Train Log likelihood, step 154450 in nats: 0.083938\n",
      "Train Log likelihood, step 154500 in nats: 0.083951\n",
      "Train epoch average loss: 0.0839452732962537\n",
      "\n",
      "\n",
      "Epoch: 948\n",
      "Train Log likelihood, step 154550 in nats: 0.083951\n",
      "Train Log likelihood, step 154600 in nats: 0.083964\n",
      "Train Log likelihood, step 154650 in nats: 0.083976\n",
      "Train epoch average loss: 0.08398269735281902\n",
      "\n",
      "\n",
      "Epoch: 949\n",
      "Train Log likelihood, step 154700 in nats: 0.083990\n",
      "Train Log likelihood, step 154750 in nats: 0.083986\n",
      "Train Log likelihood, step 154800 in nats: 0.083999\n",
      "Train epoch average loss: 0.08400706607162674\n",
      "\n",
      "\n",
      "Epoch: 950\n",
      "Train Log likelihood, step 154850 in nats: 0.084007\n",
      "Train Log likelihood, step 154900 in nats: 0.084017\n",
      "Train Log likelihood, step 154950 in nats: 0.084024\n",
      "Train Log likelihood, step 155000 in nats: 0.084042\n",
      "Train epoch average loss: 0.08404472855531496\n",
      "\n",
      "\n",
      "Epoch: 951\n",
      "Train Log likelihood, step 155050 in nats: 0.084048\n",
      "Train Log likelihood, step 155100 in nats: 0.084061\n",
      "Train Log likelihood, step 155150 in nats: 0.084070\n",
      "Train epoch average loss: 0.08407700020687044\n",
      "\n",
      "\n",
      "Epoch: 952\n",
      "Train Log likelihood, step 155200 in nats: 0.084090\n",
      "Train Log likelihood, step 155250 in nats: 0.084106\n",
      "Train Log likelihood, step 155300 in nats: 0.084116\n",
      "Train epoch average loss: 0.08412151809561084\n",
      "\n",
      "\n",
      "Epoch: 953\n",
      "Train Log likelihood, step 155350 in nats: 0.084127\n",
      "Train Log likelihood, step 155400 in nats: 0.084141\n",
      "Train Log likelihood, step 155450 in nats: 0.084153\n",
      "Train Log likelihood, step 155500 in nats: 0.084148\n",
      "Train epoch average loss: 0.0841484421397181\n",
      "\n",
      "\n",
      "Epoch: 954\n",
      "Train Log likelihood, step 155550 in nats: 0.084154\n",
      "Train Log likelihood, step 155600 in nats: 0.084163\n",
      "Train Log likelihood, step 155650 in nats: 0.084162\n",
      "Train epoch average loss: 0.08416882976119197\n",
      "\n",
      "\n",
      "Epoch: 955\n",
      "Train Log likelihood, step 155700 in nats: 0.084182\n",
      "Train Log likelihood, step 155750 in nats: 0.084192\n",
      "Train Log likelihood, step 155800 in nats: 0.084201\n",
      "Train epoch average loss: 0.08420472527328654\n",
      "\n",
      "\n",
      "Epoch: 956\n",
      "Train Log likelihood, step 155850 in nats: 0.084206\n",
      "Train Log likelihood, step 155900 in nats: 0.084212\n",
      "Train Log likelihood, step 155950 in nats: 0.084212\n",
      "Train epoch average loss: 0.08422250999449413\n",
      "\n",
      "\n",
      "Epoch: 957\n",
      "Train Log likelihood, step 156000 in nats: 0.084225\n",
      "Train Log likelihood, step 156050 in nats: 0.084240\n",
      "Train Log likelihood, step 156100 in nats: 0.084252\n",
      "Train Log likelihood, step 156150 in nats: 0.084276\n",
      "Train epoch average loss: 0.08427488812856897\n",
      "\n",
      "\n",
      "Epoch: 958\n",
      "Train Log likelihood, step 156200 in nats: 0.084290\n",
      "Train Log likelihood, step 156250 in nats: 0.084305\n",
      "Train Log likelihood, step 156300 in nats: 0.084325\n",
      "Train epoch average loss: 0.08433322906853653\n",
      "\n",
      "\n",
      "Epoch: 959\n",
      "Train Log likelihood, step 156350 in nats: 0.084340\n",
      "Train Log likelihood, step 156400 in nats: 0.084354\n",
      "Train Log likelihood, step 156450 in nats: 0.084369\n",
      "Train epoch average loss: 0.08437697575179959\n",
      "\n",
      "\n",
      "Epoch: 960\n",
      "Train Log likelihood, step 156500 in nats: 0.084378\n",
      "Train Log likelihood, step 156550 in nats: 0.084397\n",
      "Train Log likelihood, step 156600 in nats: 0.084419\n",
      "Train epoch average loss: 0.0844188998378366\n",
      "\n",
      "\n",
      "Epoch: 961\n",
      "Train Log likelihood, step 156650 in nats: 0.084419\n",
      "Train Log likelihood, step 156700 in nats: 0.084428\n",
      "Train Log likelihood, step 156750 in nats: 0.084453\n",
      "Train Log likelihood, step 156800 in nats: 0.084477\n",
      "Train epoch average loss: 0.08447809599213509\n",
      "\n",
      "\n",
      "Epoch: 962\n",
      "Train Log likelihood, step 156850 in nats: 0.084479\n",
      "Train Log likelihood, step 156900 in nats: 0.084497\n",
      "Train Log likelihood, step 156950 in nats: 0.084510\n",
      "Train epoch average loss: 0.0845169132259211\n",
      "\n",
      "\n",
      "Epoch: 963\n",
      "Train Log likelihood, step 157000 in nats: 0.084521\n",
      "Train Log likelihood, step 157050 in nats: 0.084528\n",
      "Train Log likelihood, step 157100 in nats: 0.084534\n",
      "Train epoch average loss: 0.08454605339822223\n",
      "\n",
      "\n",
      "Epoch: 964\n",
      "Train Log likelihood, step 157150 in nats: 0.084549\n",
      "Train Log likelihood, step 157200 in nats: 0.084580\n",
      "Train Log likelihood, step 157250 in nats: 0.084599\n",
      "Train epoch average loss: 0.08461677883808541\n",
      "\n",
      "\n",
      "Epoch: 965\n",
      "Train Log likelihood, step 157300 in nats: 0.084619\n",
      "Train Log likelihood, step 157350 in nats: 0.084639\n",
      "Train Log likelihood, step 157400 in nats: 0.084651\n",
      "Train Log likelihood, step 157450 in nats: 0.084670\n",
      "Train epoch average loss: 0.08466965950055656\n",
      "\n",
      "\n",
      "Epoch: 966\n",
      "Train Log likelihood, step 157500 in nats: 0.084658\n",
      "Train Log likelihood, step 157550 in nats: 0.084661\n",
      "Train Log likelihood, step 157600 in nats: 0.084654\n",
      "Train epoch average loss: 0.08465969125436416\n",
      "\n",
      "\n",
      "Epoch: 967\n",
      "Train Log likelihood, step 157650 in nats: 0.084667\n",
      "Train Log likelihood, step 157700 in nats: 0.084685\n",
      "Train Log likelihood, step 157750 in nats: 0.084691\n",
      "Train epoch average loss: 0.08469827302866974\n",
      "\n",
      "\n",
      "Epoch: 968\n",
      "Train Log likelihood, step 157800 in nats: 0.084703\n",
      "Train Log likelihood, step 157850 in nats: 0.084707\n",
      "Train Log likelihood, step 157900 in nats: 0.084732\n",
      "Train epoch average loss: 0.0847480563371499\n",
      "\n",
      "\n",
      "Epoch: 969\n",
      "Train Log likelihood, step 157950 in nats: 0.084750\n",
      "Train Log likelihood, step 158000 in nats: 0.084755\n",
      "Train Log likelihood, step 158050 in nats: 0.084760\n",
      "Train Log likelihood, step 158100 in nats: 0.084772\n",
      "Train epoch average loss: 0.0847769096408081\n",
      "\n",
      "\n",
      "Epoch: 970\n",
      "Train Log likelihood, step 158150 in nats: 0.084787\n",
      "Train Log likelihood, step 158200 in nats: 0.084802\n",
      "Train Log likelihood, step 158250 in nats: 0.084809\n",
      "Train epoch average loss: 0.08481608765803939\n",
      "\n",
      "\n",
      "Epoch: 971\n",
      "Train Log likelihood, step 158300 in nats: 0.084827\n",
      "Train Log likelihood, step 158350 in nats: 0.084843\n",
      "Train Log likelihood, step 158400 in nats: 0.084857\n",
      "Train epoch average loss: 0.0848659689039408\n",
      "\n",
      "\n",
      "Epoch: 972\n",
      "Train Log likelihood, step 158450 in nats: 0.084870\n",
      "Train Log likelihood, step 158500 in nats: 0.084883\n",
      "Train Log likelihood, step 158550 in nats: 0.084894\n",
      "Train epoch average loss: 0.08491474897612598\n",
      "\n",
      "\n",
      "Epoch: 973\n",
      "Train Log likelihood, step 158600 in nats: 0.084916\n",
      "Train Log likelihood, step 158650 in nats: 0.084934\n",
      "Train Log likelihood, step 158700 in nats: 0.084943\n",
      "Train Log likelihood, step 158750 in nats: 0.084951\n",
      "Train epoch average loss: 0.08495439364076385\n",
      "\n",
      "\n",
      "Epoch: 974\n",
      "Train Log likelihood, step 158800 in nats: 0.084958\n",
      "Train Log likelihood, step 158850 in nats: 0.084966\n",
      "Train Log likelihood, step 158900 in nats: 0.084985\n",
      "Train epoch average loss: 0.08499299679878142\n",
      "\n",
      "\n",
      "Epoch: 975\n",
      "Train Log likelihood, step 158950 in nats: 0.085000\n",
      "Train Log likelihood, step 159000 in nats: 0.085008\n",
      "Train Log likelihood, step 159050 in nats: 0.085035\n",
      "Train epoch average loss: 0.085050777236458\n",
      "\n",
      "\n",
      "Epoch: 976\n",
      "Train Log likelihood, step 159100 in nats: 0.085053\n",
      "Train Log likelihood, step 159150 in nats: 0.085056\n",
      "Train Log likelihood, step 159200 in nats: 0.085067\n",
      "Train Log likelihood, step 159250 in nats: 0.085077\n",
      "Train epoch average loss: 0.08507660297553106\n",
      "\n",
      "\n",
      "Epoch: 977\n",
      "Train Log likelihood, step 159300 in nats: 0.085090\n",
      "Train Log likelihood, step 159350 in nats: 0.085098\n",
      "Train Log likelihood, step 159400 in nats: 0.085095\n",
      "Train epoch average loss: 0.08509991382075176\n",
      "\n",
      "\n",
      "Epoch: 978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 159450 in nats: 0.085113\n",
      "Train Log likelihood, step 159500 in nats: 0.085120\n",
      "Train Log likelihood, step 159550 in nats: 0.085129\n",
      "Train epoch average loss: 0.08513581288492579\n",
      "\n",
      "\n",
      "Epoch: 979\n",
      "Train Log likelihood, step 159600 in nats: 0.085140\n",
      "Train Log likelihood, step 159650 in nats: 0.085151\n",
      "Train Log likelihood, step 159700 in nats: 0.085158\n",
      "Train epoch average loss: 0.08517408095232507\n",
      "\n",
      "\n",
      "Epoch: 980\n",
      "Train Log likelihood, step 159750 in nats: 0.085176\n",
      "Train Log likelihood, step 159800 in nats: 0.085175\n",
      "Train Log likelihood, step 159850 in nats: 0.085195\n",
      "Train Log likelihood, step 159900 in nats: 0.085212\n",
      "Train epoch average loss: 0.08521324203273699\n",
      "\n",
      "\n",
      "Epoch: 981\n",
      "Train Log likelihood, step 159950 in nats: 0.085224\n",
      "Train Log likelihood, step 160000 in nats: 0.085224\n",
      "Train Log likelihood, step 160050 in nats: 0.085225\n",
      "Train epoch average loss: 0.08522214373813779\n",
      "\n",
      "\n",
      "Epoch: 982\n",
      "Train Log likelihood, step 160100 in nats: 0.085220\n",
      "Train Log likelihood, step 160150 in nats: 0.085219\n",
      "Train Log likelihood, step 160200 in nats: 0.085235\n",
      "Train epoch average loss: 0.08523748417164051\n",
      "\n",
      "\n",
      "Epoch: 983\n",
      "Train Log likelihood, step 160250 in nats: 0.085241\n",
      "Train Log likelihood, step 160300 in nats: 0.085249\n",
      "Train Log likelihood, step 160350 in nats: 0.085248\n",
      "Train epoch average loss: 0.08526205493378312\n",
      "\n",
      "\n",
      "Epoch: 984\n",
      "Train Log likelihood, step 160400 in nats: 0.085258\n",
      "Train Log likelihood, step 160450 in nats: 0.085261\n",
      "Train Log likelihood, step 160500 in nats: 0.085265\n",
      "Train Log likelihood, step 160550 in nats: 0.085280\n",
      "Train epoch average loss: 0.08528086572261363\n",
      "\n",
      "\n",
      "Epoch: 985\n",
      "Train Log likelihood, step 160600 in nats: 0.085300\n",
      "Train Log likelihood, step 160650 in nats: 0.085306\n",
      "Train Log likelihood, step 160700 in nats: 0.085322\n",
      "Train epoch average loss: 0.0853200960527704\n",
      "\n",
      "\n",
      "Epoch: 986\n",
      "Train Log likelihood, step 160750 in nats: 0.085334\n",
      "Train Log likelihood, step 160800 in nats: 0.085351\n",
      "Train Log likelihood, step 160850 in nats: 0.085370\n",
      "Train epoch average loss: 0.08537408583262532\n",
      "\n",
      "\n",
      "Epoch: 987\n",
      "Train Log likelihood, step 160900 in nats: 0.085376\n",
      "Train Log likelihood, step 160950 in nats: 0.085382\n",
      "Train Log likelihood, step 161000 in nats: 0.085389\n",
      "Train epoch average loss: 0.08540222506733415\n",
      "\n",
      "\n",
      "Epoch: 988\n",
      "Train Log likelihood, step 161050 in nats: 0.085405\n",
      "Train Log likelihood, step 161100 in nats: 0.085422\n",
      "Train Log likelihood, step 161150 in nats: 0.085439\n",
      "Train Log likelihood, step 161200 in nats: 0.085447\n",
      "Train epoch average loss: 0.08544827331012715\n",
      "\n",
      "\n",
      "Epoch: 989\n",
      "Train Log likelihood, step 161250 in nats: 0.085446\n",
      "Train Log likelihood, step 161300 in nats: 0.085458\n",
      "Train Log likelihood, step 161350 in nats: 0.085465\n",
      "Train epoch average loss: 0.0854719712291881\n",
      "\n",
      "\n",
      "Epoch: 990\n",
      "Train Log likelihood, step 161400 in nats: 0.085480\n",
      "Train Log likelihood, step 161450 in nats: 0.085499\n",
      "Train Log likelihood, step 161500 in nats: 0.085508\n",
      "Train epoch average loss: 0.08551774616270492\n",
      "\n",
      "\n",
      "Epoch: 991\n",
      "Train Log likelihood, step 161550 in nats: 0.085518\n",
      "Train Log likelihood, step 161600 in nats: 0.085531\n",
      "Train Log likelihood, step 161650 in nats: 0.085549\n",
      "Train epoch average loss: 0.08555763434335599\n",
      "\n",
      "\n",
      "Epoch: 992\n",
      "Train Log likelihood, step 161700 in nats: 0.085560\n",
      "Train Log likelihood, step 161750 in nats: 0.085574\n",
      "Train Log likelihood, step 161800 in nats: 0.085578\n",
      "Train Log likelihood, step 161850 in nats: 0.085588\n",
      "Train epoch average loss: 0.08558687858866573\n",
      "\n",
      "\n",
      "Epoch: 993\n",
      "Train Log likelihood, step 161900 in nats: 0.085597\n",
      "Train Log likelihood, step 161950 in nats: 0.085601\n",
      "Train Log likelihood, step 162000 in nats: 0.085616\n",
      "Train epoch average loss: 0.08562178613745583\n",
      "\n",
      "\n",
      "Epoch: 994\n",
      "Train Log likelihood, step 162050 in nats: 0.085626\n",
      "Train Log likelihood, step 162100 in nats: 0.085633\n",
      "Train Log likelihood, step 162150 in nats: 0.085651\n",
      "Train epoch average loss: 0.08566143141302088\n",
      "\n",
      "\n",
      "Epoch: 995\n",
      "Train Log likelihood, step 162200 in nats: 0.085665\n",
      "Train Log likelihood, step 162250 in nats: 0.085678\n",
      "Train Log likelihood, step 162300 in nats: 0.085682\n",
      "Train epoch average loss: 0.0856900909250291\n",
      "\n",
      "\n",
      "Epoch: 996\n",
      "Train Log likelihood, step 162350 in nats: 0.085690\n",
      "Train Log likelihood, step 162400 in nats: 0.085704\n",
      "Train Log likelihood, step 162450 in nats: 0.085717\n",
      "Train Log likelihood, step 162500 in nats: 0.085730\n",
      "Train epoch average loss: 0.08573352153429269\n",
      "\n",
      "\n",
      "Epoch: 997\n",
      "Train Log likelihood, step 162550 in nats: 0.085751\n",
      "Train Log likelihood, step 162600 in nats: 0.085766\n",
      "Train Log likelihood, step 162650 in nats: 0.085769\n",
      "Train epoch average loss: 0.08577386145891956\n",
      "\n",
      "\n",
      "Epoch: 998\n",
      "Train Log likelihood, step 162700 in nats: 0.085787\n",
      "Train Log likelihood, step 162750 in nats: 0.085794\n",
      "Train Log likelihood, step 162800 in nats: 0.085799\n",
      "Train epoch average loss: 0.0858127468646292\n",
      "\n",
      "\n",
      "Epoch: 999\n",
      "Train Log likelihood, step 162850 in nats: 0.085816\n",
      "Train Log likelihood, step 162900 in nats: 0.085816\n",
      "Train Log likelihood, step 162950 in nats: 0.085821\n",
      "Train epoch average loss: 0.0858234188971334\n",
      "\n",
      "\n",
      "Epoch: 1000\n",
      "Train Log likelihood, step 163000 in nats: 0.085822\n",
      "Train Log likelihood, step 163050 in nats: 0.085832\n",
      "Train Log likelihood, step 163100 in nats: 0.085843\n",
      "Train Log likelihood, step 163150 in nats: 0.085852\n",
      "Train epoch average loss: 0.08585517331304691\n",
      "\n",
      "\n",
      "Epoch: 1001\n",
      "Train Log likelihood, step 163200 in nats: 0.085866\n",
      "Train Log likelihood, step 163250 in nats: 0.085882\n",
      "Train Log likelihood, step 163300 in nats: 0.085892\n",
      "Train epoch average loss: 0.0858967457494969\n",
      "\n",
      "\n",
      "Epoch: 1002\n",
      "Train Log likelihood, step 163350 in nats: 0.085908\n",
      "Train Log likelihood, step 163400 in nats: 0.085918\n",
      "Train Log likelihood, step 163450 in nats: 0.085936\n",
      "Train epoch average loss: 0.08592919273871209\n",
      "\n",
      "\n",
      "Epoch: 1003\n",
      "Train Log likelihood, step 163500 in nats: 0.085926\n",
      "Train Log likelihood, step 163550 in nats: 0.085929\n",
      "Train Log likelihood, step 163600 in nats: 0.085932\n",
      "Train Log likelihood, step 163650 in nats: 0.085938\n",
      "Train epoch average loss: 0.08593852115696836\n",
      "\n",
      "\n",
      "Epoch: 1004\n",
      "Train Log likelihood, step 163700 in nats: 0.085951\n",
      "Train Log likelihood, step 163750 in nats: 0.085960\n",
      "Train Log likelihood, step 163800 in nats: 0.085969\n",
      "Train epoch average loss: 0.08597011191878905\n",
      "\n",
      "\n",
      "Epoch: 1005\n",
      "Train Log likelihood, step 163850 in nats: 0.085987\n",
      "Train Log likelihood, step 163900 in nats: 0.085998\n",
      "Train Log likelihood, step 163950 in nats: 0.086014\n",
      "Train epoch average loss: 0.0860176776255456\n",
      "\n",
      "\n",
      "Epoch: 1006\n",
      "Train Log likelihood, step 164000 in nats: 0.086022\n",
      "Train Log likelihood, step 164050 in nats: 0.086025\n",
      "Train Log likelihood, step 164100 in nats: 0.086045\n",
      "Train epoch average loss: 0.08605536606034131\n",
      "\n",
      "\n",
      "Epoch: 1007\n",
      "Train Log likelihood, step 164150 in nats: 0.086055\n",
      "Train Log likelihood, step 164200 in nats: 0.086067\n",
      "Train Log likelihood, step 164250 in nats: 0.086084\n",
      "Train Log likelihood, step 164300 in nats: 0.086095\n",
      "Train epoch average loss: 0.08609695996764764\n",
      "\n",
      "\n",
      "Epoch: 1008\n",
      "Train Log likelihood, step 164350 in nats: 0.086108\n",
      "Train Log likelihood, step 164400 in nats: 0.086120\n",
      "Train Log likelihood, step 164450 in nats: 0.086125\n",
      "Train epoch average loss: 0.08612344500451968\n",
      "\n",
      "\n",
      "Epoch: 1009\n",
      "Train Log likelihood, step 164500 in nats: 0.086129\n",
      "Train Log likelihood, step 164550 in nats: 0.086125\n",
      "Train Log likelihood, step 164600 in nats: 0.086144\n",
      "Train epoch average loss: 0.0861440724609708\n",
      "\n",
      "\n",
      "Epoch: 1010\n",
      "Train Log likelihood, step 164650 in nats: 0.086147\n",
      "Train Log likelihood, step 164700 in nats: 0.086148\n",
      "Train Log likelihood, step 164750 in nats: 0.086165\n",
      "Train epoch average loss: 0.0861803078393789\n",
      "\n",
      "\n",
      "Epoch: 1011\n",
      "Train Log likelihood, step 164800 in nats: 0.086183\n",
      "Train Log likelihood, step 164850 in nats: 0.086189\n",
      "Train Log likelihood, step 164900 in nats: 0.086206\n",
      "Train Log likelihood, step 164950 in nats: 0.086232\n",
      "Train epoch average loss: 0.08623243615154831\n",
      "\n",
      "\n",
      "Epoch: 1012\n",
      "Train Log likelihood, step 165000 in nats: 0.086246\n",
      "Train Log likelihood, step 165050 in nats: 0.086261\n",
      "Train Log likelihood, step 165100 in nats: 0.086274\n",
      "Train epoch average loss: 0.08627959148212158\n",
      "\n",
      "\n",
      "Epoch: 1013\n",
      "Train Log likelihood, step 165150 in nats: 0.086296\n",
      "Train Log likelihood, step 165200 in nats: 0.086315\n",
      "Train Log likelihood, step 165250 in nats: 0.086323\n",
      "Train epoch average loss: 0.08633075872119506\n",
      "\n",
      "\n",
      "Epoch: 1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 165300 in nats: 0.086337\n",
      "Train Log likelihood, step 165350 in nats: 0.086351\n",
      "Train Log likelihood, step 165400 in nats: 0.086363\n",
      "Train epoch average loss: 0.08637303769744951\n",
      "\n",
      "\n",
      "Epoch: 1015\n",
      "Train Log likelihood, step 165450 in nats: 0.086373\n",
      "Train Log likelihood, step 165500 in nats: 0.086397\n",
      "Train Log likelihood, step 165550 in nats: 0.086402\n",
      "Train Log likelihood, step 165600 in nats: 0.086412\n",
      "Train epoch average loss: 0.08641092905014437\n",
      "\n",
      "\n",
      "Epoch: 1016\n",
      "Train Log likelihood, step 165650 in nats: 0.086426\n",
      "Train Log likelihood, step 165700 in nats: 0.086435\n",
      "Train Log likelihood, step 165750 in nats: 0.086440\n",
      "Train epoch average loss: 0.08644039567226196\n",
      "\n",
      "\n",
      "Epoch: 1017\n",
      "Train Log likelihood, step 165800 in nats: 0.086439\n",
      "Train Log likelihood, step 165850 in nats: 0.086442\n",
      "Train Log likelihood, step 165900 in nats: 0.086450\n",
      "Train epoch average loss: 0.08645447417726952\n",
      "\n",
      "\n",
      "Epoch: 1018\n",
      "Train Log likelihood, step 165950 in nats: 0.086465\n",
      "Train Log likelihood, step 166000 in nats: 0.086473\n",
      "Train Log likelihood, step 166050 in nats: 0.086491\n",
      "Train epoch average loss: 0.08650464346567625\n",
      "\n",
      "\n",
      "Epoch: 1019\n",
      "Train Log likelihood, step 166100 in nats: 0.086503\n",
      "Train Log likelihood, step 166150 in nats: 0.086513\n",
      "Train Log likelihood, step 166200 in nats: 0.086522\n",
      "Train Log likelihood, step 166250 in nats: 0.086529\n",
      "Train epoch average loss: 0.08653360038921375\n",
      "\n",
      "\n",
      "Epoch: 1020\n",
      "Train Log likelihood, step 166300 in nats: 0.086545\n",
      "Train Log likelihood, step 166350 in nats: 0.086554\n",
      "Train Log likelihood, step 166400 in nats: 0.086569\n",
      "Train epoch average loss: 0.0865777226824528\n",
      "\n",
      "\n",
      "Epoch: 1021\n",
      "Train Log likelihood, step 166450 in nats: 0.086585\n",
      "Train Log likelihood, step 166500 in nats: 0.086595\n",
      "Train Log likelihood, step 166550 in nats: 0.086608\n",
      "Train epoch average loss: 0.08661889052608882\n",
      "\n",
      "\n",
      "Epoch: 1022\n",
      "Train Log likelihood, step 166600 in nats: 0.086629\n",
      "Train Log likelihood, step 166650 in nats: 0.086644\n",
      "Train Log likelihood, step 166700 in nats: 0.086665\n",
      "Train epoch average loss: 0.08666082662808783\n",
      "\n",
      "\n",
      "Epoch: 1023\n",
      "Train Log likelihood, step 166750 in nats: 0.086660\n",
      "Train Log likelihood, step 166800 in nats: 0.086659\n",
      "Train Log likelihood, step 166850 in nats: 0.086666\n",
      "Train Log likelihood, step 166900 in nats: 0.086675\n",
      "Train epoch average loss: 0.08667370137311989\n",
      "\n",
      "\n",
      "Epoch: 1024\n",
      "Train Log likelihood, step 166950 in nats: 0.086681\n",
      "Train Log likelihood, step 167000 in nats: 0.086695\n",
      "Train Log likelihood, step 167050 in nats: 0.086712\n",
      "Train epoch average loss: 0.08672100165151402\n",
      "\n",
      "\n",
      "Epoch: 1025\n",
      "Train Log likelihood, step 167100 in nats: 0.086730\n",
      "Train Log likelihood, step 167150 in nats: 0.086743\n",
      "Train Log likelihood, step 167200 in nats: 0.086757\n",
      "Train epoch average loss: 0.08677015139833347\n",
      "\n",
      "\n",
      "Epoch: 1026\n",
      "Train Log likelihood, step 167250 in nats: 0.086773\n",
      "Train Log likelihood, step 167300 in nats: 0.086789\n",
      "Train Log likelihood, step 167350 in nats: 0.086797\n",
      "Train Log likelihood, step 167400 in nats: 0.086806\n",
      "Train epoch average loss: 0.08680645932034665\n",
      "\n",
      "\n",
      "Epoch: 1027\n",
      "Train Log likelihood, step 167450 in nats: 0.086817\n",
      "Train Log likelihood, step 167500 in nats: 0.086817\n",
      "Train Log likelihood, step 167550 in nats: 0.086821\n",
      "Train epoch average loss: 0.0868244365635035\n",
      "\n",
      "\n",
      "Epoch: 1028\n",
      "Train Log likelihood, step 167600 in nats: 0.086835\n",
      "Train Log likelihood, step 167650 in nats: 0.086848\n",
      "Train Log likelihood, step 167700 in nats: 0.086855\n",
      "Train epoch average loss: 0.08686941211888356\n",
      "\n",
      "\n",
      "Epoch: 1029\n",
      "Train Log likelihood, step 167750 in nats: 0.086878\n",
      "Train Log likelihood, step 167800 in nats: 0.086885\n",
      "Train Log likelihood, step 167850 in nats: 0.086900\n",
      "Train epoch average loss: 0.08691280623400957\n",
      "\n",
      "\n",
      "Epoch: 1030\n",
      "Train Log likelihood, step 167900 in nats: 0.086914\n",
      "Train Log likelihood, step 167950 in nats: 0.086922\n",
      "Train Log likelihood, step 168000 in nats: 0.086928\n",
      "Train Log likelihood, step 168050 in nats: 0.086936\n",
      "Train epoch average loss: 0.086936224750802\n",
      "\n",
      "\n",
      "Epoch: 1031\n",
      "Train Log likelihood, step 168100 in nats: 0.086925\n",
      "Train Log likelihood, step 168150 in nats: 0.086938\n",
      "Train Log likelihood, step 168200 in nats: 0.086956\n",
      "Train epoch average loss: 0.0869597986348392\n",
      "\n",
      "\n",
      "Epoch: 1032\n",
      "Train Log likelihood, step 168250 in nats: 0.086956\n",
      "Train Log likelihood, step 168300 in nats: 0.086971\n",
      "Train Log likelihood, step 168350 in nats: 0.086986\n",
      "Train epoch average loss: 0.08698873178233185\n",
      "\n",
      "\n",
      "Epoch: 1033\n",
      "Train Log likelihood, step 168400 in nats: 0.086999\n",
      "Train Log likelihood, step 168450 in nats: 0.087020\n",
      "Train Log likelihood, step 168500 in nats: 0.087036\n",
      "Train epoch average loss: 0.08704394293911435\n",
      "\n",
      "\n",
      "Epoch: 1034\n",
      "Train Log likelihood, step 168550 in nats: 0.087050\n",
      "Train Log likelihood, step 168600 in nats: 0.087061\n",
      "Train Log likelihood, step 168650 in nats: 0.087077\n",
      "Train Log likelihood, step 168700 in nats: 0.087082\n",
      "Train epoch average loss: 0.08708618987946715\n",
      "\n",
      "\n",
      "Epoch: 1035\n",
      "Train Log likelihood, step 168750 in nats: 0.087101\n",
      "Train Log likelihood, step 168800 in nats: 0.087108\n",
      "Train Log likelihood, step 168850 in nats: 0.087111\n",
      "Train epoch average loss: 0.08711382142473\n",
      "\n",
      "\n",
      "Epoch: 1036\n",
      "Train Log likelihood, step 168900 in nats: 0.087119\n",
      "Train Log likelihood, step 168950 in nats: 0.087136\n",
      "Train Log likelihood, step 169000 in nats: 0.087142\n",
      "Train epoch average loss: 0.08714435152468403\n",
      "\n",
      "\n",
      "Epoch: 1037\n",
      "Train Log likelihood, step 169050 in nats: 0.087147\n",
      "Train Log likelihood, step 169100 in nats: 0.087163\n",
      "Train Log likelihood, step 169150 in nats: 0.087167\n",
      "Train epoch average loss: 0.08717132675431129\n",
      "\n",
      "\n",
      "Epoch: 1038\n",
      "Train Log likelihood, step 169200 in nats: 0.087174\n",
      "Train Log likelihood, step 169250 in nats: 0.087182\n",
      "Train Log likelihood, step 169300 in nats: 0.087204\n",
      "Train Log likelihood, step 169350 in nats: 0.087216\n",
      "Train epoch average loss: 0.08721784425944218\n",
      "\n",
      "\n",
      "Epoch: 1039\n",
      "Train Log likelihood, step 169400 in nats: 0.087212\n",
      "Train Log likelihood, step 169450 in nats: 0.087219\n",
      "Train Log likelihood, step 169500 in nats: 0.087237\n",
      "Train epoch average loss: 0.08724620895922411\n",
      "\n",
      "\n",
      "Epoch: 1040\n",
      "Train Log likelihood, step 169550 in nats: 0.087260\n",
      "Train Log likelihood, step 169600 in nats: 0.087281\n",
      "Train Log likelihood, step 169650 in nats: 0.087292\n",
      "Train epoch average loss: 0.08729495377733222\n",
      "\n",
      "\n",
      "Epoch: 1041\n",
      "Train Log likelihood, step 169700 in nats: 0.087297\n",
      "Train Log likelihood, step 169750 in nats: 0.087309\n",
      "Train Log likelihood, step 169800 in nats: 0.087330\n",
      "Train epoch average loss: 0.0873283576796435\n",
      "\n",
      "\n",
      "Epoch: 1042\n",
      "Train Log likelihood, step 169850 in nats: 0.087330\n",
      "Train Log likelihood, step 169900 in nats: 0.087343\n",
      "Train Log likelihood, step 169950 in nats: 0.087356\n",
      "Train Log likelihood, step 170000 in nats: 0.087369\n",
      "Train epoch average loss: 0.0873732204553749\n",
      "\n",
      "\n",
      "Epoch: 1043\n",
      "Train Log likelihood, step 170050 in nats: 0.087388\n",
      "Train Log likelihood, step 170100 in nats: 0.087405\n",
      "Train Log likelihood, step 170150 in nats: 0.087411\n",
      "Train epoch average loss: 0.08742023136658364\n",
      "\n",
      "\n",
      "Epoch: 1044\n",
      "Train Log likelihood, step 170200 in nats: 0.087424\n",
      "Train Log likelihood, step 170250 in nats: 0.087434\n",
      "Train Log likelihood, step 170300 in nats: 0.087446\n",
      "Train epoch average loss: 0.08745123802844547\n",
      "\n",
      "\n",
      "Epoch: 1045\n",
      "Train Log likelihood, step 170350 in nats: 0.087456\n",
      "Train Log likelihood, step 170400 in nats: 0.087455\n",
      "Train Log likelihood, step 170450 in nats: 0.087471\n",
      "Train epoch average loss: 0.08748212868994003\n",
      "\n",
      "\n",
      "Epoch: 1046\n",
      "Train Log likelihood, step 170500 in nats: 0.087483\n",
      "Train Log likelihood, step 170550 in nats: 0.087500\n",
      "Train Log likelihood, step 170600 in nats: 0.087515\n",
      "Train Log likelihood, step 170650 in nats: 0.087522\n",
      "Train epoch average loss: 0.08752536631788359\n",
      "\n",
      "\n",
      "Epoch: 1047\n",
      "Train Log likelihood, step 170700 in nats: 0.087528\n",
      "Train Log likelihood, step 170750 in nats: 0.087538\n",
      "Train Log likelihood, step 170800 in nats: 0.087543\n",
      "Train epoch average loss: 0.08754726534356055\n",
      "\n",
      "\n",
      "Epoch: 1048\n",
      "Train Log likelihood, step 170850 in nats: 0.087550\n",
      "Train Log likelihood, step 170900 in nats: 0.087555\n",
      "Train Log likelihood, step 170950 in nats: 0.087566\n",
      "Train epoch average loss: 0.08757681834146797\n",
      "\n",
      "\n",
      "Epoch: 1049\n",
      "Train Log likelihood, step 171000 in nats: 0.087580\n",
      "Train Log likelihood, step 171050 in nats: 0.087589\n",
      "Train Log likelihood, step 171100 in nats: 0.087608\n",
      "Train epoch average loss: 0.08762451524352775\n",
      "\n",
      "\n",
      "Epoch: 1050\n",
      "Train Log likelihood, step 171150 in nats: 0.087626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 171200 in nats: 0.087637\n",
      "Train Log likelihood, step 171250 in nats: 0.087651\n",
      "Train Log likelihood, step 171300 in nats: 0.087660\n",
      "Train epoch average loss: 0.08766331518510607\n",
      "\n",
      "\n",
      "Epoch: 1051\n",
      "Train Log likelihood, step 171350 in nats: 0.087670\n",
      "Train Log likelihood, step 171400 in nats: 0.087680\n",
      "Train Log likelihood, step 171450 in nats: 0.087696\n",
      "Train epoch average loss: 0.0877080981843499\n",
      "\n",
      "\n",
      "Epoch: 1052\n",
      "Train Log likelihood, step 171500 in nats: 0.087720\n",
      "Train Log likelihood, step 171550 in nats: 0.087729\n",
      "Train Log likelihood, step 171600 in nats: 0.087732\n",
      "Train epoch average loss: 0.08773106905492141\n",
      "\n",
      "\n",
      "Epoch: 1053\n",
      "Train Log likelihood, step 171650 in nats: 0.087733\n",
      "Train Log likelihood, step 171700 in nats: 0.087735\n",
      "Train Log likelihood, step 171750 in nats: 0.087731\n",
      "Train Log likelihood, step 171800 in nats: 0.087737\n",
      "Train epoch average loss: 0.08773762754716068\n",
      "\n",
      "\n",
      "Epoch: 1054\n",
      "Train Log likelihood, step 171850 in nats: 0.087736\n",
      "Train Log likelihood, step 171900 in nats: 0.087742\n",
      "Train Log likelihood, step 171950 in nats: 0.087763\n",
      "Train epoch average loss: 0.08776638786912254\n",
      "\n",
      "\n",
      "Epoch: 1055\n",
      "Train Log likelihood, step 172000 in nats: 0.087781\n",
      "Train Log likelihood, step 172050 in nats: 0.087794\n",
      "Train Log likelihood, step 172100 in nats: 0.087811\n",
      "Train epoch average loss: 0.08781876736074415\n",
      "\n",
      "\n",
      "Epoch: 1056\n",
      "Train Log likelihood, step 172150 in nats: 0.087823\n",
      "Train Log likelihood, step 172200 in nats: 0.087830\n",
      "Train Log likelihood, step 172250 in nats: 0.087850\n",
      "Train epoch average loss: 0.08785709750952327\n",
      "\n",
      "\n",
      "Epoch: 1057\n",
      "Train Log likelihood, step 172300 in nats: 0.087862\n",
      "Train Log likelihood, step 172350 in nats: 0.087874\n",
      "Train Log likelihood, step 172400 in nats: 0.087890\n",
      "Train Log likelihood, step 172450 in nats: 0.087901\n",
      "Train epoch average loss: 0.08790319004864419\n",
      "\n",
      "\n",
      "Epoch: 1058\n",
      "Train Log likelihood, step 172500 in nats: 0.087915\n",
      "Train Log likelihood, step 172550 in nats: 0.087924\n",
      "Train Log likelihood, step 172600 in nats: 0.087941\n",
      "Train epoch average loss: 0.08794146350856644\n",
      "\n",
      "\n",
      "Epoch: 1059\n",
      "Train Log likelihood, step 172650 in nats: 0.087947\n",
      "Train Log likelihood, step 172700 in nats: 0.087962\n",
      "Train Log likelihood, step 172750 in nats: 0.087970\n",
      "Train epoch average loss: 0.08797512971266147\n",
      "\n",
      "\n",
      "Epoch: 1060\n",
      "Train Log likelihood, step 172800 in nats: 0.087981\n",
      "Train Log likelihood, step 172850 in nats: 0.087995\n",
      "Train Log likelihood, step 172900 in nats: 0.088006\n",
      "Train epoch average loss: 0.08801905801300199\n",
      "\n",
      "\n",
      "Epoch: 1061\n",
      "Train Log likelihood, step 172950 in nats: 0.088015\n",
      "Train Log likelihood, step 173000 in nats: 0.088030\n",
      "Train Log likelihood, step 173050 in nats: 0.088023\n",
      "Train Log likelihood, step 173100 in nats: 0.088029\n",
      "Train epoch average loss: 0.08802882383106626\n",
      "\n",
      "\n",
      "Epoch: 1062\n",
      "Train Log likelihood, step 173150 in nats: 0.088039\n",
      "Train Log likelihood, step 173200 in nats: 0.088055\n",
      "Train Log likelihood, step 173250 in nats: 0.088077\n",
      "Train epoch average loss: 0.08807937100902771\n",
      "\n",
      "\n",
      "Epoch: 1063\n",
      "Train Log likelihood, step 173300 in nats: 0.088084\n",
      "Train Log likelihood, step 173350 in nats: 0.088078\n",
      "Train Log likelihood, step 173400 in nats: 0.088081\n",
      "Train epoch average loss: 0.08808328391419046\n",
      "\n",
      "\n",
      "Epoch: 1064\n",
      "Train Log likelihood, step 173450 in nats: 0.088087\n",
      "Train Log likelihood, step 173500 in nats: 0.088097\n",
      "Train Log likelihood, step 173550 in nats: 0.088116\n",
      "Train epoch average loss: 0.08812335237869295\n",
      "\n",
      "\n",
      "Epoch: 1065\n",
      "Train Log likelihood, step 173600 in nats: 0.088125\n",
      "Train Log likelihood, step 173650 in nats: 0.088136\n",
      "Train Log likelihood, step 173700 in nats: 0.088151\n",
      "Train Log likelihood, step 173750 in nats: 0.088156\n",
      "Train epoch average loss: 0.08815686772590087\n",
      "\n",
      "\n",
      "Epoch: 1066\n",
      "Train Log likelihood, step 173800 in nats: 0.088167\n",
      "Train Log likelihood, step 173850 in nats: 0.088169\n",
      "Train Log likelihood, step 173900 in nats: 0.088167\n",
      "Train epoch average loss: 0.08816621638355228\n",
      "\n",
      "\n",
      "Epoch: 1067\n",
      "Train Log likelihood, step 173950 in nats: 0.088172\n",
      "Train Log likelihood, step 174000 in nats: 0.088188\n",
      "Train Log likelihood, step 174050 in nats: 0.088206\n",
      "Train epoch average loss: 0.08821453652787792\n",
      "\n",
      "\n",
      "Epoch: 1068\n",
      "Train Log likelihood, step 174100 in nats: 0.088210\n",
      "Train Log likelihood, step 174150 in nats: 0.088206\n",
      "Train Log likelihood, step 174200 in nats: 0.088221\n",
      "Train epoch average loss: 0.0882311950466802\n",
      "\n",
      "\n",
      "Epoch: 1069\n",
      "Train Log likelihood, step 174250 in nats: 0.088231\n",
      "Train Log likelihood, step 174300 in nats: 0.088248\n",
      "Train Log likelihood, step 174350 in nats: 0.088257\n",
      "Train Log likelihood, step 174400 in nats: 0.088270\n",
      "Train epoch average loss: 0.08826965847004815\n",
      "\n",
      "\n",
      "Epoch: 1070\n",
      "Train Log likelihood, step 174450 in nats: 0.088283\n",
      "Train Log likelihood, step 174500 in nats: 0.088294\n",
      "Train Log likelihood, step 174550 in nats: 0.088314\n",
      "Train epoch average loss: 0.08831857556555849\n",
      "\n",
      "\n",
      "Epoch: 1071\n",
      "Train Log likelihood, step 174600 in nats: 0.088316\n",
      "Train Log likelihood, step 174650 in nats: 0.088330\n",
      "Train Log likelihood, step 174700 in nats: 0.088344\n",
      "Train epoch average loss: 0.08834979469619353\n",
      "\n",
      "\n",
      "Epoch: 1072\n",
      "Train Log likelihood, step 174750 in nats: 0.088352\n",
      "Train Log likelihood, step 174800 in nats: 0.088365\n",
      "Train Log likelihood, step 174850 in nats: 0.088376\n",
      "Train epoch average loss: 0.08838801986336373\n",
      "\n",
      "\n",
      "Epoch: 1073\n",
      "Train Log likelihood, step 174900 in nats: 0.088389\n",
      "Train Log likelihood, step 174950 in nats: 0.088402\n",
      "Train Log likelihood, step 175000 in nats: 0.088413\n",
      "Train Log likelihood, step 175050 in nats: 0.088429\n",
      "Train epoch average loss: 0.08843139383318463\n",
      "\n",
      "\n",
      "Epoch: 1074\n",
      "Train Log likelihood, step 175100 in nats: 0.088432\n",
      "Train Log likelihood, step 175150 in nats: 0.088431\n",
      "Train Log likelihood, step 175200 in nats: 0.088436\n",
      "Train epoch average loss: 0.08844013801612598\n",
      "\n",
      "\n",
      "Epoch: 1075\n",
      "Train Log likelihood, step 175250 in nats: 0.088446\n",
      "Train Log likelihood, step 175300 in nats: 0.088444\n",
      "Train Log likelihood, step 175350 in nats: 0.088453\n",
      "Train epoch average loss: 0.08845946039761583\n",
      "\n",
      "\n",
      "Epoch: 1076\n",
      "Train Log likelihood, step 175400 in nats: 0.088461\n",
      "Train Log likelihood, step 175450 in nats: 0.088470\n",
      "Train Log likelihood, step 175500 in nats: 0.088483\n",
      "Train Log likelihood, step 175550 in nats: 0.088493\n",
      "Train epoch average loss: 0.0884930597669365\n",
      "\n",
      "\n",
      "Epoch: 1077\n",
      "Train Log likelihood, step 175600 in nats: 0.088504\n",
      "Train Log likelihood, step 175650 in nats: 0.088521\n",
      "Train Log likelihood, step 175700 in nats: 0.088531\n",
      "Train epoch average loss: 0.08853333189133561\n",
      "\n",
      "\n",
      "Epoch: 1078\n",
      "Train Log likelihood, step 175750 in nats: 0.088541\n",
      "Train Log likelihood, step 175800 in nats: 0.088542\n",
      "Train Log likelihood, step 175850 in nats: 0.088551\n",
      "Train epoch average loss: 0.08856064843613148\n",
      "\n",
      "\n",
      "Epoch: 1079\n",
      "Train Log likelihood, step 175900 in nats: 0.088561\n",
      "Train Log likelihood, step 175950 in nats: 0.088561\n",
      "Train Log likelihood, step 176000 in nats: 0.088566\n",
      "Train epoch average loss: 0.0885616880984114\n",
      "\n",
      "\n",
      "Epoch: 1080\n",
      "Train Log likelihood, step 176050 in nats: 0.088566\n",
      "Train Log likelihood, step 176100 in nats: 0.088583\n",
      "Train Log likelihood, step 176150 in nats: 0.088602\n",
      "Train Log likelihood, step 176200 in nats: 0.088612\n",
      "Train epoch average loss: 0.0886126033687319\n",
      "\n",
      "\n",
      "Epoch: 1081\n",
      "Train Log likelihood, step 176250 in nats: 0.088627\n",
      "Train Log likelihood, step 176300 in nats: 0.088633\n",
      "Train Log likelihood, step 176350 in nats: 0.088638\n",
      "Train epoch average loss: 0.08864055060940922\n",
      "\n",
      "\n",
      "Epoch: 1082\n",
      "Train Log likelihood, step 176400 in nats: 0.088648\n",
      "Train Log likelihood, step 176450 in nats: 0.088664\n",
      "Train Log likelihood, step 176500 in nats: 0.088677\n",
      "Train epoch average loss: 0.0886843090606865\n",
      "\n",
      "\n",
      "Epoch: 1083\n",
      "Train Log likelihood, step 176550 in nats: 0.088693\n",
      "Train Log likelihood, step 176600 in nats: 0.088701\n",
      "Train Log likelihood, step 176650 in nats: 0.088706\n",
      "Train epoch average loss: 0.08871780164860428\n",
      "\n",
      "\n",
      "Epoch: 1084\n",
      "Train Log likelihood, step 176700 in nats: 0.088719\n",
      "Train Log likelihood, step 176750 in nats: 0.088727\n",
      "Train Log likelihood, step 176800 in nats: 0.088731\n",
      "Train Log likelihood, step 176850 in nats: 0.088731\n",
      "Train epoch average loss: 0.08873042757959715\n",
      "\n",
      "\n",
      "Epoch: 1085\n",
      "Train Log likelihood, step 176900 in nats: 0.088747\n",
      "Train Log likelihood, step 176950 in nats: 0.088765\n",
      "Train Log likelihood, step 177000 in nats: 0.088780\n",
      "Train epoch average loss: 0.08877997214365087\n",
      "\n",
      "\n",
      "Epoch: 1086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 177050 in nats: 0.088783\n",
      "Train Log likelihood, step 177100 in nats: 0.088800\n",
      "Train Log likelihood, step 177150 in nats: 0.088814\n",
      "Train epoch average loss: 0.08881790753977668\n",
      "\n",
      "\n",
      "Epoch: 1087\n",
      "Train Log likelihood, step 177200 in nats: 0.088824\n",
      "Train Log likelihood, step 177250 in nats: 0.088831\n",
      "Train Log likelihood, step 177300 in nats: 0.088844\n",
      "Train epoch average loss: 0.08885622697098293\n",
      "\n",
      "\n",
      "Epoch: 1088\n",
      "Train Log likelihood, step 177350 in nats: 0.088857\n",
      "Train Log likelihood, step 177400 in nats: 0.088863\n",
      "Train Log likelihood, step 177450 in nats: 0.088871\n",
      "Train Log likelihood, step 177500 in nats: 0.088875\n",
      "Train epoch average loss: 0.08887564757556664\n",
      "\n",
      "\n",
      "Epoch: 1089\n",
      "Train Log likelihood, step 177550 in nats: 0.088878\n",
      "Train Log likelihood, step 177600 in nats: 0.088885\n",
      "Train Log likelihood, step 177650 in nats: 0.088893\n",
      "Train epoch average loss: 0.0888979090697896\n",
      "\n",
      "\n",
      "Epoch: 1090\n",
      "Train Log likelihood, step 177700 in nats: 0.088907\n",
      "Train Log likelihood, step 177750 in nats: 0.088904\n",
      "Train Log likelihood, step 177800 in nats: 0.088914\n",
      "Train epoch average loss: 0.08892114087687679\n",
      "\n",
      "\n",
      "Epoch: 1091\n",
      "Train Log likelihood, step 177850 in nats: 0.088925\n",
      "Train Log likelihood, step 177900 in nats: 0.088930\n",
      "Train Log likelihood, step 177950 in nats: 0.088932\n",
      "Train epoch average loss: 0.08892960300716335\n",
      "\n",
      "\n",
      "Epoch: 1092\n",
      "Train Log likelihood, step 178000 in nats: 0.088931\n",
      "Train Log likelihood, step 178050 in nats: 0.088940\n",
      "Train Log likelihood, step 178100 in nats: 0.088953\n",
      "Train Log likelihood, step 178150 in nats: 0.088960\n",
      "Train epoch average loss: 0.08896035524280242\n",
      "\n",
      "\n",
      "Epoch: 1093\n",
      "Train Log likelihood, step 178200 in nats: 0.088966\n",
      "Train Log likelihood, step 178250 in nats: 0.088978\n",
      "Train Log likelihood, step 178300 in nats: 0.088990\n",
      "Train epoch average loss: 0.08899460725818169\n",
      "\n",
      "\n",
      "Epoch: 1094\n",
      "Train Log likelihood, step 178350 in nats: 0.088998\n",
      "Train Log likelihood, step 178400 in nats: 0.089008\n",
      "Train Log likelihood, step 178450 in nats: 0.089020\n",
      "Train epoch average loss: 0.08902306020579441\n",
      "\n",
      "\n",
      "Epoch: 1095\n",
      "Train Log likelihood, step 178500 in nats: 0.089018\n",
      "Train Log likelihood, step 178550 in nats: 0.089019\n",
      "Train Log likelihood, step 178600 in nats: 0.089026\n",
      "Train epoch average loss: 0.08902749580810333\n",
      "\n",
      "\n",
      "Epoch: 1096\n",
      "Train Log likelihood, step 178650 in nats: 0.089028\n",
      "Train Log likelihood, step 178700 in nats: 0.089034\n",
      "Train Log likelihood, step 178750 in nats: 0.089041\n",
      "Train Log likelihood, step 178800 in nats: 0.089057\n",
      "Train epoch average loss: 0.0890591220196738\n",
      "\n",
      "\n",
      "Epoch: 1097\n",
      "Train Log likelihood, step 178850 in nats: 0.089068\n",
      "Train Log likelihood, step 178900 in nats: 0.089077\n",
      "Train Log likelihood, step 178950 in nats: 0.089083\n",
      "Train epoch average loss: 0.08909134538655145\n",
      "\n",
      "\n",
      "Epoch: 1098\n",
      "Train Log likelihood, step 179000 in nats: 0.089096\n",
      "Train Log likelihood, step 179050 in nats: 0.089106\n",
      "Train Log likelihood, step 179100 in nats: 0.089118\n",
      "Train epoch average loss: 0.08912389041140828\n",
      "\n",
      "\n",
      "Epoch: 1099\n",
      "Train Log likelihood, step 179150 in nats: 0.089126\n",
      "Train Log likelihood, step 179200 in nats: 0.089142\n",
      "Train Log likelihood, step 179250 in nats: 0.089153\n",
      "Train epoch average loss: 0.0891642692017348\n",
      "\n",
      "\n",
      "Epoch: 1100\n",
      "Train Log likelihood, step 179300 in nats: 0.089165\n",
      "Train Log likelihood, step 179350 in nats: 0.089172\n",
      "Train Log likelihood, step 179400 in nats: 0.089187\n",
      "Train Log likelihood, step 179450 in nats: 0.089203\n",
      "Train epoch average loss: 0.08920319562993825\n",
      "\n",
      "\n",
      "Epoch: 1101\n",
      "Train Log likelihood, step 179500 in nats: 0.089200\n",
      "Train Log likelihood, step 179550 in nats: 0.089198\n",
      "Train Log likelihood, step 179600 in nats: 0.089212\n",
      "Train epoch average loss: 0.08921526405909211\n",
      "\n",
      "\n",
      "Epoch: 1102\n",
      "Train Log likelihood, step 179650 in nats: 0.089222\n",
      "Train Log likelihood, step 179700 in nats: 0.089233\n",
      "Train Log likelihood, step 179750 in nats: 0.089249\n",
      "Train epoch average loss: 0.08925636847599124\n",
      "\n",
      "\n",
      "Epoch: 1103\n",
      "Train Log likelihood, step 179800 in nats: 0.089256\n",
      "Train Log likelihood, step 179850 in nats: 0.089269\n",
      "Train Log likelihood, step 179900 in nats: 0.089286\n",
      "Train Log likelihood, step 179950 in nats: 0.089298\n",
      "Train epoch average loss: 0.08929883887659548\n",
      "\n",
      "\n",
      "Epoch: 1104\n",
      "Train Log likelihood, step 180000 in nats: 0.089298\n",
      "Train Log likelihood, step 180050 in nats: 0.089313\n",
      "Train Log likelihood, step 180100 in nats: 0.089319\n",
      "Train epoch average loss: 0.08932379661711401\n",
      "\n",
      "\n",
      "Epoch: 1105\n",
      "Train Log likelihood, step 180150 in nats: 0.089326\n",
      "Train Log likelihood, step 180200 in nats: 0.089329\n",
      "Train Log likelihood, step 180250 in nats: 0.089338\n",
      "Train epoch average loss: 0.0893401455606514\n",
      "\n",
      "\n",
      "Epoch: 1106\n",
      "Train Log likelihood, step 180300 in nats: 0.089342\n",
      "Train Log likelihood, step 180350 in nats: 0.089345\n",
      "Train Log likelihood, step 180400 in nats: 0.089355\n",
      "Train epoch average loss: 0.08936283556647047\n",
      "\n",
      "\n",
      "Epoch: 1107\n",
      "Train Log likelihood, step 180450 in nats: 0.089362\n",
      "Train Log likelihood, step 180500 in nats: 0.089364\n",
      "Train Log likelihood, step 180550 in nats: 0.089381\n",
      "Train Log likelihood, step 180600 in nats: 0.089385\n",
      "Train epoch average loss: 0.08938676935796146\n",
      "\n",
      "\n",
      "Epoch: 1108\n",
      "Train Log likelihood, step 180650 in nats: 0.089404\n",
      "Train Log likelihood, step 180700 in nats: 0.089418\n",
      "Train Log likelihood, step 180750 in nats: 0.089427\n",
      "Train epoch average loss: 0.08943204333020188\n",
      "\n",
      "\n",
      "Epoch: 1109\n",
      "Train Log likelihood, step 180800 in nats: 0.089446\n",
      "Train Log likelihood, step 180850 in nats: 0.089445\n",
      "Train Log likelihood, step 180900 in nats: 0.089463\n",
      "Train epoch average loss: 0.0894748506462555\n",
      "\n",
      "\n",
      "Epoch: 1110\n",
      "Train Log likelihood, step 180950 in nats: 0.089480\n",
      "Train Log likelihood, step 181000 in nats: 0.089489\n",
      "Train Log likelihood, step 181050 in nats: 0.089493\n",
      "Train epoch average loss: 0.08950608318545361\n",
      "\n",
      "\n",
      "Epoch: 1111\n",
      "Train Log likelihood, step 181100 in nats: 0.089509\n",
      "Train Log likelihood, step 181150 in nats: 0.089514\n",
      "Train Log likelihood, step 181200 in nats: 0.089528\n",
      "Train Log likelihood, step 181250 in nats: 0.089542\n",
      "Train epoch average loss: 0.08954457534139608\n",
      "\n",
      "\n",
      "Epoch: 1112\n",
      "Train Log likelihood, step 181300 in nats: 0.089559\n",
      "Train Log likelihood, step 181350 in nats: 0.089554\n",
      "Train Log likelihood, step 181400 in nats: 0.089567\n",
      "Train epoch average loss: 0.08957140615136433\n",
      "\n",
      "\n",
      "Epoch: 1113\n",
      "Train Log likelihood, step 181450 in nats: 0.089575\n",
      "Train Log likelihood, step 181500 in nats: 0.089593\n",
      "Train Log likelihood, step 181550 in nats: 0.089605\n",
      "Train epoch average loss: 0.08960113236822422\n",
      "\n",
      "\n",
      "Epoch: 1114\n",
      "Train Log likelihood, step 181600 in nats: 0.089605\n",
      "Train Log likelihood, step 181650 in nats: 0.089612\n",
      "Train Log likelihood, step 181700 in nats: 0.089619\n",
      "Train epoch average loss: 0.08963104465940237\n",
      "\n",
      "\n",
      "Epoch: 1115\n",
      "Train Log likelihood, step 181750 in nats: 0.089633\n",
      "Train Log likelihood, step 181800 in nats: 0.089643\n",
      "Train Log likelihood, step 181850 in nats: 0.089651\n",
      "Train Log likelihood, step 181900 in nats: 0.089654\n",
      "Train epoch average loss: 0.0896541725618872\n",
      "\n",
      "\n",
      "Epoch: 1116\n",
      "Train Log likelihood, step 181950 in nats: 0.089660\n",
      "Train Log likelihood, step 182000 in nats: 0.089668\n",
      "Train Log likelihood, step 182050 in nats: 0.089671\n",
      "Train epoch average loss: 0.08967403301465524\n",
      "\n",
      "\n",
      "Epoch: 1117\n",
      "Train Log likelihood, step 182100 in nats: 0.089686\n",
      "Train Log likelihood, step 182150 in nats: 0.089691\n",
      "Train Log likelihood, step 182200 in nats: 0.089703\n",
      "Train epoch average loss: 0.08970692976119597\n",
      "\n",
      "\n",
      "Epoch: 1118\n",
      "Train Log likelihood, step 182250 in nats: 0.089711\n",
      "Train Log likelihood, step 182300 in nats: 0.089725\n",
      "Train Log likelihood, step 182350 in nats: 0.089735\n",
      "Train epoch average loss: 0.08973642568338036\n",
      "\n",
      "\n",
      "Epoch: 1119\n",
      "Train Log likelihood, step 182400 in nats: 0.089737\n",
      "Train Log likelihood, step 182450 in nats: 0.089755\n",
      "Train Log likelihood, step 182500 in nats: 0.089760\n",
      "Train Log likelihood, step 182550 in nats: 0.089774\n",
      "Train epoch average loss: 0.0897743639844866\n",
      "\n",
      "\n",
      "Epoch: 1120\n",
      "Train Log likelihood, step 182600 in nats: 0.089784\n",
      "Train Log likelihood, step 182650 in nats: 0.089784\n",
      "Train Log likelihood, step 182700 in nats: 0.089798\n",
      "Train epoch average loss: 0.08980340391335392\n",
      "\n",
      "\n",
      "Epoch: 1121\n",
      "Train Log likelihood, step 182750 in nats: 0.089803\n",
      "Train Log likelihood, step 182800 in nats: 0.089816\n",
      "Train Log likelihood, step 182850 in nats: 0.089828\n",
      "Train epoch average loss: 0.08983062081164814\n",
      "\n",
      "\n",
      "Epoch: 1122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 182900 in nats: 0.089833\n",
      "Train Log likelihood, step 182950 in nats: 0.089842\n",
      "Train Log likelihood, step 183000 in nats: 0.089848\n",
      "Train epoch average loss: 0.08985489678307085\n",
      "\n",
      "\n",
      "Epoch: 1123\n",
      "Train Log likelihood, step 183050 in nats: 0.089856\n",
      "Train Log likelihood, step 183100 in nats: 0.089852\n",
      "Train Log likelihood, step 183150 in nats: 0.089863\n",
      "Train Log likelihood, step 183200 in nats: 0.089862\n",
      "Train epoch average loss: 0.0898648688253781\n",
      "\n",
      "\n",
      "Epoch: 1124\n",
      "Train Log likelihood, step 183250 in nats: 0.089867\n",
      "Train Log likelihood, step 183300 in nats: 0.089879\n",
      "Train Log likelihood, step 183350 in nats: 0.089892\n",
      "Train epoch average loss: 0.08989851401710007\n",
      "\n",
      "\n",
      "Epoch: 1125\n",
      "Train Log likelihood, step 183400 in nats: 0.089904\n",
      "Train Log likelihood, step 183450 in nats: 0.089916\n",
      "Train Log likelihood, step 183500 in nats: 0.089927\n",
      "Train epoch average loss: 0.08994190285582161\n",
      "\n",
      "\n",
      "Epoch: 1126\n",
      "Train Log likelihood, step 183550 in nats: 0.089943\n",
      "Train Log likelihood, step 183600 in nats: 0.089965\n",
      "Train Log likelihood, step 183650 in nats: 0.089970\n",
      "Train Log likelihood, step 183700 in nats: 0.089973\n",
      "Train epoch average loss: 0.08997307195596878\n",
      "\n",
      "\n",
      "Epoch: 1127\n",
      "Train Log likelihood, step 183750 in nats: 0.089988\n",
      "Train Log likelihood, step 183800 in nats: 0.089993\n",
      "Train Log likelihood, step 183850 in nats: 0.090010\n",
      "Train epoch average loss: 0.09001798523887512\n",
      "\n",
      "\n",
      "Epoch: 1128\n",
      "Train Log likelihood, step 183900 in nats: 0.090026\n",
      "Train Log likelihood, step 183950 in nats: 0.090039\n",
      "Train Log likelihood, step 184000 in nats: 0.090049\n",
      "Train epoch average loss: 0.09005520554044684\n",
      "\n",
      "\n",
      "Epoch: 1129\n",
      "Train Log likelihood, step 184050 in nats: 0.090057\n",
      "Train Log likelihood, step 184100 in nats: 0.090070\n",
      "Train Log likelihood, step 184150 in nats: 0.090073\n",
      "Train epoch average loss: 0.09008689382428811\n",
      "\n",
      "\n",
      "Epoch: 1130\n",
      "Train Log likelihood, step 184200 in nats: 0.090091\n",
      "Train Log likelihood, step 184250 in nats: 0.090102\n",
      "Train Log likelihood, step 184300 in nats: 0.090111\n",
      "Train Log likelihood, step 184350 in nats: 0.090123\n",
      "Train epoch average loss: 0.09012362178384756\n",
      "\n",
      "\n",
      "Epoch: 1131\n",
      "Train Log likelihood, step 184400 in nats: 0.090131\n",
      "Train Log likelihood, step 184450 in nats: 0.090145\n",
      "Train Log likelihood, step 184500 in nats: 0.090150\n",
      "Train epoch average loss: 0.09015469051235091\n",
      "\n",
      "\n",
      "Epoch: 1132\n",
      "Train Log likelihood, step 184550 in nats: 0.090161\n",
      "Train Log likelihood, step 184600 in nats: 0.090158\n",
      "Train Log likelihood, step 184650 in nats: 0.090158\n",
      "Train epoch average loss: 0.0901646872979008\n",
      "\n",
      "\n",
      "Epoch: 1133\n",
      "Train Log likelihood, step 184700 in nats: 0.090168\n",
      "Train Log likelihood, step 184750 in nats: 0.090180\n",
      "Train Log likelihood, step 184800 in nats: 0.090190\n",
      "Train epoch average loss: 0.09020471430409581\n",
      "\n",
      "\n",
      "Epoch: 1134\n",
      "Train Log likelihood, step 184850 in nats: 0.090205\n",
      "Train Log likelihood, step 184900 in nats: 0.090227\n",
      "Train Log likelihood, step 184950 in nats: 0.090239\n",
      "Train Log likelihood, step 185000 in nats: 0.090246\n",
      "Train epoch average loss: 0.09024891945986581\n",
      "\n",
      "\n",
      "Epoch: 1135\n",
      "Train Log likelihood, step 185050 in nats: 0.090259\n",
      "Train Log likelihood, step 185100 in nats: 0.090270\n",
      "Train Log likelihood, step 185150 in nats: 0.090285\n",
      "Train epoch average loss: 0.0902852235294581\n",
      "\n",
      "\n",
      "Epoch: 1136\n",
      "Train Log likelihood, step 185200 in nats: 0.090287\n",
      "Train Log likelihood, step 185250 in nats: 0.090301\n",
      "Train Log likelihood, step 185300 in nats: 0.090305\n",
      "Train epoch average loss: 0.0903106358238349\n",
      "\n",
      "\n",
      "Epoch: 1137\n",
      "Train Log likelihood, step 185350 in nats: 0.090314\n",
      "Train Log likelihood, step 185400 in nats: 0.090329\n",
      "Train Log likelihood, step 185450 in nats: 0.090336\n",
      "Train epoch average loss: 0.09034180955008565\n",
      "\n",
      "\n",
      "Epoch: 1138\n",
      "Train Log likelihood, step 185500 in nats: 0.090340\n",
      "Train Log likelihood, step 185550 in nats: 0.090339\n",
      "Train Log likelihood, step 185600 in nats: 0.090340\n",
      "Train Log likelihood, step 185650 in nats: 0.090349\n",
      "Train epoch average loss: 0.09034941257662982\n",
      "\n",
      "\n",
      "Epoch: 1139\n",
      "Train Log likelihood, step 185700 in nats: 0.090352\n",
      "Train Log likelihood, step 185750 in nats: 0.090362\n",
      "Train Log likelihood, step 185800 in nats: 0.090366\n",
      "Train epoch average loss: 0.09037131329508585\n",
      "\n",
      "\n",
      "Epoch: 1140\n",
      "Train Log likelihood, step 185850 in nats: 0.090378\n",
      "Train Log likelihood, step 185900 in nats: 0.090381\n",
      "Train Log likelihood, step 185950 in nats: 0.090390\n",
      "Train epoch average loss: 0.09038996727655321\n",
      "\n",
      "\n",
      "Epoch: 1141\n",
      "Train Log likelihood, step 186000 in nats: 0.090398\n",
      "Train Log likelihood, step 186050 in nats: 0.090409\n",
      "Train Log likelihood, step 186100 in nats: 0.090424\n",
      "Train epoch average loss: 0.09042991203220614\n",
      "\n",
      "\n",
      "Epoch: 1142\n",
      "Train Log likelihood, step 186150 in nats: 0.090429\n",
      "Train Log likelihood, step 186200 in nats: 0.090435\n",
      "Train Log likelihood, step 186250 in nats: 0.090445\n",
      "Train Log likelihood, step 186300 in nats: 0.090458\n",
      "Train epoch average loss: 0.09045996239530106\n",
      "\n",
      "\n",
      "Epoch: 1143\n",
      "Train Log likelihood, step 186350 in nats: 0.090473\n",
      "Train Log likelihood, step 186400 in nats: 0.090478\n",
      "Train Log likelihood, step 186450 in nats: 0.090489\n",
      "Train epoch average loss: 0.09049301072111815\n",
      "\n",
      "\n",
      "Epoch: 1144\n",
      "Train Log likelihood, step 186500 in nats: 0.090499\n",
      "Train Log likelihood, step 186550 in nats: 0.090505\n",
      "Train Log likelihood, step 186600 in nats: 0.090512\n",
      "Train epoch average loss: 0.0905141606227863\n",
      "\n",
      "\n",
      "Epoch: 1145\n",
      "Train Log likelihood, step 186650 in nats: 0.090519\n",
      "Train Log likelihood, step 186700 in nats: 0.090522\n",
      "Train Log likelihood, step 186750 in nats: 0.090534\n",
      "Train epoch average loss: 0.0905471861967435\n",
      "\n",
      "\n",
      "Epoch: 1146\n",
      "Train Log likelihood, step 186800 in nats: 0.090548\n",
      "Train Log likelihood, step 186850 in nats: 0.090558\n",
      "Train Log likelihood, step 186900 in nats: 0.090578\n",
      "Train Log likelihood, step 186950 in nats: 0.090593\n",
      "Train epoch average loss: 0.09059661415350695\n",
      "\n",
      "\n",
      "Epoch: 1147\n",
      "Train Log likelihood, step 187000 in nats: 0.090600\n",
      "Train Log likelihood, step 187050 in nats: 0.090614\n",
      "Train Log likelihood, step 187100 in nats: 0.090623\n",
      "Train epoch average loss: 0.09062400331717357\n",
      "\n",
      "\n",
      "Epoch: 1148\n",
      "Train Log likelihood, step 187150 in nats: 0.090630\n",
      "Train Log likelihood, step 187200 in nats: 0.090644\n",
      "Train Log likelihood, step 187250 in nats: 0.090667\n",
      "Train epoch average loss: 0.09066934060373551\n",
      "\n",
      "\n",
      "Epoch: 1149\n",
      "Train Log likelihood, step 187300 in nats: 0.090674\n",
      "Train Log likelihood, step 187350 in nats: 0.090685\n",
      "Train Log likelihood, step 187400 in nats: 0.090705\n",
      "Train epoch average loss: 0.09071691056603805\n",
      "\n",
      "\n",
      "Epoch: 1150\n",
      "Train Log likelihood, step 187450 in nats: 0.090718\n",
      "Train Log likelihood, step 187500 in nats: 0.090730\n",
      "Train Log likelihood, step 187550 in nats: 0.090751\n",
      "Train Log likelihood, step 187600 in nats: 0.090766\n",
      "Train epoch average loss: 0.09077013211351602\n",
      "\n",
      "\n",
      "Epoch: 1151\n",
      "Train Log likelihood, step 187650 in nats: 0.090778\n",
      "Train Log likelihood, step 187700 in nats: 0.090793\n",
      "Train Log likelihood, step 187750 in nats: 0.090804\n",
      "Train epoch average loss: 0.09080472170093716\n",
      "\n",
      "\n",
      "Epoch: 1152\n",
      "Train Log likelihood, step 187800 in nats: 0.090803\n",
      "Train Log likelihood, step 187850 in nats: 0.090803\n",
      "Train Log likelihood, step 187900 in nats: 0.090815\n",
      "Train epoch average loss: 0.09082134263379847\n",
      "\n",
      "\n",
      "Epoch: 1153\n",
      "Train Log likelihood, step 187950 in nats: 0.090825\n",
      "Train Log likelihood, step 188000 in nats: 0.090832\n",
      "Train Log likelihood, step 188050 in nats: 0.090841\n",
      "Train Log likelihood, step 188100 in nats: 0.090858\n",
      "Train epoch average loss: 0.09085829585695007\n",
      "\n",
      "\n",
      "Epoch: 1154\n",
      "Train Log likelihood, step 188150 in nats: 0.090865\n",
      "Train Log likelihood, step 188200 in nats: 0.090868\n",
      "Train Log likelihood, step 188250 in nats: 0.090873\n",
      "Train epoch average loss: 0.09087833585492464\n",
      "\n",
      "\n",
      "Epoch: 1155\n",
      "Train Log likelihood, step 188300 in nats: 0.090897\n",
      "Train Log likelihood, step 188350 in nats: 0.090904\n",
      "Train Log likelihood, step 188400 in nats: 0.090914\n",
      "Train epoch average loss: 0.0909203304547654\n",
      "\n",
      "\n",
      "Epoch: 1156\n",
      "Train Log likelihood, step 188450 in nats: 0.090921\n",
      "Train Log likelihood, step 188500 in nats: 0.090939\n",
      "Train Log likelihood, step 188550 in nats: 0.090953\n",
      "Train epoch average loss: 0.09095881451281031\n",
      "\n",
      "\n",
      "Epoch: 1157\n",
      "Train Log likelihood, step 188600 in nats: 0.090959\n",
      "Train Log likelihood, step 188650 in nats: 0.090967\n",
      "Train Log likelihood, step 188700 in nats: 0.090979\n",
      "Train Log likelihood, step 188750 in nats: 0.090985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch average loss: 0.09098623330038988\n",
      "\n",
      "\n",
      "Epoch: 1158\n",
      "Train Log likelihood, step 188800 in nats: 0.090998\n",
      "Train Log likelihood, step 188850 in nats: 0.091002\n",
      "Train Log likelihood, step 188900 in nats: 0.091008\n",
      "Train epoch average loss: 0.09101114922024621\n",
      "\n",
      "\n",
      "Epoch: 1159\n",
      "Train Log likelihood, step 188950 in nats: 0.091019\n",
      "Train Log likelihood, step 189000 in nats: 0.091024\n",
      "Train Log likelihood, step 189050 in nats: 0.091033\n",
      "Train epoch average loss: 0.09103681441725728\n",
      "\n",
      "\n",
      "Epoch: 1160\n",
      "Train Log likelihood, step 189100 in nats: 0.091044\n",
      "Train Log likelihood, step 189150 in nats: 0.091059\n",
      "Train Log likelihood, step 189200 in nats: 0.091069\n",
      "Train epoch average loss: 0.09107831032464946\n",
      "\n",
      "\n",
      "Epoch: 1161\n",
      "Train Log likelihood, step 189250 in nats: 0.091079\n",
      "Train Log likelihood, step 189300 in nats: 0.091086\n",
      "Train Log likelihood, step 189350 in nats: 0.091086\n",
      "Train Log likelihood, step 189400 in nats: 0.091101\n",
      "Train epoch average loss: 0.09110408979001848\n",
      "\n",
      "\n",
      "Epoch: 1162\n",
      "Train Log likelihood, step 189450 in nats: 0.091097\n",
      "Train Log likelihood, step 189500 in nats: 0.091101\n",
      "Train Log likelihood, step 189550 in nats: 0.091101\n",
      "Train epoch average loss: 0.09110217301438352\n",
      "\n",
      "\n",
      "Epoch: 1163\n",
      "Train Log likelihood, step 189600 in nats: 0.091101\n",
      "Train Log likelihood, step 189650 in nats: 0.091106\n",
      "Train Log likelihood, step 189700 in nats: 0.091118\n",
      "Train epoch average loss: 0.09112505393876634\n",
      "\n",
      "\n",
      "Epoch: 1164\n",
      "Train Log likelihood, step 189750 in nats: 0.091132\n",
      "Train Log likelihood, step 189800 in nats: 0.091145\n",
      "Train Log likelihood, step 189850 in nats: 0.091158\n",
      "Train epoch average loss: 0.09116659340164138\n",
      "\n",
      "\n",
      "Epoch: 1165\n",
      "Train Log likelihood, step 189900 in nats: 0.091168\n",
      "Train Log likelihood, step 189950 in nats: 0.091182\n",
      "Train Log likelihood, step 190000 in nats: 0.091183\n",
      "Train Log likelihood, step 190050 in nats: 0.091192\n",
      "Train epoch average loss: 0.09119312227653195\n",
      "\n",
      "\n",
      "Epoch: 1166\n",
      "Train Log likelihood, step 190100 in nats: 0.091202\n",
      "Train Log likelihood, step 190150 in nats: 0.091215\n",
      "Train Log likelihood, step 190200 in nats: 0.091221\n",
      "Train epoch average loss: 0.09123111872606317\n",
      "\n",
      "\n",
      "Epoch: 1167\n",
      "Train Log likelihood, step 190250 in nats: 0.091228\n",
      "Train Log likelihood, step 190300 in nats: 0.091243\n",
      "Train Log likelihood, step 190350 in nats: 0.091254\n",
      "Train epoch average loss: 0.09126262391640148\n",
      "\n",
      "\n",
      "Epoch: 1168\n",
      "Train Log likelihood, step 190400 in nats: 0.091271\n",
      "Train Log likelihood, step 190450 in nats: 0.091282\n",
      "Train Log likelihood, step 190500 in nats: 0.091298\n",
      "Train epoch average loss: 0.09130608087263224\n",
      "\n",
      "\n",
      "Epoch: 1169\n",
      "Train Log likelihood, step 190550 in nats: 0.091308\n",
      "Train Log likelihood, step 190600 in nats: 0.091316\n",
      "Train Log likelihood, step 190650 in nats: 0.091329\n",
      "Train Log likelihood, step 190700 in nats: 0.091340\n",
      "Train epoch average loss: 0.09134044147349535\n",
      "\n",
      "\n",
      "Epoch: 1170\n",
      "Train Log likelihood, step 190750 in nats: 0.091355\n",
      "Train Log likelihood, step 190800 in nats: 0.091362\n",
      "Train Log likelihood, step 190850 in nats: 0.091371\n",
      "Train epoch average loss: 0.09138301253573833\n",
      "\n",
      "\n",
      "Epoch: 1171\n",
      "Train Log likelihood, step 190900 in nats: 0.091387\n",
      "Train Log likelihood, step 190950 in nats: 0.091398\n",
      "Train Log likelihood, step 191000 in nats: 0.091407\n",
      "Train epoch average loss: 0.09140933592079643\n",
      "\n",
      "\n",
      "Epoch: 1172\n",
      "Train Log likelihood, step 191050 in nats: 0.091411\n",
      "Train Log likelihood, step 191100 in nats: 0.091418\n",
      "Train Log likelihood, step 191150 in nats: 0.091426\n",
      "Train epoch average loss: 0.09142830787856042\n",
      "\n",
      "\n",
      "Epoch: 1173\n",
      "Train Log likelihood, step 191200 in nats: 0.091428\n",
      "Train Log likelihood, step 191250 in nats: 0.091435\n",
      "Train Log likelihood, step 191300 in nats: 0.091441\n",
      "Train Log likelihood, step 191350 in nats: 0.091441\n",
      "Train epoch average loss: 0.0914440724784261\n",
      "\n",
      "\n",
      "Epoch: 1174\n",
      "Train Log likelihood, step 191400 in nats: 0.091458\n",
      "Train Log likelihood, step 191450 in nats: 0.091474\n",
      "Train Log likelihood, step 191500 in nats: 0.091490\n",
      "Train epoch average loss: 0.09149427071815545\n",
      "\n",
      "\n",
      "Epoch: 1175\n",
      "Train Log likelihood, step 191550 in nats: 0.091498\n",
      "Train Log likelihood, step 191600 in nats: 0.091506\n",
      "Train Log likelihood, step 191650 in nats: 0.091518\n",
      "Train epoch average loss: 0.09152327231953926\n",
      "\n",
      "\n",
      "Epoch: 1176\n",
      "Train Log likelihood, step 191700 in nats: 0.091526\n",
      "Train Log likelihood, step 191750 in nats: 0.091535\n",
      "Train Log likelihood, step 191800 in nats: 0.091547\n",
      "Train Log likelihood, step 191850 in nats: 0.091550\n",
      "Train epoch average loss: 0.09155031125458538\n",
      "\n",
      "\n",
      "Epoch: 1177\n",
      "Train Log likelihood, step 191900 in nats: 0.091561\n",
      "Train Log likelihood, step 191950 in nats: 0.091571\n",
      "Train Log likelihood, step 192000 in nats: 0.091584\n",
      "Train epoch average loss: 0.09158417219241727\n",
      "\n",
      "\n",
      "Epoch: 1178\n",
      "Train Log likelihood, step 192050 in nats: 0.091591\n",
      "Train Log likelihood, step 192100 in nats: 0.091601\n",
      "Train Log likelihood, step 192150 in nats: 0.091601\n",
      "Train epoch average loss: 0.09160939015344619\n",
      "\n",
      "\n",
      "Epoch: 1179\n",
      "Train Log likelihood, step 192200 in nats: 0.091608\n",
      "Train Log likelihood, step 192250 in nats: 0.091614\n",
      "Train Log likelihood, step 192300 in nats: 0.091624\n",
      "Train epoch average loss: 0.09163122361943113\n",
      "\n",
      "\n",
      "Epoch: 1180\n",
      "Train Log likelihood, step 192350 in nats: 0.091637\n",
      "Train Log likelihood, step 192400 in nats: 0.091644\n",
      "Train Log likelihood, step 192450 in nats: 0.091653\n",
      "Train Log likelihood, step 192500 in nats: 0.091663\n",
      "Train epoch average loss: 0.09166399967482723\n",
      "\n",
      "\n",
      "Epoch: 1181\n",
      "Train Log likelihood, step 192550 in nats: 0.091679\n",
      "Train Log likelihood, step 192600 in nats: 0.091687\n",
      "Train Log likelihood, step 192650 in nats: 0.091702\n",
      "Train epoch average loss: 0.09170591003144066\n",
      "\n",
      "\n",
      "Epoch: 1182\n",
      "Train Log likelihood, step 192700 in nats: 0.091712\n",
      "Train Log likelihood, step 192750 in nats: 0.091721\n",
      "Train Log likelihood, step 192800 in nats: 0.091721\n",
      "Train epoch average loss: 0.09172965421639022\n",
      "\n",
      "\n",
      "Epoch: 1183\n",
      "Train Log likelihood, step 192850 in nats: 0.091738\n",
      "Train Log likelihood, step 192900 in nats: 0.091745\n",
      "Train Log likelihood, step 192950 in nats: 0.091755\n",
      "Train epoch average loss: 0.09176257797773674\n",
      "\n",
      "\n",
      "Epoch: 1184\n",
      "Train Log likelihood, step 193000 in nats: 0.091766\n",
      "Train Log likelihood, step 193050 in nats: 0.091776\n",
      "Train Log likelihood, step 193100 in nats: 0.091791\n",
      "Train Log likelihood, step 193150 in nats: 0.091810\n",
      "Train epoch average loss: 0.09181181503785343\n",
      "\n",
      "\n",
      "Epoch: 1185\n",
      "Train Log likelihood, step 193200 in nats: 0.091822\n",
      "Train Log likelihood, step 193250 in nats: 0.091834\n",
      "Train Log likelihood, step 193300 in nats: 0.091847\n",
      "Train epoch average loss: 0.09185367507505801\n",
      "\n",
      "\n",
      "Epoch: 1186\n",
      "Train Log likelihood, step 193350 in nats: 0.091859\n",
      "Train Log likelihood, step 193400 in nats: 0.091866\n",
      "Train Log likelihood, step 193450 in nats: 0.091868\n",
      "Train epoch average loss: 0.09187160387985356\n",
      "\n",
      "\n",
      "Epoch: 1187\n",
      "Train Log likelihood, step 193500 in nats: 0.091876\n",
      "Train Log likelihood, step 193550 in nats: 0.091878\n",
      "Train Log likelihood, step 193600 in nats: 0.091895\n",
      "Train epoch average loss: 0.09189857558440313\n",
      "\n",
      "\n",
      "Epoch: 1188\n",
      "Train Log likelihood, step 193650 in nats: 0.091899\n",
      "Train Log likelihood, step 193700 in nats: 0.091901\n",
      "Train Log likelihood, step 193750 in nats: 0.091922\n",
      "Train Log likelihood, step 193800 in nats: 0.091934\n",
      "Train epoch average loss: 0.09193644327552149\n",
      "\n",
      "\n",
      "Epoch: 1189\n",
      "Train Log likelihood, step 193850 in nats: 0.091944\n",
      "Train Log likelihood, step 193900 in nats: 0.091949\n",
      "Train Log likelihood, step 193950 in nats: 0.091952\n",
      "Train epoch average loss: 0.09195076178760009\n",
      "\n",
      "\n",
      "Epoch: 1190\n",
      "Train Log likelihood, step 194000 in nats: 0.091955\n",
      "Train Log likelihood, step 194050 in nats: 0.091962\n",
      "Train Log likelihood, step 194100 in nats: 0.091969\n",
      "Train epoch average loss: 0.09197852599328751\n",
      "\n",
      "\n",
      "Epoch: 1191\n",
      "Train Log likelihood, step 194150 in nats: 0.091990\n",
      "Train Log likelihood, step 194200 in nats: 0.092001\n",
      "Train Log likelihood, step 194250 in nats: 0.092010\n",
      "Train epoch average loss: 0.09201373169953432\n",
      "\n",
      "\n",
      "Epoch: 1192\n",
      "Train Log likelihood, step 194300 in nats: 0.092016\n",
      "Train Log likelihood, step 194350 in nats: 0.092029\n",
      "Train Log likelihood, step 194400 in nats: 0.092048\n",
      "Train Log likelihood, step 194450 in nats: 0.092063\n",
      "Train epoch average loss: 0.09206478128764017\n",
      "\n",
      "\n",
      "Epoch: 1193\n",
      "Train Log likelihood, step 194500 in nats: 0.092075\n",
      "Train Log likelihood, step 194550 in nats: 0.092083\n",
      "Train Log likelihood, step 194600 in nats: 0.092092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch average loss: 0.09209681591951913\n",
      "\n",
      "\n",
      "Epoch: 1194\n",
      "Train Log likelihood, step 194650 in nats: 0.092104\n",
      "Train Log likelihood, step 194700 in nats: 0.092114\n",
      "Train Log likelihood, step 194750 in nats: 0.092110\n",
      "Train epoch average loss: 0.09211896847790318\n",
      "\n",
      "\n",
      "Epoch: 1195\n",
      "Train Log likelihood, step 194800 in nats: 0.092122\n",
      "Train Log likelihood, step 194850 in nats: 0.092130\n",
      "Train Log likelihood, step 194900 in nats: 0.092136\n",
      "Train epoch average loss: 0.09213984254570519\n",
      "\n",
      "\n",
      "Epoch: 1196\n",
      "Train Log likelihood, step 194950 in nats: 0.092138\n",
      "Train Log likelihood, step 195000 in nats: 0.092145\n",
      "Train Log likelihood, step 195050 in nats: 0.092154\n",
      "Train Log likelihood, step 195100 in nats: 0.092165\n",
      "Train epoch average loss: 0.09216945570791195\n",
      "\n",
      "\n",
      "Epoch: 1197\n",
      "Train Log likelihood, step 195150 in nats: 0.092179\n",
      "Train Log likelihood, step 195200 in nats: 0.092184\n",
      "Train Log likelihood, step 195250 in nats: 0.092185\n",
      "Train epoch average loss: 0.09218855066130854\n",
      "\n",
      "\n",
      "Epoch: 1198\n",
      "Train Log likelihood, step 195300 in nats: 0.092196\n",
      "Train Log likelihood, step 195350 in nats: 0.092204\n",
      "Train Log likelihood, step 195400 in nats: 0.092211\n",
      "Train epoch average loss: 0.09221369914612682\n",
      "\n",
      "\n",
      "Epoch: 1199\n",
      "Train Log likelihood, step 195450 in nats: 0.092213\n",
      "Train Log likelihood, step 195500 in nats: 0.092214\n",
      "Train Log likelihood, step 195550 in nats: 0.092214\n",
      "Train epoch average loss: 0.09221331886836308\n",
      "\n",
      "\n",
      "Epoch: 1200\n",
      "Train Log likelihood, step 195600 in nats: 0.092212\n",
      "Train Log likelihood, step 195650 in nats: 0.092221\n",
      "Train Log likelihood, step 195700 in nats: 0.092220\n",
      "Train Log likelihood, step 195750 in nats: 0.092236\n",
      "Train epoch average loss: 0.09224096723654736\n",
      "\n",
      "\n",
      "Epoch: 1201\n",
      "Train Log likelihood, step 195800 in nats: 0.092250\n",
      "Train Log likelihood, step 195850 in nats: 0.092260\n",
      "Train Log likelihood, step 195900 in nats: 0.092268\n",
      "Train epoch average loss: 0.09226988714318746\n",
      "\n",
      "\n",
      "Epoch: 1202\n",
      "Train Log likelihood, step 195950 in nats: 0.092274\n",
      "Train Log likelihood, step 196000 in nats: 0.092285\n",
      "Train Log likelihood, step 196050 in nats: 0.092292\n",
      "Train epoch average loss: 0.09230605405757253\n",
      "\n",
      "\n",
      "Epoch: 1203\n",
      "Train Log likelihood, step 196100 in nats: 0.092309\n",
      "Train Log likelihood, step 196150 in nats: 0.092320\n",
      "Train Log likelihood, step 196200 in nats: 0.092333\n",
      "Train Log likelihood, step 196250 in nats: 0.092348\n",
      "Train epoch average loss: 0.09234831297343457\n",
      "\n",
      "\n",
      "Epoch: 1204\n",
      "Train Log likelihood, step 196300 in nats: 0.092355\n",
      "Train Log likelihood, step 196350 in nats: 0.092379\n",
      "Train Log likelihood, step 196400 in nats: 0.092390\n",
      "Train epoch average loss: 0.09239287131884116\n",
      "\n",
      "\n",
      "Epoch: 1205\n",
      "Train Log likelihood, step 196450 in nats: 0.092404\n",
      "Train Log likelihood, step 196500 in nats: 0.092412\n",
      "Train Log likelihood, step 196550 in nats: 0.092419\n",
      "Train epoch average loss: 0.09242913305320839\n",
      "\n",
      "\n",
      "Epoch: 1206\n",
      "Train Log likelihood, step 196600 in nats: 0.092436\n",
      "Train Log likelihood, step 196650 in nats: 0.092434\n",
      "Train Log likelihood, step 196700 in nats: 0.092430\n",
      "Train epoch average loss: 0.09243114934904581\n",
      "\n",
      "\n",
      "Epoch: 1207\n",
      "Train Log likelihood, step 196750 in nats: 0.092434\n",
      "Train Log likelihood, step 196800 in nats: 0.092438\n",
      "Train Log likelihood, step 196850 in nats: 0.092444\n",
      "Train Log likelihood, step 196900 in nats: 0.092455\n",
      "Train epoch average loss: 0.09245536345493183\n",
      "\n",
      "\n",
      "Epoch: 1208\n",
      "Train Log likelihood, step 196950 in nats: 0.092465\n",
      "Train Log likelihood, step 197000 in nats: 0.092478\n",
      "Train Log likelihood, step 197050 in nats: 0.092490\n",
      "Train epoch average loss: 0.09249453721384132\n",
      "\n",
      "\n",
      "Epoch: 1209\n",
      "Train Log likelihood, step 197100 in nats: 0.092499\n",
      "Train Log likelihood, step 197150 in nats: 0.092503\n",
      "Train Log likelihood, step 197200 in nats: 0.092507\n",
      "Train epoch average loss: 0.09250810862212712\n",
      "\n",
      "\n",
      "Epoch: 1210\n",
      "Train Log likelihood, step 197250 in nats: 0.092513\n",
      "Train Log likelihood, step 197300 in nats: 0.092522\n",
      "Train Log likelihood, step 197350 in nats: 0.092533\n",
      "Train epoch average loss: 0.09254256056324336\n",
      "\n",
      "\n",
      "Epoch: 1211\n",
      "Train Log likelihood, step 197400 in nats: 0.092545\n",
      "Train Log likelihood, step 197450 in nats: 0.092553\n",
      "Train Log likelihood, step 197500 in nats: 0.092563\n",
      "Train Log likelihood, step 197550 in nats: 0.092584\n",
      "Train epoch average loss: 0.09258422426060038\n",
      "\n",
      "\n",
      "Epoch: 1212\n",
      "Train Log likelihood, step 197600 in nats: 0.092594\n",
      "Train Log likelihood, step 197650 in nats: 0.092601\n",
      "Train Log likelihood, step 197700 in nats: 0.092618\n",
      "Train epoch average loss: 0.09261802329876632\n",
      "\n",
      "\n",
      "Epoch: 1213\n",
      "Train Log likelihood, step 197750 in nats: 0.092623\n",
      "Train Log likelihood, step 197800 in nats: 0.092640\n",
      "Train Log likelihood, step 197850 in nats: 0.092640\n",
      "Train epoch average loss: 0.09264726060228366\n",
      "\n",
      "\n",
      "Epoch: 1214\n",
      "Train Log likelihood, step 197900 in nats: 0.092652\n",
      "Train Log likelihood, step 197950 in nats: 0.092659\n",
      "Train Log likelihood, step 198000 in nats: 0.092673\n",
      "Train epoch average loss: 0.09267917761982379\n",
      "\n",
      "\n",
      "Epoch: 1215\n",
      "Train Log likelihood, step 198050 in nats: 0.092677\n",
      "Train Log likelihood, step 198100 in nats: 0.092685\n",
      "Train Log likelihood, step 198150 in nats: 0.092691\n",
      "Train Log likelihood, step 198200 in nats: 0.092700\n",
      "Train epoch average loss: 0.09270147469487346\n",
      "\n",
      "\n",
      "Epoch: 1216\n",
      "Train Log likelihood, step 198250 in nats: 0.092705\n",
      "Train Log likelihood, step 198300 in nats: 0.092706\n",
      "Train Log likelihood, step 198350 in nats: 0.092710\n",
      "Train epoch average loss: 0.09271591342327073\n",
      "\n",
      "\n",
      "Epoch: 1217\n",
      "Train Log likelihood, step 198400 in nats: 0.092720\n",
      "Train Log likelihood, step 198450 in nats: 0.092725\n",
      "Train Log likelihood, step 198500 in nats: 0.092736\n",
      "Train epoch average loss: 0.09274131268681375\n",
      "\n",
      "\n",
      "Epoch: 1218\n",
      "Train Log likelihood, step 198550 in nats: 0.092740\n",
      "Train Log likelihood, step 198600 in nats: 0.092752\n",
      "Train Log likelihood, step 198650 in nats: 0.092762\n",
      "Train epoch average loss: 0.09277588608852688\n",
      "\n",
      "\n",
      "Epoch: 1219\n",
      "Train Log likelihood, step 198700 in nats: 0.092776\n",
      "Train Log likelihood, step 198750 in nats: 0.092779\n",
      "Train Log likelihood, step 198800 in nats: 0.092789\n",
      "Train Log likelihood, step 198850 in nats: 0.092792\n",
      "Train epoch average loss: 0.09279297990787896\n",
      "\n",
      "\n",
      "Epoch: 1220\n",
      "Train Log likelihood, step 198900 in nats: 0.092797\n",
      "Train Log likelihood, step 198950 in nats: 0.092818\n",
      "Train Log likelihood, step 199000 in nats: 0.092826\n",
      "Train epoch average loss: 0.09282683447696324\n",
      "\n",
      "\n",
      "Epoch: 1221\n",
      "Train Log likelihood, step 199050 in nats: 0.092823\n",
      "Train Log likelihood, step 199100 in nats: 0.092819\n",
      "Train Log likelihood, step 199150 in nats: 0.092825\n",
      "Train epoch average loss: 0.09282860491209241\n",
      "\n",
      "\n",
      "Epoch: 1222\n",
      "Train Log likelihood, step 199200 in nats: 0.092834\n",
      "Train Log likelihood, step 199250 in nats: 0.092847\n",
      "Train Log likelihood, step 199300 in nats: 0.092851\n",
      "Train epoch average loss: 0.092857954743994\n",
      "\n",
      "\n",
      "Epoch: 1223\n",
      "Train Log likelihood, step 199350 in nats: 0.092858\n",
      "Train Log likelihood, step 199400 in nats: 0.092869\n",
      "Train Log likelihood, step 199450 in nats: 0.092870\n",
      "Train Log likelihood, step 199500 in nats: 0.092877\n",
      "Train epoch average loss: 0.0928768730722149\n",
      "\n",
      "\n",
      "Epoch: 1224\n",
      "Train Log likelihood, step 199550 in nats: 0.092894\n",
      "Train Log likelihood, step 199600 in nats: 0.092894\n",
      "Train Log likelihood, step 199650 in nats: 0.092901\n",
      "Train epoch average loss: 0.0929081826306624\n",
      "\n",
      "\n",
      "Epoch: 1225\n",
      "Train Log likelihood, step 199700 in nats: 0.092913\n",
      "Train Log likelihood, step 199750 in nats: 0.092919\n",
      "Train Log likelihood, step 199800 in nats: 0.092925\n",
      "Train epoch average loss: 0.09293274661839157\n",
      "\n",
      "\n",
      "Epoch: 1226\n",
      "Train Log likelihood, step 199850 in nats: 0.092933\n",
      "Train Log likelihood, step 199900 in nats: 0.092941\n",
      "Train Log likelihood, step 199950 in nats: 0.092947\n",
      "Train Log likelihood, step 200000 in nats: 0.092960\n",
      "Train epoch average loss: 0.09295954510035126\n",
      "\n",
      "\n",
      "Epoch: 1227\n",
      "Train Log likelihood, step 200050 in nats: 0.092968\n",
      "Train Log likelihood, step 200100 in nats: 0.092982\n",
      "Train Log likelihood, step 200150 in nats: 0.092988\n",
      "Train epoch average loss: 0.09298894956249702\n",
      "\n",
      "\n",
      "Epoch: 1228\n",
      "Train Log likelihood, step 200200 in nats: 0.092992\n",
      "Train Log likelihood, step 200250 in nats: 0.093002\n",
      "Train Log likelihood, step 200300 in nats: 0.093017\n",
      "Train epoch average loss: 0.09302485034625309\n",
      "\n",
      "\n",
      "Epoch: 1229\n",
      "Train Log likelihood, step 200350 in nats: 0.093034\n",
      "Train Log likelihood, step 200400 in nats: 0.093055\n",
      "Train Log likelihood, step 200450 in nats: 0.093066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch average loss: 0.09307606127629674\n",
      "\n",
      "\n",
      "Epoch: 1230\n",
      "Train Log likelihood, step 200500 in nats: 0.093076\n",
      "Train Log likelihood, step 200550 in nats: 0.093086\n",
      "Train Log likelihood, step 200600 in nats: 0.093096\n",
      "Train Log likelihood, step 200650 in nats: 0.093106\n",
      "Train epoch average loss: 0.09310596915519169\n",
      "\n",
      "\n",
      "Epoch: 1231\n",
      "Train Log likelihood, step 200700 in nats: 0.093120\n",
      "Train Log likelihood, step 200750 in nats: 0.093123\n",
      "Train Log likelihood, step 200800 in nats: 0.093126\n",
      "Train epoch average loss: 0.09312755281432795\n",
      "\n",
      "\n",
      "Epoch: 1232\n",
      "Train Log likelihood, step 200850 in nats: 0.093140\n",
      "Train Log likelihood, step 200900 in nats: 0.093156\n",
      "Train Log likelihood, step 200950 in nats: 0.093167\n",
      "Train epoch average loss: 0.09317188065897782\n",
      "\n",
      "\n",
      "Epoch: 1233\n",
      "Train Log likelihood, step 201000 in nats: 0.093177\n",
      "Train Log likelihood, step 201050 in nats: 0.093189\n",
      "Train Log likelihood, step 201100 in nats: 0.093199\n",
      "Train epoch average loss: 0.09321272066701641\n",
      "\n",
      "\n",
      "Epoch: 1234\n",
      "Train Log likelihood, step 201150 in nats: 0.093213\n",
      "Train Log likelihood, step 201200 in nats: 0.093229\n",
      "Train Log likelihood, step 201250 in nats: 0.093240\n",
      "Train Log likelihood, step 201300 in nats: 0.093242\n",
      "Train epoch average loss: 0.09324133421772304\n",
      "\n",
      "\n",
      "Epoch: 1235\n",
      "Train Log likelihood, step 201350 in nats: 0.093249\n",
      "Train Log likelihood, step 201400 in nats: 0.093252\n",
      "Train Log likelihood, step 201450 in nats: 0.093254\n",
      "Train epoch average loss: 0.0932576331420357\n",
      "\n",
      "\n",
      "Epoch: 1236\n",
      "Train Log likelihood, step 201500 in nats: 0.093264\n",
      "Train Log likelihood, step 201550 in nats: 0.093278\n",
      "Train Log likelihood, step 201600 in nats: 0.093283\n",
      "Train epoch average loss: 0.09328510451809606\n",
      "\n",
      "\n",
      "Epoch: 1237\n",
      "Train Log likelihood, step 201650 in nats: 0.093284\n",
      "Train Log likelihood, step 201700 in nats: 0.093294\n",
      "Train Log likelihood, step 201750 in nats: 0.093309\n",
      "Train epoch average loss: 0.09331025180034735\n",
      "\n",
      "\n",
      "Epoch: 1238\n",
      "Train Log likelihood, step 201800 in nats: 0.093307\n",
      "Train Log likelihood, step 201850 in nats: 0.093318\n",
      "Train Log likelihood, step 201900 in nats: 0.093321\n",
      "Train Log likelihood, step 201950 in nats: 0.093330\n",
      "Train epoch average loss: 0.09332819812411437\n",
      "\n",
      "\n",
      "Epoch: 1239\n",
      "Train Log likelihood, step 202000 in nats: 0.093337\n",
      "Train Log likelihood, step 202050 in nats: 0.093334\n",
      "Train Log likelihood, step 202100 in nats: 0.093340\n",
      "Train epoch average loss: 0.09333596553824489\n",
      "\n",
      "\n",
      "Epoch: 1240\n",
      "Train Log likelihood, step 202150 in nats: 0.093343\n",
      "Train Log likelihood, step 202200 in nats: 0.093352\n",
      "Train Log likelihood, step 202250 in nats: 0.093363\n",
      "Train epoch average loss: 0.09336798867304393\n",
      "\n",
      "\n",
      "Epoch: 1241\n",
      "Train Log likelihood, step 202300 in nats: 0.093367\n",
      "Train Log likelihood, step 202350 in nats: 0.093377\n",
      "Train Log likelihood, step 202400 in nats: 0.093388\n",
      "Train epoch average loss: 0.09339122833973981\n",
      "\n",
      "\n",
      "Epoch: 1242\n",
      "Train Log likelihood, step 202450 in nats: 0.093392\n",
      "Train Log likelihood, step 202500 in nats: 0.093408\n",
      "Train Log likelihood, step 202550 in nats: 0.093420\n",
      "Train Log likelihood, step 202600 in nats: 0.093428\n",
      "Train epoch average loss: 0.09342837588016596\n",
      "\n",
      "\n",
      "Epoch: 1243\n",
      "Train Log likelihood, step 202650 in nats: 0.093433\n",
      "Train Log likelihood, step 202700 in nats: 0.093445\n",
      "Train Log likelihood, step 202750 in nats: 0.093453\n",
      "Train epoch average loss: 0.09344836945769773\n",
      "\n",
      "\n",
      "Epoch: 1244\n",
      "Train Log likelihood, step 202800 in nats: 0.093452\n",
      "Train Log likelihood, step 202850 in nats: 0.093458\n",
      "Train Log likelihood, step 202900 in nats: 0.093456\n",
      "Train epoch average loss: 0.09346310781946714\n",
      "\n",
      "\n",
      "Epoch: 1245\n",
      "Train Log likelihood, step 202950 in nats: 0.093468\n",
      "Train Log likelihood, step 203000 in nats: 0.093481\n",
      "Train Log likelihood, step 203050 in nats: 0.093492\n",
      "Train epoch average loss: 0.0934972818942999\n",
      "\n",
      "\n",
      "Epoch: 1246\n",
      "Train Log likelihood, step 203100 in nats: 0.093499\n",
      "Train Log likelihood, step 203150 in nats: 0.093517\n",
      "Train Log likelihood, step 203200 in nats: 0.093522\n",
      "Train Log likelihood, step 203250 in nats: 0.093539\n",
      "Train epoch average loss: 0.09354066562427797\n",
      "\n",
      "\n",
      "Epoch: 1247\n",
      "Train Log likelihood, step 203300 in nats: 0.093547\n",
      "Train Log likelihood, step 203350 in nats: 0.093554\n",
      "Train Log likelihood, step 203400 in nats: 0.093562\n",
      "Train epoch average loss: 0.09356493722296587\n",
      "\n",
      "\n",
      "Epoch: 1248\n",
      "Train Log likelihood, step 203450 in nats: 0.093565\n",
      "Train Log likelihood, step 203500 in nats: 0.093575\n",
      "Train Log likelihood, step 203550 in nats: 0.093584\n",
      "Train epoch average loss: 0.09358414210644625\n",
      "\n",
      "\n",
      "Epoch: 1249\n",
      "Train Log likelihood, step 203600 in nats: 0.093585\n",
      "Train Log likelihood, step 203650 in nats: 0.093596\n",
      "Train Log likelihood, step 203700 in nats: 0.093603\n",
      "Train epoch average loss: 0.09361215728732288\n",
      "\n",
      "\n",
      "Epoch: 1250\n",
      "Train Log likelihood, step 203750 in nats: 0.093612\n",
      "Train Log likelihood, step 203800 in nats: 0.093620\n",
      "Train Log likelihood, step 203850 in nats: 0.093631\n",
      "Train Log likelihood, step 203900 in nats: 0.093638\n",
      "Train epoch average loss: 0.09364430311494312\n",
      "\n",
      "\n",
      "Epoch: 1251\n",
      "Train Log likelihood, step 203950 in nats: 0.093649\n",
      "Train Log likelihood, step 204000 in nats: 0.093655\n",
      "Train Log likelihood, step 204050 in nats: 0.093659\n",
      "Train epoch average loss: 0.09366834923450496\n",
      "\n",
      "\n",
      "Epoch: 1252\n",
      "Train Log likelihood, step 204100 in nats: 0.093672\n",
      "Train Log likelihood, step 204150 in nats: 0.093689\n",
      "Train Log likelihood, step 204200 in nats: 0.093698\n",
      "Train epoch average loss: 0.09370465960080808\n",
      "\n",
      "\n",
      "Epoch: 1253\n",
      "Train Log likelihood, step 204250 in nats: 0.093708\n",
      "Train Log likelihood, step 204300 in nats: 0.093713\n",
      "Train Log likelihood, step 204350 in nats: 0.093729\n",
      "Train Log likelihood, step 204400 in nats: 0.093737\n",
      "Train epoch average loss: 0.09373728841628447\n",
      "\n",
      "\n",
      "Epoch: 1254\n",
      "Train Log likelihood, step 204450 in nats: 0.093742\n",
      "Train Log likelihood, step 204500 in nats: 0.093743\n",
      "Train Log likelihood, step 204550 in nats: 0.093745\n",
      "Train epoch average loss: 0.09374787794735427\n",
      "\n",
      "\n",
      "Epoch: 1255\n",
      "Train Log likelihood, step 204600 in nats: 0.093755\n",
      "Train Log likelihood, step 204650 in nats: 0.093764\n",
      "Train Log likelihood, step 204700 in nats: 0.093777\n",
      "Train epoch average loss: 0.09378371009277651\n",
      "\n",
      "\n",
      "Epoch: 1256\n",
      "Train Log likelihood, step 204750 in nats: 0.093796\n",
      "Train Log likelihood, step 204800 in nats: 0.093812\n",
      "Train Log likelihood, step 204850 in nats: 0.093825\n",
      "Train epoch average loss: 0.0938276946719631\n",
      "\n",
      "\n",
      "Epoch: 1257\n",
      "Train Log likelihood, step 204900 in nats: 0.093832\n",
      "Train Log likelihood, step 204950 in nats: 0.093834\n",
      "Train Log likelihood, step 205000 in nats: 0.093848\n",
      "Train Log likelihood, step 205050 in nats: 0.093854\n",
      "Train epoch average loss: 0.09385342665783888\n",
      "\n",
      "\n",
      "Epoch: 1258\n",
      "Train Log likelihood, step 205100 in nats: 0.093862\n",
      "Train Log likelihood, step 205150 in nats: 0.093874\n",
      "Train Log likelihood, step 205200 in nats: 0.093891\n",
      "Train epoch average loss: 0.0938924120861598\n",
      "\n",
      "\n",
      "Epoch: 1259\n",
      "Train Log likelihood, step 205250 in nats: 0.093883\n",
      "Train Log likelihood, step 205300 in nats: 0.093888\n",
      "Train Log likelihood, step 205350 in nats: 0.093900\n",
      "Train epoch average loss: 0.09390441000432793\n",
      "\n",
      "\n",
      "Epoch: 1260\n",
      "Train Log likelihood, step 205400 in nats: 0.093908\n",
      "Train Log likelihood, step 205450 in nats: 0.093914\n",
      "Train Log likelihood, step 205500 in nats: 0.093918\n",
      "Train epoch average loss: 0.0939195574661028\n",
      "\n",
      "\n",
      "Epoch: 1261\n",
      "Train Log likelihood, step 205550 in nats: 0.093921\n",
      "Train Log likelihood, step 205600 in nats: 0.093924\n",
      "Train Log likelihood, step 205650 in nats: 0.093937\n",
      "Train Log likelihood, step 205700 in nats: 0.093952\n",
      "Train epoch average loss: 0.09395481660845635\n",
      "\n",
      "\n",
      "Epoch: 1262\n",
      "Train Log likelihood, step 205750 in nats: 0.093962\n",
      "Train Log likelihood, step 205800 in nats: 0.093969\n",
      "Train Log likelihood, step 205850 in nats: 0.093975\n",
      "Train epoch average loss: 0.09397601093620205\n",
      "\n",
      "\n",
      "Epoch: 1263\n",
      "Train Log likelihood, step 205900 in nats: 0.093976\n",
      "Train Log likelihood, step 205950 in nats: 0.093988\n",
      "Train Log likelihood, step 206000 in nats: 0.093992\n",
      "Train epoch average loss: 0.09399935900014487\n",
      "\n",
      "\n",
      "Epoch: 1264\n",
      "Train Log likelihood, step 206050 in nats: 0.094002\n",
      "Train Log likelihood, step 206100 in nats: 0.094006\n",
      "Train Log likelihood, step 206150 in nats: 0.094014\n",
      "Train epoch average loss: 0.09401883426215969\n",
      "\n",
      "\n",
      "Epoch: 1265\n",
      "Train Log likelihood, step 206200 in nats: 0.094019\n",
      "Train Log likelihood, step 206250 in nats: 0.094022\n",
      "Train Log likelihood, step 206300 in nats: 0.094028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 206350 in nats: 0.094034\n",
      "Train epoch average loss: 0.0940302162872806\n",
      "\n",
      "\n",
      "Epoch: 1266\n",
      "Train Log likelihood, step 206400 in nats: 0.094038\n",
      "Train Log likelihood, step 206450 in nats: 0.094048\n",
      "Train Log likelihood, step 206500 in nats: 0.094057\n",
      "Train epoch average loss: 0.09406411399810723\n",
      "\n",
      "\n",
      "Epoch: 1267\n",
      "Train Log likelihood, step 206550 in nats: 0.094073\n",
      "Train Log likelihood, step 206600 in nats: 0.094072\n",
      "Train Log likelihood, step 206650 in nats: 0.094087\n",
      "Train epoch average loss: 0.09409593604217387\n",
      "\n",
      "\n",
      "Epoch: 1268\n",
      "Train Log likelihood, step 206700 in nats: 0.094097\n",
      "Train Log likelihood, step 206750 in nats: 0.094107\n",
      "Train Log likelihood, step 206800 in nats: 0.094112\n",
      "Train epoch average loss: 0.09412265780288794\n",
      "\n",
      "\n",
      "Epoch: 1269\n",
      "Train Log likelihood, step 206850 in nats: 0.094124\n",
      "Train Log likelihood, step 206900 in nats: 0.094134\n",
      "Train Log likelihood, step 206950 in nats: 0.094144\n",
      "Train Log likelihood, step 207000 in nats: 0.094149\n",
      "Train epoch average loss: 0.09415314549815763\n",
      "\n",
      "\n",
      "Epoch: 1270\n",
      "Train Log likelihood, step 207050 in nats: 0.094161\n",
      "Train Log likelihood, step 207100 in nats: 0.094175\n",
      "Train Log likelihood, step 207150 in nats: 0.094189\n",
      "Train epoch average loss: 0.09419516364863241\n",
      "\n",
      "\n",
      "Epoch: 1271\n",
      "Train Log likelihood, step 207200 in nats: 0.094206\n",
      "Train Log likelihood, step 207250 in nats: 0.094221\n",
      "Train Log likelihood, step 207300 in nats: 0.094225\n",
      "Train epoch average loss: 0.09424181317746197\n",
      "\n",
      "\n",
      "Epoch: 1272\n",
      "Train Log likelihood, step 207350 in nats: 0.094244\n",
      "Train Log likelihood, step 207400 in nats: 0.094249\n",
      "Train Log likelihood, step 207450 in nats: 0.094264\n",
      "Train epoch average loss: 0.0942740496548826\n",
      "\n",
      "\n",
      "Epoch: 1273\n",
      "Train Log likelihood, step 207500 in nats: 0.094275\n",
      "Train Log likelihood, step 207550 in nats: 0.094278\n",
      "Train Log likelihood, step 207600 in nats: 0.094288\n",
      "Train Log likelihood, step 207650 in nats: 0.094299\n",
      "Train epoch average loss: 0.09429918493666233\n",
      "\n",
      "\n",
      "Epoch: 1274\n",
      "Train Log likelihood, step 207700 in nats: 0.094303\n",
      "Train Log likelihood, step 207750 in nats: 0.094316\n",
      "Train Log likelihood, step 207800 in nats: 0.094328\n",
      "Train epoch average loss: 0.09433059073370381\n",
      "\n",
      "\n",
      "Epoch: 1275\n",
      "Train Log likelihood, step 207850 in nats: 0.094336\n",
      "Train Log likelihood, step 207900 in nats: 0.094349\n",
      "Train Log likelihood, step 207950 in nats: 0.094355\n",
      "Train epoch average loss: 0.09435940208901111\n",
      "\n",
      "\n",
      "Epoch: 1276\n",
      "Train Log likelihood, step 208000 in nats: 0.094362\n",
      "Train Log likelihood, step 208050 in nats: 0.094369\n",
      "Train Log likelihood, step 208100 in nats: 0.094372\n",
      "Train Log likelihood, step 208150 in nats: 0.094380\n",
      "Train epoch average loss: 0.09438033964630851\n",
      "\n",
      "\n",
      "Epoch: 1277\n",
      "Train Log likelihood, step 208200 in nats: 0.094387\n",
      "Train Log likelihood, step 208250 in nats: 0.094392\n",
      "Train Log likelihood, step 208300 in nats: 0.094393\n",
      "Train epoch average loss: 0.09439412156410136\n",
      "\n",
      "\n",
      "Epoch: 1278\n",
      "Train Log likelihood, step 208350 in nats: 0.094399\n",
      "Train Log likelihood, step 208400 in nats: 0.094411\n",
      "Train Log likelihood, step 208450 in nats: 0.094416\n",
      "Train epoch average loss: 0.09442045778114949\n",
      "\n",
      "\n",
      "Epoch: 1279\n",
      "Train Log likelihood, step 208500 in nats: 0.094428\n",
      "Train Log likelihood, step 208550 in nats: 0.094430\n",
      "Train Log likelihood, step 208600 in nats: 0.094434\n",
      "Train epoch average loss: 0.0944336176550631\n",
      "\n",
      "\n",
      "Epoch: 1280\n",
      "Train Log likelihood, step 208650 in nats: 0.094435\n",
      "Train Log likelihood, step 208700 in nats: 0.094447\n",
      "Train Log likelihood, step 208750 in nats: 0.094460\n",
      "Train Log likelihood, step 208800 in nats: 0.094474\n",
      "Train epoch average loss: 0.09447197912545063\n",
      "\n",
      "\n",
      "Epoch: 1281\n",
      "Train Log likelihood, step 208850 in nats: 0.094474\n",
      "Train Log likelihood, step 208900 in nats: 0.094469\n",
      "Train Log likelihood, step 208950 in nats: 0.094472\n",
      "Train epoch average loss: 0.0944732034422302\n",
      "\n",
      "\n",
      "Epoch: 1282\n",
      "Train Log likelihood, step 209000 in nats: 0.094477\n",
      "Train Log likelihood, step 209050 in nats: 0.094485\n",
      "Train Log likelihood, step 209100 in nats: 0.094487\n",
      "Train epoch average loss: 0.094491707582975\n",
      "\n",
      "\n",
      "Epoch: 1283\n",
      "Train Log likelihood, step 209150 in nats: 0.094497\n",
      "Train Log likelihood, step 209200 in nats: 0.094500\n",
      "Train Log likelihood, step 209250 in nats: 0.094510\n",
      "Train epoch average loss: 0.09451927247005659\n",
      "\n",
      "\n",
      "Epoch: 1284\n",
      "Train Log likelihood, step 209300 in nats: 0.094519\n",
      "Train Log likelihood, step 209350 in nats: 0.094527\n",
      "Train Log likelihood, step 209400 in nats: 0.094541\n",
      "Train Log likelihood, step 209450 in nats: 0.094543\n",
      "Train epoch average loss: 0.09454459003082612\n",
      "\n",
      "\n",
      "Epoch: 1285\n",
      "Train Log likelihood, step 209500 in nats: 0.094549\n",
      "Train Log likelihood, step 209550 in nats: 0.094556\n",
      "Train Log likelihood, step 209600 in nats: 0.094562\n",
      "Train epoch average loss: 0.09456886066155235\n",
      "\n",
      "\n",
      "Epoch: 1286\n",
      "Train Log likelihood, step 209650 in nats: 0.094573\n",
      "Train Log likelihood, step 209700 in nats: 0.094578\n",
      "Train Log likelihood, step 209750 in nats: 0.094587\n",
      "Train epoch average loss: 0.09458953426052259\n",
      "\n",
      "\n",
      "Epoch: 1287\n",
      "Train Log likelihood, step 209800 in nats: 0.094593\n",
      "Train Log likelihood, step 209850 in nats: 0.094591\n",
      "Train Log likelihood, step 209900 in nats: 0.094595\n",
      "Train epoch average loss: 0.09460168013694444\n",
      "\n",
      "\n",
      "Epoch: 1288\n",
      "Train Log likelihood, step 209950 in nats: 0.094600\n",
      "Train Log likelihood, step 210000 in nats: 0.094606\n",
      "Train Log likelihood, step 210050 in nats: 0.094613\n",
      "Train Log likelihood, step 210100 in nats: 0.094620\n",
      "Train epoch average loss: 0.09461969708664295\n",
      "\n",
      "\n",
      "Epoch: 1289\n",
      "Train Log likelihood, step 210150 in nats: 0.094616\n",
      "Train Log likelihood, step 210200 in nats: 0.094617\n",
      "Train Log likelihood, step 210250 in nats: 0.094619\n",
      "Train epoch average loss: 0.09462456630923488\n",
      "\n",
      "\n",
      "Epoch: 1290\n",
      "Train Log likelihood, step 210300 in nats: 0.094635\n",
      "Train Log likelihood, step 210350 in nats: 0.094643\n",
      "Train Log likelihood, step 210400 in nats: 0.094650\n",
      "Train epoch average loss: 0.09464927256228918\n",
      "\n",
      "\n",
      "Epoch: 1291\n",
      "Train Log likelihood, step 210450 in nats: 0.094652\n",
      "Train Log likelihood, step 210500 in nats: 0.094657\n",
      "Train Log likelihood, step 210550 in nats: 0.094661\n",
      "Train epoch average loss: 0.09467139717374302\n",
      "\n",
      "\n",
      "Epoch: 1292\n",
      "Train Log likelihood, step 210600 in nats: 0.094671\n",
      "Train Log likelihood, step 210650 in nats: 0.094681\n",
      "Train Log likelihood, step 210700 in nats: 0.094698\n",
      "Train Log likelihood, step 210750 in nats: 0.094701\n",
      "Train epoch average loss: 0.09470067765162128\n",
      "\n",
      "\n",
      "Epoch: 1293\n",
      "Train Log likelihood, step 210800 in nats: 0.094705\n",
      "Train Log likelihood, step 210850 in nats: 0.094714\n",
      "Train Log likelihood, step 210900 in nats: 0.094718\n",
      "Train epoch average loss: 0.09472466898527014\n",
      "\n",
      "\n",
      "Epoch: 1294\n",
      "Train Log likelihood, step 210950 in nats: 0.094732\n",
      "Train Log likelihood, step 211000 in nats: 0.094737\n",
      "Train Log likelihood, step 211050 in nats: 0.094749\n",
      "Train epoch average loss: 0.09475744422575226\n",
      "\n",
      "\n",
      "Epoch: 1295\n",
      "Train Log likelihood, step 211100 in nats: 0.094757\n",
      "Train Log likelihood, step 211150 in nats: 0.094765\n",
      "Train Log likelihood, step 211200 in nats: 0.094774\n",
      "Train epoch average loss: 0.09478770207658352\n",
      "\n",
      "\n",
      "Epoch: 1296\n",
      "Train Log likelihood, step 211250 in nats: 0.094790\n",
      "Train Log likelihood, step 211300 in nats: 0.094805\n",
      "Train Log likelihood, step 211350 in nats: 0.094817\n",
      "Train Log likelihood, step 211400 in nats: 0.094825\n",
      "Train epoch average loss: 0.09482782554540233\n",
      "\n",
      "\n",
      "Epoch: 1297\n",
      "Train Log likelihood, step 211450 in nats: 0.094830\n",
      "Train Log likelihood, step 211500 in nats: 0.094838\n",
      "Train Log likelihood, step 211550 in nats: 0.094847\n",
      "Train epoch average loss: 0.0948499458223375\n",
      "\n",
      "\n",
      "Epoch: 1298\n",
      "Train Log likelihood, step 211600 in nats: 0.094853\n",
      "Train Log likelihood, step 211650 in nats: 0.094860\n",
      "Train Log likelihood, step 211700 in nats: 0.094876\n",
      "Train epoch average loss: 0.09488586366321994\n",
      "\n",
      "\n",
      "Epoch: 1299\n",
      "Train Log likelihood, step 211750 in nats: 0.094889\n",
      "Train Log likelihood, step 211800 in nats: 0.094893\n",
      "Train Log likelihood, step 211850 in nats: 0.094900\n",
      "Train epoch average loss: 0.09490375663640506\n",
      "\n",
      "\n",
      "Epoch: 1300\n",
      "Train Log likelihood, step 211900 in nats: 0.094903\n",
      "Train Log likelihood, step 211950 in nats: 0.094910\n",
      "Train Log likelihood, step 212000 in nats: 0.094917\n",
      "Train Log likelihood, step 212050 in nats: 0.094925\n",
      "Train epoch average loss: 0.09492695394771215\n",
      "\n",
      "\n",
      "Epoch: 1301\n",
      "Train Log likelihood, step 212100 in nats: 0.094937\n",
      "Train Log likelihood, step 212150 in nats: 0.094945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 212200 in nats: 0.094957\n",
      "Train epoch average loss: 0.09496394311668208\n",
      "\n",
      "\n",
      "Epoch: 1302\n",
      "Train Log likelihood, step 212250 in nats: 0.094973\n",
      "Train Log likelihood, step 212300 in nats: 0.094980\n",
      "Train Log likelihood, step 212350 in nats: 0.094986\n",
      "Train epoch average loss: 0.09498867858835042\n",
      "\n",
      "\n",
      "Epoch: 1303\n",
      "Train Log likelihood, step 212400 in nats: 0.094991\n",
      "Train Log likelihood, step 212450 in nats: 0.094999\n",
      "Train Log likelihood, step 212500 in nats: 0.095014\n",
      "Train Log likelihood, step 212550 in nats: 0.095023\n",
      "Train epoch average loss: 0.09502252624883806\n",
      "\n",
      "\n",
      "Epoch: 1304\n",
      "Train Log likelihood, step 212600 in nats: 0.095029\n",
      "Train Log likelihood, step 212650 in nats: 0.095028\n",
      "Train Log likelihood, step 212700 in nats: 0.095035\n",
      "Train epoch average loss: 0.09503677761902404\n",
      "\n",
      "\n",
      "Epoch: 1305\n",
      "Train Log likelihood, step 212750 in nats: 0.095044\n",
      "Train Log likelihood, step 212800 in nats: 0.095054\n",
      "Train Log likelihood, step 212850 in nats: 0.095062\n",
      "Train epoch average loss: 0.09506959288616026\n",
      "\n",
      "\n",
      "Epoch: 1306\n",
      "Train Log likelihood, step 212900 in nats: 0.095069\n",
      "Train Log likelihood, step 212950 in nats: 0.095073\n",
      "Train Log likelihood, step 213000 in nats: 0.095075\n",
      "Train epoch average loss: 0.0950831365671647\n",
      "\n",
      "\n",
      "Epoch: 1307\n",
      "Train Log likelihood, step 213050 in nats: 0.095086\n",
      "Train Log likelihood, step 213100 in nats: 0.095094\n",
      "Train Log likelihood, step 213150 in nats: 0.095102\n",
      "Train Log likelihood, step 213200 in nats: 0.095113\n",
      "Train epoch average loss: 0.09511246407999864\n",
      "\n",
      "\n",
      "Epoch: 1308\n",
      "Train Log likelihood, step 213250 in nats: 0.095124\n",
      "Train Log likelihood, step 213300 in nats: 0.095128\n",
      "Train Log likelihood, step 213350 in nats: 0.095129\n",
      "Train epoch average loss: 0.09512625389731824\n",
      "\n",
      "\n",
      "Epoch: 1309\n",
      "Train Log likelihood, step 213400 in nats: 0.095129\n",
      "Train Log likelihood, step 213450 in nats: 0.095134\n",
      "Train Log likelihood, step 213500 in nats: 0.095141\n",
      "Train epoch average loss: 0.09514360513964595\n",
      "\n",
      "\n",
      "Epoch: 1310\n",
      "Train Log likelihood, step 213550 in nats: 0.095149\n",
      "Train Log likelihood, step 213600 in nats: 0.095160\n",
      "Train Log likelihood, step 213650 in nats: 0.095172\n",
      "Train epoch average loss: 0.09518690728802445\n",
      "\n",
      "\n",
      "Epoch: 1311\n",
      "Train Log likelihood, step 213700 in nats: 0.095191\n",
      "Train Log likelihood, step 213750 in nats: 0.095199\n",
      "Train Log likelihood, step 213800 in nats: 0.095198\n",
      "Train Log likelihood, step 213850 in nats: 0.095201\n",
      "Train epoch average loss: 0.09520106184611528\n",
      "\n",
      "\n",
      "Epoch: 1312\n",
      "Train Log likelihood, step 213900 in nats: 0.095203\n",
      "Train Log likelihood, step 213950 in nats: 0.095209\n",
      "Train Log likelihood, step 214000 in nats: 0.095213\n",
      "Train epoch average loss: 0.09521433638056545\n",
      "\n",
      "\n",
      "Epoch: 1313\n",
      "Train Log likelihood, step 214050 in nats: 0.095217\n",
      "Train Log likelihood, step 214100 in nats: 0.095228\n",
      "Train Log likelihood, step 214150 in nats: 0.095233\n",
      "Train epoch average loss: 0.09523493343196342\n",
      "\n",
      "\n",
      "Epoch: 1314\n",
      "Train Log likelihood, step 214200 in nats: 0.095235\n",
      "Train Log likelihood, step 214250 in nats: 0.095247\n",
      "Train Log likelihood, step 214300 in nats: 0.095253\n",
      "Train epoch average loss: 0.0952577655193774\n",
      "\n",
      "\n",
      "Epoch: 1315\n",
      "Train Log likelihood, step 214350 in nats: 0.095259\n",
      "Train Log likelihood, step 214400 in nats: 0.095267\n",
      "Train Log likelihood, step 214450 in nats: 0.095270\n",
      "Train Log likelihood, step 214500 in nats: 0.095272\n",
      "Train epoch average loss: 0.09527248051908536\n",
      "\n",
      "\n",
      "Epoch: 1316\n",
      "Train Log likelihood, step 214550 in nats: 0.095272\n",
      "Train Log likelihood, step 214600 in nats: 0.095285\n",
      "Train Log likelihood, step 214650 in nats: 0.095289\n",
      "Train epoch average loss: 0.0952959652088557\n",
      "\n",
      "\n",
      "Epoch: 1317\n",
      "Train Log likelihood, step 214700 in nats: 0.095299\n",
      "Train Log likelihood, step 214750 in nats: 0.095312\n",
      "Train Log likelihood, step 214800 in nats: 0.095322\n",
      "Train epoch average loss: 0.09532447929098599\n",
      "\n",
      "\n",
      "Epoch: 1318\n",
      "Train Log likelihood, step 214850 in nats: 0.095327\n",
      "Train Log likelihood, step 214900 in nats: 0.095334\n",
      "Train Log likelihood, step 214950 in nats: 0.095338\n",
      "Train epoch average loss: 0.09534839839966953\n",
      "\n",
      "\n",
      "Epoch: 1319\n",
      "Train Log likelihood, step 215000 in nats: 0.095348\n",
      "Train Log likelihood, step 215050 in nats: 0.095357\n",
      "Train Log likelihood, step 215100 in nats: 0.095368\n",
      "Train Log likelihood, step 215150 in nats: 0.095375\n",
      "Train epoch average loss: 0.09537859923157853\n",
      "\n",
      "\n",
      "Epoch: 1320\n",
      "Train Log likelihood, step 215200 in nats: 0.095389\n",
      "Train Log likelihood, step 215250 in nats: 0.095389\n",
      "Train Log likelihood, step 215300 in nats: 0.095393\n",
      "Train epoch average loss: 0.09539735137455002\n",
      "\n",
      "\n",
      "Epoch: 1321\n",
      "Train Log likelihood, step 215350 in nats: 0.095399\n",
      "Train Log likelihood, step 215400 in nats: 0.095408\n",
      "Train Log likelihood, step 215450 in nats: 0.095415\n",
      "Train epoch average loss: 0.0954252926017692\n",
      "\n",
      "\n",
      "Epoch: 1322\n",
      "Train Log likelihood, step 215500 in nats: 0.095427\n",
      "Train Log likelihood, step 215550 in nats: 0.095438\n",
      "Train Log likelihood, step 215600 in nats: 0.095451\n",
      "Train epoch average loss: 0.09545379135306581\n",
      "\n",
      "\n",
      "Epoch: 1323\n",
      "Train Log likelihood, step 215650 in nats: 0.095454\n",
      "Train Log likelihood, step 215700 in nats: 0.095470\n",
      "Train Log likelihood, step 215750 in nats: 0.095482\n",
      "Train Log likelihood, step 215800 in nats: 0.095489\n",
      "Train epoch average loss: 0.09548935897873714\n",
      "\n",
      "\n",
      "Epoch: 1324\n",
      "Train Log likelihood, step 215850 in nats: 0.095490\n",
      "Train Log likelihood, step 215900 in nats: 0.095504\n",
      "Train Log likelihood, step 215950 in nats: 0.095511\n",
      "Train epoch average loss: 0.09551758601878894\n",
      "\n",
      "\n",
      "Epoch: 1325\n",
      "Train Log likelihood, step 216000 in nats: 0.095525\n",
      "Train Log likelihood, step 216050 in nats: 0.095534\n",
      "Train Log likelihood, step 216100 in nats: 0.095543\n",
      "Train epoch average loss: 0.09555010344300792\n",
      "\n",
      "\n",
      "Epoch: 1326\n",
      "Train Log likelihood, step 216150 in nats: 0.095554\n",
      "Train Log likelihood, step 216200 in nats: 0.095567\n",
      "Train Log likelihood, step 216250 in nats: 0.095576\n",
      "Train Log likelihood, step 216300 in nats: 0.095583\n",
      "Train epoch average loss: 0.09558265414140714\n",
      "\n",
      "\n",
      "Epoch: 1327\n",
      "Train Log likelihood, step 216350 in nats: 0.095583\n",
      "Train Log likelihood, step 216400 in nats: 0.095591\n",
      "Train Log likelihood, step 216450 in nats: 0.095604\n",
      "Train epoch average loss: 0.0956051041073404\n",
      "\n",
      "\n",
      "Epoch: 1328\n",
      "Train Log likelihood, step 216500 in nats: 0.095613\n",
      "Train Log likelihood, step 216550 in nats: 0.095622\n",
      "Train Log likelihood, step 216600 in nats: 0.095624\n",
      "Train epoch average loss: 0.09562845489696721\n",
      "\n",
      "\n",
      "Epoch: 1329\n",
      "Train Log likelihood, step 216650 in nats: 0.095633\n",
      "Train Log likelihood, step 216700 in nats: 0.095641\n",
      "Train Log likelihood, step 216750 in nats: 0.095647\n",
      "Train epoch average loss: 0.09564977895720268\n",
      "\n",
      "\n",
      "Epoch: 1330\n",
      "Train Log likelihood, step 216800 in nats: 0.095652\n",
      "Train Log likelihood, step 216850 in nats: 0.095661\n",
      "Train Log likelihood, step 216900 in nats: 0.095665\n",
      "Train Log likelihood, step 216950 in nats: 0.095667\n",
      "Train epoch average loss: 0.09566695676322426\n",
      "\n",
      "\n",
      "Epoch: 1331\n",
      "Train Log likelihood, step 217000 in nats: 0.095677\n",
      "Train Log likelihood, step 217050 in nats: 0.095685\n",
      "Train Log likelihood, step 217100 in nats: 0.095693\n",
      "Train epoch average loss: 0.09569828225087405\n",
      "\n",
      "\n",
      "Epoch: 1332\n",
      "Train Log likelihood, step 217150 in nats: 0.095700\n",
      "Train Log likelihood, step 217200 in nats: 0.095718\n",
      "Train Log likelihood, step 217250 in nats: 0.095723\n",
      "Train epoch average loss: 0.09573185203608396\n",
      "\n",
      "\n",
      "Epoch: 1333\n",
      "Train Log likelihood, step 217300 in nats: 0.095741\n",
      "Train Log likelihood, step 217350 in nats: 0.095750\n",
      "Train Log likelihood, step 217400 in nats: 0.095763\n",
      "Train epoch average loss: 0.09576832799204764\n",
      "\n",
      "\n",
      "Epoch: 1334\n",
      "Train Log likelihood, step 217450 in nats: 0.095769\n",
      "Train Log likelihood, step 217500 in nats: 0.095778\n",
      "Train Log likelihood, step 217550 in nats: 0.095792\n",
      "Train Log likelihood, step 217600 in nats: 0.095810\n",
      "Train epoch average loss: 0.09581104601060098\n",
      "\n",
      "\n",
      "Epoch: 1335\n",
      "Train Log likelihood, step 217650 in nats: 0.095810\n",
      "Train Log likelihood, step 217700 in nats: 0.095811\n",
      "Train Log likelihood, step 217750 in nats: 0.095815\n",
      "Train epoch average loss: 0.09581988093627944\n",
      "\n",
      "\n",
      "Epoch: 1336\n",
      "Train Log likelihood, step 217800 in nats: 0.095822\n",
      "Train Log likelihood, step 217850 in nats: 0.095830\n",
      "Train Log likelihood, step 217900 in nats: 0.095838\n",
      "Train epoch average loss: 0.09583842139476305\n",
      "\n",
      "\n",
      "Epoch: 1337\n",
      "Train Log likelihood, step 217950 in nats: 0.095839\n",
      "Train Log likelihood, step 218000 in nats: 0.095853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 218050 in nats: 0.095863\n",
      "Train epoch average loss: 0.09586640704574054\n",
      "\n",
      "\n",
      "Epoch: 1338\n",
      "Train Log likelihood, step 218100 in nats: 0.095868\n",
      "Train Log likelihood, step 218150 in nats: 0.095876\n",
      "Train Log likelihood, step 218200 in nats: 0.095884\n",
      "Train Log likelihood, step 218250 in nats: 0.095889\n",
      "Train epoch average loss: 0.09589078208566457\n",
      "\n",
      "\n",
      "Epoch: 1339\n",
      "Train Log likelihood, step 218300 in nats: 0.095898\n",
      "Train Log likelihood, step 218350 in nats: 0.095908\n",
      "Train Log likelihood, step 218400 in nats: 0.095914\n",
      "Train epoch average loss: 0.0959182752263615\n",
      "\n",
      "\n",
      "Epoch: 1340\n",
      "Train Log likelihood, step 218450 in nats: 0.095927\n",
      "Train Log likelihood, step 218500 in nats: 0.095942\n",
      "Train Log likelihood, step 218550 in nats: 0.095944\n",
      "Train epoch average loss: 0.09594902636631604\n",
      "\n",
      "\n",
      "Epoch: 1341\n",
      "Train Log likelihood, step 218600 in nats: 0.095952\n",
      "Train Log likelihood, step 218650 in nats: 0.095957\n",
      "Train Log likelihood, step 218700 in nats: 0.095961\n",
      "Train epoch average loss: 0.09596977712728377\n",
      "\n",
      "\n",
      "Epoch: 1342\n",
      "Train Log likelihood, step 218750 in nats: 0.095973\n",
      "Train Log likelihood, step 218800 in nats: 0.095988\n",
      "Train Log likelihood, step 218850 in nats: 0.096006\n",
      "Train Log likelihood, step 218900 in nats: 0.096014\n",
      "Train epoch average loss: 0.09601343575716192\n",
      "\n",
      "\n",
      "Epoch: 1343\n",
      "Train Log likelihood, step 218950 in nats: 0.096022\n",
      "Train Log likelihood, step 219000 in nats: 0.096033\n",
      "Train Log likelihood, step 219050 in nats: 0.096037\n",
      "Train epoch average loss: 0.09603491129605546\n",
      "\n",
      "\n",
      "Epoch: 1344\n",
      "Train Log likelihood, step 219100 in nats: 0.096034\n",
      "Train Log likelihood, step 219150 in nats: 0.096040\n",
      "Train Log likelihood, step 219200 in nats: 0.096048\n",
      "Train epoch average loss: 0.09605769444561743\n",
      "\n",
      "\n",
      "Epoch: 1345\n",
      "Train Log likelihood, step 219250 in nats: 0.096058\n",
      "Train Log likelihood, step 219300 in nats: 0.096067\n",
      "Train Log likelihood, step 219350 in nats: 0.096077\n",
      "Train epoch average loss: 0.09608555799801997\n",
      "\n",
      "\n",
      "Epoch: 1346\n",
      "Train Log likelihood, step 219400 in nats: 0.096087\n",
      "Train Log likelihood, step 219450 in nats: 0.096090\n",
      "Train Log likelihood, step 219500 in nats: 0.096103\n",
      "Train Log likelihood, step 219550 in nats: 0.096121\n",
      "Train epoch average loss: 0.09612320470992979\n",
      "\n",
      "\n",
      "Epoch: 1347\n",
      "Train Log likelihood, step 219600 in nats: 0.096127\n",
      "Train Log likelihood, step 219650 in nats: 0.096139\n",
      "Train Log likelihood, step 219700 in nats: 0.096142\n",
      "Train epoch average loss: 0.09614513981761126\n",
      "\n",
      "\n",
      "Epoch: 1348\n",
      "Train Log likelihood, step 219750 in nats: 0.096150\n",
      "Train Log likelihood, step 219800 in nats: 0.096154\n",
      "Train Log likelihood, step 219850 in nats: 0.096170\n",
      "Train epoch average loss: 0.09617402919307425\n",
      "\n",
      "\n",
      "Epoch: 1349\n",
      "Train Log likelihood, step 219900 in nats: 0.096176\n",
      "Train Log likelihood, step 219950 in nats: 0.096188\n",
      "Train Log likelihood, step 220000 in nats: 0.096195\n",
      "Train epoch average loss: 0.09620702586374026\n",
      "\n",
      "\n",
      "Epoch: 1350\n",
      "Train Log likelihood, step 220050 in nats: 0.096208\n",
      "Train Log likelihood, step 220100 in nats: 0.096207\n",
      "Train Log likelihood, step 220150 in nats: 0.096217\n",
      "Train Log likelihood, step 220200 in nats: 0.096219\n",
      "Train epoch average loss: 0.09622142937107088\n",
      "\n",
      "\n",
      "Epoch: 1351\n",
      "Train Log likelihood, step 220250 in nats: 0.096230\n",
      "Train Log likelihood, step 220300 in nats: 0.096243\n",
      "Train Log likelihood, step 220350 in nats: 0.096246\n",
      "Train epoch average loss: 0.09624746231194926\n",
      "\n",
      "\n",
      "Epoch: 1352\n",
      "Train Log likelihood, step 220400 in nats: 0.096243\n",
      "Train Log likelihood, step 220450 in nats: 0.096249\n",
      "Train Log likelihood, step 220500 in nats: 0.096259\n",
      "Train epoch average loss: 0.09627333103330372\n",
      "\n",
      "\n",
      "Epoch: 1353\n",
      "Train Log likelihood, step 220550 in nats: 0.096281\n",
      "Train Log likelihood, step 220600 in nats: 0.096290\n",
      "Train Log likelihood, step 220650 in nats: 0.096297\n",
      "Train Log likelihood, step 220700 in nats: 0.096306\n",
      "Train epoch average loss: 0.09630633689613241\n",
      "\n",
      "\n",
      "Epoch: 1354\n",
      "Train Log likelihood, step 220750 in nats: 0.096311\n",
      "Train Log likelihood, step 220800 in nats: 0.096314\n",
      "Train Log likelihood, step 220850 in nats: 0.096316\n",
      "Train epoch average loss: 0.09631801176940838\n",
      "\n",
      "\n",
      "Epoch: 1355\n",
      "Train Log likelihood, step 220900 in nats: 0.096326\n",
      "Train Log likelihood, step 220950 in nats: 0.096333\n",
      "Train Log likelihood, step 221000 in nats: 0.096347\n",
      "Train epoch average loss: 0.09635049767978637\n",
      "\n",
      "\n",
      "Epoch: 1356\n",
      "Train Log likelihood, step 221050 in nats: 0.096352\n",
      "Train Log likelihood, step 221100 in nats: 0.096368\n",
      "Train Log likelihood, step 221150 in nats: 0.096376\n",
      "Train epoch average loss: 0.0963791052575344\n",
      "\n",
      "\n",
      "Epoch: 1357\n",
      "Train Log likelihood, step 221200 in nats: 0.096382\n",
      "Train Log likelihood, step 221250 in nats: 0.096400\n",
      "Train Log likelihood, step 221300 in nats: 0.096405\n",
      "Train Log likelihood, step 221350 in nats: 0.096411\n",
      "Train epoch average loss: 0.09640952970368265\n",
      "\n",
      "\n",
      "Epoch: 1358\n",
      "Train Log likelihood, step 221400 in nats: 0.096416\n",
      "Train Log likelihood, step 221450 in nats: 0.096422\n",
      "Train Log likelihood, step 221500 in nats: 0.096430\n",
      "Train epoch average loss: 0.09643348243089103\n",
      "\n",
      "\n",
      "Epoch: 1359\n",
      "Train Log likelihood, step 221550 in nats: 0.096441\n",
      "Train Log likelihood, step 221600 in nats: 0.096455\n",
      "Train Log likelihood, step 221650 in nats: 0.096466\n",
      "Train epoch average loss: 0.09647220247523752\n",
      "\n",
      "\n",
      "Epoch: 1360\n",
      "Train Log likelihood, step 221700 in nats: 0.096477\n",
      "Train Log likelihood, step 221750 in nats: 0.096478\n",
      "Train Log likelihood, step 221800 in nats: 0.096488\n",
      "Train epoch average loss: 0.09649212085677085\n",
      "\n",
      "\n",
      "Epoch: 1361\n",
      "Train Log likelihood, step 221850 in nats: 0.096494\n",
      "Train Log likelihood, step 221900 in nats: 0.096495\n",
      "Train Log likelihood, step 221950 in nats: 0.096500\n",
      "Train Log likelihood, step 222000 in nats: 0.096492\n",
      "Train epoch average loss: 0.09649282408594768\n",
      "\n",
      "\n",
      "Epoch: 1362\n",
      "Train Log likelihood, step 222050 in nats: 0.096495\n",
      "Train Log likelihood, step 222100 in nats: 0.096506\n",
      "Train Log likelihood, step 222150 in nats: 0.096510\n",
      "Train epoch average loss: 0.09650810495468866\n",
      "\n",
      "\n",
      "Epoch: 1363\n",
      "Train Log likelihood, step 222200 in nats: 0.096516\n",
      "Train Log likelihood, step 222250 in nats: 0.096528\n",
      "Train Log likelihood, step 222300 in nats: 0.096541\n",
      "Train epoch average loss: 0.09654523341097099\n",
      "\n",
      "\n",
      "Epoch: 1364\n",
      "Train Log likelihood, step 222350 in nats: 0.096548\n",
      "Train Log likelihood, step 222400 in nats: 0.096556\n",
      "Train Log likelihood, step 222450 in nats: 0.096558\n",
      "Train epoch average loss: 0.09656361614378556\n",
      "\n",
      "\n",
      "Epoch: 1365\n",
      "Train Log likelihood, step 222500 in nats: 0.096566\n",
      "Train Log likelihood, step 222550 in nats: 0.096579\n",
      "Train Log likelihood, step 222600 in nats: 0.096586\n",
      "Train Log likelihood, step 222650 in nats: 0.096596\n",
      "Train epoch average loss: 0.09659860056787217\n",
      "\n",
      "\n",
      "Epoch: 1366\n",
      "Train Log likelihood, step 222700 in nats: 0.096604\n",
      "Train Log likelihood, step 222750 in nats: 0.096601\n",
      "Train Log likelihood, step 222800 in nats: 0.096610\n",
      "Train epoch average loss: 0.09661452366580499\n",
      "\n",
      "\n",
      "Epoch: 1367\n",
      "Train Log likelihood, step 222850 in nats: 0.096616\n",
      "Train Log likelihood, step 222900 in nats: 0.096619\n",
      "Train Log likelihood, step 222950 in nats: 0.096622\n",
      "Train epoch average loss: 0.09662614370413602\n",
      "\n",
      "\n",
      "Epoch: 1368\n",
      "Train Log likelihood, step 223000 in nats: 0.096629\n",
      "Train Log likelihood, step 223050 in nats: 0.096638\n",
      "Train Log likelihood, step 223100 in nats: 0.096645\n",
      "Train epoch average loss: 0.09664904162333675\n",
      "\n",
      "\n",
      "Epoch: 1369\n",
      "Train Log likelihood, step 223150 in nats: 0.096649\n",
      "Train Log likelihood, step 223200 in nats: 0.096652\n",
      "Train Log likelihood, step 223250 in nats: 0.096660\n",
      "Train Log likelihood, step 223300 in nats: 0.096664\n",
      "Train epoch average loss: 0.09666477989084786\n",
      "\n",
      "\n",
      "Epoch: 1370\n",
      "Train Log likelihood, step 223350 in nats: 0.096677\n",
      "Train Log likelihood, step 223400 in nats: 0.096683\n",
      "Train Log likelihood, step 223450 in nats: 0.096691\n",
      "Train epoch average loss: 0.09669211083475417\n",
      "\n",
      "\n",
      "Epoch: 1371\n",
      "Train Log likelihood, step 223500 in nats: 0.096688\n",
      "Train Log likelihood, step 223550 in nats: 0.096691\n",
      "Train Log likelihood, step 223600 in nats: 0.096700\n",
      "Train epoch average loss: 0.09670312303886754\n",
      "\n",
      "\n",
      "Epoch: 1372\n",
      "Train Log likelihood, step 223650 in nats: 0.096705\n",
      "Train Log likelihood, step 223700 in nats: 0.096708\n",
      "Train Log likelihood, step 223750 in nats: 0.096714\n",
      "Train epoch average loss: 0.09671679419236669\n",
      "\n",
      "\n",
      "Epoch: 1373\n",
      "Train Log likelihood, step 223800 in nats: 0.096716\n",
      "Train Log likelihood, step 223850 in nats: 0.096723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 223900 in nats: 0.096722\n",
      "Train Log likelihood, step 223950 in nats: 0.096735\n",
      "Train epoch average loss: 0.09673638618729692\n",
      "\n",
      "\n",
      "Epoch: 1374\n",
      "Train Log likelihood, step 224000 in nats: 0.096743\n",
      "Train Log likelihood, step 224050 in nats: 0.096757\n",
      "Train Log likelihood, step 224100 in nats: 0.096765\n",
      "Train epoch average loss: 0.09676604682841114\n",
      "\n",
      "\n",
      "Epoch: 1375\n",
      "Train Log likelihood, step 224150 in nats: 0.096767\n",
      "Train Log likelihood, step 224200 in nats: 0.096774\n",
      "Train Log likelihood, step 224250 in nats: 0.096780\n",
      "Train epoch average loss: 0.09678388374487801\n",
      "\n",
      "\n",
      "Epoch: 1376\n",
      "Train Log likelihood, step 224300 in nats: 0.096787\n",
      "Train Log likelihood, step 224350 in nats: 0.096800\n",
      "Train Log likelihood, step 224400 in nats: 0.096808\n",
      "Train Log likelihood, step 224450 in nats: 0.096814\n",
      "Train epoch average loss: 0.09681413715061292\n",
      "\n",
      "\n",
      "Epoch: 1377\n",
      "Train Log likelihood, step 224500 in nats: 0.096821\n",
      "Train Log likelihood, step 224550 in nats: 0.096825\n",
      "Train Log likelihood, step 224600 in nats: 0.096837\n",
      "Train epoch average loss: 0.0968390144039231\n",
      "\n",
      "\n",
      "Epoch: 1378\n",
      "Train Log likelihood, step 224650 in nats: 0.096845\n",
      "Train Log likelihood, step 224700 in nats: 0.096851\n",
      "Train Log likelihood, step 224750 in nats: 0.096863\n",
      "Train epoch average loss: 0.09686499369991955\n",
      "\n",
      "\n",
      "Epoch: 1379\n",
      "Train Log likelihood, step 224800 in nats: 0.096866\n",
      "Train Log likelihood, step 224850 in nats: 0.096876\n",
      "Train Log likelihood, step 224900 in nats: 0.096890\n",
      "Train epoch average loss: 0.09689812912945078\n",
      "\n",
      "\n",
      "Epoch: 1380\n",
      "Train Log likelihood, step 224950 in nats: 0.096904\n",
      "Train Log likelihood, step 225000 in nats: 0.096912\n",
      "Train Log likelihood, step 225050 in nats: 0.096913\n",
      "Train Log likelihood, step 225100 in nats: 0.096904\n",
      "Train epoch average loss: 0.09690423498843743\n",
      "\n",
      "\n",
      "Epoch: 1381\n",
      "Train Log likelihood, step 225150 in nats: 0.096899\n",
      "Train Log likelihood, step 225200 in nats: 0.096898\n",
      "Train Log likelihood, step 225250 in nats: 0.096898\n",
      "Train epoch average loss: 0.09689949875523199\n",
      "\n",
      "\n",
      "Epoch: 1382\n",
      "Train Log likelihood, step 225300 in nats: 0.096903\n",
      "Train Log likelihood, step 225350 in nats: 0.096912\n",
      "Train Log likelihood, step 225400 in nats: 0.096920\n",
      "Train epoch average loss: 0.09692199950863499\n",
      "\n",
      "\n",
      "Epoch: 1383\n",
      "Train Log likelihood, step 225450 in nats: 0.096925\n",
      "Train Log likelihood, step 225500 in nats: 0.096930\n",
      "Train Log likelihood, step 225550 in nats: 0.096929\n",
      "Train epoch average loss: 0.0969294953172046\n",
      "\n",
      "\n",
      "Epoch: 1384\n",
      "Train Log likelihood, step 225600 in nats: 0.096932\n",
      "Train Log likelihood, step 225650 in nats: 0.096943\n",
      "Train Log likelihood, step 225700 in nats: 0.096952\n",
      "Train Log likelihood, step 225750 in nats: 0.096951\n",
      "Train epoch average loss: 0.09695138939216037\n",
      "\n",
      "\n",
      "Epoch: 1385\n",
      "Train Log likelihood, step 225800 in nats: 0.096954\n",
      "Train Log likelihood, step 225850 in nats: 0.096965\n",
      "Train Log likelihood, step 225900 in nats: 0.096968\n",
      "Train epoch average loss: 0.09697205980339452\n",
      "\n",
      "\n",
      "Epoch: 1386\n",
      "Train Log likelihood, step 225950 in nats: 0.096974\n",
      "Train Log likelihood, step 226000 in nats: 0.096989\n",
      "Train Log likelihood, step 226050 in nats: 0.097000\n",
      "Train epoch average loss: 0.09700087057707762\n",
      "\n",
      "\n",
      "Epoch: 1387\n",
      "Train Log likelihood, step 226100 in nats: 0.097004\n",
      "Train Log likelihood, step 226150 in nats: 0.097010\n",
      "Train Log likelihood, step 226200 in nats: 0.097019\n",
      "Train epoch average loss: 0.09702651445667113\n",
      "\n",
      "\n",
      "Epoch: 1388\n",
      "Train Log likelihood, step 226250 in nats: 0.097024\n",
      "Train Log likelihood, step 226300 in nats: 0.097033\n",
      "Train Log likelihood, step 226350 in nats: 0.097042\n",
      "Train Log likelihood, step 226400 in nats: 0.097053\n",
      "Train epoch average loss: 0.0970556357804863\n",
      "\n",
      "\n",
      "Epoch: 1389\n",
      "Train Log likelihood, step 226450 in nats: 0.097058\n",
      "Train Log likelihood, step 226500 in nats: 0.097063\n",
      "Train Log likelihood, step 226550 in nats: 0.097073\n",
      "Train epoch average loss: 0.09707237558002975\n",
      "\n",
      "\n",
      "Epoch: 1390\n",
      "Train Log likelihood, step 226600 in nats: 0.097077\n",
      "Train Log likelihood, step 226650 in nats: 0.097084\n",
      "Train Log likelihood, step 226700 in nats: 0.097087\n",
      "Train epoch average loss: 0.09709162019116543\n",
      "\n",
      "\n",
      "Epoch: 1391\n",
      "Train Log likelihood, step 226750 in nats: 0.097093\n",
      "Train Log likelihood, step 226800 in nats: 0.097108\n",
      "Train Log likelihood, step 226850 in nats: 0.097114\n",
      "Train epoch average loss: 0.09712411175494544\n",
      "\n",
      "\n",
      "Epoch: 1392\n",
      "Train Log likelihood, step 226900 in nats: 0.097123\n",
      "Train Log likelihood, step 226950 in nats: 0.097128\n",
      "Train Log likelihood, step 227000 in nats: 0.097140\n",
      "Train Log likelihood, step 227050 in nats: 0.097144\n",
      "Train epoch average loss: 0.09714703366275378\n",
      "\n",
      "\n",
      "Epoch: 1393\n",
      "Train Log likelihood, step 227100 in nats: 0.097151\n",
      "Train Log likelihood, step 227150 in nats: 0.097154\n",
      "Train Log likelihood, step 227200 in nats: 0.097168\n",
      "Train epoch average loss: 0.09717304936125792\n",
      "\n",
      "\n",
      "Epoch: 1394\n",
      "Train Log likelihood, step 227250 in nats: 0.097174\n",
      "Train Log likelihood, step 227300 in nats: 0.097185\n",
      "Train Log likelihood, step 227350 in nats: 0.097183\n",
      "Train epoch average loss: 0.0971911118757755\n",
      "\n",
      "\n",
      "Epoch: 1395\n",
      "Train Log likelihood, step 227400 in nats: 0.097193\n",
      "Train Log likelihood, step 227450 in nats: 0.097196\n",
      "Train Log likelihood, step 227500 in nats: 0.097204\n",
      "Train epoch average loss: 0.09721415145016077\n",
      "\n",
      "\n",
      "Epoch: 1396\n",
      "Train Log likelihood, step 227550 in nats: 0.097216\n",
      "Train Log likelihood, step 227600 in nats: 0.097222\n",
      "Train Log likelihood, step 227650 in nats: 0.097227\n",
      "Train Log likelihood, step 227700 in nats: 0.097238\n",
      "Train epoch average loss: 0.09723668219604654\n",
      "\n",
      "\n",
      "Epoch: 1397\n",
      "Train Log likelihood, step 227750 in nats: 0.097239\n",
      "Train Log likelihood, step 227800 in nats: 0.097246\n",
      "Train Log likelihood, step 227850 in nats: 0.097250\n",
      "Train epoch average loss: 0.09725626760158858\n",
      "\n",
      "\n",
      "Epoch: 1398\n",
      "Train Log likelihood, step 227900 in nats: 0.097264\n",
      "Train Log likelihood, step 227950 in nats: 0.097278\n",
      "Train Log likelihood, step 228000 in nats: 0.097284\n",
      "Train epoch average loss: 0.09727945411995531\n",
      "\n",
      "\n",
      "Epoch: 1399\n",
      "Train Log likelihood, step 228050 in nats: 0.097284\n",
      "Train Log likelihood, step 228100 in nats: 0.097291\n",
      "Train Log likelihood, step 228150 in nats: 0.097297\n",
      "Train epoch average loss: 0.09730010675104098\n",
      "\n",
      "\n",
      "Epoch: 1400\n",
      "Train Log likelihood, step 228200 in nats: 0.097301\n",
      "Train Log likelihood, step 228250 in nats: 0.097316\n",
      "Train Log likelihood, step 228300 in nats: 0.097323\n",
      "Train Log likelihood, step 228350 in nats: 0.097334\n",
      "Train epoch average loss: 0.09733676479134913\n",
      "\n",
      "\n",
      "Epoch: 1401\n",
      "Train Log likelihood, step 228400 in nats: 0.097348\n",
      "Train Log likelihood, step 228450 in nats: 0.097359\n",
      "Train Log likelihood, step 228500 in nats: 0.097367\n",
      "Train epoch average loss: 0.0973728423257975\n",
      "\n",
      "\n",
      "Epoch: 1402\n",
      "Train Log likelihood, step 228550 in nats: 0.097377\n",
      "Train Log likelihood, step 228600 in nats: 0.097387\n",
      "Train Log likelihood, step 228650 in nats: 0.097384\n",
      "Train epoch average loss: 0.09738305079741895\n",
      "\n",
      "\n",
      "Epoch: 1403\n",
      "Train Log likelihood, step 228700 in nats: 0.097385\n",
      "Train Log likelihood, step 228750 in nats: 0.097396\n",
      "Train Log likelihood, step 228800 in nats: 0.097411\n",
      "Train Log likelihood, step 228850 in nats: 0.097418\n",
      "Train epoch average loss: 0.09741890980679219\n",
      "\n",
      "\n",
      "Epoch: 1404\n",
      "Train Log likelihood, step 228900 in nats: 0.097429\n",
      "Train Log likelihood, step 228950 in nats: 0.097427\n",
      "Train Log likelihood, step 229000 in nats: 0.097434\n",
      "Train epoch average loss: 0.09744087995499422\n",
      "\n",
      "\n",
      "Epoch: 1405\n",
      "Train Log likelihood, step 229050 in nats: 0.097449\n",
      "Train Log likelihood, step 229100 in nats: 0.097465\n",
      "Train Log likelihood, step 229150 in nats: 0.097477\n",
      "Train epoch average loss: 0.09748135547523003\n",
      "\n",
      "\n",
      "Epoch: 1406\n",
      "Train Log likelihood, step 229200 in nats: 0.097480\n",
      "Train Log likelihood, step 229250 in nats: 0.097484\n",
      "Train Log likelihood, step 229300 in nats: 0.097493\n",
      "Train epoch average loss: 0.0974994197670448\n",
      "\n",
      "\n",
      "Epoch: 1407\n",
      "Train Log likelihood, step 229350 in nats: 0.097501\n",
      "Train Log likelihood, step 229400 in nats: 0.097504\n",
      "Train Log likelihood, step 229450 in nats: 0.097503\n",
      "Train Log likelihood, step 229500 in nats: 0.097506\n",
      "Train epoch average loss: 0.09750669704433604\n",
      "\n",
      "\n",
      "Epoch: 1408\n",
      "Train Log likelihood, step 229550 in nats: 0.097512\n",
      "Train Log likelihood, step 229600 in nats: 0.097522\n",
      "Train Log likelihood, step 229650 in nats: 0.097527\n",
      "Train epoch average loss: 0.09753187201387806\n",
      "\n",
      "\n",
      "Epoch: 1409\n",
      "Train Log likelihood, step 229700 in nats: 0.097539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 229750 in nats: 0.097540\n",
      "Train Log likelihood, step 229800 in nats: 0.097545\n",
      "Train epoch average loss: 0.09754773960814436\n",
      "\n",
      "\n",
      "Epoch: 1410\n",
      "Train Log likelihood, step 229850 in nats: 0.097549\n",
      "Train Log likelihood, step 229900 in nats: 0.097559\n",
      "Train Log likelihood, step 229950 in nats: 0.097565\n",
      "Train epoch average loss: 0.09757144923699979\n",
      "\n",
      "\n",
      "Epoch: 1411\n",
      "Train Log likelihood, step 230000 in nats: 0.097571\n",
      "Train Log likelihood, step 230050 in nats: 0.097587\n",
      "Train Log likelihood, step 230100 in nats: 0.097593\n",
      "Train Log likelihood, step 230150 in nats: 0.097605\n",
      "Train epoch average loss: 0.09760703957795026\n",
      "\n",
      "\n",
      "Epoch: 1412\n",
      "Train Log likelihood, step 230200 in nats: 0.097618\n",
      "Train Log likelihood, step 230250 in nats: 0.097633\n",
      "Train Log likelihood, step 230300 in nats: 0.097642\n",
      "Train epoch average loss: 0.09764402819672727\n",
      "\n",
      "\n",
      "Epoch: 1413\n",
      "Train Log likelihood, step 230350 in nats: 0.097648\n",
      "Train Log likelihood, step 230400 in nats: 0.097645\n",
      "Train Log likelihood, step 230450 in nats: 0.097660\n",
      "Train epoch average loss: 0.09766750518895245\n",
      "\n",
      "\n",
      "Epoch: 1414\n",
      "Train Log likelihood, step 230500 in nats: 0.097672\n",
      "Train Log likelihood, step 230550 in nats: 0.097679\n",
      "Train Log likelihood, step 230600 in nats: 0.097692\n",
      "Train epoch average loss: 0.09769848085607932\n",
      "\n",
      "\n",
      "Epoch: 1415\n",
      "Train Log likelihood, step 230650 in nats: 0.097700\n",
      "Train Log likelihood, step 230700 in nats: 0.097704\n",
      "Train Log likelihood, step 230750 in nats: 0.097715\n",
      "Train Log likelihood, step 230800 in nats: 0.097718\n",
      "Train epoch average loss: 0.09771771817391071\n",
      "\n",
      "\n",
      "Epoch: 1416\n",
      "Train Log likelihood, step 230850 in nats: 0.097716\n",
      "Train Log likelihood, step 230900 in nats: 0.097724\n",
      "Train Log likelihood, step 230950 in nats: 0.097731\n",
      "Train epoch average loss: 0.09773867682407461\n",
      "\n",
      "\n",
      "Epoch: 1417\n",
      "Train Log likelihood, step 231000 in nats: 0.097742\n",
      "Train Log likelihood, step 231050 in nats: 0.097750\n",
      "Train Log likelihood, step 231100 in nats: 0.097754\n",
      "Train epoch average loss: 0.09776047127729193\n",
      "\n",
      "\n",
      "Epoch: 1418\n",
      "Train Log likelihood, step 231150 in nats: 0.097763\n",
      "Train Log likelihood, step 231200 in nats: 0.097774\n",
      "Train Log likelihood, step 231250 in nats: 0.097777\n",
      "Train epoch average loss: 0.09778563743279459\n",
      "\n",
      "\n",
      "Epoch: 1419\n",
      "Train Log likelihood, step 231300 in nats: 0.097785\n",
      "Train Log likelihood, step 231350 in nats: 0.097796\n",
      "Train Log likelihood, step 231400 in nats: 0.097799\n",
      "Train Log likelihood, step 231450 in nats: 0.097801\n",
      "Train epoch average loss: 0.09780581186414769\n",
      "\n",
      "\n",
      "Epoch: 1420\n",
      "Train Log likelihood, step 231500 in nats: 0.097813\n",
      "Train Log likelihood, step 231550 in nats: 0.097814\n",
      "Train Log likelihood, step 231600 in nats: 0.097824\n",
      "Train epoch average loss: 0.09782285754461735\n",
      "\n",
      "\n",
      "Epoch: 1421\n",
      "Train Log likelihood, step 231650 in nats: 0.097831\n",
      "Train Log likelihood, step 231700 in nats: 0.097843\n",
      "Train Log likelihood, step 231750 in nats: 0.097849\n",
      "Train epoch average loss: 0.09784516395608568\n",
      "\n",
      "\n",
      "Epoch: 1422\n",
      "Train Log likelihood, step 231800 in nats: 0.097850\n",
      "Train Log likelihood, step 231850 in nats: 0.097852\n",
      "Train Log likelihood, step 231900 in nats: 0.097853\n",
      "Train epoch average loss: 0.09786603692135813\n",
      "\n",
      "\n",
      "Epoch: 1423\n",
      "Train Log likelihood, step 231950 in nats: 0.097867\n",
      "Train Log likelihood, step 232000 in nats: 0.097878\n",
      "Train Log likelihood, step 232050 in nats: 0.097880\n",
      "Train Log likelihood, step 232100 in nats: 0.097883\n",
      "Train epoch average loss: 0.09788272635618346\n",
      "\n",
      "\n",
      "Epoch: 1424\n",
      "Train Log likelihood, step 232150 in nats: 0.097885\n",
      "Train Log likelihood, step 232200 in nats: 0.097892\n",
      "Train Log likelihood, step 232250 in nats: 0.097900\n",
      "Train epoch average loss: 0.09789987775638329\n",
      "\n",
      "\n",
      "Epoch: 1425\n",
      "Train Log likelihood, step 232300 in nats: 0.097905\n",
      "Train Log likelihood, step 232350 in nats: 0.097917\n",
      "Train Log likelihood, step 232400 in nats: 0.097928\n",
      "Train epoch average loss: 0.09793431687713569\n",
      "\n",
      "\n",
      "Epoch: 1426\n",
      "Train Log likelihood, step 232450 in nats: 0.097935\n",
      "Train Log likelihood, step 232500 in nats: 0.097949\n",
      "Train Log likelihood, step 232550 in nats: 0.097956\n",
      "Train Log likelihood, step 232600 in nats: 0.097964\n",
      "Train epoch average loss: 0.09796400670972617\n",
      "\n",
      "\n",
      "Epoch: 1427\n",
      "Train Log likelihood, step 232650 in nats: 0.097972\n",
      "Train Log likelihood, step 232700 in nats: 0.097968\n",
      "Train Log likelihood, step 232750 in nats: 0.097981\n",
      "Train epoch average loss: 0.09798541320584467\n",
      "\n",
      "\n",
      "Epoch: 1428\n",
      "Train Log likelihood, step 232800 in nats: 0.097996\n",
      "Train Log likelihood, step 232850 in nats: 0.098000\n",
      "Train Log likelihood, step 232900 in nats: 0.098003\n",
      "Train epoch average loss: 0.09800751909167028\n",
      "\n",
      "\n",
      "Epoch: 1429\n",
      "Train Log likelihood, step 232950 in nats: 0.098010\n",
      "Train Log likelihood, step 233000 in nats: 0.098010\n",
      "Train Log likelihood, step 233050 in nats: 0.098016\n",
      "Train epoch average loss: 0.09802518692579304\n",
      "\n",
      "\n",
      "Epoch: 1430\n",
      "Train Log likelihood, step 233100 in nats: 0.098024\n",
      "Train Log likelihood, step 233150 in nats: 0.098035\n",
      "Train Log likelihood, step 233200 in nats: 0.098032\n",
      "Train Log likelihood, step 233250 in nats: 0.098035\n",
      "Train epoch average loss: 0.0980341931601209\n",
      "\n",
      "\n",
      "Epoch: 1431\n",
      "Train Log likelihood, step 233300 in nats: 0.098042\n",
      "Train Log likelihood, step 233350 in nats: 0.098046\n",
      "Train Log likelihood, step 233400 in nats: 0.098055\n",
      "Train epoch average loss: 0.09805644797146408\n",
      "\n",
      "\n",
      "Epoch: 1432\n",
      "Train Log likelihood, step 233450 in nats: 0.098064\n",
      "Train Log likelihood, step 233500 in nats: 0.098074\n",
      "Train Log likelihood, step 233550 in nats: 0.098073\n",
      "Train epoch average loss: 0.09807663494807635\n",
      "\n",
      "\n",
      "Epoch: 1433\n",
      "Train Log likelihood, step 233600 in nats: 0.098078\n",
      "Train Log likelihood, step 233650 in nats: 0.098079\n",
      "Train Log likelihood, step 233700 in nats: 0.098079\n",
      "Train epoch average loss: 0.09808850566297947\n",
      "\n",
      "\n",
      "Epoch: 1434\n",
      "Train Log likelihood, step 233750 in nats: 0.098093\n",
      "Train Log likelihood, step 233800 in nats: 0.098101\n",
      "Train Log likelihood, step 233850 in nats: 0.098107\n",
      "Train Log likelihood, step 233900 in nats: 0.098111\n",
      "Train epoch average loss: 0.09811119563059183\n",
      "\n",
      "\n",
      "Epoch: 1435\n",
      "Train Log likelihood, step 233950 in nats: 0.098116\n",
      "Train Log likelihood, step 234000 in nats: 0.098122\n",
      "Train Log likelihood, step 234050 in nats: 0.098129\n",
      "Train epoch average loss: 0.0981339811402823\n",
      "\n",
      "\n",
      "Epoch: 1436\n",
      "Train Log likelihood, step 234100 in nats: 0.098139\n",
      "Train Log likelihood, step 234150 in nats: 0.098154\n",
      "Train Log likelihood, step 234200 in nats: 0.098158\n",
      "Train epoch average loss: 0.09816078293630448\n",
      "\n",
      "\n",
      "Epoch: 1437\n",
      "Train Log likelihood, step 234250 in nats: 0.098165\n",
      "Train Log likelihood, step 234300 in nats: 0.098167\n",
      "Train Log likelihood, step 234350 in nats: 0.098180\n",
      "Train epoch average loss: 0.09818467425860408\n",
      "\n",
      "\n",
      "Epoch: 1438\n",
      "Train Log likelihood, step 234400 in nats: 0.098185\n",
      "Train Log likelihood, step 234450 in nats: 0.098184\n",
      "Train Log likelihood, step 234500 in nats: 0.098194\n",
      "Train Log likelihood, step 234550 in nats: 0.098201\n",
      "Train epoch average loss: 0.09820462154300068\n",
      "\n",
      "\n",
      "Epoch: 1439\n",
      "Train Log likelihood, step 234600 in nats: 0.098213\n",
      "Train Log likelihood, step 234650 in nats: 0.098219\n",
      "Train Log likelihood, step 234700 in nats: 0.098224\n",
      "Train epoch average loss: 0.09822507100892601\n",
      "\n",
      "\n",
      "Epoch: 1440\n",
      "Train Log likelihood, step 234750 in nats: 0.098229\n",
      "Train Log likelihood, step 234800 in nats: 0.098243\n",
      "Train Log likelihood, step 234850 in nats: 0.098251\n",
      "Train epoch average loss: 0.09826264814732519\n",
      "\n",
      "\n",
      "Epoch: 1441\n",
      "Train Log likelihood, step 234900 in nats: 0.098265\n",
      "Train Log likelihood, step 234950 in nats: 0.098273\n",
      "Train Log likelihood, step 235000 in nats: 0.098281\n",
      "Train epoch average loss: 0.09828268499772963\n",
      "\n",
      "\n",
      "Epoch: 1442\n",
      "Train Log likelihood, step 235050 in nats: 0.098285\n",
      "Train Log likelihood, step 235100 in nats: 0.098293\n",
      "Train Log likelihood, step 235150 in nats: 0.098299\n",
      "Train Log likelihood, step 235200 in nats: 0.098303\n",
      "Train epoch average loss: 0.09830304430316385\n",
      "\n",
      "\n",
      "Epoch: 1443\n",
      "Train Log likelihood, step 235250 in nats: 0.098308\n",
      "Train Log likelihood, step 235300 in nats: 0.098310\n",
      "Train Log likelihood, step 235350 in nats: 0.098318\n",
      "Train epoch average loss: 0.09831942157201089\n",
      "\n",
      "\n",
      "Epoch: 1444\n",
      "Train Log likelihood, step 235400 in nats: 0.098326\n",
      "Train Log likelihood, step 235450 in nats: 0.098338\n",
      "Train Log likelihood, step 235500 in nats: 0.098349\n",
      "Train epoch average loss: 0.09835813158156292\n",
      "\n",
      "\n",
      "Epoch: 1445\n",
      "Train Log likelihood, step 235550 in nats: 0.098358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 235600 in nats: 0.098356\n",
      "Train Log likelihood, step 235650 in nats: 0.098356\n",
      "Train epoch average loss: 0.0983615796421497\n",
      "\n",
      "\n",
      "Epoch: 1446\n",
      "Train Log likelihood, step 235700 in nats: 0.098362\n",
      "Train Log likelihood, step 235750 in nats: 0.098374\n",
      "Train Log likelihood, step 235800 in nats: 0.098381\n",
      "Train Log likelihood, step 235850 in nats: 0.098394\n",
      "Train epoch average loss: 0.09839556621776849\n",
      "\n",
      "\n",
      "Epoch: 1447\n",
      "Train Log likelihood, step 235900 in nats: 0.098398\n",
      "Train Log likelihood, step 235950 in nats: 0.098410\n",
      "Train Log likelihood, step 236000 in nats: 0.098420\n",
      "Train epoch average loss: 0.0984254047160336\n",
      "\n",
      "\n",
      "Epoch: 1448\n",
      "Train Log likelihood, step 236050 in nats: 0.098428\n",
      "Train Log likelihood, step 236100 in nats: 0.098440\n",
      "Train Log likelihood, step 236150 in nats: 0.098443\n",
      "Train epoch average loss: 0.09845184980565497\n",
      "\n",
      "\n",
      "Epoch: 1449\n",
      "Train Log likelihood, step 236200 in nats: 0.098456\n",
      "Train Log likelihood, step 236250 in nats: 0.098457\n",
      "Train Log likelihood, step 236300 in nats: 0.098459\n",
      "Train epoch average loss: 0.09847211005294552\n",
      "\n",
      "\n",
      "Epoch: 1450\n",
      "Train Log likelihood, step 236350 in nats: 0.098473\n",
      "Train Log likelihood, step 236400 in nats: 0.098476\n",
      "Train Log likelihood, step 236450 in nats: 0.098481\n",
      "Train Log likelihood, step 236500 in nats: 0.098489\n",
      "Train epoch average loss: 0.09849034594133027\n",
      "\n",
      "\n",
      "Epoch: 1451\n",
      "Train Log likelihood, step 236550 in nats: 0.098492\n",
      "Train Log likelihood, step 236600 in nats: 0.098490\n",
      "Train Log likelihood, step 236650 in nats: 0.098492\n",
      "Train epoch average loss: 0.09849183867695718\n",
      "\n",
      "\n",
      "Epoch: 1452\n",
      "Train Log likelihood, step 236700 in nats: 0.098494\n",
      "Train Log likelihood, step 236750 in nats: 0.098508\n",
      "Train Log likelihood, step 236800 in nats: 0.098514\n",
      "Train epoch average loss: 0.0985245054693078\n",
      "\n",
      "\n",
      "Epoch: 1453\n",
      "Train Log likelihood, step 236850 in nats: 0.098528\n",
      "Train Log likelihood, step 236900 in nats: 0.098542\n",
      "Train Log likelihood, step 236950 in nats: 0.098548\n",
      "Train Log likelihood, step 237000 in nats: 0.098554\n",
      "Train epoch average loss: 0.09855444865478996\n",
      "\n",
      "\n",
      "Epoch: 1454\n",
      "Train Log likelihood, step 237050 in nats: 0.098567\n",
      "Train Log likelihood, step 237100 in nats: 0.098579\n",
      "Train Log likelihood, step 237150 in nats: 0.098586\n",
      "Train epoch average loss: 0.09858553943743184\n",
      "\n",
      "\n",
      "Epoch: 1455\n",
      "Train Log likelihood, step 237200 in nats: 0.098591\n",
      "Train Log likelihood, step 237250 in nats: 0.098601\n",
      "Train Log likelihood, step 237300 in nats: 0.098615\n",
      "Train epoch average loss: 0.09861903607207413\n",
      "\n",
      "\n",
      "Epoch: 1456\n",
      "Train Log likelihood, step 237350 in nats: 0.098622\n",
      "Train Log likelihood, step 237400 in nats: 0.098633\n",
      "Train Log likelihood, step 237450 in nats: 0.098642\n",
      "Train epoch average loss: 0.09865389463148368\n",
      "\n",
      "\n",
      "Epoch: 1457\n",
      "Train Log likelihood, step 237500 in nats: 0.098653\n",
      "Train Log likelihood, step 237550 in nats: 0.098669\n",
      "Train Log likelihood, step 237600 in nats: 0.098681\n",
      "Train Log likelihood, step 237650 in nats: 0.098688\n",
      "Train epoch average loss: 0.09868844780562812\n",
      "\n",
      "\n",
      "Epoch: 1458\n",
      "Train Log likelihood, step 237700 in nats: 0.098690\n",
      "Train Log likelihood, step 237750 in nats: 0.098691\n",
      "Train Log likelihood, step 237800 in nats: 0.098702\n",
      "Train epoch average loss: 0.09870396021944587\n",
      "\n",
      "\n",
      "Epoch: 1459\n",
      "Train Log likelihood, step 237850 in nats: 0.098717\n",
      "Train Log likelihood, step 237900 in nats: 0.098720\n",
      "Train Log likelihood, step 237950 in nats: 0.098728\n",
      "Train epoch average loss: 0.09873367995394441\n",
      "\n",
      "\n",
      "Epoch: 1460\n",
      "Train Log likelihood, step 238000 in nats: 0.098736\n",
      "Train Log likelihood, step 238050 in nats: 0.098739\n",
      "Train Log likelihood, step 238100 in nats: 0.098748\n",
      "Train epoch average loss: 0.09874960146497326\n",
      "\n",
      "\n",
      "Epoch: 1461\n",
      "Train Log likelihood, step 238150 in nats: 0.098753\n",
      "Train Log likelihood, step 238200 in nats: 0.098757\n",
      "Train Log likelihood, step 238250 in nats: 0.098765\n",
      "Train Log likelihood, step 238300 in nats: 0.098773\n",
      "Train epoch average loss: 0.09877161444978381\n",
      "\n",
      "\n",
      "Epoch: 1462\n",
      "Train Log likelihood, step 238350 in nats: 0.098784\n",
      "Train Log likelihood, step 238400 in nats: 0.098789\n",
      "Train Log likelihood, step 238450 in nats: 0.098798\n",
      "Train epoch average loss: 0.09880140164123301\n",
      "\n",
      "\n",
      "Epoch: 1463\n",
      "Train Log likelihood, step 238500 in nats: 0.098805\n",
      "Train Log likelihood, step 238550 in nats: 0.098815\n",
      "Train Log likelihood, step 238600 in nats: 0.098817\n",
      "Train epoch average loss: 0.09882227064018223\n",
      "\n",
      "\n",
      "Epoch: 1464\n",
      "Train Log likelihood, step 238650 in nats: 0.098827\n",
      "Train Log likelihood, step 238700 in nats: 0.098831\n",
      "Train Log likelihood, step 238750 in nats: 0.098835\n",
      "Train epoch average loss: 0.09884506611759146\n",
      "\n",
      "\n",
      "Epoch: 1465\n",
      "Train Log likelihood, step 238800 in nats: 0.098846\n",
      "Train Log likelihood, step 238850 in nats: 0.098853\n",
      "Train Log likelihood, step 238900 in nats: 0.098863\n",
      "Train Log likelihood, step 238950 in nats: 0.098876\n",
      "Train epoch average loss: 0.09887450291411805\n",
      "\n",
      "\n",
      "Epoch: 1466\n",
      "Train Log likelihood, step 239000 in nats: 0.098882\n",
      "Train Log likelihood, step 239050 in nats: 0.098894\n",
      "Train Log likelihood, step 239100 in nats: 0.098906\n",
      "Train epoch average loss: 0.09891053226627915\n",
      "\n",
      "\n",
      "Epoch: 1467\n",
      "Train Log likelihood, step 239150 in nats: 0.098911\n",
      "Train Log likelihood, step 239200 in nats: 0.098918\n",
      "Train Log likelihood, step 239250 in nats: 0.098921\n",
      "Train epoch average loss: 0.09892562772444753\n",
      "\n",
      "\n",
      "Epoch: 1468\n",
      "Train Log likelihood, step 239300 in nats: 0.098929\n",
      "Train Log likelihood, step 239350 in nats: 0.098933\n",
      "Train Log likelihood, step 239400 in nats: 0.098938\n",
      "Train epoch average loss: 0.09894275598245589\n",
      "\n",
      "\n",
      "Epoch: 1469\n",
      "Train Log likelihood, step 239450 in nats: 0.098943\n",
      "Train Log likelihood, step 239500 in nats: 0.098949\n",
      "Train Log likelihood, step 239550 in nats: 0.098957\n",
      "Train Log likelihood, step 239600 in nats: 0.098968\n",
      "Train epoch average loss: 0.0989685590347868\n",
      "\n",
      "\n",
      "Epoch: 1470\n",
      "Train Log likelihood, step 239650 in nats: 0.098972\n",
      "Train Log likelihood, step 239700 in nats: 0.098975\n",
      "Train Log likelihood, step 239750 in nats: 0.098977\n",
      "Train epoch average loss: 0.09898138140920926\n",
      "\n",
      "\n",
      "Epoch: 1471\n",
      "Train Log likelihood, step 239800 in nats: 0.098987\n",
      "Train Log likelihood, step 239850 in nats: 0.098997\n",
      "Train Log likelihood, step 239900 in nats: 0.099008\n",
      "Train epoch average loss: 0.09901352800461802\n",
      "\n",
      "\n",
      "Epoch: 1472\n",
      "Train Log likelihood, step 239950 in nats: 0.099019\n",
      "Train Log likelihood, step 240000 in nats: 0.099025\n",
      "Train Log likelihood, step 240050 in nats: 0.099028\n",
      "Train epoch average loss: 0.09903916774521015\n",
      "\n",
      "\n",
      "Epoch: 1473\n",
      "Train Log likelihood, step 240100 in nats: 0.099041\n",
      "Train Log likelihood, step 240150 in nats: 0.099044\n",
      "Train Log likelihood, step 240200 in nats: 0.099052\n",
      "Train Log likelihood, step 240250 in nats: 0.099058\n",
      "Train epoch average loss: 0.09905857499985825\n",
      "\n",
      "\n",
      "Epoch: 1474\n",
      "Train Log likelihood, step 240300 in nats: 0.099063\n",
      "Train Log likelihood, step 240350 in nats: 0.099069\n",
      "Train Log likelihood, step 240400 in nats: 0.099077\n",
      "Train epoch average loss: 0.09908090934914764\n",
      "\n",
      "\n",
      "Epoch: 1475\n",
      "Train Log likelihood, step 240450 in nats: 0.099081\n",
      "Train Log likelihood, step 240500 in nats: 0.099089\n",
      "Train Log likelihood, step 240550 in nats: 0.099101\n",
      "Train epoch average loss: 0.0991095776394347\n",
      "\n",
      "\n",
      "Epoch: 1476\n",
      "Train Log likelihood, step 240600 in nats: 0.099110\n",
      "Train Log likelihood, step 240650 in nats: 0.099122\n",
      "Train Log likelihood, step 240700 in nats: 0.099131\n",
      "Train Log likelihood, step 240750 in nats: 0.099141\n",
      "Train epoch average loss: 0.09914090331093221\n",
      "\n",
      "\n",
      "Epoch: 1477\n",
      "Train Log likelihood, step 240800 in nats: 0.099146\n",
      "Train Log likelihood, step 240850 in nats: 0.099159\n",
      "Train Log likelihood, step 240900 in nats: 0.099165\n",
      "Train epoch average loss: 0.09916982125916529\n",
      "\n",
      "\n",
      "Epoch: 1478\n",
      "Train Log likelihood, step 240950 in nats: 0.099178\n",
      "Train Log likelihood, step 241000 in nats: 0.099180\n",
      "Train Log likelihood, step 241050 in nats: 0.099191\n",
      "Train epoch average loss: 0.09919481937829121\n",
      "\n",
      "\n",
      "Epoch: 1479\n",
      "Train Log likelihood, step 241100 in nats: 0.099196\n",
      "Train Log likelihood, step 241150 in nats: 0.099205\n",
      "Train Log likelihood, step 241200 in nats: 0.099210\n",
      "Train epoch average loss: 0.09922144621636322\n",
      "\n",
      "\n",
      "Epoch: 1480\n",
      "Train Log likelihood, step 241250 in nats: 0.099222\n",
      "Train Log likelihood, step 241300 in nats: 0.099223\n",
      "Train Log likelihood, step 241350 in nats: 0.099224\n",
      "Train Log likelihood, step 241400 in nats: 0.099225\n",
      "Train epoch average loss: 0.0992246450641647\n",
      "\n",
      "\n",
      "Epoch: 1481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 241450 in nats: 0.099234\n",
      "Train Log likelihood, step 241500 in nats: 0.099240\n",
      "Train Log likelihood, step 241550 in nats: 0.099250\n",
      "Train epoch average loss: 0.09925196407902882\n",
      "\n",
      "\n",
      "Epoch: 1482\n",
      "Train Log likelihood, step 241600 in nats: 0.099258\n",
      "Train Log likelihood, step 241650 in nats: 0.099267\n",
      "Train Log likelihood, step 241700 in nats: 0.099262\n",
      "Train epoch average loss: 0.09926526388406763\n",
      "\n",
      "\n",
      "Epoch: 1483\n",
      "Train Log likelihood, step 241750 in nats: 0.099270\n",
      "Train Log likelihood, step 241800 in nats: 0.099277\n",
      "Train Log likelihood, step 241850 in nats: 0.099272\n",
      "Train epoch average loss: 0.09927997144592116\n",
      "\n",
      "\n",
      "Epoch: 1484\n",
      "Train Log likelihood, step 241900 in nats: 0.099279\n",
      "Train Log likelihood, step 241950 in nats: 0.099284\n",
      "Train Log likelihood, step 242000 in nats: 0.099293\n",
      "Train Log likelihood, step 242050 in nats: 0.099296\n",
      "Train epoch average loss: 0.09929452830437452\n",
      "\n",
      "\n",
      "Epoch: 1485\n",
      "Train Log likelihood, step 242100 in nats: 0.099302\n",
      "Train Log likelihood, step 242150 in nats: 0.099307\n",
      "Train Log likelihood, step 242200 in nats: 0.099316\n",
      "Train epoch average loss: 0.09932051709613587\n",
      "\n",
      "\n",
      "Epoch: 1486\n",
      "Train Log likelihood, step 242250 in nats: 0.099325\n",
      "Train Log likelihood, step 242300 in nats: 0.099334\n",
      "Train Log likelihood, step 242350 in nats: 0.099348\n",
      "Train epoch average loss: 0.09935444245174839\n",
      "\n",
      "\n",
      "Epoch: 1487\n",
      "Train Log likelihood, step 242400 in nats: 0.099354\n",
      "Train Log likelihood, step 242450 in nats: 0.099358\n",
      "Train Log likelihood, step 242500 in nats: 0.099367\n",
      "Train epoch average loss: 0.09937459083448484\n",
      "\n",
      "\n",
      "Epoch: 1488\n",
      "Train Log likelihood, step 242550 in nats: 0.099375\n",
      "Train Log likelihood, step 242600 in nats: 0.099385\n",
      "Train Log likelihood, step 242650 in nats: 0.099393\n",
      "Train Log likelihood, step 242700 in nats: 0.099397\n",
      "Train epoch average loss: 0.09939821011996852\n",
      "\n",
      "\n",
      "Epoch: 1489\n",
      "Train Log likelihood, step 242750 in nats: 0.099407\n",
      "Train Log likelihood, step 242800 in nats: 0.099416\n",
      "Train Log likelihood, step 242850 in nats: 0.099426\n",
      "Train epoch average loss: 0.09942465662105635\n",
      "\n",
      "\n",
      "Epoch: 1490\n",
      "Train Log likelihood, step 242900 in nats: 0.099426\n",
      "Train Log likelihood, step 242950 in nats: 0.099423\n",
      "Train Log likelihood, step 243000 in nats: 0.099424\n",
      "Train epoch average loss: 0.09942788480936589\n",
      "\n",
      "\n",
      "Epoch: 1491\n",
      "Train Log likelihood, step 243050 in nats: 0.099433\n",
      "Train Log likelihood, step 243100 in nats: 0.099430\n",
      "Train Log likelihood, step 243150 in nats: 0.099436\n",
      "Train epoch average loss: 0.0994424562694936\n",
      "\n",
      "\n",
      "Epoch: 1492\n",
      "Train Log likelihood, step 243200 in nats: 0.099444\n",
      "Train Log likelihood, step 243250 in nats: 0.099442\n",
      "Train Log likelihood, step 243300 in nats: 0.099445\n",
      "Train Log likelihood, step 243350 in nats: 0.099461\n",
      "Train epoch average loss: 0.0994618078231471\n",
      "\n",
      "\n",
      "Epoch: 1493\n",
      "Train Log likelihood, step 243400 in nats: 0.099465\n",
      "Train Log likelihood, step 243450 in nats: 0.099479\n",
      "Train Log likelihood, step 243500 in nats: 0.099491\n",
      "Train epoch average loss: 0.09949456319820485\n",
      "\n",
      "\n",
      "Epoch: 1494\n",
      "Train Log likelihood, step 243550 in nats: 0.099505\n",
      "Train Log likelihood, step 243600 in nats: 0.099509\n",
      "Train Log likelihood, step 243650 in nats: 0.099510\n",
      "Train epoch average loss: 0.0995192800536733\n",
      "\n",
      "\n",
      "Epoch: 1495\n",
      "Train Log likelihood, step 243700 in nats: 0.099520\n",
      "Train Log likelihood, step 243750 in nats: 0.099533\n",
      "Train Log likelihood, step 243800 in nats: 0.099538\n",
      "Train epoch average loss: 0.0995450173756985\n",
      "\n",
      "\n",
      "Epoch: 1496\n",
      "Train Log likelihood, step 243850 in nats: 0.099545\n",
      "Train Log likelihood, step 243900 in nats: 0.099544\n",
      "Train Log likelihood, step 243950 in nats: 0.099550\n",
      "Train Log likelihood, step 244000 in nats: 0.099555\n",
      "Train epoch average loss: 0.09955655107736407\n",
      "\n",
      "\n",
      "Epoch: 1497\n",
      "Train Log likelihood, step 244050 in nats: 0.099566\n",
      "Train Log likelihood, step 244100 in nats: 0.099571\n",
      "Train Log likelihood, step 244150 in nats: 0.099575\n",
      "Train epoch average loss: 0.09957719778527466\n",
      "\n",
      "\n",
      "Epoch: 1498\n",
      "Train Log likelihood, step 244200 in nats: 0.099581\n",
      "Train Log likelihood, step 244250 in nats: 0.099587\n",
      "Train Log likelihood, step 244300 in nats: 0.099597\n",
      "Train epoch average loss: 0.09960052100982847\n",
      "\n",
      "\n",
      "Epoch: 1499\n",
      "Train Log likelihood, step 244350 in nats: 0.099601\n",
      "Train Log likelihood, step 244400 in nats: 0.099608\n",
      "Train Log likelihood, step 244450 in nats: 0.099608\n",
      "Train epoch average loss: 0.09961700912217528\n",
      "\n",
      "\n",
      "Epoch: 1500\n",
      "Train Log likelihood, step 244500 in nats: 0.099616\n",
      "Train Log likelihood, step 244550 in nats: 0.099625\n",
      "Train Log likelihood, step 244600 in nats: 0.099630\n",
      "Train Log likelihood, step 244650 in nats: 0.099631\n",
      "Train epoch average loss: 0.09963423534863956\n",
      "\n",
      "\n",
      "Epoch: 1501\n",
      "Train Log likelihood, step 244700 in nats: 0.099634\n",
      "Train Log likelihood, step 244750 in nats: 0.099644\n",
      "Train Log likelihood, step 244800 in nats: 0.099649\n",
      "Train epoch average loss: 0.09964972456176943\n",
      "\n",
      "\n",
      "Epoch: 1502\n",
      "Train Log likelihood, step 244850 in nats: 0.099654\n",
      "Train Log likelihood, step 244900 in nats: 0.099659\n",
      "Train Log likelihood, step 244950 in nats: 0.099666\n",
      "Train epoch average loss: 0.09967274533887337\n",
      "\n",
      "\n",
      "Epoch: 1503\n",
      "Train Log likelihood, step 245000 in nats: 0.099675\n",
      "Train Log likelihood, step 245050 in nats: 0.099675\n",
      "Train Log likelihood, step 245100 in nats: 0.099680\n",
      "Train Log likelihood, step 245150 in nats: 0.099684\n",
      "Train epoch average loss: 0.09968413463505943\n",
      "\n",
      "\n",
      "Epoch: 1504\n",
      "Train Log likelihood, step 245200 in nats: 0.099688\n",
      "Train Log likelihood, step 245250 in nats: 0.099698\n",
      "Train Log likelihood, step 245300 in nats: 0.099697\n",
      "Train epoch average loss: 0.09970087291553684\n",
      "\n",
      "\n",
      "Epoch: 1505\n",
      "Train Log likelihood, step 245350 in nats: 0.099706\n",
      "Train Log likelihood, step 245400 in nats: 0.099717\n",
      "Train Log likelihood, step 245450 in nats: 0.099718\n",
      "Train epoch average loss: 0.09972323347176901\n",
      "\n",
      "\n",
      "Epoch: 1506\n",
      "Train Log likelihood, step 245500 in nats: 0.099723\n",
      "Train Log likelihood, step 245550 in nats: 0.099725\n",
      "Train Log likelihood, step 245600 in nats: 0.099728\n",
      "Train epoch average loss: 0.09973068039431093\n",
      "\n",
      "\n",
      "Epoch: 1507\n",
      "Train Log likelihood, step 245650 in nats: 0.099730\n",
      "Train Log likelihood, step 245700 in nats: 0.099732\n",
      "Train Log likelihood, step 245750 in nats: 0.099743\n",
      "Train Log likelihood, step 245800 in nats: 0.099757\n",
      "Train epoch average loss: 0.09975801275366628\n",
      "\n",
      "\n",
      "Epoch: 1508\n",
      "Train Log likelihood, step 245850 in nats: 0.099768\n",
      "Train Log likelihood, step 245900 in nats: 0.099769\n",
      "Train Log likelihood, step 245950 in nats: 0.099779\n",
      "Train epoch average loss: 0.09977891937121335\n",
      "\n",
      "\n",
      "Epoch: 1509\n",
      "Train Log likelihood, step 246000 in nats: 0.099782\n",
      "Train Log likelihood, step 246050 in nats: 0.099795\n",
      "Train Log likelihood, step 246100 in nats: 0.099790\n",
      "Train epoch average loss: 0.09978866871418715\n",
      "\n",
      "\n",
      "Epoch: 1510\n",
      "Train Log likelihood, step 246150 in nats: 0.099787\n",
      "Train Log likelihood, step 246200 in nats: 0.099799\n",
      "Train Log likelihood, step 246250 in nats: 0.099807\n",
      "Train epoch average loss: 0.09981311786246169\n",
      "\n",
      "\n",
      "Epoch: 1511\n",
      "Train Log likelihood, step 246300 in nats: 0.099814\n",
      "Train Log likelihood, step 246350 in nats: 0.099826\n",
      "Train Log likelihood, step 246400 in nats: 0.099835\n",
      "Train Log likelihood, step 246450 in nats: 0.099845\n",
      "Train epoch average loss: 0.09984435369205748\n",
      "\n",
      "\n",
      "Epoch: 1512\n",
      "Train Log likelihood, step 246500 in nats: 0.099846\n",
      "Train Log likelihood, step 246550 in nats: 0.099860\n",
      "Train Log likelihood, step 246600 in nats: 0.099870\n",
      "Train epoch average loss: 0.09986619906214465\n",
      "\n",
      "\n",
      "Epoch: 1513\n",
      "Train Log likelihood, step 246650 in nats: 0.099863\n",
      "Train Log likelihood, step 246700 in nats: 0.099873\n",
      "Train Log likelihood, step 246750 in nats: 0.099880\n",
      "Train epoch average loss: 0.0998866039520674\n",
      "\n",
      "\n",
      "Epoch: 1514\n",
      "Train Log likelihood, step 246800 in nats: 0.099891\n",
      "Train Log likelihood, step 246850 in nats: 0.099896\n",
      "Train Log likelihood, step 246900 in nats: 0.099909\n",
      "Train epoch average loss: 0.09991821698856139\n",
      "\n",
      "\n",
      "Epoch: 1515\n",
      "Train Log likelihood, step 246950 in nats: 0.099919\n",
      "Train Log likelihood, step 247000 in nats: 0.099919\n",
      "Train Log likelihood, step 247050 in nats: 0.099920\n",
      "Train Log likelihood, step 247100 in nats: 0.099931\n",
      "Train epoch average loss: 0.09993074134471966\n",
      "\n",
      "\n",
      "Epoch: 1516\n",
      "Train Log likelihood, step 247150 in nats: 0.099941\n",
      "Train Log likelihood, step 247200 in nats: 0.099947\n",
      "Train Log likelihood, step 247250 in nats: 0.099953\n",
      "Train epoch average loss: 0.09995670062078818\n",
      "\n",
      "\n",
      "Epoch: 1517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 247300 in nats: 0.099966\n",
      "Train Log likelihood, step 247350 in nats: 0.099973\n",
      "Train Log likelihood, step 247400 in nats: 0.099981\n",
      "Train epoch average loss: 0.09998716533977892\n",
      "\n",
      "\n",
      "Epoch: 1518\n",
      "Train Log likelihood, step 247450 in nats: 0.099990\n",
      "Train Log likelihood, step 247500 in nats: 0.099997\n",
      "Train Log likelihood, step 247550 in nats: 0.100006\n",
      "Train epoch average loss: 0.1000138622561492\n",
      "\n",
      "\n",
      "Epoch: 1519\n",
      "Train Log likelihood, step 247600 in nats: 0.100015\n",
      "Train Log likelihood, step 247650 in nats: 0.100017\n",
      "Train Log likelihood, step 247700 in nats: 0.100021\n",
      "Train Log likelihood, step 247750 in nats: 0.100026\n",
      "Train epoch average loss: 0.10002800850583952\n",
      "\n",
      "\n",
      "Epoch: 1520\n",
      "Train Log likelihood, step 247800 in nats: 0.100036\n",
      "Train Log likelihood, step 247850 in nats: 0.100042\n",
      "Train Log likelihood, step 247900 in nats: 0.100049\n",
      "Train epoch average loss: 0.1000487962927175\n",
      "\n",
      "\n",
      "Epoch: 1521\n",
      "Train Log likelihood, step 247950 in nats: 0.100052\n",
      "Train Log likelihood, step 248000 in nats: 0.100057\n",
      "Train Log likelihood, step 248050 in nats: 0.100060\n",
      "Train epoch average loss: 0.10005819367737039\n",
      "\n",
      "\n",
      "Epoch: 1522\n",
      "Train Log likelihood, step 248100 in nats: 0.100058\n",
      "Train Log likelihood, step 248150 in nats: 0.100073\n",
      "Train Log likelihood, step 248200 in nats: 0.100077\n",
      "Train epoch average loss: 0.10007839517278767\n",
      "\n",
      "\n",
      "Epoch: 1523\n",
      "Train Log likelihood, step 248250 in nats: 0.100077\n",
      "Train Log likelihood, step 248300 in nats: 0.100088\n",
      "Train Log likelihood, step 248350 in nats: 0.100098\n",
      "Train Log likelihood, step 248400 in nats: 0.100102\n",
      "Train epoch average loss: 0.10010487160830447\n",
      "\n",
      "\n",
      "Epoch: 1524\n",
      "Train Log likelihood, step 248450 in nats: 0.100112\n",
      "Train Log likelihood, step 248500 in nats: 0.100121\n",
      "Train Log likelihood, step 248550 in nats: 0.100130\n",
      "Train epoch average loss: 0.10013798764882853\n",
      "\n",
      "\n",
      "Epoch: 1525\n",
      "Train Log likelihood, step 248600 in nats: 0.100145\n",
      "Train Log likelihood, step 248650 in nats: 0.100151\n",
      "Train Log likelihood, step 248700 in nats: 0.100161\n",
      "Train epoch average loss: 0.1001660079943276\n",
      "\n",
      "\n",
      "Epoch: 1526\n",
      "Train Log likelihood, step 248750 in nats: 0.100169\n",
      "Train Log likelihood, step 248800 in nats: 0.100180\n",
      "Train Log likelihood, step 248850 in nats: 0.100187\n",
      "Train Log likelihood, step 248900 in nats: 0.100200\n",
      "Train epoch average loss: 0.10020049139973923\n",
      "\n",
      "\n",
      "Epoch: 1527\n",
      "Train Log likelihood, step 248950 in nats: 0.100201\n",
      "Train Log likelihood, step 249000 in nats: 0.100211\n",
      "Train Log likelihood, step 249050 in nats: 0.100220\n",
      "Train epoch average loss: 0.10022391106058098\n",
      "\n",
      "\n",
      "Epoch: 1528\n",
      "Train Log likelihood, step 249100 in nats: 0.100231\n",
      "Train Log likelihood, step 249150 in nats: 0.100233\n",
      "Train Log likelihood, step 249200 in nats: 0.100240\n",
      "Train epoch average loss: 0.10024428969448611\n",
      "\n",
      "\n",
      "Epoch: 1529\n",
      "Train Log likelihood, step 249250 in nats: 0.100251\n",
      "Train Log likelihood, step 249300 in nats: 0.100258\n",
      "Train Log likelihood, step 249350 in nats: 0.100263\n",
      "Train epoch average loss: 0.10026605664591946\n",
      "\n",
      "\n",
      "Epoch: 1530\n",
      "Train Log likelihood, step 249400 in nats: 0.100266\n",
      "Train Log likelihood, step 249450 in nats: 0.100268\n",
      "Train Log likelihood, step 249500 in nats: 0.100283\n",
      "Train Log likelihood, step 249550 in nats: 0.100289\n",
      "Train epoch average loss: 0.10029014750028557\n",
      "\n",
      "\n",
      "Epoch: 1531\n",
      "Train Log likelihood, step 249600 in nats: 0.100298\n",
      "Train Log likelihood, step 249650 in nats: 0.100301\n",
      "Train Log likelihood, step 249700 in nats: 0.100302\n",
      "Train epoch average loss: 0.10030381863906428\n",
      "\n",
      "\n",
      "Epoch: 1532\n",
      "Train Log likelihood, step 249750 in nats: 0.100301\n",
      "Train Log likelihood, step 249800 in nats: 0.100305\n",
      "Train Log likelihood, step 249850 in nats: 0.100309\n",
      "Train epoch average loss: 0.10031274937853238\n",
      "\n",
      "\n",
      "Epoch: 1533\n",
      "Train Log likelihood, step 249900 in nats: 0.100316\n",
      "Train Log likelihood, step 249950 in nats: 0.100321\n",
      "Train Log likelihood, step 250000 in nats: 0.100332\n",
      "Train epoch average loss: 0.10033502911603388\n",
      "\n",
      "\n",
      "Epoch: 1534\n",
      "Train Log likelihood, step 250050 in nats: 0.100334\n",
      "Train Log likelihood, step 250100 in nats: 0.100336\n",
      "Train Log likelihood, step 250150 in nats: 0.100335\n",
      "Train Log likelihood, step 250200 in nats: 0.100341\n",
      "Train epoch average loss: 0.10034202729629607\n",
      "\n",
      "\n",
      "Epoch: 1535\n",
      "Train Log likelihood, step 250250 in nats: 0.100351\n",
      "Train Log likelihood, step 250300 in nats: 0.100359\n",
      "Train Log likelihood, step 250350 in nats: 0.100363\n",
      "Train epoch average loss: 0.1003630440146718\n",
      "\n",
      "\n",
      "Epoch: 1536\n",
      "Train Log likelihood, step 250400 in nats: 0.100370\n",
      "Train Log likelihood, step 250450 in nats: 0.100380\n",
      "Train Log likelihood, step 250500 in nats: 0.100390\n",
      "Train epoch average loss: 0.10039580225570378\n",
      "\n",
      "\n",
      "Epoch: 1537\n",
      "Train Log likelihood, step 250550 in nats: 0.100395\n",
      "Train Log likelihood, step 250600 in nats: 0.100405\n",
      "Train Log likelihood, step 250650 in nats: 0.100411\n",
      "Train epoch average loss: 0.10041963043955318\n",
      "\n",
      "\n",
      "Epoch: 1538\n",
      "Train Log likelihood, step 250700 in nats: 0.100419\n",
      "Train Log likelihood, step 250750 in nats: 0.100425\n",
      "Train Log likelihood, step 250800 in nats: 0.100426\n",
      "Train Log likelihood, step 250850 in nats: 0.100434\n",
      "Train epoch average loss: 0.10043417808160955\n",
      "\n",
      "\n",
      "Epoch: 1539\n",
      "Train Log likelihood, step 250900 in nats: 0.100435\n",
      "Train Log likelihood, step 250950 in nats: 0.100440\n",
      "Train Log likelihood, step 251000 in nats: 0.100442\n",
      "Train epoch average loss: 0.10044101578391035\n",
      "\n",
      "\n",
      "Epoch: 1540\n",
      "Train Log likelihood, step 251050 in nats: 0.100448\n",
      "Train Log likelihood, step 251100 in nats: 0.100444\n",
      "Train Log likelihood, step 251150 in nats: 0.100443\n",
      "Train epoch average loss: 0.10045166404470911\n",
      "\n",
      "\n",
      "Epoch: 1541\n",
      "Train Log likelihood, step 251200 in nats: 0.100454\n",
      "Train Log likelihood, step 251250 in nats: 0.100464\n",
      "Train Log likelihood, step 251300 in nats: 0.100469\n",
      "Train epoch average loss: 0.10047951206550547\n",
      "\n",
      "\n",
      "Epoch: 1542\n",
      "Train Log likelihood, step 251350 in nats: 0.100480\n",
      "Train Log likelihood, step 251400 in nats: 0.100485\n",
      "Train Log likelihood, step 251450 in nats: 0.100483\n",
      "Train Log likelihood, step 251500 in nats: 0.100492\n",
      "Train epoch average loss: 0.10049096735137218\n",
      "\n",
      "\n",
      "Epoch: 1543\n",
      "Train Log likelihood, step 251550 in nats: 0.100497\n",
      "Train Log likelihood, step 251600 in nats: 0.100499\n",
      "Train Log likelihood, step 251650 in nats: 0.100504\n",
      "Train epoch average loss: 0.10050428025912944\n",
      "\n",
      "\n",
      "Epoch: 1544\n",
      "Train Log likelihood, step 251700 in nats: 0.100507\n",
      "Train Log likelihood, step 251750 in nats: 0.100515\n",
      "Train Log likelihood, step 251800 in nats: 0.100522\n",
      "Train epoch average loss: 0.10052728893381005\n",
      "\n",
      "\n",
      "Epoch: 1545\n",
      "Train Log likelihood, step 251850 in nats: 0.100532\n",
      "Train Log likelihood, step 251900 in nats: 0.100536\n",
      "Train Log likelihood, step 251950 in nats: 0.100542\n",
      "Train epoch average loss: 0.10054808638613581\n",
      "\n",
      "\n",
      "Epoch: 1546\n",
      "Train Log likelihood, step 252000 in nats: 0.100549\n",
      "Train Log likelihood, step 252050 in nats: 0.100556\n",
      "Train Log likelihood, step 252100 in nats: 0.100569\n",
      "Train Log likelihood, step 252150 in nats: 0.100573\n",
      "Train epoch average loss: 0.1005740031768077\n",
      "\n",
      "\n",
      "Epoch: 1547\n",
      "Train Log likelihood, step 252200 in nats: 0.100584\n",
      "Train Log likelihood, step 252250 in nats: 0.100593\n",
      "Train Log likelihood, step 252300 in nats: 0.100600\n",
      "Train epoch average loss: 0.10060403805515754\n",
      "\n",
      "\n",
      "Epoch: 1548\n",
      "Train Log likelihood, step 252350 in nats: 0.100606\n",
      "Train Log likelihood, step 252400 in nats: 0.100616\n",
      "Train Log likelihood, step 252450 in nats: 0.100625\n",
      "Train epoch average loss: 0.10062664053084619\n",
      "\n",
      "\n",
      "Epoch: 1549\n",
      "Train Log likelihood, step 252500 in nats: 0.100630\n",
      "Train Log likelihood, step 252550 in nats: 0.100640\n",
      "Train Log likelihood, step 252600 in nats: 0.100648\n",
      "Train epoch average loss: 0.10065750349544844\n",
      "\n",
      "\n",
      "Epoch: 1550\n",
      "Train Log likelihood, step 252650 in nats: 0.100658\n",
      "Train Log likelihood, step 252700 in nats: 0.100662\n",
      "Train Log likelihood, step 252750 in nats: 0.100670\n",
      "Train Log likelihood, step 252800 in nats: 0.100673\n",
      "Train epoch average loss: 0.10067855538125978\n",
      "\n",
      "\n",
      "Epoch: 1551\n",
      "Train Log likelihood, step 252850 in nats: 0.100682\n",
      "Train Log likelihood, step 252900 in nats: 0.100690\n",
      "Train Log likelihood, step 252950 in nats: 0.100689\n",
      "Train epoch average loss: 0.10069673100565575\n",
      "\n",
      "\n",
      "Epoch: 1552\n",
      "Train Log likelihood, step 253000 in nats: 0.100699\n",
      "Train Log likelihood, step 253050 in nats: 0.100704\n",
      "Train Log likelihood, step 253100 in nats: 0.100715\n",
      "Train epoch average loss: 0.10071803440103055\n",
      "\n",
      "\n",
      "Epoch: 1553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 253150 in nats: 0.100715\n",
      "Train Log likelihood, step 253200 in nats: 0.100720\n",
      "Train Log likelihood, step 253250 in nats: 0.100726\n",
      "Train Log likelihood, step 253300 in nats: 0.100728\n",
      "Train epoch average loss: 0.10072878205889976\n",
      "\n",
      "\n",
      "Epoch: 1554\n",
      "Train Log likelihood, step 253350 in nats: 0.100739\n",
      "Train Log likelihood, step 253400 in nats: 0.100750\n",
      "Train Log likelihood, step 253450 in nats: 0.100755\n",
      "Train epoch average loss: 0.10075936404877744\n",
      "\n",
      "\n",
      "Epoch: 1555\n",
      "Train Log likelihood, step 253500 in nats: 0.100763\n",
      "Train Log likelihood, step 253550 in nats: 0.100764\n",
      "Train Log likelihood, step 253600 in nats: 0.100770\n",
      "Train epoch average loss: 0.100772380814683\n",
      "\n",
      "\n",
      "Epoch: 1556\n",
      "Train Log likelihood, step 253650 in nats: 0.100776\n",
      "Train Log likelihood, step 253700 in nats: 0.100776\n",
      "Train Log likelihood, step 253750 in nats: 0.100783\n",
      "Train epoch average loss: 0.10078928954174166\n",
      "\n",
      "\n",
      "Epoch: 1557\n",
      "Train Log likelihood, step 253800 in nats: 0.100791\n",
      "Train Log likelihood, step 253850 in nats: 0.100798\n",
      "Train Log likelihood, step 253900 in nats: 0.100809\n",
      "Train Log likelihood, step 253950 in nats: 0.100811\n",
      "Train epoch average loss: 0.10080865231894975\n",
      "\n",
      "\n",
      "Epoch: 1558\n",
      "Train Log likelihood, step 254000 in nats: 0.100808\n",
      "Train Log likelihood, step 254050 in nats: 0.100818\n",
      "Train Log likelihood, step 254100 in nats: 0.100823\n",
      "Train epoch average loss: 0.10082435702115843\n",
      "\n",
      "\n",
      "Epoch: 1559\n",
      "Train Log likelihood, step 254150 in nats: 0.100826\n",
      "Train Log likelihood, step 254200 in nats: 0.100834\n",
      "Train Log likelihood, step 254250 in nats: 0.100834\n",
      "Train epoch average loss: 0.1008339290173226\n",
      "\n",
      "\n",
      "Epoch: 1560\n",
      "Train Log likelihood, step 254300 in nats: 0.100838\n",
      "Train Log likelihood, step 254350 in nats: 0.100850\n",
      "Train Log likelihood, step 254400 in nats: 0.100853\n",
      "Train epoch average loss: 0.10085738093772811\n",
      "\n",
      "\n",
      "Epoch: 1561\n",
      "Train Log likelihood, step 254450 in nats: 0.100858\n",
      "Train Log likelihood, step 254500 in nats: 0.100865\n",
      "Train Log likelihood, step 254550 in nats: 0.100868\n",
      "Train Log likelihood, step 254600 in nats: 0.100877\n",
      "Train epoch average loss: 0.10087879008840789\n",
      "\n",
      "\n",
      "Epoch: 1562\n",
      "Train Log likelihood, step 254650 in nats: 0.100879\n",
      "Train Log likelihood, step 254700 in nats: 0.100881\n",
      "Train Log likelihood, step 254750 in nats: 0.100884\n",
      "Train epoch average loss: 0.10088863064160086\n",
      "\n",
      "\n",
      "Epoch: 1563\n",
      "Train Log likelihood, step 254800 in nats: 0.100890\n",
      "Train Log likelihood, step 254850 in nats: 0.100900\n",
      "Train Log likelihood, step 254900 in nats: 0.100912\n",
      "Train epoch average loss: 0.10091138573489199\n",
      "\n",
      "\n",
      "Epoch: 1564\n",
      "Train Log likelihood, step 254950 in nats: 0.100914\n",
      "Train Log likelihood, step 255000 in nats: 0.100921\n",
      "Train Log likelihood, step 255050 in nats: 0.100925\n",
      "Train epoch average loss: 0.10092511838570496\n",
      "\n",
      "\n",
      "Epoch: 1565\n",
      "Train Log likelihood, step 255100 in nats: 0.100927\n",
      "Train Log likelihood, step 255150 in nats: 0.100929\n",
      "Train Log likelihood, step 255200 in nats: 0.100934\n",
      "Train Log likelihood, step 255250 in nats: 0.100943\n",
      "Train epoch average loss: 0.10094168353783184\n",
      "\n",
      "\n",
      "Epoch: 1566\n",
      "Train Log likelihood, step 255300 in nats: 0.100946\n",
      "Train Log likelihood, step 255350 in nats: 0.100949\n",
      "Train Log likelihood, step 255400 in nats: 0.100955\n",
      "Train epoch average loss: 0.10095488107705834\n",
      "\n",
      "\n",
      "Epoch: 1567\n",
      "Train Log likelihood, step 255450 in nats: 0.100955\n",
      "Train Log likelihood, step 255500 in nats: 0.100957\n",
      "Train Log likelihood, step 255550 in nats: 0.100952\n",
      "Train epoch average loss: 0.10095625443362835\n",
      "\n",
      "\n",
      "Epoch: 1568\n",
      "Train Log likelihood, step 255600 in nats: 0.100959\n",
      "Train Log likelihood, step 255650 in nats: 0.100961\n",
      "Train Log likelihood, step 255700 in nats: 0.100967\n",
      "Train epoch average loss: 0.10097113162709011\n",
      "\n",
      "\n",
      "Epoch: 1569\n",
      "Train Log likelihood, step 255750 in nats: 0.100970\n",
      "Train Log likelihood, step 255800 in nats: 0.100971\n",
      "Train Log likelihood, step 255850 in nats: 0.100976\n",
      "Train Log likelihood, step 255900 in nats: 0.100988\n",
      "Train epoch average loss: 0.10099004943841348\n",
      "\n",
      "\n",
      "Epoch: 1570\n",
      "Train Log likelihood, step 255950 in nats: 0.100991\n",
      "Train Log likelihood, step 256000 in nats: 0.100996\n",
      "Train Log likelihood, step 256050 in nats: 0.101006\n",
      "Train epoch average loss: 0.10101018171703127\n",
      "\n",
      "\n",
      "Epoch: 1571\n",
      "Train Log likelihood, step 256100 in nats: 0.101011\n",
      "Train Log likelihood, step 256150 in nats: 0.101013\n",
      "Train Log likelihood, step 256200 in nats: 0.101023\n",
      "Train epoch average loss: 0.10103129328828282\n",
      "\n",
      "\n",
      "Epoch: 1572\n",
      "Train Log likelihood, step 256250 in nats: 0.101032\n",
      "Train Log likelihood, step 256300 in nats: 0.101037\n",
      "Train Log likelihood, step 256350 in nats: 0.101042\n",
      "Train epoch average loss: 0.10105266439129826\n",
      "\n",
      "\n",
      "Epoch: 1573\n",
      "Train Log likelihood, step 256400 in nats: 0.101052\n",
      "Train Log likelihood, step 256450 in nats: 0.101060\n",
      "Train Log likelihood, step 256500 in nats: 0.101059\n",
      "Train Log likelihood, step 256550 in nats: 0.101069\n",
      "Train epoch average loss: 0.10107185081329466\n",
      "\n",
      "\n",
      "Epoch: 1574\n",
      "Train Log likelihood, step 256600 in nats: 0.101073\n",
      "Train Log likelihood, step 256650 in nats: 0.101079\n",
      "Train Log likelihood, step 256700 in nats: 0.101086\n",
      "Train epoch average loss: 0.10108828000507068\n",
      "\n",
      "\n",
      "Epoch: 1575\n",
      "Train Log likelihood, step 256750 in nats: 0.101091\n",
      "Train Log likelihood, step 256800 in nats: 0.101100\n",
      "Train Log likelihood, step 256850 in nats: 0.101102\n",
      "Train epoch average loss: 0.10110460736697706\n",
      "\n",
      "\n",
      "Epoch: 1576\n",
      "Train Log likelihood, step 256900 in nats: 0.101104\n",
      "Train Log likelihood, step 256950 in nats: 0.101116\n",
      "Train Log likelihood, step 257000 in nats: 0.101121\n",
      "Train Log likelihood, step 257050 in nats: 0.101124\n",
      "Train epoch average loss: 0.10112372692434239\n",
      "\n",
      "\n",
      "Epoch: 1577\n",
      "Train Log likelihood, step 257100 in nats: 0.101134\n",
      "Train Log likelihood, step 257150 in nats: 0.101142\n",
      "Train Log likelihood, step 257200 in nats: 0.101146\n",
      "Train epoch average loss: 0.10114824248235885\n",
      "\n",
      "\n",
      "Epoch: 1578\n",
      "Train Log likelihood, step 257250 in nats: 0.101152\n",
      "Train Log likelihood, step 257300 in nats: 0.101151\n",
      "Train Log likelihood, step 257350 in nats: 0.101163\n",
      "Train epoch average loss: 0.1011656667447148\n",
      "\n",
      "\n",
      "Epoch: 1579\n",
      "Train Log likelihood, step 257400 in nats: 0.101167\n",
      "Train Log likelihood, step 257450 in nats: 0.101179\n",
      "Train Log likelihood, step 257500 in nats: 0.101185\n",
      "Train epoch average loss: 0.10118678899503196\n",
      "\n",
      "\n",
      "Epoch: 1580\n",
      "Train Log likelihood, step 257550 in nats: 0.101191\n",
      "Train Log likelihood, step 257600 in nats: 0.101203\n",
      "Train Log likelihood, step 257650 in nats: 0.101212\n",
      "Train Log likelihood, step 257700 in nats: 0.101222\n",
      "Train epoch average loss: 0.10122218537733674\n",
      "\n",
      "\n",
      "Epoch: 1581\n",
      "Train Log likelihood, step 257750 in nats: 0.101223\n",
      "Train Log likelihood, step 257800 in nats: 0.101232\n",
      "Train Log likelihood, step 257850 in nats: 0.101237\n",
      "Train epoch average loss: 0.10124091801858988\n",
      "\n",
      "\n",
      "Epoch: 1582\n",
      "Train Log likelihood, step 257900 in nats: 0.101240\n",
      "Train Log likelihood, step 257950 in nats: 0.101240\n",
      "Train Log likelihood, step 258000 in nats: 0.101250\n",
      "Train epoch average loss: 0.1012533936895229\n",
      "\n",
      "\n",
      "Epoch: 1583\n",
      "Train Log likelihood, step 258050 in nats: 0.101256\n",
      "Train Log likelihood, step 258100 in nats: 0.101262\n",
      "Train Log likelihood, step 258150 in nats: 0.101272\n",
      "Train epoch average loss: 0.101283179461108\n",
      "\n",
      "\n",
      "Epoch: 1584\n",
      "Train Log likelihood, step 258200 in nats: 0.101285\n",
      "Train Log likelihood, step 258250 in nats: 0.101289\n",
      "Train Log likelihood, step 258300 in nats: 0.101295\n",
      "Train Log likelihood, step 258350 in nats: 0.101295\n",
      "Train epoch average loss: 0.10129518631904111\n",
      "\n",
      "\n",
      "Epoch: 1585\n",
      "Train Log likelihood, step 258400 in nats: 0.101301\n",
      "Train Log likelihood, step 258450 in nats: 0.101309\n",
      "Train Log likelihood, step 258500 in nats: 0.101316\n",
      "Train epoch average loss: 0.10132216589734352\n",
      "\n",
      "\n",
      "Epoch: 1586\n",
      "Train Log likelihood, step 258550 in nats: 0.101325\n",
      "Train Log likelihood, step 258600 in nats: 0.101331\n",
      "Train Log likelihood, step 258650 in nats: 0.101342\n",
      "Train epoch average loss: 0.10134472299888748\n",
      "\n",
      "\n",
      "Epoch: 1587\n",
      "Train Log likelihood, step 258700 in nats: 0.101344\n",
      "Train Log likelihood, step 258750 in nats: 0.101347\n",
      "Train Log likelihood, step 258800 in nats: 0.101358\n",
      "Train epoch average loss: 0.10136168486463053\n",
      "\n",
      "\n",
      "Epoch: 1588\n",
      "Train Log likelihood, step 258850 in nats: 0.101361\n",
      "Train Log likelihood, step 258900 in nats: 0.101364\n",
      "Train Log likelihood, step 258950 in nats: 0.101374\n",
      "Train Log likelihood, step 259000 in nats: 0.101381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch average loss: 0.10138214373638586\n",
      "\n",
      "\n",
      "Epoch: 1589\n",
      "Train Log likelihood, step 259050 in nats: 0.101388\n",
      "Train Log likelihood, step 259100 in nats: 0.101396\n",
      "Train Log likelihood, step 259150 in nats: 0.101397\n",
      "Train epoch average loss: 0.1013972539013975\n",
      "\n",
      "\n",
      "Epoch: 1590\n",
      "Train Log likelihood, step 259200 in nats: 0.101405\n",
      "Train Log likelihood, step 259250 in nats: 0.101415\n",
      "Train Log likelihood, step 259300 in nats: 0.101422\n",
      "Train epoch average loss: 0.10142810389181739\n",
      "\n",
      "\n",
      "Epoch: 1591\n",
      "Train Log likelihood, step 259350 in nats: 0.101432\n",
      "Train Log likelihood, step 259400 in nats: 0.101441\n",
      "Train Log likelihood, step 259450 in nats: 0.101445\n",
      "Train epoch average loss: 0.10145525264463515\n",
      "\n",
      "\n",
      "Epoch: 1592\n",
      "Train Log likelihood, step 259500 in nats: 0.101455\n",
      "Train Log likelihood, step 259550 in nats: 0.101456\n",
      "Train Log likelihood, step 259600 in nats: 0.101461\n",
      "Train Log likelihood, step 259650 in nats: 0.101469\n",
      "Train epoch average loss: 0.10147116399143274\n",
      "\n",
      "\n",
      "Epoch: 1593\n",
      "Train Log likelihood, step 259700 in nats: 0.101476\n",
      "Train Log likelihood, step 259750 in nats: 0.101478\n",
      "Train Log likelihood, step 259800 in nats: 0.101480\n",
      "Train epoch average loss: 0.10147714160003209\n",
      "\n",
      "\n",
      "Epoch: 1594\n",
      "Train Log likelihood, step 259850 in nats: 0.101485\n",
      "Train Log likelihood, step 259900 in nats: 0.101496\n",
      "Train Log likelihood, step 259950 in nats: 0.101504\n",
      "Train epoch average loss: 0.1015090086081798\n",
      "\n",
      "\n",
      "Epoch: 1595\n",
      "Train Log likelihood, step 260000 in nats: 0.101513\n",
      "Train Log likelihood, step 260050 in nats: 0.101516\n",
      "Train Log likelihood, step 260100 in nats: 0.101526\n",
      "Train epoch average loss: 0.10153875341967752\n",
      "\n",
      "\n",
      "Epoch: 1596\n",
      "Train Log likelihood, step 260150 in nats: 0.101540\n",
      "Train Log likelihood, step 260200 in nats: 0.101553\n",
      "Train Log likelihood, step 260250 in nats: 0.101556\n",
      "Train Log likelihood, step 260300 in nats: 0.101561\n",
      "Train epoch average loss: 0.10156005302160236\n",
      "\n",
      "\n",
      "Epoch: 1597\n",
      "Train Log likelihood, step 260350 in nats: 0.101559\n",
      "Train Log likelihood, step 260400 in nats: 0.101562\n",
      "Train Log likelihood, step 260450 in nats: 0.101572\n",
      "Train epoch average loss: 0.10157732407647882\n",
      "\n",
      "\n",
      "Epoch: 1598\n",
      "Train Log likelihood, step 260500 in nats: 0.101580\n",
      "Train Log likelihood, step 260550 in nats: 0.101572\n",
      "Train Log likelihood, step 260600 in nats: 0.101575\n",
      "Train epoch average loss: 0.10157640520443544\n",
      "\n",
      "\n",
      "Epoch: 1599\n",
      "Train Log likelihood, step 260650 in nats: 0.101577\n",
      "Train Log likelihood, step 260700 in nats: 0.101586\n",
      "Train Log likelihood, step 260750 in nats: 0.101593\n",
      "Train epoch average loss: 0.10159920021993922\n",
      "\n",
      "\n",
      "Epoch: 1600\n",
      "Train Log likelihood, step 260800 in nats: 0.101600\n",
      "Train Log likelihood, step 260850 in nats: 0.101615\n",
      "Train Log likelihood, step 260900 in nats: 0.101627\n",
      "Train Log likelihood, step 260950 in nats: 0.101632\n",
      "Train epoch average loss: 0.10163265712242643\n",
      "\n",
      "\n",
      "Epoch: 1601\n",
      "Train Log likelihood, step 261000 in nats: 0.101640\n",
      "Train Log likelihood, step 261050 in nats: 0.101645\n",
      "Train Log likelihood, step 261100 in nats: 0.101656\n",
      "Train epoch average loss: 0.10165505245533998\n",
      "\n",
      "\n",
      "Epoch: 1602\n",
      "Train Log likelihood, step 261150 in nats: 0.101660\n",
      "Train Log likelihood, step 261200 in nats: 0.101668\n",
      "Train Log likelihood, step 261250 in nats: 0.101671\n",
      "Train epoch average loss: 0.10167350776832523\n",
      "\n",
      "\n",
      "Epoch: 1603\n",
      "Train Log likelihood, step 261300 in nats: 0.101676\n",
      "Train Log likelihood, step 261350 in nats: 0.101686\n",
      "Train Log likelihood, step 261400 in nats: 0.101694\n",
      "Train Log likelihood, step 261450 in nats: 0.101707\n",
      "Train epoch average loss: 0.10170705236400178\n",
      "\n",
      "\n",
      "Epoch: 1604\n",
      "Train Log likelihood, step 261500 in nats: 0.101710\n",
      "Train Log likelihood, step 261550 in nats: 0.101711\n",
      "Train Log likelihood, step 261600 in nats: 0.101710\n",
      "Train epoch average loss: 0.10171278633961178\n",
      "\n",
      "\n",
      "Epoch: 1605\n",
      "Train Log likelihood, step 261650 in nats: 0.101712\n",
      "Train Log likelihood, step 261700 in nats: 0.101720\n",
      "Train Log likelihood, step 261750 in nats: 0.101727\n",
      "Train epoch average loss: 0.10173077636612606\n",
      "\n",
      "\n",
      "Epoch: 1606\n",
      "Train Log likelihood, step 261800 in nats: 0.101737\n",
      "Train Log likelihood, step 261850 in nats: 0.101751\n",
      "Train Log likelihood, step 261900 in nats: 0.101757\n",
      "Train epoch average loss: 0.10176201279705778\n",
      "\n",
      "\n",
      "Epoch: 1607\n",
      "Train Log likelihood, step 261950 in nats: 0.101765\n",
      "Train Log likelihood, step 262000 in nats: 0.101768\n",
      "Train Log likelihood, step 262050 in nats: 0.101771\n",
      "Train Log likelihood, step 262100 in nats: 0.101776\n",
      "Train epoch average loss: 0.10177760100894605\n",
      "\n",
      "\n",
      "Epoch: 1608\n",
      "Train Log likelihood, step 262150 in nats: 0.101781\n",
      "Train Log likelihood, step 262200 in nats: 0.101786\n",
      "Train Log likelihood, step 262250 in nats: 0.101784\n",
      "Train epoch average loss: 0.10178380134333737\n",
      "\n",
      "\n",
      "Epoch: 1609\n",
      "Train Log likelihood, step 262300 in nats: 0.101788\n",
      "Train Log likelihood, step 262350 in nats: 0.101792\n",
      "Train Log likelihood, step 262400 in nats: 0.101795\n",
      "Train epoch average loss: 0.10179934410494783\n",
      "\n",
      "\n",
      "Epoch: 1610\n",
      "Train Log likelihood, step 262450 in nats: 0.101797\n",
      "Train Log likelihood, step 262500 in nats: 0.101802\n",
      "Train Log likelihood, step 262550 in nats: 0.101799\n",
      "Train epoch average loss: 0.10180702352022748\n",
      "\n",
      "\n",
      "Epoch: 1611\n",
      "Train Log likelihood, step 262600 in nats: 0.101806\n",
      "Train Log likelihood, step 262650 in nats: 0.101816\n",
      "Train Log likelihood, step 262700 in nats: 0.101827\n",
      "Train Log likelihood, step 262750 in nats: 0.101835\n",
      "Train epoch average loss: 0.10183491580560548\n",
      "\n",
      "\n",
      "Epoch: 1612\n",
      "Train Log likelihood, step 262800 in nats: 0.101838\n",
      "Train Log likelihood, step 262850 in nats: 0.101840\n",
      "Train Log likelihood, step 262900 in nats: 0.101839\n",
      "Train epoch average loss: 0.1018411945794923\n",
      "\n",
      "\n",
      "Epoch: 1613\n",
      "Train Log likelihood, step 262950 in nats: 0.101848\n",
      "Train Log likelihood, step 263000 in nats: 0.101849\n",
      "Train Log likelihood, step 263050 in nats: 0.101852\n",
      "Train epoch average loss: 0.10185880415333579\n",
      "\n",
      "\n",
      "Epoch: 1614\n",
      "Train Log likelihood, step 263100 in nats: 0.101865\n",
      "Train Log likelihood, step 263150 in nats: 0.101873\n",
      "Train Log likelihood, step 263200 in nats: 0.101881\n",
      "Train epoch average loss: 0.10188708642606503\n",
      "\n",
      "\n",
      "Epoch: 1615\n",
      "Train Log likelihood, step 263250 in nats: 0.101888\n",
      "Train Log likelihood, step 263300 in nats: 0.101899\n",
      "Train Log likelihood, step 263350 in nats: 0.101906\n",
      "Train Log likelihood, step 263400 in nats: 0.101919\n",
      "Train epoch average loss: 0.1019210257067575\n",
      "\n",
      "\n",
      "Epoch: 1616\n",
      "Train Log likelihood, step 263450 in nats: 0.101933\n",
      "Train Log likelihood, step 263500 in nats: 0.101938\n",
      "Train Log likelihood, step 263550 in nats: 0.101940\n",
      "Train epoch average loss: 0.10194551656112613\n",
      "\n",
      "\n",
      "Epoch: 1617\n",
      "Train Log likelihood, step 263600 in nats: 0.101950\n",
      "Train Log likelihood, step 263650 in nats: 0.101945\n",
      "Train Log likelihood, step 263700 in nats: 0.101953\n",
      "Train epoch average loss: 0.10195607392950831\n",
      "\n",
      "\n",
      "Epoch: 1618\n",
      "Train Log likelihood, step 263750 in nats: 0.101958\n",
      "Train Log likelihood, step 263800 in nats: 0.101966\n",
      "Train Log likelihood, step 263850 in nats: 0.101973\n",
      "Train epoch average loss: 0.10197890615497894\n",
      "\n",
      "\n",
      "Epoch: 1619\n",
      "Train Log likelihood, step 263900 in nats: 0.101979\n",
      "Train Log likelihood, step 263950 in nats: 0.101987\n",
      "Train Log likelihood, step 264000 in nats: 0.101995\n",
      "Train Log likelihood, step 264050 in nats: 0.102005\n",
      "Train epoch average loss: 0.10200486926047876\n",
      "\n",
      "\n",
      "Epoch: 1620\n",
      "Train Log likelihood, step 264100 in nats: 0.102011\n",
      "Train Log likelihood, step 264150 in nats: 0.102018\n",
      "Train Log likelihood, step 264200 in nats: 0.102029\n",
      "Train epoch average loss: 0.10203096115477017\n",
      "\n",
      "\n",
      "Epoch: 1621\n",
      "Train Log likelihood, step 264250 in nats: 0.102036\n",
      "Train Log likelihood, step 264300 in nats: 0.102044\n",
      "Train Log likelihood, step 264350 in nats: 0.102046\n",
      "Train epoch average loss: 0.10204843271369374\n",
      "\n",
      "\n",
      "Epoch: 1622\n",
      "Train Log likelihood, step 264400 in nats: 0.102051\n",
      "Train Log likelihood, step 264450 in nats: 0.102052\n",
      "Train Log likelihood, step 264500 in nats: 0.102055\n",
      "Train epoch average loss: 0.10205312661983275\n",
      "\n",
      "\n",
      "Epoch: 1623\n",
      "Train Log likelihood, step 264550 in nats: 0.102054\n",
      "Train Log likelihood, step 264600 in nats: 0.102061\n",
      "Train Log likelihood, step 264650 in nats: 0.102072\n",
      "Train Log likelihood, step 264700 in nats: 0.102086\n",
      "Train epoch average loss: 0.10208654582271144\n",
      "\n",
      "\n",
      "Epoch: 1624\n",
      "Train Log likelihood, step 264750 in nats: 0.102087\n",
      "Train Log likelihood, step 264800 in nats: 0.102091\n",
      "Train Log likelihood, step 264850 in nats: 0.102091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch average loss: 0.10209255596178127\n",
      "\n",
      "\n",
      "Epoch: 1625\n",
      "Train Log likelihood, step 264900 in nats: 0.102095\n",
      "Train Log likelihood, step 264950 in nats: 0.102098\n",
      "Train Log likelihood, step 265000 in nats: 0.102103\n",
      "Train epoch average loss: 0.10210822554517784\n",
      "\n",
      "\n",
      "Epoch: 1626\n",
      "Train Log likelihood, step 265050 in nats: 0.102111\n",
      "Train Log likelihood, step 265100 in nats: 0.102115\n",
      "Train Log likelihood, step 265150 in nats: 0.102124\n",
      "Train Log likelihood, step 265200 in nats: 0.102133\n",
      "Train epoch average loss: 0.10213290742939718\n",
      "\n",
      "\n",
      "Epoch: 1627\n",
      "Train Log likelihood, step 265250 in nats: 0.102136\n",
      "Train Log likelihood, step 265300 in nats: 0.102141\n",
      "Train Log likelihood, step 265350 in nats: 0.102150\n",
      "Train epoch average loss: 0.10215233432141228\n",
      "\n",
      "\n",
      "Epoch: 1628\n",
      "Train Log likelihood, step 265400 in nats: 0.102155\n",
      "Train Log likelihood, step 265450 in nats: 0.102152\n",
      "Train Log likelihood, step 265500 in nats: 0.102157\n",
      "Train epoch average loss: 0.1021602779186653\n",
      "\n",
      "\n",
      "Epoch: 1629\n",
      "Train Log likelihood, step 265550 in nats: 0.102163\n",
      "Train Log likelihood, step 265600 in nats: 0.102172\n",
      "Train Log likelihood, step 265650 in nats: 0.102179\n",
      "Train epoch average loss: 0.10218638834690368\n",
      "\n",
      "\n",
      "Epoch: 1630\n",
      "Train Log likelihood, step 265700 in nats: 0.102189\n",
      "Train Log likelihood, step 265750 in nats: 0.102193\n",
      "Train Log likelihood, step 265800 in nats: 0.102197\n",
      "Train Log likelihood, step 265850 in nats: 0.102205\n",
      "Train epoch average loss: 0.10220470596358\n",
      "\n",
      "\n",
      "Epoch: 1631\n",
      "Train Log likelihood, step 265900 in nats: 0.102213\n",
      "Train Log likelihood, step 265950 in nats: 0.102216\n",
      "Train Log likelihood, step 266000 in nats: 0.102223\n",
      "Train epoch average loss: 0.10222746445318938\n",
      "\n",
      "\n",
      "Epoch: 1632\n",
      "Train Log likelihood, step 266050 in nats: 0.102234\n",
      "Train Log likelihood, step 266100 in nats: 0.102236\n",
      "Train Log likelihood, step 266150 in nats: 0.102236\n",
      "Train epoch average loss: 0.10223913404893809\n",
      "\n",
      "\n",
      "Epoch: 1633\n",
      "Train Log likelihood, step 266200 in nats: 0.102240\n",
      "Train Log likelihood, step 266250 in nats: 0.102250\n",
      "Train Log likelihood, step 266300 in nats: 0.102256\n",
      "Train epoch average loss: 0.10225486633363674\n",
      "\n",
      "\n",
      "Epoch: 1634\n",
      "Train Log likelihood, step 266350 in nats: 0.102253\n",
      "Train Log likelihood, step 266400 in nats: 0.102259\n",
      "Train Log likelihood, step 266450 in nats: 0.102267\n",
      "Train Log likelihood, step 266500 in nats: 0.102276\n",
      "Train epoch average loss: 0.10227660384560909\n",
      "\n",
      "\n",
      "Epoch: 1635\n",
      "Train Log likelihood, step 266550 in nats: 0.102285\n",
      "Train Log likelihood, step 266600 in nats: 0.102293\n",
      "Train Log likelihood, step 266650 in nats: 0.102297\n",
      "Train epoch average loss: 0.10229537070541657\n",
      "\n",
      "\n",
      "Epoch: 1636\n",
      "Train Log likelihood, step 266700 in nats: 0.102296\n",
      "Train Log likelihood, step 266750 in nats: 0.102302\n",
      "Train Log likelihood, step 266800 in nats: 0.102309\n",
      "Train epoch average loss: 0.10230957625997904\n",
      "\n",
      "\n",
      "Epoch: 1637\n",
      "Train Log likelihood, step 266850 in nats: 0.102316\n",
      "Train Log likelihood, step 266900 in nats: 0.102322\n",
      "Train Log likelihood, step 266950 in nats: 0.102329\n",
      "Train epoch average loss: 0.10233381749642305\n",
      "\n",
      "\n",
      "Epoch: 1638\n",
      "Train Log likelihood, step 267000 in nats: 0.102337\n",
      "Train Log likelihood, step 267050 in nats: 0.102345\n",
      "Train Log likelihood, step 267100 in nats: 0.102350\n",
      "Train Log likelihood, step 267150 in nats: 0.102349\n",
      "Train epoch average loss: 0.10234964404250217\n",
      "\n",
      "\n",
      "Epoch: 1639\n",
      "Train Log likelihood, step 267200 in nats: 0.102361\n",
      "Train Log likelihood, step 267250 in nats: 0.102368\n",
      "Train Log likelihood, step 267300 in nats: 0.102362\n",
      "Train epoch average loss: 0.10236299613299142\n",
      "\n",
      "\n",
      "Epoch: 1640\n",
      "Train Log likelihood, step 267350 in nats: 0.102367\n",
      "Train Log likelihood, step 267400 in nats: 0.102370\n",
      "Train Log likelihood, step 267450 in nats: 0.102373\n",
      "Train epoch average loss: 0.10237628266234587\n",
      "\n",
      "\n",
      "Epoch: 1641\n",
      "Train Log likelihood, step 267500 in nats: 0.102377\n",
      "Train Log likelihood, step 267550 in nats: 0.102376\n",
      "Train Log likelihood, step 267600 in nats: 0.102383\n",
      "Train epoch average loss: 0.10238471484365554\n",
      "\n",
      "\n",
      "Epoch: 1642\n",
      "Train Log likelihood, step 267650 in nats: 0.102386\n",
      "Train Log likelihood, step 267700 in nats: 0.102386\n",
      "Train Log likelihood, step 267750 in nats: 0.102391\n",
      "Train Log likelihood, step 267800 in nats: 0.102397\n",
      "Train epoch average loss: 0.1023995097518009\n",
      "\n",
      "\n",
      "Epoch: 1643\n",
      "Train Log likelihood, step 267850 in nats: 0.102406\n",
      "Train Log likelihood, step 267900 in nats: 0.102416\n",
      "Train Log likelihood, step 267950 in nats: 0.102422\n",
      "Train epoch average loss: 0.10242352716355582\n",
      "\n",
      "\n",
      "Epoch: 1644\n",
      "Train Log likelihood, step 268000 in nats: 0.102424\n",
      "Train Log likelihood, step 268050 in nats: 0.102434\n",
      "Train Log likelihood, step 268100 in nats: 0.102439\n",
      "Train epoch average loss: 0.10245063168925746\n",
      "\n",
      "\n",
      "Epoch: 1645\n",
      "Train Log likelihood, step 268150 in nats: 0.102455\n",
      "Train Log likelihood, step 268200 in nats: 0.102467\n",
      "Train Log likelihood, step 268250 in nats: 0.102472\n",
      "Train epoch average loss: 0.10247522688805101\n",
      "\n",
      "\n",
      "Epoch: 1646\n",
      "Train Log likelihood, step 268300 in nats: 0.102476\n",
      "Train Log likelihood, step 268350 in nats: 0.102483\n",
      "Train Log likelihood, step 268400 in nats: 0.102488\n",
      "Train Log likelihood, step 268450 in nats: 0.102493\n",
      "Train epoch average loss: 0.10249365146887543\n",
      "\n",
      "\n",
      "Epoch: 1647\n",
      "Train Log likelihood, step 268500 in nats: 0.102495\n",
      "Train Log likelihood, step 268550 in nats: 0.102504\n",
      "Train Log likelihood, step 268600 in nats: 0.102511\n",
      "Train epoch average loss: 0.10251522723649964\n",
      "\n",
      "\n",
      "Epoch: 1648\n",
      "Train Log likelihood, step 268650 in nats: 0.102523\n",
      "Train Log likelihood, step 268700 in nats: 0.102526\n",
      "Train Log likelihood, step 268750 in nats: 0.102531\n",
      "Train epoch average loss: 0.10253700408373782\n",
      "\n",
      "\n",
      "Epoch: 1649\n",
      "Train Log likelihood, step 268800 in nats: 0.102541\n",
      "Train Log likelihood, step 268850 in nats: 0.102543\n",
      "Train Log likelihood, step 268900 in nats: 0.102545\n",
      "Train epoch average loss: 0.10254831697398581\n",
      "\n",
      "\n",
      "Epoch: 1650\n",
      "Train Log likelihood, step 268950 in nats: 0.102548\n",
      "Train Log likelihood, step 269000 in nats: 0.102555\n",
      "Train Log likelihood, step 269050 in nats: 0.102560\n",
      "Train Log likelihood, step 269100 in nats: 0.102559\n",
      "Train epoch average loss: 0.10255816751347507\n",
      "\n",
      "\n",
      "Epoch: 1651\n",
      "Train Log likelihood, step 269150 in nats: 0.102568\n",
      "Train Log likelihood, step 269200 in nats: 0.102575\n",
      "Train Log likelihood, step 269250 in nats: 0.102577\n",
      "Train epoch average loss: 0.10257884377259623\n",
      "\n",
      "\n",
      "Epoch: 1652\n",
      "Train Log likelihood, step 269300 in nats: 0.102581\n",
      "Train Log likelihood, step 269350 in nats: 0.102580\n",
      "Train Log likelihood, step 269400 in nats: 0.102583\n",
      "Train epoch average loss: 0.10258666449335321\n",
      "\n",
      "\n",
      "Epoch: 1653\n",
      "Train Log likelihood, step 269450 in nats: 0.102589\n",
      "Train Log likelihood, step 269500 in nats: 0.102596\n",
      "Train Log likelihood, step 269550 in nats: 0.102597\n",
      "Train Log likelihood, step 269600 in nats: 0.102602\n",
      "Train epoch average loss: 0.10260179842968055\n",
      "\n",
      "\n",
      "Epoch: 1654\n",
      "Train Log likelihood, step 269650 in nats: 0.102610\n",
      "Train Log likelihood, step 269700 in nats: 0.102617\n",
      "Train Log likelihood, step 269750 in nats: 0.102615\n",
      "Train epoch average loss: 0.10261691408051282\n",
      "\n",
      "\n",
      "Epoch: 1655\n",
      "Train Log likelihood, step 269800 in nats: 0.102617\n",
      "Train Log likelihood, step 269850 in nats: 0.102618\n",
      "Train Log likelihood, step 269900 in nats: 0.102624\n",
      "Train epoch average loss: 0.10262509295456786\n",
      "\n",
      "\n",
      "Epoch: 1656\n",
      "Train Log likelihood, step 269950 in nats: 0.102628\n",
      "Train Log likelihood, step 270000 in nats: 0.102632\n",
      "Train Log likelihood, step 270050 in nats: 0.102639\n",
      "Train epoch average loss: 0.1026410195114227\n",
      "\n",
      "\n",
      "Epoch: 1657\n",
      "Train Log likelihood, step 270100 in nats: 0.102644\n",
      "Train Log likelihood, step 270150 in nats: 0.102655\n",
      "Train Log likelihood, step 270200 in nats: 0.102670\n",
      "Train Log likelihood, step 270250 in nats: 0.102675\n",
      "Train epoch average loss: 0.10267551710742408\n",
      "\n",
      "\n",
      "Epoch: 1658\n",
      "Train Log likelihood, step 270300 in nats: 0.102677\n",
      "Train Log likelihood, step 270350 in nats: 0.102688\n",
      "Train Log likelihood, step 270400 in nats: 0.102701\n",
      "Train epoch average loss: 0.10270004405948907\n",
      "\n",
      "\n",
      "Epoch: 1659\n",
      "Train Log likelihood, step 270450 in nats: 0.102708\n",
      "Train Log likelihood, step 270500 in nats: 0.102711\n",
      "Train Log likelihood, step 270550 in nats: 0.102713\n",
      "Train epoch average loss: 0.10271383477139316\n",
      "\n",
      "\n",
      "Epoch: 1660\n",
      "Train Log likelihood, step 270600 in nats: 0.102716\n",
      "Train Log likelihood, step 270650 in nats: 0.102720\n",
      "Train Log likelihood, step 270700 in nats: 0.102723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch average loss: 0.10272060076138481\n",
      "\n",
      "\n",
      "Epoch: 1661\n",
      "Train Log likelihood, step 270750 in nats: 0.102722\n",
      "Train Log likelihood, step 270800 in nats: 0.102722\n",
      "Train Log likelihood, step 270850 in nats: 0.102731\n",
      "Train Log likelihood, step 270900 in nats: 0.102733\n",
      "Train epoch average loss: 0.10273359828256276\n",
      "\n",
      "\n",
      "Epoch: 1662\n",
      "Train Log likelihood, step 270950 in nats: 0.102741\n",
      "Train Log likelihood, step 271000 in nats: 0.102755\n",
      "Train Log likelihood, step 271050 in nats: 0.102764\n",
      "Train epoch average loss: 0.10276785422601423\n",
      "\n",
      "\n",
      "Epoch: 1663\n",
      "Train Log likelihood, step 271100 in nats: 0.102770\n",
      "Train Log likelihood, step 271150 in nats: 0.102769\n",
      "Train Log likelihood, step 271200 in nats: 0.102776\n",
      "Train epoch average loss: 0.10277834427850814\n",
      "\n",
      "\n",
      "Epoch: 1664\n",
      "Train Log likelihood, step 271250 in nats: 0.102783\n",
      "Train Log likelihood, step 271300 in nats: 0.102792\n",
      "Train Log likelihood, step 271350 in nats: 0.102807\n",
      "Train epoch average loss: 0.10281210306528686\n",
      "\n",
      "\n",
      "Epoch: 1665\n",
      "Train Log likelihood, step 271400 in nats: 0.102813\n",
      "Train Log likelihood, step 271450 in nats: 0.102817\n",
      "Train Log likelihood, step 271500 in nats: 0.102824\n",
      "Train Log likelihood, step 271550 in nats: 0.102840\n",
      "Train epoch average loss: 0.10284119824252266\n",
      "\n",
      "\n",
      "Epoch: 1666\n",
      "Train Log likelihood, step 271600 in nats: 0.102849\n",
      "Train Log likelihood, step 271650 in nats: 0.102859\n",
      "Train Log likelihood, step 271700 in nats: 0.102862\n",
      "Train epoch average loss: 0.10286309233599288\n",
      "\n",
      "\n",
      "Epoch: 1667\n",
      "Train Log likelihood, step 271750 in nats: 0.102869\n",
      "Train Log likelihood, step 271800 in nats: 0.102882\n",
      "Train Log likelihood, step 271850 in nats: 0.102884\n",
      "Train epoch average loss: 0.10288724615719622\n",
      "\n",
      "\n",
      "Epoch: 1668\n",
      "Train Log likelihood, step 271900 in nats: 0.102891\n",
      "Train Log likelihood, step 271950 in nats: 0.102895\n",
      "Train Log likelihood, step 272000 in nats: 0.102906\n",
      "Train epoch average loss: 0.1029111053689564\n",
      "\n",
      "\n",
      "Epoch: 1669\n",
      "Train Log likelihood, step 272050 in nats: 0.102913\n",
      "Train Log likelihood, step 272100 in nats: 0.102918\n",
      "Train Log likelihood, step 272150 in nats: 0.102926\n",
      "Train Log likelihood, step 272200 in nats: 0.102930\n",
      "Train epoch average loss: 0.10293089416497683\n",
      "\n",
      "\n",
      "Epoch: 1670\n",
      "Train Log likelihood, step 272250 in nats: 0.102938\n",
      "Train Log likelihood, step 272300 in nats: 0.102940\n",
      "Train Log likelihood, step 272350 in nats: 0.102941\n",
      "Train epoch average loss: 0.10294813796807915\n",
      "\n",
      "\n",
      "Epoch: 1671\n",
      "Train Log likelihood, step 272400 in nats: 0.102949\n",
      "Train Log likelihood, step 272450 in nats: 0.102957\n",
      "Train Log likelihood, step 272500 in nats: 0.102968\n",
      "Train epoch average loss: 0.10297043135301738\n",
      "\n",
      "\n",
      "Epoch: 1672\n",
      "Train Log likelihood, step 272550 in nats: 0.102974\n",
      "Train Log likelihood, step 272600 in nats: 0.102979\n",
      "Train Log likelihood, step 272650 in nats: 0.102984\n",
      "Train epoch average loss: 0.10298605471004092\n",
      "\n",
      "\n",
      "Epoch: 1673\n",
      "Train Log likelihood, step 272700 in nats: 0.102986\n",
      "Train Log likelihood, step 272750 in nats: 0.102997\n",
      "Train Log likelihood, step 272800 in nats: 0.103002\n",
      "Train Log likelihood, step 272850 in nats: 0.103008\n",
      "Train epoch average loss: 0.10301173081085847\n",
      "\n",
      "\n",
      "Epoch: 1674\n",
      "Train Log likelihood, step 272900 in nats: 0.103021\n",
      "Train Log likelihood, step 272950 in nats: 0.103028\n",
      "Train Log likelihood, step 273000 in nats: 0.103031\n",
      "Train epoch average loss: 0.1030327328406717\n",
      "\n",
      "\n",
      "Epoch: 1675\n",
      "Train Log likelihood, step 273050 in nats: 0.103035\n",
      "Train Log likelihood, step 273100 in nats: 0.103045\n",
      "Train Log likelihood, step 273150 in nats: 0.103050\n",
      "Train epoch average loss: 0.1030536595033348\n",
      "\n",
      "\n",
      "Epoch: 1676\n",
      "Train Log likelihood, step 273200 in nats: 0.103058\n",
      "Train Log likelihood, step 273250 in nats: 0.103062\n",
      "Train Log likelihood, step 273300 in nats: 0.103068\n",
      "Train Log likelihood, step 273350 in nats: 0.103074\n",
      "Train epoch average loss: 0.10307445796977262\n",
      "\n",
      "\n",
      "Epoch: 1677\n",
      "Train Log likelihood, step 273400 in nats: 0.103084\n",
      "Train Log likelihood, step 273450 in nats: 0.103089\n",
      "Train Log likelihood, step 273500 in nats: 0.103096\n",
      "Train epoch average loss: 0.10309245651452799\n",
      "\n",
      "\n",
      "Epoch: 1678\n",
      "Train Log likelihood, step 273550 in nats: 0.103101\n",
      "Train Log likelihood, step 273600 in nats: 0.103111\n",
      "Train Log likelihood, step 273650 in nats: 0.103115\n",
      "Train epoch average loss: 0.1031171927187538\n",
      "\n",
      "\n",
      "Epoch: 1679\n",
      "Train Log likelihood, step 273700 in nats: 0.103119\n",
      "Train Log likelihood, step 273750 in nats: 0.103123\n",
      "Train Log likelihood, step 273800 in nats: 0.103127\n",
      "Train epoch average loss: 0.10312526787095638\n",
      "\n",
      "\n",
      "Epoch: 1680\n",
      "Train Log likelihood, step 273850 in nats: 0.103124\n",
      "Train Log likelihood, step 273900 in nats: 0.103133\n",
      "Train Log likelihood, step 273950 in nats: 0.103138\n",
      "Train Log likelihood, step 274000 in nats: 0.103147\n",
      "Train epoch average loss: 0.10314754392633764\n",
      "\n",
      "\n",
      "Epoch: 1681\n",
      "Train Log likelihood, step 274050 in nats: 0.103156\n",
      "Train Log likelihood, step 274100 in nats: 0.103157\n",
      "Train Log likelihood, step 274150 in nats: 0.103170\n",
      "Train epoch average loss: 0.10317134147138285\n",
      "\n",
      "\n",
      "Epoch: 1682\n",
      "Train Log likelihood, step 274200 in nats: 0.103174\n",
      "Train Log likelihood, step 274250 in nats: 0.103183\n",
      "Train Log likelihood, step 274300 in nats: 0.103184\n",
      "Train epoch average loss: 0.10318958270190802\n",
      "\n",
      "\n",
      "Epoch: 1683\n",
      "Train Log likelihood, step 274350 in nats: 0.103192\n",
      "Train Log likelihood, step 274400 in nats: 0.103193\n",
      "Train Log likelihood, step 274450 in nats: 0.103202\n",
      "Train epoch average loss: 0.10320168398831417\n",
      "\n",
      "\n",
      "Epoch: 1684\n",
      "Train Log likelihood, step 274500 in nats: 0.103203\n",
      "Train Log likelihood, step 274550 in nats: 0.103211\n",
      "Train Log likelihood, step 274600 in nats: 0.103218\n",
      "Train Log likelihood, step 274650 in nats: 0.103224\n",
      "Train epoch average loss: 0.10322479915641838\n",
      "\n",
      "\n",
      "Epoch: 1685\n",
      "Train Log likelihood, step 274700 in nats: 0.103234\n",
      "Train Log likelihood, step 274750 in nats: 0.103247\n",
      "Train Log likelihood, step 274800 in nats: 0.103250\n",
      "Train epoch average loss: 0.10325089374490246\n",
      "\n",
      "\n",
      "Epoch: 1686\n",
      "Train Log likelihood, step 274850 in nats: 0.103253\n",
      "Train Log likelihood, step 274900 in nats: 0.103262\n",
      "Train Log likelihood, step 274950 in nats: 0.103272\n",
      "Train epoch average loss: 0.10327694545569346\n",
      "\n",
      "\n",
      "Epoch: 1687\n",
      "Train Log likelihood, step 275000 in nats: 0.103279\n",
      "Train Log likelihood, step 275050 in nats: 0.103283\n",
      "Train Log likelihood, step 275100 in nats: 0.103291\n",
      "Train epoch average loss: 0.10329714516178769\n",
      "\n",
      "\n",
      "Epoch: 1688\n",
      "Train Log likelihood, step 275150 in nats: 0.103297\n",
      "Train Log likelihood, step 275200 in nats: 0.103306\n",
      "Train Log likelihood, step 275250 in nats: 0.103310\n",
      "Train Log likelihood, step 275300 in nats: 0.103309\n",
      "Train epoch average loss: 0.10330874872720743\n",
      "\n",
      "\n",
      "Epoch: 1689\n",
      "Train Log likelihood, step 275350 in nats: 0.103316\n",
      "Train Log likelihood, step 275400 in nats: 0.103319\n",
      "Train Log likelihood, step 275450 in nats: 0.103327\n",
      "Train epoch average loss: 0.10333354854998149\n",
      "\n",
      "\n",
      "Epoch: 1690\n",
      "Train Log likelihood, step 275500 in nats: 0.103342\n",
      "Train Log likelihood, step 275550 in nats: 0.103346\n",
      "Train Log likelihood, step 275600 in nats: 0.103345\n",
      "Train epoch average loss: 0.1033478527961049\n",
      "\n",
      "\n",
      "Epoch: 1691\n",
      "Train Log likelihood, step 275650 in nats: 0.103354\n",
      "Train Log likelihood, step 275700 in nats: 0.103363\n",
      "Train Log likelihood, step 275750 in nats: 0.103370\n",
      "Train epoch average loss: 0.10338091014320432\n",
      "\n",
      "\n",
      "Epoch: 1692\n",
      "Train Log likelihood, step 275800 in nats: 0.103381\n",
      "Train Log likelihood, step 275850 in nats: 0.103386\n",
      "Train Log likelihood, step 275900 in nats: 0.103395\n",
      "Train Log likelihood, step 275950 in nats: 0.103403\n",
      "Train epoch average loss: 0.10340495028192366\n",
      "\n",
      "\n",
      "Epoch: 1693\n",
      "Train Log likelihood, step 276000 in nats: 0.103410\n",
      "Train Log likelihood, step 276050 in nats: 0.103419\n",
      "Train Log likelihood, step 276100 in nats: 0.103424\n",
      "Train epoch average loss: 0.10342400225879295\n",
      "\n",
      "\n",
      "Epoch: 1694\n",
      "Train Log likelihood, step 276150 in nats: 0.103430\n",
      "Train Log likelihood, step 276200 in nats: 0.103438\n",
      "Train Log likelihood, step 276250 in nats: 0.103442\n",
      "Train epoch average loss: 0.10344728634376833\n",
      "\n",
      "\n",
      "Epoch: 1695\n",
      "Train Log likelihood, step 276300 in nats: 0.103453\n",
      "Train Log likelihood, step 276350 in nats: 0.103461\n",
      "Train Log likelihood, step 276400 in nats: 0.103471\n",
      "Train epoch average loss: 0.10347538936484285\n",
      "\n",
      "\n",
      "Epoch: 1696\n",
      "Train Log likelihood, step 276450 in nats: 0.103475\n",
      "Train Log likelihood, step 276500 in nats: 0.103479\n",
      "Train Log likelihood, step 276550 in nats: 0.103487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 276600 in nats: 0.103492\n",
      "Train epoch average loss: 0.1034936151054484\n",
      "\n",
      "\n",
      "Epoch: 1697\n",
      "Train Log likelihood, step 276650 in nats: 0.103496\n",
      "Train Log likelihood, step 276700 in nats: 0.103505\n",
      "Train Log likelihood, step 276750 in nats: 0.103514\n",
      "Train epoch average loss: 0.10351674482181186\n",
      "\n",
      "\n",
      "Epoch: 1698\n",
      "Train Log likelihood, step 276800 in nats: 0.103519\n",
      "Train Log likelihood, step 276850 in nats: 0.103530\n",
      "Train Log likelihood, step 276900 in nats: 0.103537\n",
      "Train epoch average loss: 0.10354386551072575\n",
      "\n",
      "\n",
      "Epoch: 1699\n",
      "Train Log likelihood, step 276950 in nats: 0.103546\n",
      "Train Log likelihood, step 277000 in nats: 0.103545\n",
      "Train Log likelihood, step 277050 in nats: 0.103546\n",
      "Train epoch average loss: 0.1035554482869416\n",
      "\n",
      "\n",
      "Epoch: 1700\n",
      "Train Log likelihood, step 277100 in nats: 0.103556\n",
      "Train Log likelihood, step 277150 in nats: 0.103569\n",
      "Train Log likelihood, step 277200 in nats: 0.103579\n",
      "Train Log likelihood, step 277250 in nats: 0.103583\n",
      "Train epoch average loss: 0.10358448537641009\n",
      "\n",
      "\n",
      "Epoch: 1701\n",
      "Train Log likelihood, step 277300 in nats: 0.103590\n",
      "Train Log likelihood, step 277350 in nats: 0.103593\n",
      "Train Log likelihood, step 277400 in nats: 0.103595\n",
      "Train epoch average loss: 0.10360272098434863\n",
      "\n",
      "\n",
      "Epoch: 1702\n",
      "Train Log likelihood, step 277450 in nats: 0.103609\n",
      "Train Log likelihood, step 277500 in nats: 0.103617\n",
      "Train Log likelihood, step 277550 in nats: 0.103625\n",
      "Train epoch average loss: 0.10362754097729701\n",
      "\n",
      "\n",
      "Epoch: 1703\n",
      "Train Log likelihood, step 277600 in nats: 0.103628\n",
      "Train Log likelihood, step 277650 in nats: 0.103634\n",
      "Train Log likelihood, step 277700 in nats: 0.103639\n",
      "Train Log likelihood, step 277750 in nats: 0.103651\n",
      "Train epoch average loss: 0.10365132843875555\n",
      "\n",
      "\n",
      "Epoch: 1704\n",
      "Train Log likelihood, step 277800 in nats: 0.103654\n",
      "Train Log likelihood, step 277850 in nats: 0.103654\n",
      "Train Log likelihood, step 277900 in nats: 0.103661\n",
      "Train epoch average loss: 0.10366331669368\n",
      "\n",
      "\n",
      "Epoch: 1705\n",
      "Train Log likelihood, step 277950 in nats: 0.103667\n",
      "Train Log likelihood, step 278000 in nats: 0.103673\n",
      "Train Log likelihood, step 278050 in nats: 0.103682\n",
      "Train epoch average loss: 0.10368899025962225\n",
      "\n",
      "\n",
      "Epoch: 1706\n",
      "Train Log likelihood, step 278100 in nats: 0.103687\n",
      "Train Log likelihood, step 278150 in nats: 0.103692\n",
      "Train Log likelihood, step 278200 in nats: 0.103701\n",
      "Train epoch average loss: 0.10370836040497722\n",
      "\n",
      "\n",
      "Epoch: 1707\n",
      "Train Log likelihood, step 278250 in nats: 0.103709\n",
      "Train Log likelihood, step 278300 in nats: 0.103714\n",
      "Train Log likelihood, step 278350 in nats: 0.103722\n",
      "Train Log likelihood, step 278400 in nats: 0.103721\n",
      "Train epoch average loss: 0.10372049763118932\n",
      "\n",
      "\n",
      "Epoch: 1708\n",
      "Train Log likelihood, step 278450 in nats: 0.103729\n",
      "Train Log likelihood, step 278500 in nats: 0.103735\n",
      "Train Log likelihood, step 278550 in nats: 0.103741\n",
      "Train epoch average loss: 0.10374475939108703\n",
      "\n",
      "\n",
      "Epoch: 1709\n",
      "Train Log likelihood, step 278600 in nats: 0.103750\n",
      "Train Log likelihood, step 278650 in nats: 0.103762\n",
      "Train Log likelihood, step 278700 in nats: 0.103773\n",
      "Train epoch average loss: 0.103772888593466\n",
      "\n",
      "\n",
      "Epoch: 1710\n",
      "Train Log likelihood, step 278750 in nats: 0.103778\n",
      "Train Log likelihood, step 278800 in nats: 0.103787\n",
      "Train Log likelihood, step 278850 in nats: 0.103792\n",
      "Train epoch average loss: 0.10378922561138203\n",
      "\n",
      "\n",
      "Epoch: 1711\n",
      "Train Log likelihood, step 278900 in nats: 0.103791\n",
      "Train Log likelihood, step 278950 in nats: 0.103795\n",
      "Train Log likelihood, step 279000 in nats: 0.103795\n",
      "Train Log likelihood, step 279050 in nats: 0.103792\n",
      "Train epoch average loss: 0.10379136711717413\n",
      "\n",
      "\n",
      "Epoch: 1712\n",
      "Train Log likelihood, step 279100 in nats: 0.103796\n",
      "Train Log likelihood, step 279150 in nats: 0.103800\n",
      "Train Log likelihood, step 279200 in nats: 0.103801\n",
      "Train epoch average loss: 0.10380329410965117\n",
      "\n",
      "\n",
      "Epoch: 1713\n",
      "Train Log likelihood, step 279250 in nats: 0.103803\n",
      "Train Log likelihood, step 279300 in nats: 0.103810\n",
      "Train Log likelihood, step 279350 in nats: 0.103812\n",
      "Train epoch average loss: 0.10382058777736505\n",
      "\n",
      "\n",
      "Epoch: 1714\n",
      "Train Log likelihood, step 279400 in nats: 0.103824\n",
      "Train Log likelihood, step 279450 in nats: 0.103831\n",
      "Train Log likelihood, step 279500 in nats: 0.103841\n",
      "Train epoch average loss: 0.10384750062962832\n",
      "\n",
      "\n",
      "Epoch: 1715\n",
      "Train Log likelihood, step 279550 in nats: 0.103849\n",
      "Train Log likelihood, step 279600 in nats: 0.103858\n",
      "Train Log likelihood, step 279650 in nats: 0.103866\n",
      "Train Log likelihood, step 279700 in nats: 0.103869\n",
      "Train epoch average loss: 0.10387163209137813\n",
      "\n",
      "\n",
      "Epoch: 1716\n",
      "Train Log likelihood, step 279750 in nats: 0.103874\n",
      "Train Log likelihood, step 279800 in nats: 0.103882\n",
      "Train Log likelihood, step 279850 in nats: 0.103893\n",
      "Train epoch average loss: 0.10389290714667887\n",
      "\n",
      "\n",
      "Epoch: 1717\n",
      "Train Log likelihood, step 279900 in nats: 0.103902\n",
      "Train Log likelihood, step 279950 in nats: 0.103906\n",
      "Train Log likelihood, step 280000 in nats: 0.103909\n",
      "Train epoch average loss: 0.10391901495047509\n",
      "\n",
      "\n",
      "Epoch: 1718\n",
      "Train Log likelihood, step 280050 in nats: 0.103921\n",
      "Train Log likelihood, step 280100 in nats: 0.103931\n",
      "Train Log likelihood, step 280150 in nats: 0.103933\n",
      "Train epoch average loss: 0.10393596069420848\n",
      "\n",
      "\n",
      "Epoch: 1719\n",
      "Train Log likelihood, step 280200 in nats: 0.103936\n",
      "Train Log likelihood, step 280250 in nats: 0.103943\n",
      "Train Log likelihood, step 280300 in nats: 0.103950\n",
      "Train Log likelihood, step 280350 in nats: 0.103954\n",
      "Train epoch average loss: 0.10395550561826092\n",
      "\n",
      "\n",
      "Epoch: 1720\n",
      "Train Log likelihood, step 280400 in nats: 0.103957\n",
      "Train Log likelihood, step 280450 in nats: 0.103958\n",
      "Train Log likelihood, step 280500 in nats: 0.103955\n",
      "Train epoch average loss: 0.1039554837098488\n",
      "\n",
      "\n",
      "Epoch: 1721\n",
      "Train Log likelihood, step 280550 in nats: 0.103958\n",
      "Train Log likelihood, step 280600 in nats: 0.103953\n",
      "Train Log likelihood, step 280650 in nats: 0.103952\n",
      "Train epoch average loss: 0.10395325971750682\n",
      "\n",
      "\n",
      "Epoch: 1722\n",
      "Train Log likelihood, step 280700 in nats: 0.103955\n",
      "Train Log likelihood, step 280750 in nats: 0.103962\n",
      "Train Log likelihood, step 280800 in nats: 0.103965\n",
      "Train epoch average loss: 0.10396532624353823\n",
      "\n",
      "\n",
      "Epoch: 1723\n",
      "Train Log likelihood, step 280850 in nats: 0.103965\n",
      "Train Log likelihood, step 280900 in nats: 0.103972\n",
      "Train Log likelihood, step 280950 in nats: 0.103980\n",
      "Train Log likelihood, step 281000 in nats: 0.103985\n",
      "Train epoch average loss: 0.10398926979118582\n",
      "\n",
      "\n",
      "Epoch: 1724\n",
      "Train Log likelihood, step 281050 in nats: 0.103991\n",
      "Train Log likelihood, step 281100 in nats: 0.103999\n",
      "Train Log likelihood, step 281150 in nats: 0.103999\n",
      "Train epoch average loss: 0.1040008774178682\n",
      "\n",
      "\n",
      "Epoch: 1725\n",
      "Train Log likelihood, step 281200 in nats: 0.104006\n",
      "Train Log likelihood, step 281250 in nats: 0.104010\n",
      "Train Log likelihood, step 281300 in nats: 0.104019\n",
      "Train epoch average loss: 0.10401773010015584\n",
      "\n",
      "\n",
      "Epoch: 1726\n",
      "Train Log likelihood, step 281350 in nats: 0.104022\n",
      "Train Log likelihood, step 281400 in nats: 0.104024\n",
      "Train Log likelihood, step 281450 in nats: 0.104030\n",
      "Train Log likelihood, step 281500 in nats: 0.104033\n",
      "Train epoch average loss: 0.10403260486416294\n",
      "\n",
      "\n",
      "Epoch: 1727\n",
      "Train Log likelihood, step 281550 in nats: 0.104036\n",
      "Train Log likelihood, step 281600 in nats: 0.104038\n",
      "Train Log likelihood, step 281650 in nats: 0.104052\n",
      "Train epoch average loss: 0.10404881168418219\n",
      "\n",
      "\n",
      "Epoch: 1728\n",
      "Train Log likelihood, step 281700 in nats: 0.104051\n",
      "Train Log likelihood, step 281750 in nats: 0.104059\n",
      "Train Log likelihood, step 281800 in nats: 0.104068\n",
      "Train epoch average loss: 0.1040738889132146\n",
      "\n",
      "\n",
      "Epoch: 1729\n",
      "Train Log likelihood, step 281850 in nats: 0.104077\n",
      "Train Log likelihood, step 281900 in nats: 0.104090\n",
      "Train Log likelihood, step 281950 in nats: 0.104094\n",
      "Train epoch average loss: 0.10410253402841775\n",
      "\n",
      "\n",
      "Epoch: 1730\n",
      "Train Log likelihood, step 282000 in nats: 0.104104\n",
      "Train Log likelihood, step 282050 in nats: 0.104108\n",
      "Train Log likelihood, step 282100 in nats: 0.104114\n",
      "Train Log likelihood, step 282150 in nats: 0.104124\n",
      "Train epoch average loss: 0.10412475152348832\n",
      "\n",
      "\n",
      "Epoch: 1731\n",
      "Train Log likelihood, step 282200 in nats: 0.104129\n",
      "Train Log likelihood, step 282250 in nats: 0.104130\n",
      "Train Log likelihood, step 282300 in nats: 0.104127\n",
      "Train epoch average loss: 0.10413014000540755\n",
      "\n",
      "\n",
      "Epoch: 1732\n",
      "Train Log likelihood, step 282350 in nats: 0.104129\n",
      "Train Log likelihood, step 282400 in nats: 0.104131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 282450 in nats: 0.104132\n",
      "Train epoch average loss: 0.1041360176280878\n",
      "\n",
      "\n",
      "Epoch: 1733\n",
      "Train Log likelihood, step 282500 in nats: 0.104136\n",
      "Train Log likelihood, step 282550 in nats: 0.104139\n",
      "Train Log likelihood, step 282600 in nats: 0.104143\n",
      "Train epoch average loss: 0.10414332465461978\n",
      "\n",
      "\n",
      "Epoch: 1734\n",
      "Train Log likelihood, step 282650 in nats: 0.104144\n",
      "Train Log likelihood, step 282700 in nats: 0.104151\n",
      "Train Log likelihood, step 282750 in nats: 0.104158\n",
      "Train Log likelihood, step 282800 in nats: 0.104164\n",
      "Train epoch average loss: 0.10416427170364631\n",
      "\n",
      "\n",
      "Epoch: 1735\n",
      "Train Log likelihood, step 282850 in nats: 0.104166\n",
      "Train Log likelihood, step 282900 in nats: 0.104176\n",
      "Train Log likelihood, step 282950 in nats: 0.104184\n",
      "Train epoch average loss: 0.10418429783253631\n",
      "\n",
      "\n",
      "Epoch: 1736\n",
      "Train Log likelihood, step 283000 in nats: 0.104187\n",
      "Train Log likelihood, step 283050 in nats: 0.104191\n",
      "Train Log likelihood, step 283100 in nats: 0.104195\n",
      "Train epoch average loss: 0.10419683612278524\n",
      "\n",
      "\n",
      "Epoch: 1737\n",
      "Train Log likelihood, step 283150 in nats: 0.104202\n",
      "Train Log likelihood, step 283200 in nats: 0.104203\n",
      "Train Log likelihood, step 283250 in nats: 0.104211\n",
      "Train epoch average loss: 0.10421883761747686\n",
      "\n",
      "\n",
      "Epoch: 1738\n",
      "Train Log likelihood, step 283300 in nats: 0.104220\n",
      "Train Log likelihood, step 283350 in nats: 0.104223\n",
      "Train Log likelihood, step 283400 in nats: 0.104232\n",
      "Train Log likelihood, step 283450 in nats: 0.104230\n",
      "Train epoch average loss: 0.10423082645241462\n",
      "\n",
      "\n",
      "Epoch: 1739\n",
      "Train Log likelihood, step 283500 in nats: 0.104229\n",
      "Train Log likelihood, step 283550 in nats: 0.104234\n",
      "Train Log likelihood, step 283600 in nats: 0.104235\n",
      "Train epoch average loss: 0.10423530665946124\n",
      "\n",
      "\n",
      "Epoch: 1740\n",
      "Train Log likelihood, step 283650 in nats: 0.104241\n",
      "Train Log likelihood, step 283700 in nats: 0.104247\n",
      "Train Log likelihood, step 283750 in nats: 0.104256\n",
      "Train epoch average loss: 0.10426076666492329\n",
      "\n",
      "\n",
      "Epoch: 1741\n",
      "Train Log likelihood, step 283800 in nats: 0.104266\n",
      "Train Log likelihood, step 283850 in nats: 0.104276\n",
      "Train Log likelihood, step 283900 in nats: 0.104291\n",
      "Train epoch average loss: 0.10429556943623382\n",
      "\n",
      "\n",
      "Epoch: 1742\n",
      "Train Log likelihood, step 283950 in nats: 0.104295\n",
      "Train Log likelihood, step 284000 in nats: 0.104304\n",
      "Train Log likelihood, step 284050 in nats: 0.104320\n",
      "Train Log likelihood, step 284100 in nats: 0.104324\n",
      "Train epoch average loss: 0.10432389850973087\n",
      "\n",
      "\n",
      "Epoch: 1743\n",
      "Train Log likelihood, step 284150 in nats: 0.104331\n",
      "Train Log likelihood, step 284200 in nats: 0.104336\n",
      "Train Log likelihood, step 284250 in nats: 0.104341\n",
      "Train epoch average loss: 0.10434218552996893\n",
      "\n",
      "\n",
      "Epoch: 1744\n",
      "Train Log likelihood, step 284300 in nats: 0.104349\n",
      "Train Log likelihood, step 284350 in nats: 0.104361\n",
      "Train Log likelihood, step 284400 in nats: 0.104370\n",
      "Train epoch average loss: 0.10437470793705636\n",
      "\n",
      "\n",
      "Epoch: 1745\n",
      "Train Log likelihood, step 284450 in nats: 0.104378\n",
      "Train Log likelihood, step 284500 in nats: 0.104386\n",
      "Train Log likelihood, step 284550 in nats: 0.104393\n",
      "Train epoch average loss: 0.10439994687955274\n",
      "\n",
      "\n",
      "Epoch: 1746\n",
      "Train Log likelihood, step 284600 in nats: 0.104400\n",
      "Train Log likelihood, step 284650 in nats: 0.104403\n",
      "Train Log likelihood, step 284700 in nats: 0.104409\n",
      "Train Log likelihood, step 284750 in nats: 0.104415\n",
      "Train epoch average loss: 0.10441792225461616\n",
      "\n",
      "\n",
      "Epoch: 1747\n",
      "Train Log likelihood, step 284800 in nats: 0.104419\n",
      "Train Log likelihood, step 284850 in nats: 0.104428\n",
      "Train Log likelihood, step 284900 in nats: 0.104438\n",
      "Train epoch average loss: 0.10444181134245405\n",
      "\n",
      "\n",
      "Epoch: 1748\n",
      "Train Log likelihood, step 284950 in nats: 0.104443\n",
      "Train Log likelihood, step 285000 in nats: 0.104438\n",
      "Train Log likelihood, step 285050 in nats: 0.104438\n",
      "Train epoch average loss: 0.10443973894496053\n",
      "\n",
      "\n",
      "Epoch: 1749\n",
      "Train Log likelihood, step 285100 in nats: 0.104444\n",
      "Train Log likelihood, step 285150 in nats: 0.104454\n",
      "Train Log likelihood, step 285200 in nats: 0.104457\n",
      "Train epoch average loss: 0.10446369084944551\n",
      "\n",
      "\n",
      "Epoch: 1750\n",
      "Train Log likelihood, step 285250 in nats: 0.104464\n",
      "Train Log likelihood, step 285300 in nats: 0.104472\n",
      "Train Log likelihood, step 285350 in nats: 0.104475\n",
      "Train Log likelihood, step 285400 in nats: 0.104485\n",
      "Train epoch average loss: 0.10448406192922126\n",
      "\n",
      "\n",
      "Epoch: 1751\n",
      "Train Log likelihood, step 285450 in nats: 0.104490\n",
      "Train Log likelihood, step 285500 in nats: 0.104501\n",
      "Train Log likelihood, step 285550 in nats: 0.104509\n",
      "Train epoch average loss: 0.10451231477925212\n",
      "\n",
      "\n",
      "Epoch: 1752\n",
      "Train Log likelihood, step 285600 in nats: 0.104512\n",
      "Train Log likelihood, step 285650 in nats: 0.104519\n",
      "Train Log likelihood, step 285700 in nats: 0.104528\n",
      "Train epoch average loss: 0.1045303950947903\n",
      "\n",
      "\n",
      "Epoch: 1753\n",
      "Train Log likelihood, step 285750 in nats: 0.104533\n",
      "Train Log likelihood, step 285800 in nats: 0.104537\n",
      "Train Log likelihood, step 285850 in nats: 0.104536\n",
      "Train Log likelihood, step 285900 in nats: 0.104538\n",
      "Train epoch average loss: 0.10453796217446902\n",
      "\n",
      "\n",
      "Epoch: 1754\n",
      "Train Log likelihood, step 285950 in nats: 0.104544\n",
      "Train Log likelihood, step 286000 in nats: 0.104550\n",
      "Train Log likelihood, step 286050 in nats: 0.104552\n",
      "Train epoch average loss: 0.10455172948615285\n",
      "\n",
      "\n",
      "Epoch: 1755\n",
      "Train Log likelihood, step 286100 in nats: 0.104556\n",
      "Train Log likelihood, step 286150 in nats: 0.104558\n",
      "Train Log likelihood, step 286200 in nats: 0.104559\n",
      "Train epoch average loss: 0.1045623489817639\n",
      "\n",
      "\n",
      "Epoch: 1756\n",
      "Train Log likelihood, step 286250 in nats: 0.104563\n",
      "Train Log likelihood, step 286300 in nats: 0.104561\n",
      "Train Log likelihood, step 286350 in nats: 0.104570\n",
      "Train epoch average loss: 0.10457770656785258\n",
      "\n",
      "\n",
      "Epoch: 1757\n",
      "Train Log likelihood, step 286400 in nats: 0.104577\n",
      "Train Log likelihood, step 286450 in nats: 0.104585\n",
      "Train Log likelihood, step 286500 in nats: 0.104591\n",
      "Train Log likelihood, step 286550 in nats: 0.104590\n",
      "Train epoch average loss: 0.10459021301070713\n",
      "\n",
      "\n",
      "Epoch: 1758\n",
      "Train Log likelihood, step 286600 in nats: 0.104588\n",
      "Train Log likelihood, step 286650 in nats: 0.104589\n",
      "Train Log likelihood, step 286700 in nats: 0.104594\n",
      "Train epoch average loss: 0.10459693042463522\n",
      "\n",
      "\n",
      "Epoch: 1759\n",
      "Train Log likelihood, step 286750 in nats: 0.104604\n",
      "Train Log likelihood, step 286800 in nats: 0.104612\n",
      "Train Log likelihood, step 286850 in nats: 0.104620\n",
      "Train epoch average loss: 0.10462196454650459\n",
      "\n",
      "\n",
      "Epoch: 1760\n",
      "Train Log likelihood, step 286900 in nats: 0.104628\n",
      "Train Log likelihood, step 286950 in nats: 0.104637\n",
      "Train Log likelihood, step 287000 in nats: 0.104642\n",
      "Train epoch average loss: 0.10464434430811148\n",
      "\n",
      "\n",
      "Epoch: 1761\n",
      "Train Log likelihood, step 287050 in nats: 0.104645\n",
      "Train Log likelihood, step 287100 in nats: 0.104654\n",
      "Train Log likelihood, step 287150 in nats: 0.104664\n",
      "Train Log likelihood, step 287200 in nats: 0.104673\n",
      "Train epoch average loss: 0.10467501859387694\n",
      "\n",
      "\n",
      "Epoch: 1762\n",
      "Train Log likelihood, step 287250 in nats: 0.104684\n",
      "Train Log likelihood, step 287300 in nats: 0.104690\n",
      "Train Log likelihood, step 287350 in nats: 0.104698\n",
      "Train epoch average loss: 0.10469888545774335\n",
      "\n",
      "\n",
      "Epoch: 1763\n",
      "Train Log likelihood, step 287400 in nats: 0.104704\n",
      "Train Log likelihood, step 287450 in nats: 0.104702\n",
      "Train Log likelihood, step 287500 in nats: 0.104710\n",
      "Train epoch average loss: 0.10471676829432285\n",
      "\n",
      "\n",
      "Epoch: 1764\n",
      "Train Log likelihood, step 287550 in nats: 0.104720\n",
      "Train Log likelihood, step 287600 in nats: 0.104727\n",
      "Train Log likelihood, step 287650 in nats: 0.104737\n",
      "Train epoch average loss: 0.104744381723948\n",
      "\n",
      "\n",
      "Epoch: 1765\n",
      "Train Log likelihood, step 287700 in nats: 0.104747\n",
      "Train Log likelihood, step 287750 in nats: 0.104752\n",
      "Train Log likelihood, step 287800 in nats: 0.104754\n",
      "Train Log likelihood, step 287850 in nats: 0.104758\n",
      "Train epoch average loss: 0.1047583275987649\n",
      "\n",
      "\n",
      "Epoch: 1766\n",
      "Train Log likelihood, step 287900 in nats: 0.104765\n",
      "Train Log likelihood, step 287950 in nats: 0.104770\n",
      "Train Log likelihood, step 288000 in nats: 0.104774\n",
      "Train epoch average loss: 0.10477668822275028\n",
      "\n",
      "\n",
      "Epoch: 1767\n",
      "Train Log likelihood, step 288050 in nats: 0.104780\n",
      "Train Log likelihood, step 288100 in nats: 0.104786\n",
      "Train Log likelihood, step 288150 in nats: 0.104792\n",
      "Train epoch average loss: 0.1047956732234169\n",
      "\n",
      "\n",
      "Epoch: 1768\n",
      "Train Log likelihood, step 288200 in nats: 0.104799\n",
      "Train Log likelihood, step 288250 in nats: 0.104802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 288300 in nats: 0.104810\n",
      "Train epoch average loss: 0.10480763222701828\n",
      "\n",
      "\n",
      "Epoch: 1769\n",
      "Train Log likelihood, step 288350 in nats: 0.104807\n",
      "Train Log likelihood, step 288400 in nats: 0.104816\n",
      "Train Log likelihood, step 288450 in nats: 0.104824\n",
      "Train Log likelihood, step 288500 in nats: 0.104832\n",
      "Train epoch average loss: 0.1048337865983272\n",
      "\n",
      "\n",
      "Epoch: 1770\n",
      "Train Log likelihood, step 288550 in nats: 0.104839\n",
      "Train Log likelihood, step 288600 in nats: 0.104843\n",
      "Train Log likelihood, step 288650 in nats: 0.104843\n",
      "Train epoch average loss: 0.10484633462500845\n",
      "\n",
      "\n",
      "Epoch: 1771\n",
      "Train Log likelihood, step 288700 in nats: 0.104844\n",
      "Train Log likelihood, step 288750 in nats: 0.104850\n",
      "Train Log likelihood, step 288800 in nats: 0.104859\n",
      "Train epoch average loss: 0.10486711836673039\n",
      "\n",
      "\n",
      "Epoch: 1772\n",
      "Train Log likelihood, step 288850 in nats: 0.104871\n",
      "Train Log likelihood, step 288900 in nats: 0.104874\n",
      "Train Log likelihood, step 288950 in nats: 0.104873\n",
      "Train epoch average loss: 0.10488203197421829\n",
      "\n",
      "\n",
      "Epoch: 1773\n",
      "Train Log likelihood, step 289000 in nats: 0.104882\n",
      "Train Log likelihood, step 289050 in nats: 0.104887\n",
      "Train Log likelihood, step 289100 in nats: 0.104887\n",
      "Train Log likelihood, step 289150 in nats: 0.104889\n",
      "Train epoch average loss: 0.1048909172905366\n",
      "\n",
      "\n",
      "Epoch: 1774\n",
      "Train Log likelihood, step 289200 in nats: 0.104895\n",
      "Train Log likelihood, step 289250 in nats: 0.104899\n",
      "Train Log likelihood, step 289300 in nats: 0.104903\n",
      "Train epoch average loss: 0.10490010656108525\n",
      "\n",
      "\n",
      "Epoch: 1775\n",
      "Train Log likelihood, step 289350 in nats: 0.104903\n",
      "Train Log likelihood, step 289400 in nats: 0.104901\n",
      "Train Log likelihood, step 289450 in nats: 0.104909\n",
      "Train epoch average loss: 0.10491127495675669\n",
      "\n",
      "\n",
      "Epoch: 1776\n",
      "Train Log likelihood, step 289500 in nats: 0.104913\n",
      "Train Log likelihood, step 289550 in nats: 0.104919\n",
      "Train Log likelihood, step 289600 in nats: 0.104922\n",
      "Train Log likelihood, step 289650 in nats: 0.104924\n",
      "Train epoch average loss: 0.10492385032341744\n",
      "\n",
      "\n",
      "Epoch: 1777\n",
      "Train Log likelihood, step 289700 in nats: 0.104930\n",
      "Train Log likelihood, step 289750 in nats: 0.104938\n",
      "Train Log likelihood, step 289800 in nats: 0.104946\n",
      "Train epoch average loss: 0.10494942890966742\n",
      "\n",
      "\n",
      "Epoch: 1778\n",
      "Train Log likelihood, step 289850 in nats: 0.104955\n",
      "Train Log likelihood, step 289900 in nats: 0.104961\n",
      "Train Log likelihood, step 289950 in nats: 0.104968\n",
      "Train epoch average loss: 0.10497154881437415\n",
      "\n",
      "\n",
      "Epoch: 1779\n",
      "Train Log likelihood, step 290000 in nats: 0.104975\n",
      "Train Log likelihood, step 290050 in nats: 0.104982\n",
      "Train Log likelihood, step 290100 in nats: 0.104988\n",
      "Train epoch average loss: 0.10498920872332071\n",
      "\n",
      "\n",
      "Epoch: 1780\n",
      "Train Log likelihood, step 290150 in nats: 0.104989\n",
      "Train Log likelihood, step 290200 in nats: 0.104998\n",
      "Train Log likelihood, step 290250 in nats: 0.105005\n",
      "Train Log likelihood, step 290300 in nats: 0.105009\n",
      "Train epoch average loss: 0.10500903282267338\n",
      "\n",
      "\n",
      "Epoch: 1781\n",
      "Train Log likelihood, step 290350 in nats: 0.105019\n",
      "Train Log likelihood, step 290400 in nats: 0.105020\n",
      "Train Log likelihood, step 290450 in nats: 0.105021\n",
      "Train epoch average loss: 0.10502185849424225\n",
      "\n",
      "\n",
      "Epoch: 1782\n",
      "Train Log likelihood, step 290500 in nats: 0.105026\n",
      "Train Log likelihood, step 290550 in nats: 0.105029\n",
      "Train Log likelihood, step 290600 in nats: 0.105036\n",
      "Train epoch average loss: 0.10503864357486678\n",
      "\n",
      "\n",
      "Epoch: 1783\n",
      "Train Log likelihood, step 290650 in nats: 0.105041\n",
      "Train Log likelihood, step 290700 in nats: 0.105045\n",
      "Train Log likelihood, step 290750 in nats: 0.105052\n",
      "Train epoch average loss: 0.1050489552598332\n",
      "\n",
      "\n",
      "Epoch: 1784\n",
      "Train Log likelihood, step 290800 in nats: 0.105052\n",
      "Train Log likelihood, step 290850 in nats: 0.105056\n",
      "Train Log likelihood, step 290900 in nats: 0.105061\n",
      "Train Log likelihood, step 290950 in nats: 0.105069\n",
      "Train epoch average loss: 0.10506868061735164\n",
      "\n",
      "\n",
      "Epoch: 1785\n",
      "Train Log likelihood, step 291000 in nats: 0.105071\n",
      "Train Log likelihood, step 291050 in nats: 0.105078\n",
      "Train Log likelihood, step 291100 in nats: 0.105082\n",
      "Train epoch average loss: 0.10508420542938972\n",
      "\n",
      "\n",
      "Epoch: 1786\n",
      "Train Log likelihood, step 291150 in nats: 0.105086\n",
      "Train Log likelihood, step 291200 in nats: 0.105088\n",
      "Train Log likelihood, step 291250 in nats: 0.105085\n",
      "Train epoch average loss: 0.10508364989481563\n",
      "\n",
      "\n",
      "Epoch: 1787\n",
      "Train Log likelihood, step 291300 in nats: 0.105084\n",
      "Train Log likelihood, step 291350 in nats: 0.105085\n",
      "Train Log likelihood, step 291400 in nats: 0.105090\n",
      "Train epoch average loss: 0.10509475642057436\n",
      "\n",
      "\n",
      "Epoch: 1788\n",
      "Train Log likelihood, step 291450 in nats: 0.105093\n",
      "Train Log likelihood, step 291500 in nats: 0.105097\n",
      "Train Log likelihood, step 291550 in nats: 0.105097\n",
      "Train Log likelihood, step 291600 in nats: 0.105109\n",
      "Train epoch average loss: 0.1051100330815118\n",
      "\n",
      "\n",
      "Epoch: 1789\n",
      "Train Log likelihood, step 291650 in nats: 0.105115\n",
      "Train Log likelihood, step 291700 in nats: 0.105122\n",
      "Train Log likelihood, step 291750 in nats: 0.105124\n",
      "Train epoch average loss: 0.1051266573743327\n",
      "\n",
      "\n",
      "Epoch: 1790\n",
      "Train Log likelihood, step 291800 in nats: 0.105128\n",
      "Train Log likelihood, step 291850 in nats: 0.105134\n",
      "Train Log likelihood, step 291900 in nats: 0.105142\n",
      "Train epoch average loss: 0.10514312835374433\n",
      "\n",
      "\n",
      "Epoch: 1791\n",
      "Train Log likelihood, step 291950 in nats: 0.105146\n",
      "Train Log likelihood, step 292000 in nats: 0.105150\n",
      "Train Log likelihood, step 292050 in nats: 0.105149\n",
      "Train epoch average loss: 0.10514733300042409\n",
      "\n",
      "\n",
      "Epoch: 1792\n",
      "Train Log likelihood, step 292100 in nats: 0.105149\n",
      "Train Log likelihood, step 292150 in nats: 0.105149\n",
      "Train Log likelihood, step 292200 in nats: 0.105155\n",
      "Train Log likelihood, step 292250 in nats: 0.105159\n",
      "Train epoch average loss: 0.10516066699403442\n",
      "\n",
      "\n",
      "Epoch: 1793\n",
      "Train Log likelihood, step 292300 in nats: 0.105164\n",
      "Train Log likelihood, step 292350 in nats: 0.105167\n",
      "Train Log likelihood, step 292400 in nats: 0.105178\n",
      "Train epoch average loss: 0.10517857337629308\n",
      "\n",
      "\n",
      "Epoch: 1794\n",
      "Train Log likelihood, step 292450 in nats: 0.105179\n",
      "Train Log likelihood, step 292500 in nats: 0.105187\n",
      "Train Log likelihood, step 292550 in nats: 0.105189\n",
      "Train epoch average loss: 0.10519380348903844\n",
      "\n",
      "\n",
      "Epoch: 1795\n",
      "Train Log likelihood, step 292600 in nats: 0.105195\n",
      "Train Log likelihood, step 292650 in nats: 0.105203\n",
      "Train Log likelihood, step 292700 in nats: 0.105214\n",
      "Train epoch average loss: 0.10521741531812086\n",
      "\n",
      "\n",
      "Epoch: 1796\n",
      "Train Log likelihood, step 292750 in nats: 0.105219\n",
      "Train Log likelihood, step 292800 in nats: 0.105221\n",
      "Train Log likelihood, step 292850 in nats: 0.105221\n",
      "Train Log likelihood, step 292900 in nats: 0.105224\n",
      "Train epoch average loss: 0.10522475344558059\n",
      "\n",
      "\n",
      "Epoch: 1797\n",
      "Train Log likelihood, step 292950 in nats: 0.105227\n",
      "Train Log likelihood, step 293000 in nats: 0.105231\n",
      "Train Log likelihood, step 293050 in nats: 0.105237\n",
      "Train epoch average loss: 0.10523833283719604\n",
      "\n",
      "\n",
      "Epoch: 1798\n",
      "Train Log likelihood, step 293100 in nats: 0.105241\n",
      "Train Log likelihood, step 293150 in nats: 0.105239\n",
      "Train Log likelihood, step 293200 in nats: 0.105244\n",
      "Train epoch average loss: 0.10524184194646756\n",
      "\n",
      "\n",
      "Epoch: 1799\n",
      "Train Log likelihood, step 293250 in nats: 0.105243\n",
      "Train Log likelihood, step 293300 in nats: 0.105248\n",
      "Train Log likelihood, step 293350 in nats: 0.105255\n",
      "Train epoch average loss: 0.10526042862235445\n",
      "\n",
      "\n",
      "Epoch: 1800\n",
      "Train Log likelihood, step 293400 in nats: 0.105261\n",
      "Train Log likelihood, step 293450 in nats: 0.105266\n",
      "Train Log likelihood, step 293500 in nats: 0.105272\n",
      "Train Log likelihood, step 293550 in nats: 0.105281\n",
      "Train epoch average loss: 0.10528167790705988\n",
      "\n",
      "\n",
      "Epoch: 1801\n",
      "Train Log likelihood, step 293600 in nats: 0.105288\n",
      "Train Log likelihood, step 293650 in nats: 0.105288\n",
      "Train Log likelihood, step 293700 in nats: 0.105298\n",
      "Train epoch average loss: 0.10530259852920788\n",
      "\n",
      "\n",
      "Epoch: 1802\n",
      "Train Log likelihood, step 293750 in nats: 0.105308\n",
      "Train Log likelihood, step 293800 in nats: 0.105310\n",
      "Train Log likelihood, step 293850 in nats: 0.105315\n",
      "Train epoch average loss: 0.1053196146009559\n",
      "\n",
      "\n",
      "Epoch: 1803\n",
      "Train Log likelihood, step 293900 in nats: 0.105319\n",
      "Train Log likelihood, step 293950 in nats: 0.105322\n",
      "Train Log likelihood, step 294000 in nats: 0.105324\n",
      "Train Log likelihood, step 294050 in nats: 0.105319\n",
      "Train epoch average loss: 0.10531801875452826\n",
      "\n",
      "\n",
      "Epoch: 1804\n",
      "Train Log likelihood, step 294100 in nats: 0.105322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 294150 in nats: 0.105327\n",
      "Train Log likelihood, step 294200 in nats: 0.105334\n",
      "Train epoch average loss: 0.10533569741277758\n",
      "\n",
      "\n",
      "Epoch: 1805\n",
      "Train Log likelihood, step 294250 in nats: 0.105341\n",
      "Train Log likelihood, step 294300 in nats: 0.105344\n",
      "Train Log likelihood, step 294350 in nats: 0.105352\n",
      "Train epoch average loss: 0.10535434963880234\n",
      "\n",
      "\n",
      "Epoch: 1806\n",
      "Train Log likelihood, step 294400 in nats: 0.105354\n",
      "Train Log likelihood, step 294450 in nats: 0.105358\n",
      "Train Log likelihood, step 294500 in nats: 0.105365\n",
      "Train epoch average loss: 0.10536793779854074\n",
      "\n",
      "\n",
      "Epoch: 1807\n",
      "Train Log likelihood, step 294550 in nats: 0.105368\n",
      "Train Log likelihood, step 294600 in nats: 0.105370\n",
      "Train Log likelihood, step 294650 in nats: 0.105380\n",
      "Train Log likelihood, step 294700 in nats: 0.105386\n",
      "Train epoch average loss: 0.1053863791019808\n",
      "\n",
      "\n",
      "Epoch: 1808\n",
      "Train Log likelihood, step 294750 in nats: 0.105387\n",
      "Train Log likelihood, step 294800 in nats: 0.105388\n",
      "Train Log likelihood, step 294850 in nats: 0.105389\n",
      "Train epoch average loss: 0.10539245150894022\n",
      "\n",
      "\n",
      "Epoch: 1809\n",
      "Train Log likelihood, step 294900 in nats: 0.105389\n",
      "Train Log likelihood, step 294950 in nats: 0.105387\n",
      "Train Log likelihood, step 295000 in nats: 0.105391\n",
      "Train epoch average loss: 0.10539513037028334\n",
      "\n",
      "\n",
      "Epoch: 1810\n",
      "Train Log likelihood, step 295050 in nats: 0.105395\n",
      "Train Log likelihood, step 295100 in nats: 0.105399\n",
      "Train Log likelihood, step 295150 in nats: 0.105408\n",
      "Train epoch average loss: 0.10541348657203312\n",
      "\n",
      "\n",
      "Epoch: 1811\n",
      "Train Log likelihood, step 295200 in nats: 0.105415\n",
      "Train Log likelihood, step 295250 in nats: 0.105415\n",
      "Train Log likelihood, step 295300 in nats: 0.105420\n",
      "Train Log likelihood, step 295350 in nats: 0.105422\n",
      "Train epoch average loss: 0.10542101751262835\n",
      "\n",
      "\n",
      "Epoch: 1812\n",
      "Train Log likelihood, step 295400 in nats: 0.105417\n",
      "Train Log likelihood, step 295450 in nats: 0.105426\n",
      "Train Log likelihood, step 295500 in nats: 0.105433\n",
      "Train epoch average loss: 0.10543430999832935\n",
      "\n",
      "\n",
      "Epoch: 1813\n",
      "Train Log likelihood, step 295550 in nats: 0.105437\n",
      "Train Log likelihood, step 295600 in nats: 0.105439\n",
      "Train Log likelihood, step 295650 in nats: 0.105442\n",
      "Train epoch average loss: 0.10544411109780392\n",
      "\n",
      "\n",
      "Epoch: 1814\n",
      "Train Log likelihood, step 295700 in nats: 0.105447\n",
      "Train Log likelihood, step 295750 in nats: 0.105453\n",
      "Train Log likelihood, step 295800 in nats: 0.105457\n",
      "Train epoch average loss: 0.10545689235574036\n",
      "\n",
      "\n",
      "Epoch: 1815\n",
      "Train Log likelihood, step 295850 in nats: 0.105458\n",
      "Train Log likelihood, step 295900 in nats: 0.105459\n",
      "Train Log likelihood, step 295950 in nats: 0.105458\n",
      "Train Log likelihood, step 296000 in nats: 0.105462\n",
      "Train epoch average loss: 0.10546255619824567\n",
      "\n",
      "\n",
      "Epoch: 1816\n",
      "Train Log likelihood, step 296050 in nats: 0.105468\n",
      "Train Log likelihood, step 296100 in nats: 0.105471\n",
      "Train Log likelihood, step 296150 in nats: 0.105472\n",
      "Train epoch average loss: 0.10547062410420657\n",
      "\n",
      "\n",
      "Epoch: 1817\n",
      "Train Log likelihood, step 296200 in nats: 0.105471\n",
      "Train Log likelihood, step 296250 in nats: 0.105476\n",
      "Train Log likelihood, step 296300 in nats: 0.105485\n",
      "Train epoch average loss: 0.10548810735145778\n",
      "\n",
      "\n",
      "Epoch: 1818\n",
      "Train Log likelihood, step 296350 in nats: 0.105490\n",
      "Train Log likelihood, step 296400 in nats: 0.105496\n",
      "Train Log likelihood, step 296450 in nats: 0.105506\n",
      "Train epoch average loss: 0.10551119313926138\n",
      "\n",
      "\n",
      "Epoch: 1819\n",
      "Train Log likelihood, step 296500 in nats: 0.105512\n",
      "Train Log likelihood, step 296550 in nats: 0.105516\n",
      "Train Log likelihood, step 296600 in nats: 0.105521\n",
      "Train Log likelihood, step 296650 in nats: 0.105529\n",
      "Train epoch average loss: 0.10552862703834462\n",
      "\n",
      "\n",
      "Epoch: 1820\n",
      "Train Log likelihood, step 296700 in nats: 0.105534\n",
      "Train Log likelihood, step 296750 in nats: 0.105540\n",
      "Train Log likelihood, step 296800 in nats: 0.105543\n",
      "Train epoch average loss: 0.10554558747977988\n",
      "\n",
      "\n",
      "Epoch: 1821\n",
      "Train Log likelihood, step 296850 in nats: 0.105548\n",
      "Train Log likelihood, step 296900 in nats: 0.105546\n",
      "Train Log likelihood, step 296950 in nats: 0.105551\n",
      "Train epoch average loss: 0.10555452820796069\n",
      "\n",
      "\n",
      "Epoch: 1822\n",
      "Train Log likelihood, step 297000 in nats: 0.105556\n",
      "Train Log likelihood, step 297050 in nats: 0.105565\n",
      "Train Log likelihood, step 297100 in nats: 0.105572\n",
      "Train epoch average loss: 0.10557490387625373\n",
      "\n",
      "\n",
      "Epoch: 1823\n",
      "Train Log likelihood, step 297150 in nats: 0.105575\n",
      "Train Log likelihood, step 297200 in nats: 0.105584\n",
      "Train Log likelihood, step 297250 in nats: 0.105594\n",
      "Train Log likelihood, step 297300 in nats: 0.105597\n",
      "Train epoch average loss: 0.10559881250108674\n",
      "\n",
      "\n",
      "Epoch: 1824\n",
      "Train Log likelihood, step 297350 in nats: 0.105604\n",
      "Train Log likelihood, step 297400 in nats: 0.105611\n",
      "Train Log likelihood, step 297450 in nats: 0.105620\n",
      "Train epoch average loss: 0.10561991133019158\n",
      "\n",
      "\n",
      "Epoch: 1825\n",
      "Train Log likelihood, step 297500 in nats: 0.105621\n",
      "Train Log likelihood, step 297550 in nats: 0.105634\n",
      "Train Log likelihood, step 297600 in nats: 0.105638\n",
      "Train epoch average loss: 0.1056425000455205\n",
      "\n",
      "\n",
      "Epoch: 1826\n",
      "Train Log likelihood, step 297650 in nats: 0.105646\n",
      "Train Log likelihood, step 297700 in nats: 0.105649\n",
      "Train Log likelihood, step 297750 in nats: 0.105649\n",
      "Train Log likelihood, step 297800 in nats: 0.105654\n",
      "Train epoch average loss: 0.10565430278102206\n",
      "\n",
      "\n",
      "Epoch: 1827\n",
      "Train Log likelihood, step 297850 in nats: 0.105659\n",
      "Train Log likelihood, step 297900 in nats: 0.105662\n",
      "Train Log likelihood, step 297950 in nats: 0.105671\n",
      "Train epoch average loss: 0.10567427740152771\n",
      "\n",
      "\n",
      "Epoch: 1828\n",
      "Train Log likelihood, step 298000 in nats: 0.105676\n",
      "Train Log likelihood, step 298050 in nats: 0.105679\n",
      "Train Log likelihood, step 298100 in nats: 0.105684\n",
      "Train epoch average loss: 0.10568806680567487\n",
      "\n",
      "\n",
      "Epoch: 1829\n",
      "Train Log likelihood, step 298150 in nats: 0.105692\n",
      "Train Log likelihood, step 298200 in nats: 0.105692\n",
      "Train Log likelihood, step 298250 in nats: 0.105695\n",
      "Train epoch average loss: 0.1057033108562066\n",
      "\n",
      "\n",
      "Epoch: 1830\n",
      "Train Log likelihood, step 298300 in nats: 0.105705\n",
      "Train Log likelihood, step 298350 in nats: 0.105708\n",
      "Train Log likelihood, step 298400 in nats: 0.105719\n",
      "Train Log likelihood, step 298450 in nats: 0.105728\n",
      "Train epoch average loss: 0.10572738934465174\n",
      "\n",
      "\n",
      "Epoch: 1831\n",
      "Train Log likelihood, step 298500 in nats: 0.105741\n",
      "Train Log likelihood, step 298550 in nats: 0.105748\n",
      "Train Log likelihood, step 298600 in nats: 0.105745\n",
      "Train epoch average loss: 0.10574190423507006\n",
      "\n",
      "\n",
      "Epoch: 1832\n",
      "Train Log likelihood, step 298650 in nats: 0.105741\n",
      "Train Log likelihood, step 298700 in nats: 0.105739\n",
      "Train Log likelihood, step 298750 in nats: 0.105739\n",
      "Train epoch average loss: 0.10574097899639558\n",
      "\n",
      "\n",
      "Epoch: 1833\n",
      "Train Log likelihood, step 298800 in nats: 0.105747\n",
      "Train Log likelihood, step 298850 in nats: 0.105748\n",
      "Train Log likelihood, step 298900 in nats: 0.105747\n",
      "Train epoch average loss: 0.10575105512820411\n",
      "\n",
      "\n",
      "Epoch: 1834\n",
      "Train Log likelihood, step 298950 in nats: 0.105752\n",
      "Train Log likelihood, step 299000 in nats: 0.105759\n",
      "Train Log likelihood, step 299050 in nats: 0.105761\n",
      "Train Log likelihood, step 299100 in nats: 0.105767\n",
      "Train epoch average loss: 0.10576802074865777\n",
      "\n",
      "\n",
      "Epoch: 1835\n",
      "Train Log likelihood, step 299150 in nats: 0.105769\n",
      "Train Log likelihood, step 299200 in nats: 0.105776\n",
      "Train Log likelihood, step 299250 in nats: 0.105785\n",
      "Train epoch average loss: 0.10578772665709126\n",
      "\n",
      "\n",
      "Epoch: 1836\n",
      "Train Log likelihood, step 299300 in nats: 0.105789\n",
      "Train Log likelihood, step 299350 in nats: 0.105794\n",
      "Train Log likelihood, step 299400 in nats: 0.105795\n",
      "Train epoch average loss: 0.10579939270500008\n",
      "\n",
      "\n",
      "Epoch: 1837\n",
      "Train Log likelihood, step 299450 in nats: 0.105804\n",
      "Train Log likelihood, step 299500 in nats: 0.105815\n",
      "Train Log likelihood, step 299550 in nats: 0.105824\n",
      "Train epoch average loss: 0.1058279156687511\n",
      "\n",
      "\n",
      "Epoch: 1838\n",
      "Train Log likelihood, step 299600 in nats: 0.105827\n",
      "Train Log likelihood, step 299650 in nats: 0.105830\n",
      "Train Log likelihood, step 299700 in nats: 0.105832\n",
      "Train Log likelihood, step 299750 in nats: 0.105840\n",
      "Train epoch average loss: 0.10584061015869982\n",
      "\n",
      "\n",
      "Epoch: 1839\n",
      "Train Log likelihood, step 299800 in nats: 0.105841\n",
      "Train Log likelihood, step 299850 in nats: 0.105839\n",
      "Train Log likelihood, step 299900 in nats: 0.105848\n",
      "Train epoch average loss: 0.10584838729592189\n",
      "\n",
      "\n",
      "Epoch: 1840\n",
      "Train Log likelihood, step 299950 in nats: 0.105851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 300000 in nats: 0.105853\n",
      "Train Log likelihood, step 300050 in nats: 0.105854\n",
      "Train epoch average loss: 0.10585298668831254\n",
      "\n",
      "\n",
      "Epoch: 1841\n",
      "Train Log likelihood, step 300100 in nats: 0.105855\n",
      "Train Log likelihood, step 300150 in nats: 0.105864\n",
      "Train Log likelihood, step 300200 in nats: 0.105870\n",
      "Train epoch average loss: 0.10587609902465148\n",
      "\n",
      "\n",
      "Epoch: 1842\n",
      "Train Log likelihood, step 300250 in nats: 0.105878\n",
      "Train Log likelihood, step 300300 in nats: 0.105877\n",
      "Train Log likelihood, step 300350 in nats: 0.105882\n",
      "Train Log likelihood, step 300400 in nats: 0.105890\n",
      "Train epoch average loss: 0.10588916310068719\n",
      "\n",
      "\n",
      "Epoch: 1843\n",
      "Train Log likelihood, step 300450 in nats: 0.105898\n",
      "Train Log likelihood, step 300500 in nats: 0.105898\n",
      "Train Log likelihood, step 300550 in nats: 0.105900\n",
      "Train epoch average loss: 0.10590255981932926\n",
      "\n",
      "\n",
      "Epoch: 1844\n",
      "Train Log likelihood, step 300600 in nats: 0.105910\n",
      "Train Log likelihood, step 300650 in nats: 0.105915\n",
      "Train Log likelihood, step 300700 in nats: 0.105915\n",
      "Train epoch average loss: 0.1059173213499274\n",
      "\n",
      "\n",
      "Epoch: 1845\n",
      "Train Log likelihood, step 300750 in nats: 0.105919\n",
      "Train Log likelihood, step 300800 in nats: 0.105925\n",
      "Train Log likelihood, step 300850 in nats: 0.105927\n",
      "Train epoch average loss: 0.1059296701264164\n",
      "\n",
      "\n",
      "Epoch: 1846\n",
      "Train Log likelihood, step 300900 in nats: 0.105930\n",
      "Train Log likelihood, step 300950 in nats: 0.105930\n",
      "Train Log likelihood, step 301000 in nats: 0.105933\n",
      "Train Log likelihood, step 301050 in nats: 0.105935\n",
      "Train epoch average loss: 0.10593640602964327\n",
      "\n",
      "\n",
      "Epoch: 1847\n",
      "Train Log likelihood, step 301100 in nats: 0.105937\n",
      "Train Log likelihood, step 301150 in nats: 0.105936\n",
      "Train Log likelihood, step 301200 in nats: 0.105933\n",
      "Train epoch average loss: 0.105932430422736\n",
      "\n",
      "\n",
      "Epoch: 1848\n",
      "Train Log likelihood, step 301250 in nats: 0.105933\n",
      "Train Log likelihood, step 301300 in nats: 0.105933\n",
      "Train Log likelihood, step 301350 in nats: 0.105937\n",
      "Train epoch average loss: 0.10593889798216666\n",
      "\n",
      "\n",
      "Epoch: 1849\n",
      "Train Log likelihood, step 301400 in nats: 0.105940\n",
      "Train Log likelihood, step 301450 in nats: 0.105945\n",
      "Train Log likelihood, step 301500 in nats: 0.105954\n",
      "Train epoch average loss: 0.10596334547915026\n",
      "\n",
      "\n",
      "Epoch: 1850\n",
      "Train Log likelihood, step 301550 in nats: 0.105963\n",
      "Train Log likelihood, step 301600 in nats: 0.105965\n",
      "Train Log likelihood, step 301650 in nats: 0.105967\n",
      "Train Log likelihood, step 301700 in nats: 0.105972\n",
      "Train epoch average loss: 0.10597541116864284\n",
      "\n",
      "\n",
      "Epoch: 1851\n",
      "Train Log likelihood, step 301750 in nats: 0.105975\n",
      "Train Log likelihood, step 301800 in nats: 0.105977\n",
      "Train Log likelihood, step 301850 in nats: 0.105982\n",
      "Train epoch average loss: 0.10598218175766427\n",
      "\n",
      "\n",
      "Epoch: 1852\n",
      "Train Log likelihood, step 301900 in nats: 0.105983\n",
      "Train Log likelihood, step 301950 in nats: 0.105981\n",
      "Train Log likelihood, step 302000 in nats: 0.105986\n",
      "Train epoch average loss: 0.10598354107045484\n",
      "\n",
      "\n",
      "Epoch: 1853\n",
      "Train Log likelihood, step 302050 in nats: 0.105983\n",
      "Train Log likelihood, step 302100 in nats: 0.105981\n",
      "Train Log likelihood, step 302150 in nats: 0.105992\n",
      "Train Log likelihood, step 302200 in nats: 0.105995\n",
      "Train epoch average loss: 0.10599502772525553\n",
      "\n",
      "\n",
      "Epoch: 1854\n",
      "Train Log likelihood, step 302250 in nats: 0.105995\n",
      "Train Log likelihood, step 302300 in nats: 0.105996\n",
      "Train Log likelihood, step 302350 in nats: 0.106002\n",
      "Train epoch average loss: 0.10600319805023793\n",
      "\n",
      "\n",
      "Epoch: 1855\n",
      "Train Log likelihood, step 302400 in nats: 0.106009\n",
      "Train Log likelihood, step 302450 in nats: 0.106015\n",
      "Train Log likelihood, step 302500 in nats: 0.106021\n",
      "Train epoch average loss: 0.10602636723258821\n",
      "\n",
      "\n",
      "Epoch: 1856\n",
      "Train Log likelihood, step 302550 in nats: 0.106030\n",
      "Train Log likelihood, step 302600 in nats: 0.106027\n",
      "Train Log likelihood, step 302650 in nats: 0.106033\n",
      "Train epoch average loss: 0.10603625713244602\n",
      "\n",
      "\n",
      "Epoch: 1857\n",
      "Train Log likelihood, step 302700 in nats: 0.106036\n",
      "Train Log likelihood, step 302750 in nats: 0.106041\n",
      "Train Log likelihood, step 302800 in nats: 0.106045\n",
      "Train Log likelihood, step 302850 in nats: 0.106049\n",
      "Train epoch average loss: 0.10604900476357078\n",
      "\n",
      "\n",
      "Epoch: 1858\n",
      "Train Log likelihood, step 302900 in nats: 0.106049\n",
      "Train Log likelihood, step 302950 in nats: 0.106047\n",
      "Train Log likelihood, step 303000 in nats: 0.106057\n",
      "Train epoch average loss: 0.10605764615632447\n",
      "\n",
      "\n",
      "Epoch: 1859\n",
      "Train Log likelihood, step 303050 in nats: 0.106065\n",
      "Train Log likelihood, step 303100 in nats: 0.106073\n",
      "Train Log likelihood, step 303150 in nats: 0.106079\n",
      "Train epoch average loss: 0.1060825443446549\n",
      "\n",
      "\n",
      "Epoch: 1860\n",
      "Train Log likelihood, step 303200 in nats: 0.106085\n",
      "Train Log likelihood, step 303250 in nats: 0.106095\n",
      "Train Log likelihood, step 303300 in nats: 0.106098\n",
      "Train epoch average loss: 0.10610332004941861\n",
      "\n",
      "\n",
      "Epoch: 1861\n",
      "Train Log likelihood, step 303350 in nats: 0.106104\n",
      "Train Log likelihood, step 303400 in nats: 0.106104\n",
      "Train Log likelihood, step 303450 in nats: 0.106114\n",
      "Train Log likelihood, step 303500 in nats: 0.106117\n",
      "Train epoch average loss: 0.10611685124956113\n",
      "\n",
      "\n",
      "Epoch: 1862\n",
      "Train Log likelihood, step 303550 in nats: 0.106118\n",
      "Train Log likelihood, step 303600 in nats: 0.106124\n",
      "Train Log likelihood, step 303650 in nats: 0.106126\n",
      "Train epoch average loss: 0.10612999332477377\n",
      "\n",
      "\n",
      "Epoch: 1863\n",
      "Train Log likelihood, step 303700 in nats: 0.106130\n",
      "Train Log likelihood, step 303750 in nats: 0.106136\n",
      "Train Log likelihood, step 303800 in nats: 0.106138\n",
      "Train epoch average loss: 0.1061375185008842\n",
      "\n",
      "\n",
      "Epoch: 1864\n",
      "Train Log likelihood, step 303850 in nats: 0.106139\n",
      "Train Log likelihood, step 303900 in nats: 0.106145\n",
      "Train Log likelihood, step 303950 in nats: 0.106148\n",
      "Train epoch average loss: 0.10615279736219961\n",
      "\n",
      "\n",
      "Epoch: 1865\n",
      "Train Log likelihood, step 304000 in nats: 0.106153\n",
      "Train Log likelihood, step 304050 in nats: 0.106154\n",
      "Train Log likelihood, step 304100 in nats: 0.106160\n",
      "Train Log likelihood, step 304150 in nats: 0.106173\n",
      "Train epoch average loss: 0.10617431615741486\n",
      "\n",
      "\n",
      "Epoch: 1866\n",
      "Train Log likelihood, step 304200 in nats: 0.106181\n",
      "Train Log likelihood, step 304250 in nats: 0.106182\n",
      "Train Log likelihood, step 304300 in nats: 0.106188\n",
      "Train epoch average loss: 0.10618826916322939\n",
      "\n",
      "\n",
      "Epoch: 1867\n",
      "Train Log likelihood, step 304350 in nats: 0.106194\n",
      "Train Log likelihood, step 304400 in nats: 0.106207\n",
      "Train Log likelihood, step 304450 in nats: 0.106213\n",
      "Train epoch average loss: 0.10621611626948205\n",
      "\n",
      "\n",
      "Epoch: 1868\n",
      "Train Log likelihood, step 304500 in nats: 0.106219\n",
      "Train Log likelihood, step 304550 in nats: 0.106224\n",
      "Train Log likelihood, step 304600 in nats: 0.106226\n",
      "Train epoch average loss: 0.10623350514826711\n",
      "\n",
      "\n",
      "Epoch: 1869\n",
      "Train Log likelihood, step 304650 in nats: 0.106235\n",
      "Train Log likelihood, step 304700 in nats: 0.106244\n",
      "Train Log likelihood, step 304750 in nats: 0.106251\n",
      "Train Log likelihood, step 304800 in nats: 0.106258\n",
      "Train epoch average loss: 0.10625888850549921\n",
      "\n",
      "\n",
      "Epoch: 1870\n",
      "Train Log likelihood, step 304850 in nats: 0.106265\n",
      "Train Log likelihood, step 304900 in nats: 0.106268\n",
      "Train Log likelihood, step 304950 in nats: 0.106271\n",
      "Train epoch average loss: 0.1062755100515957\n",
      "\n",
      "\n",
      "Epoch: 1871\n",
      "Train Log likelihood, step 305000 in nats: 0.106277\n",
      "Train Log likelihood, step 305050 in nats: 0.106282\n",
      "Train Log likelihood, step 305100 in nats: 0.106280\n",
      "Train epoch average loss: 0.10628441706973589\n",
      "\n",
      "\n",
      "Epoch: 1872\n",
      "Train Log likelihood, step 305150 in nats: 0.106287\n",
      "Train Log likelihood, step 305200 in nats: 0.106295\n",
      "Train Log likelihood, step 305250 in nats: 0.106300\n",
      "Train epoch average loss: 0.10630334709769608\n",
      "\n",
      "\n",
      "Epoch: 1873\n",
      "Train Log likelihood, step 305300 in nats: 0.106303\n",
      "Train Log likelihood, step 305350 in nats: 0.106311\n",
      "Train Log likelihood, step 305400 in nats: 0.106319\n",
      "Train Log likelihood, step 305450 in nats: 0.106317\n",
      "Train epoch average loss: 0.1063194001263108\n",
      "\n",
      "\n",
      "Epoch: 1874\n",
      "Train Log likelihood, step 305500 in nats: 0.106326\n",
      "Train Log likelihood, step 305550 in nats: 0.106324\n",
      "Train Log likelihood, step 305600 in nats: 0.106326\n",
      "Train epoch average loss: 0.10632908312745179\n",
      "\n",
      "\n",
      "Epoch: 1875\n",
      "Train Log likelihood, step 305650 in nats: 0.106335\n",
      "Train Log likelihood, step 305700 in nats: 0.106343\n",
      "Train Log likelihood, step 305750 in nats: 0.106351\n",
      "Train epoch average loss: 0.1063574242072289\n",
      "\n",
      "\n",
      "Epoch: 1876\n",
      "Train Log likelihood, step 305800 in nats: 0.106360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 305850 in nats: 0.106357\n",
      "Train Log likelihood, step 305900 in nats: 0.106360\n",
      "Train Log likelihood, step 305950 in nats: 0.106358\n",
      "Train epoch average loss: 0.10635836227878238\n",
      "\n",
      "\n",
      "Epoch: 1877\n",
      "Train Log likelihood, step 306000 in nats: 0.106360\n",
      "Train Log likelihood, step 306050 in nats: 0.106362\n",
      "Train Log likelihood, step 306100 in nats: 0.106367\n",
      "Train epoch average loss: 0.10636817309331681\n",
      "\n",
      "\n",
      "Epoch: 1878\n",
      "Train Log likelihood, step 306150 in nats: 0.106371\n",
      "Train Log likelihood, step 306200 in nats: 0.106375\n",
      "Train Log likelihood, step 306250 in nats: 0.106378\n",
      "Train epoch average loss: 0.10638155188777039\n",
      "\n",
      "\n",
      "Epoch: 1879\n",
      "Train Log likelihood, step 306300 in nats: 0.106381\n",
      "Train Log likelihood, step 306350 in nats: 0.106393\n",
      "Train Log likelihood, step 306400 in nats: 0.106394\n",
      "Train epoch average loss: 0.10639529147367631\n",
      "\n",
      "\n",
      "Epoch: 1880\n",
      "Train Log likelihood, step 306450 in nats: 0.106399\n",
      "Train Log likelihood, step 306500 in nats: 0.106406\n",
      "Train Log likelihood, step 306550 in nats: 0.106405\n",
      "Train Log likelihood, step 306600 in nats: 0.106409\n",
      "Train epoch average loss: 0.10640934261160484\n",
      "\n",
      "\n",
      "Epoch: 1881\n",
      "Train Log likelihood, step 306650 in nats: 0.106413\n",
      "Train Log likelihood, step 306700 in nats: 0.106414\n",
      "Train Log likelihood, step 306750 in nats: 0.106416\n",
      "Train epoch average loss: 0.10641836888724028\n",
      "\n",
      "\n",
      "Epoch: 1882\n",
      "Train Log likelihood, step 306800 in nats: 0.106423\n",
      "Train Log likelihood, step 306850 in nats: 0.106430\n",
      "Train Log likelihood, step 306900 in nats: 0.106437\n",
      "Train epoch average loss: 0.10644239620884001\n",
      "\n",
      "\n",
      "Epoch: 1883\n",
      "Train Log likelihood, step 306950 in nats: 0.106448\n",
      "Train Log likelihood, step 307000 in nats: 0.106450\n",
      "Train Log likelihood, step 307050 in nats: 0.106450\n",
      "Train epoch average loss: 0.1064577769673675\n",
      "\n",
      "\n",
      "Epoch: 1884\n",
      "Train Log likelihood, step 307100 in nats: 0.106459\n",
      "Train Log likelihood, step 307150 in nats: 0.106467\n",
      "Train Log likelihood, step 307200 in nats: 0.106474\n",
      "Train Log likelihood, step 307250 in nats: 0.106481\n",
      "Train epoch average loss: 0.10648039288606508\n",
      "\n",
      "\n",
      "Epoch: 1885\n",
      "Train Log likelihood, step 307300 in nats: 0.106486\n",
      "Train Log likelihood, step 307350 in nats: 0.106498\n",
      "Train Log likelihood, step 307400 in nats: 0.106504\n",
      "Train epoch average loss: 0.10650550912527557\n",
      "\n",
      "\n",
      "Epoch: 1886\n",
      "Train Log likelihood, step 307450 in nats: 0.106510\n",
      "Train Log likelihood, step 307500 in nats: 0.106519\n",
      "Train Log likelihood, step 307550 in nats: 0.106525\n",
      "Train epoch average loss: 0.10652894630346331\n",
      "\n",
      "\n",
      "Epoch: 1887\n",
      "Train Log likelihood, step 307600 in nats: 0.106532\n",
      "Train Log likelihood, step 307650 in nats: 0.106540\n",
      "Train Log likelihood, step 307700 in nats: 0.106549\n",
      "Train epoch average loss: 0.10655653038058599\n",
      "\n",
      "\n",
      "Epoch: 1888\n",
      "Train Log likelihood, step 307750 in nats: 0.106556\n",
      "Train Log likelihood, step 307800 in nats: 0.106566\n",
      "Train Log likelihood, step 307850 in nats: 0.106578\n",
      "Train Log likelihood, step 307900 in nats: 0.106589\n",
      "Train epoch average loss: 0.1065906168292555\n",
      "\n",
      "\n",
      "Epoch: 1889\n",
      "Train Log likelihood, step 307950 in nats: 0.106597\n",
      "Train Log likelihood, step 308000 in nats: 0.106608\n",
      "Train Log likelihood, step 308050 in nats: 0.106615\n",
      "Train epoch average loss: 0.10661854192657379\n",
      "\n",
      "\n",
      "Epoch: 1890\n",
      "Train Log likelihood, step 308100 in nats: 0.106620\n",
      "Train Log likelihood, step 308150 in nats: 0.106622\n",
      "Train Log likelihood, step 308200 in nats: 0.106629\n",
      "Train epoch average loss: 0.10663432492586195\n",
      "\n",
      "\n",
      "Epoch: 1891\n",
      "Train Log likelihood, step 308250 in nats: 0.106638\n",
      "Train Log likelihood, step 308300 in nats: 0.106642\n",
      "Train Log likelihood, step 308350 in nats: 0.106644\n",
      "Train epoch average loss: 0.10665184405308795\n",
      "\n",
      "\n",
      "Epoch: 1892\n",
      "Train Log likelihood, step 308400 in nats: 0.106651\n",
      "Train Log likelihood, step 308450 in nats: 0.106657\n",
      "Train Log likelihood, step 308500 in nats: 0.106665\n",
      "Train Log likelihood, step 308550 in nats: 0.106676\n",
      "Train epoch average loss: 0.1066766763972998\n",
      "\n",
      "\n",
      "Epoch: 1893\n",
      "Train Log likelihood, step 308600 in nats: 0.106682\n",
      "Train Log likelihood, step 308650 in nats: 0.106694\n",
      "Train Log likelihood, step 308700 in nats: 0.106703\n",
      "Train epoch average loss: 0.10670127872695692\n",
      "\n",
      "\n",
      "Epoch: 1894\n",
      "Train Log likelihood, step 308750 in nats: 0.106707\n",
      "Train Log likelihood, step 308800 in nats: 0.106714\n",
      "Train Log likelihood, step 308850 in nats: 0.106718\n",
      "Train epoch average loss: 0.10672471982201961\n",
      "\n",
      "\n",
      "Epoch: 1895\n",
      "Train Log likelihood, step 308900 in nats: 0.106724\n",
      "Train Log likelihood, step 308950 in nats: 0.106727\n",
      "Train Log likelihood, step 309000 in nats: 0.106733\n",
      "Train epoch average loss: 0.10673889304455512\n",
      "\n",
      "\n",
      "Epoch: 1896\n",
      "Train Log likelihood, step 309050 in nats: 0.106740\n",
      "Train Log likelihood, step 309100 in nats: 0.106745\n",
      "Train Log likelihood, step 309150 in nats: 0.106750\n",
      "Train Log likelihood, step 309200 in nats: 0.106760\n",
      "Train epoch average loss: 0.10675921194944685\n",
      "\n",
      "\n",
      "Epoch: 1897\n",
      "Train Log likelihood, step 309250 in nats: 0.106766\n",
      "Train Log likelihood, step 309300 in nats: 0.106765\n",
      "Train Log likelihood, step 309350 in nats: 0.106775\n",
      "Train epoch average loss: 0.10677787669384951\n",
      "\n",
      "\n",
      "Epoch: 1898\n",
      "Train Log likelihood, step 309400 in nats: 0.106775\n",
      "Train Log likelihood, step 309450 in nats: 0.106780\n",
      "Train Log likelihood, step 309500 in nats: 0.106785\n",
      "Train epoch average loss: 0.10678730410672929\n",
      "\n",
      "\n",
      "Epoch: 1899\n",
      "Train Log likelihood, step 309550 in nats: 0.106790\n",
      "Train Log likelihood, step 309600 in nats: 0.106791\n",
      "Train Log likelihood, step 309650 in nats: 0.106797\n",
      "Train epoch average loss: 0.10680171069414059\n",
      "\n",
      "\n",
      "Epoch: 1900\n",
      "Train Log likelihood, step 309700 in nats: 0.106802\n",
      "Train Log likelihood, step 309750 in nats: 0.106805\n",
      "Train Log likelihood, step 309800 in nats: 0.106805\n",
      "Train Log likelihood, step 309850 in nats: 0.106814\n",
      "Train epoch average loss: 0.10681349419881762\n",
      "\n",
      "\n",
      "Epoch: 1901\n",
      "Train Log likelihood, step 309900 in nats: 0.106817\n",
      "Train Log likelihood, step 309950 in nats: 0.106826\n",
      "Train Log likelihood, step 310000 in nats: 0.106838\n",
      "Train epoch average loss: 0.1068399313154186\n",
      "\n",
      "\n",
      "Epoch: 1902\n",
      "Train Log likelihood, step 310050 in nats: 0.106843\n",
      "Train Log likelihood, step 310100 in nats: 0.106844\n",
      "Train Log likelihood, step 310150 in nats: 0.106855\n",
      "Train epoch average loss: 0.10685612470351848\n",
      "\n",
      "\n",
      "Epoch: 1903\n",
      "Train Log likelihood, step 310200 in nats: 0.106857\n",
      "Train Log likelihood, step 310250 in nats: 0.106868\n",
      "Train Log likelihood, step 310300 in nats: 0.106874\n",
      "Train Log likelihood, step 310350 in nats: 0.106885\n",
      "Train epoch average loss: 0.10688511002754932\n",
      "\n",
      "\n",
      "Epoch: 1904\n",
      "Train Log likelihood, step 310400 in nats: 0.106891\n",
      "Train Log likelihood, step 310450 in nats: 0.106899\n",
      "Train Log likelihood, step 310500 in nats: 0.106902\n",
      "Train epoch average loss: 0.10690084214499282\n",
      "\n",
      "\n",
      "Epoch: 1905\n",
      "Train Log likelihood, step 310550 in nats: 0.106903\n",
      "Train Log likelihood, step 310600 in nats: 0.106911\n",
      "Train Log likelihood, step 310650 in nats: 0.106917\n",
      "Train epoch average loss: 0.10692402107456654\n",
      "\n",
      "\n",
      "Epoch: 1906\n",
      "Train Log likelihood, step 310700 in nats: 0.106928\n",
      "Train Log likelihood, step 310750 in nats: 0.106934\n",
      "Train Log likelihood, step 310800 in nats: 0.106937\n",
      "Train epoch average loss: 0.10693730043249157\n",
      "\n",
      "\n",
      "Epoch: 1907\n",
      "Train Log likelihood, step 310850 in nats: 0.106941\n",
      "Train Log likelihood, step 310900 in nats: 0.106945\n",
      "Train Log likelihood, step 310950 in nats: 0.106949\n",
      "Train Log likelihood, step 311000 in nats: 0.106955\n",
      "Train epoch average loss: 0.1069555344060242\n",
      "\n",
      "\n",
      "Epoch: 1908\n",
      "Train Log likelihood, step 311050 in nats: 0.106961\n",
      "Train Log likelihood, step 311100 in nats: 0.106966\n",
      "Train Log likelihood, step 311150 in nats: 0.106972\n",
      "Train epoch average loss: 0.10697262340749193\n",
      "\n",
      "\n",
      "Epoch: 1909\n",
      "Train Log likelihood, step 311200 in nats: 0.106974\n",
      "Train Log likelihood, step 311250 in nats: 0.106975\n",
      "Train Log likelihood, step 311300 in nats: 0.106976\n",
      "Train epoch average loss: 0.10697494884560892\n",
      "\n",
      "\n",
      "Epoch: 1910\n",
      "Train Log likelihood, step 311350 in nats: 0.106975\n",
      "Train Log likelihood, step 311400 in nats: 0.106980\n",
      "Train Log likelihood, step 311450 in nats: 0.106987\n",
      "Train epoch average loss: 0.10699277892889983\n",
      "\n",
      "\n",
      "Epoch: 1911\n",
      "Train Log likelihood, step 311500 in nats: 0.106992\n",
      "Train Log likelihood, step 311550 in nats: 0.107003\n",
      "Train Log likelihood, step 311600 in nats: 0.107008\n",
      "Train Log likelihood, step 311650 in nats: 0.107015\n",
      "Train epoch average loss: 0.10701397094713416\n",
      "\n",
      "\n",
      "Epoch: 1912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 311700 in nats: 0.107017\n",
      "Train Log likelihood, step 311750 in nats: 0.107021\n",
      "Train Log likelihood, step 311800 in nats: 0.107026\n",
      "Train epoch average loss: 0.10702678008635096\n",
      "\n",
      "\n",
      "Epoch: 1913\n",
      "Train Log likelihood, step 311850 in nats: 0.107030\n",
      "Train Log likelihood, step 311900 in nats: 0.107034\n",
      "Train Log likelihood, step 311950 in nats: 0.107036\n",
      "Train epoch average loss: 0.10703977002364995\n",
      "\n",
      "\n",
      "Epoch: 1914\n",
      "Train Log likelihood, step 312000 in nats: 0.107041\n",
      "Train Log likelihood, step 312050 in nats: 0.107043\n",
      "Train Log likelihood, step 312100 in nats: 0.107049\n",
      "Train epoch average loss: 0.10705489061499486\n",
      "\n",
      "\n",
      "Epoch: 1915\n",
      "Train Log likelihood, step 312150 in nats: 0.107056\n",
      "Train Log likelihood, step 312200 in nats: 0.107062\n",
      "Train Log likelihood, step 312250 in nats: 0.107061\n",
      "Train Log likelihood, step 312300 in nats: 0.107065\n",
      "Train epoch average loss: 0.10706581305997288\n",
      "\n",
      "\n",
      "Epoch: 1916\n",
      "Train Log likelihood, step 312350 in nats: 0.107070\n",
      "Train Log likelihood, step 312400 in nats: 0.107073\n",
      "Train Log likelihood, step 312450 in nats: 0.107078\n",
      "Train epoch average loss: 0.10707824227547408\n",
      "\n",
      "\n",
      "Epoch: 1917\n",
      "Train Log likelihood, step 312500 in nats: 0.107077\n",
      "Train Log likelihood, step 312550 in nats: 0.107081\n",
      "Train Log likelihood, step 312600 in nats: 0.107089\n",
      "Train epoch average loss: 0.10709045377831364\n",
      "\n",
      "\n",
      "Epoch: 1918\n",
      "Train Log likelihood, step 312650 in nats: 0.107092\n",
      "Train Log likelihood, step 312700 in nats: 0.107099\n",
      "Train Log likelihood, step 312750 in nats: 0.107099\n",
      "Train epoch average loss: 0.10709910658726955\n",
      "\n",
      "\n",
      "Epoch: 1919\n",
      "Train Log likelihood, step 312800 in nats: 0.107099\n",
      "Train Log likelihood, step 312850 in nats: 0.107105\n",
      "Train Log likelihood, step 312900 in nats: 0.107107\n",
      "Train Log likelihood, step 312950 in nats: 0.107112\n",
      "Train epoch average loss: 0.10711166662153365\n",
      "\n",
      "\n",
      "Epoch: 1920\n",
      "Train Log likelihood, step 313000 in nats: 0.107116\n",
      "Train Log likelihood, step 313050 in nats: 0.107119\n",
      "Train Log likelihood, step 313100 in nats: 0.107130\n",
      "Train epoch average loss: 0.10713276724473277\n",
      "\n",
      "\n",
      "Epoch: 1921\n",
      "Train Log likelihood, step 313150 in nats: 0.107136\n",
      "Train Log likelihood, step 313200 in nats: 0.107141\n",
      "Train Log likelihood, step 313250 in nats: 0.107146\n",
      "Train epoch average loss: 0.10715008713997726\n",
      "\n",
      "\n",
      "Epoch: 1922\n",
      "Train Log likelihood, step 313300 in nats: 0.107155\n",
      "Train Log likelihood, step 313350 in nats: 0.107163\n",
      "Train Log likelihood, step 313400 in nats: 0.107163\n",
      "Train epoch average loss: 0.10716868501539918\n",
      "\n",
      "\n",
      "Epoch: 1923\n",
      "Train Log likelihood, step 313450 in nats: 0.107170\n",
      "Train Log likelihood, step 313500 in nats: 0.107175\n",
      "Train Log likelihood, step 313550 in nats: 0.107181\n",
      "Train Log likelihood, step 313600 in nats: 0.107185\n",
      "Train epoch average loss: 0.10718499200709493\n",
      "\n",
      "\n",
      "Epoch: 1924\n",
      "Train Log likelihood, step 313650 in nats: 0.107187\n",
      "Train Log likelihood, step 313700 in nats: 0.107195\n",
      "Train Log likelihood, step 313750 in nats: 0.107196\n",
      "Train epoch average loss: 0.10719893830821979\n",
      "\n",
      "\n",
      "Epoch: 1925\n",
      "Train Log likelihood, step 313800 in nats: 0.107202\n",
      "Train Log likelihood, step 313850 in nats: 0.107210\n",
      "Train Log likelihood, step 313900 in nats: 0.107215\n",
      "Train epoch average loss: 0.10721512061116116\n",
      "\n",
      "\n",
      "Epoch: 1926\n",
      "Train Log likelihood, step 313950 in nats: 0.107217\n",
      "Train Log likelihood, step 314000 in nats: 0.107230\n",
      "Train Log likelihood, step 314050 in nats: 0.107235\n",
      "Train Log likelihood, step 314100 in nats: 0.107239\n",
      "Train epoch average loss: 0.10723893003996454\n",
      "\n",
      "\n",
      "Epoch: 1927\n",
      "Train Log likelihood, step 314150 in nats: 0.107247\n",
      "Train Log likelihood, step 314200 in nats: 0.107253\n",
      "Train Log likelihood, step 314250 in nats: 0.107261\n",
      "Train epoch average loss: 0.10726332287988173\n",
      "\n",
      "\n",
      "Epoch: 1928\n",
      "Train Log likelihood, step 314300 in nats: 0.107267\n",
      "Train Log likelihood, step 314350 in nats: 0.107276\n",
      "Train Log likelihood, step 314400 in nats: 0.107280\n",
      "Train epoch average loss: 0.1072863890035464\n",
      "\n",
      "\n",
      "Epoch: 1929\n",
      "Train Log likelihood, step 314450 in nats: 0.107286\n",
      "Train Log likelihood, step 314500 in nats: 0.107294\n",
      "Train Log likelihood, step 314550 in nats: 0.107301\n",
      "Train epoch average loss: 0.10729862070129556\n",
      "\n",
      "\n",
      "Epoch: 1930\n",
      "Train Log likelihood, step 314600 in nats: 0.107301\n",
      "Train Log likelihood, step 314650 in nats: 0.107307\n",
      "Train Log likelihood, step 314700 in nats: 0.107314\n",
      "Train Log likelihood, step 314750 in nats: 0.107325\n",
      "Train epoch average loss: 0.1073260684805047\n",
      "\n",
      "\n",
      "Epoch: 1931\n",
      "Train Log likelihood, step 314800 in nats: 0.107332\n",
      "Train Log likelihood, step 314850 in nats: 0.107331\n",
      "Train Log likelihood, step 314900 in nats: 0.107333\n",
      "Train epoch average loss: 0.107335486988359\n",
      "\n",
      "\n",
      "Epoch: 1932\n",
      "Train Log likelihood, step 314950 in nats: 0.107338\n",
      "Train Log likelihood, step 315000 in nats: 0.107344\n",
      "Train Log likelihood, step 315050 in nats: 0.107356\n",
      "Train epoch average loss: 0.10735692897028806\n",
      "\n",
      "\n",
      "Epoch: 1933\n",
      "Train Log likelihood, step 315100 in nats: 0.107366\n",
      "Train Log likelihood, step 315150 in nats: 0.107377\n",
      "Train Log likelihood, step 315200 in nats: 0.107385\n",
      "Train epoch average loss: 0.1073864277883608\n",
      "\n",
      "\n",
      "Epoch: 1934\n",
      "Train Log likelihood, step 315250 in nats: 0.107389\n",
      "Train Log likelihood, step 315300 in nats: 0.107394\n",
      "Train Log likelihood, step 315350 in nats: 0.107403\n",
      "Train Log likelihood, step 315400 in nats: 0.107408\n",
      "Train epoch average loss: 0.10740772920045286\n",
      "\n",
      "\n",
      "Epoch: 1935\n",
      "Train Log likelihood, step 315450 in nats: 0.107409\n",
      "Train Log likelihood, step 315500 in nats: 0.107412\n",
      "Train Log likelihood, step 315550 in nats: 0.107413\n",
      "Train epoch average loss: 0.10741413075738279\n",
      "\n",
      "\n",
      "Epoch: 1936\n",
      "Train Log likelihood, step 315600 in nats: 0.107419\n",
      "Train Log likelihood, step 315650 in nats: 0.107420\n",
      "Train Log likelihood, step 315700 in nats: 0.107424\n",
      "Train epoch average loss: 0.10742253901312727\n",
      "\n",
      "\n",
      "Epoch: 1937\n",
      "Train Log likelihood, step 315750 in nats: 0.107421\n",
      "Train Log likelihood, step 315800 in nats: 0.107423\n",
      "Train Log likelihood, step 315850 in nats: 0.107427\n",
      "Train epoch average loss: 0.10743371795628422\n",
      "\n",
      "\n",
      "Epoch: 1938\n",
      "Train Log likelihood, step 315900 in nats: 0.107434\n",
      "Train Log likelihood, step 315950 in nats: 0.107442\n",
      "Train Log likelihood, step 316000 in nats: 0.107447\n",
      "Train Log likelihood, step 316050 in nats: 0.107452\n",
      "Train epoch average loss: 0.10745255568807686\n",
      "\n",
      "\n",
      "Epoch: 1939\n",
      "Train Log likelihood, step 316100 in nats: 0.107458\n",
      "Train Log likelihood, step 316150 in nats: 0.107461\n",
      "Train Log likelihood, step 316200 in nats: 0.107465\n",
      "Train epoch average loss: 0.10746774333339922\n",
      "\n",
      "\n",
      "Epoch: 1940\n",
      "Train Log likelihood, step 316250 in nats: 0.107468\n",
      "Train Log likelihood, step 316300 in nats: 0.107473\n",
      "Train Log likelihood, step 316350 in nats: 0.107479\n",
      "Train epoch average loss: 0.10748356218190921\n",
      "\n",
      "\n",
      "Epoch: 1941\n",
      "Train Log likelihood, step 316400 in nats: 0.107485\n",
      "Train Log likelihood, step 316450 in nats: 0.107489\n",
      "Train Log likelihood, step 316500 in nats: 0.107490\n",
      "Train epoch average loss: 0.10750302757972689\n",
      "\n",
      "\n",
      "Epoch: 1942\n",
      "Train Log likelihood, step 316550 in nats: 0.107505\n",
      "Train Log likelihood, step 316600 in nats: 0.107510\n",
      "Train Log likelihood, step 316650 in nats: 0.107519\n",
      "Train Log likelihood, step 316700 in nats: 0.107519\n",
      "Train epoch average loss: 0.10752184210410916\n",
      "\n",
      "\n",
      "Epoch: 1943\n",
      "Train Log likelihood, step 316750 in nats: 0.107532\n",
      "Train Log likelihood, step 316800 in nats: 0.107538\n",
      "Train Log likelihood, step 316850 in nats: 0.107540\n",
      "Train epoch average loss: 0.10754190344196778\n",
      "\n",
      "\n",
      "Epoch: 1944\n",
      "Train Log likelihood, step 316900 in nats: 0.107543\n",
      "Train Log likelihood, step 316950 in nats: 0.107539\n",
      "Train Log likelihood, step 317000 in nats: 0.107541\n",
      "Train epoch average loss: 0.10754173918464548\n",
      "\n",
      "\n",
      "Epoch: 1945\n",
      "Train Log likelihood, step 317050 in nats: 0.107545\n",
      "Train Log likelihood, step 317100 in nats: 0.107551\n",
      "Train Log likelihood, step 317150 in nats: 0.107560\n",
      "Train epoch average loss: 0.10756495654586272\n",
      "\n",
      "\n",
      "Epoch: 1946\n",
      "Train Log likelihood, step 317200 in nats: 0.107564\n",
      "Train Log likelihood, step 317250 in nats: 0.107567\n",
      "Train Log likelihood, step 317300 in nats: 0.107571\n",
      "Train Log likelihood, step 317350 in nats: 0.107580\n",
      "Train epoch average loss: 0.10758306834665571\n",
      "\n",
      "\n",
      "Epoch: 1947\n",
      "Train Log likelihood, step 317400 in nats: 0.107589\n",
      "Train Log likelihood, step 317450 in nats: 0.107588\n",
      "Train Log likelihood, step 317500 in nats: 0.107591\n",
      "Train epoch average loss: 0.10758962641639162\n",
      "\n",
      "\n",
      "Epoch: 1948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 317550 in nats: 0.107593\n",
      "Train Log likelihood, step 317600 in nats: 0.107598\n",
      "Train Log likelihood, step 317650 in nats: 0.107602\n",
      "Train epoch average loss: 0.10760487612468067\n",
      "\n",
      "\n",
      "Epoch: 1949\n",
      "Train Log likelihood, step 317700 in nats: 0.107604\n",
      "Train Log likelihood, step 317750 in nats: 0.107609\n",
      "Train Log likelihood, step 317800 in nats: 0.107617\n",
      "Train epoch average loss: 0.10762535682668375\n",
      "\n",
      "\n",
      "Epoch: 1950\n",
      "Train Log likelihood, step 317850 in nats: 0.107626\n",
      "Train Log likelihood, step 317900 in nats: 0.107629\n",
      "Train Log likelihood, step 317950 in nats: 0.107633\n",
      "Train Log likelihood, step 318000 in nats: 0.107643\n",
      "Train epoch average loss: 0.10764484392637502\n",
      "\n",
      "\n",
      "Epoch: 1951\n",
      "Train Log likelihood, step 318050 in nats: 0.107651\n",
      "Train Log likelihood, step 318100 in nats: 0.107654\n",
      "Train Log likelihood, step 318150 in nats: 0.107663\n",
      "Train epoch average loss: 0.10766361567530426\n",
      "\n",
      "\n",
      "Epoch: 1952\n",
      "Train Log likelihood, step 318200 in nats: 0.107664\n",
      "Train Log likelihood, step 318250 in nats: 0.107669\n",
      "Train Log likelihood, step 318300 in nats: 0.107669\n",
      "Train epoch average loss: 0.10767219675252968\n",
      "\n",
      "\n",
      "Epoch: 1953\n",
      "Train Log likelihood, step 318350 in nats: 0.107672\n",
      "Train Log likelihood, step 318400 in nats: 0.107675\n",
      "Train Log likelihood, step 318450 in nats: 0.107678\n",
      "Train Log likelihood, step 318500 in nats: 0.107684\n",
      "Train epoch average loss: 0.10768407861287503\n",
      "\n",
      "\n",
      "Epoch: 1954\n",
      "Train Log likelihood, step 318550 in nats: 0.107693\n",
      "Train Log likelihood, step 318600 in nats: 0.107700\n",
      "Train Log likelihood, step 318650 in nats: 0.107704\n",
      "Train epoch average loss: 0.10770478697451301\n",
      "\n",
      "\n",
      "Epoch: 1955\n",
      "Train Log likelihood, step 318700 in nats: 0.107710\n",
      "Train Log likelihood, step 318750 in nats: 0.107712\n",
      "Train Log likelihood, step 318800 in nats: 0.107720\n",
      "Train epoch average loss: 0.10771914318779353\n",
      "\n",
      "\n",
      "Epoch: 1956\n",
      "Train Log likelihood, step 318850 in nats: 0.107717\n",
      "Train Log likelihood, step 318900 in nats: 0.107723\n",
      "Train Log likelihood, step 318950 in nats: 0.107730\n",
      "Train epoch average loss: 0.10773092333799897\n",
      "\n",
      "\n",
      "Epoch: 1957\n",
      "Train Log likelihood, step 319000 in nats: 0.107730\n",
      "Train Log likelihood, step 319050 in nats: 0.107738\n",
      "Train Log likelihood, step 319100 in nats: 0.107744\n",
      "Train Log likelihood, step 319150 in nats: 0.107741\n",
      "Train epoch average loss: 0.10774023792332543\n",
      "\n",
      "\n",
      "Epoch: 1958\n",
      "Train Log likelihood, step 319200 in nats: 0.107741\n",
      "Train Log likelihood, step 319250 in nats: 0.107741\n",
      "Train Log likelihood, step 319300 in nats: 0.107742\n",
      "Train epoch average loss: 0.10774443828578734\n",
      "\n",
      "\n",
      "Epoch: 1959\n",
      "Train Log likelihood, step 319350 in nats: 0.107749\n",
      "Train Log likelihood, step 319400 in nats: 0.107752\n",
      "Train Log likelihood, step 319450 in nats: 0.107761\n",
      "Train epoch average loss: 0.10776284311906097\n",
      "\n",
      "\n",
      "Epoch: 1960\n",
      "Train Log likelihood, step 319500 in nats: 0.107761\n",
      "Train Log likelihood, step 319550 in nats: 0.107766\n",
      "Train Log likelihood, step 319600 in nats: 0.107768\n",
      "Train epoch average loss: 0.10777306803543771\n",
      "\n",
      "\n",
      "Epoch: 1961\n",
      "Train Log likelihood, step 319650 in nats: 0.107773\n",
      "Train Log likelihood, step 319700 in nats: 0.107779\n",
      "Train Log likelihood, step 319750 in nats: 0.107788\n",
      "Train Log likelihood, step 319800 in nats: 0.107795\n",
      "Train epoch average loss: 0.10779607350588956\n",
      "\n",
      "\n",
      "Epoch: 1962\n",
      "Train Log likelihood, step 319850 in nats: 0.107798\n",
      "Train Log likelihood, step 319900 in nats: 0.107805\n",
      "Train Log likelihood, step 319950 in nats: 0.107806\n",
      "Train epoch average loss: 0.10780680971157794\n",
      "\n",
      "\n",
      "Epoch: 1963\n",
      "Train Log likelihood, step 320000 in nats: 0.107811\n",
      "Train Log likelihood, step 320050 in nats: 0.107817\n",
      "Train Log likelihood, step 320100 in nats: 0.107823\n",
      "Train epoch average loss: 0.10782837116646658\n",
      "\n",
      "\n",
      "Epoch: 1964\n",
      "Train Log likelihood, step 320150 in nats: 0.107829\n",
      "Train Log likelihood, step 320200 in nats: 0.107840\n",
      "Train Log likelihood, step 320250 in nats: 0.107847\n",
      "Train epoch average loss: 0.10785687710019001\n",
      "\n",
      "\n",
      "Epoch: 1965\n",
      "Train Log likelihood, step 320300 in nats: 0.107857\n",
      "Train Log likelihood, step 320350 in nats: 0.107854\n",
      "Train Log likelihood, step 320400 in nats: 0.107853\n",
      "Train Log likelihood, step 320450 in nats: 0.107856\n",
      "Train epoch average loss: 0.10785723985582135\n",
      "\n",
      "\n",
      "Epoch: 1966\n",
      "Train Log likelihood, step 320500 in nats: 0.107857\n",
      "Train Log likelihood, step 320550 in nats: 0.107869\n",
      "Train Log likelihood, step 320600 in nats: 0.107875\n",
      "Train epoch average loss: 0.10787415707638852\n",
      "\n",
      "\n",
      "Epoch: 1967\n",
      "Train Log likelihood, step 320650 in nats: 0.107878\n",
      "Train Log likelihood, step 320700 in nats: 0.107877\n",
      "Train Log likelihood, step 320750 in nats: 0.107879\n",
      "Train epoch average loss: 0.10788522085368232\n",
      "\n",
      "\n",
      "Epoch: 1968\n",
      "Train Log likelihood, step 320800 in nats: 0.107889\n",
      "Train Log likelihood, step 320850 in nats: 0.107896\n",
      "Train Log likelihood, step 320900 in nats: 0.107907\n",
      "Train epoch average loss: 0.1079122974227992\n",
      "\n",
      "\n",
      "Epoch: 1969\n",
      "Train Log likelihood, step 320950 in nats: 0.107913\n",
      "Train Log likelihood, step 321000 in nats: 0.107916\n",
      "Train Log likelihood, step 321050 in nats: 0.107920\n",
      "Train Log likelihood, step 321100 in nats: 0.107923\n",
      "Train epoch average loss: 0.10792116323970559\n",
      "\n",
      "\n",
      "Epoch: 1970\n",
      "Train Log likelihood, step 321150 in nats: 0.107923\n",
      "Train Log likelihood, step 321200 in nats: 0.107930\n",
      "Train Log likelihood, step 321250 in nats: 0.107937\n",
      "Train epoch average loss: 0.10794156454731747\n",
      "\n",
      "\n",
      "Epoch: 1971\n",
      "Train Log likelihood, step 321300 in nats: 0.107943\n",
      "Train Log likelihood, step 321350 in nats: 0.107951\n",
      "Train Log likelihood, step 321400 in nats: 0.107954\n",
      "Train epoch average loss: 0.10795930865769553\n",
      "\n",
      "\n",
      "Epoch: 1972\n",
      "Train Log likelihood, step 321450 in nats: 0.107964\n",
      "Train Log likelihood, step 321500 in nats: 0.107972\n",
      "Train Log likelihood, step 321550 in nats: 0.107981\n",
      "Train epoch average loss: 0.10798492624315625\n",
      "\n",
      "\n",
      "Epoch: 1973\n",
      "Train Log likelihood, step 321600 in nats: 0.107986\n",
      "Train Log likelihood, step 321650 in nats: 0.107990\n",
      "Train Log likelihood, step 321700 in nats: 0.107998\n",
      "Train Log likelihood, step 321750 in nats: 0.108004\n",
      "Train epoch average loss: 0.10800657520673436\n",
      "\n",
      "\n",
      "Epoch: 1974\n",
      "Train Log likelihood, step 321800 in nats: 0.108005\n",
      "Train Log likelihood, step 321850 in nats: 0.108007\n",
      "Train Log likelihood, step 321900 in nats: 0.108016\n",
      "Train epoch average loss: 0.10801897984190935\n",
      "\n",
      "\n",
      "Epoch: 1975\n",
      "Train Log likelihood, step 321950 in nats: 0.108020\n",
      "Train Log likelihood, step 322000 in nats: 0.108029\n",
      "Train Log likelihood, step 322050 in nats: 0.108030\n",
      "Train epoch average loss: 0.10803290047407278\n",
      "\n",
      "\n",
      "Epoch: 1976\n",
      "Train Log likelihood, step 322100 in nats: 0.108032\n",
      "Train Log likelihood, step 322150 in nats: 0.108031\n",
      "Train Log likelihood, step 322200 in nats: 0.108036\n",
      "Train Log likelihood, step 322250 in nats: 0.108035\n",
      "Train epoch average loss: 0.10803547868762864\n",
      "\n",
      "\n",
      "Epoch: 1977\n",
      "Train Log likelihood, step 322300 in nats: 0.108037\n",
      "Train Log likelihood, step 322350 in nats: 0.108043\n",
      "Train Log likelihood, step 322400 in nats: 0.108054\n",
      "Train epoch average loss: 0.1080569236365733\n",
      "\n",
      "\n",
      "Epoch: 1978\n",
      "Train Log likelihood, step 322450 in nats: 0.108064\n",
      "Train Log likelihood, step 322500 in nats: 0.108071\n",
      "Train Log likelihood, step 322550 in nats: 0.108079\n",
      "Train epoch average loss: 0.10808209158857253\n",
      "\n",
      "\n",
      "Epoch: 1979\n",
      "Train Log likelihood, step 322600 in nats: 0.108087\n",
      "Train Log likelihood, step 322650 in nats: 0.108091\n",
      "Train Log likelihood, step 322700 in nats: 0.108095\n",
      "Train epoch average loss: 0.10809474559561845\n",
      "\n",
      "\n",
      "Epoch: 1980\n",
      "Train Log likelihood, step 322750 in nats: 0.108095\n",
      "Train Log likelihood, step 322800 in nats: 0.108096\n",
      "Train Log likelihood, step 322850 in nats: 0.108102\n",
      "Train Log likelihood, step 322900 in nats: 0.108108\n",
      "Train epoch average loss: 0.10810739005136977\n",
      "\n",
      "\n",
      "Epoch: 1981\n",
      "Train Log likelihood, step 322950 in nats: 0.108111\n",
      "Train Log likelihood, step 323000 in nats: 0.108110\n",
      "Train Log likelihood, step 323050 in nats: 0.108114\n",
      "Train epoch average loss: 0.10811656730306048\n",
      "\n",
      "\n",
      "Epoch: 1982\n",
      "Train Log likelihood, step 323100 in nats: 0.108124\n",
      "Train Log likelihood, step 323150 in nats: 0.108125\n",
      "Train Log likelihood, step 323200 in nats: 0.108127\n",
      "Train epoch average loss: 0.10813523871760268\n",
      "\n",
      "\n",
      "Epoch: 1983\n",
      "Train Log likelihood, step 323250 in nats: 0.108136\n",
      "Train Log likelihood, step 323300 in nats: 0.108144\n",
      "Train Log likelihood, step 323350 in nats: 0.108151\n",
      "Train epoch average loss: 0.10815727400901676\n",
      "\n",
      "\n",
      "Epoch: 1984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Log likelihood, step 323400 in nats: 0.108158\n",
      "Train Log likelihood, step 323450 in nats: 0.108161\n",
      "Train Log likelihood, step 323500 in nats: 0.108162\n",
      "Train Log likelihood, step 323550 in nats: 0.108158\n",
      "Train epoch average loss: 0.10815859315008693\n",
      "\n",
      "\n",
      "Epoch: 1985\n",
      "Train Log likelihood, step 323600 in nats: 0.108158\n",
      "Train Log likelihood, step 323650 in nats: 0.108159\n",
      "Train Log likelihood, step 323700 in nats: 0.108160\n",
      "Train epoch average loss: 0.10816061900116758\n",
      "\n",
      "\n",
      "Epoch: 1986\n",
      "Train Log likelihood, step 323750 in nats: 0.108164\n",
      "Train Log likelihood, step 323800 in nats: 0.108171\n",
      "Train Log likelihood, step 323850 in nats: 0.108178\n",
      "Train epoch average loss: 0.10817854702142368\n",
      "\n",
      "\n",
      "Epoch: 1987\n",
      "Train Log likelihood, step 323900 in nats: 0.108181\n",
      "Train Log likelihood, step 323950 in nats: 0.108186\n",
      "Train Log likelihood, step 324000 in nats: 0.108192\n",
      "Train epoch average loss: 0.1081974705710097\n",
      "\n",
      "\n",
      "Epoch: 1988\n",
      "Train Log likelihood, step 324050 in nats: 0.108198\n",
      "Train Log likelihood, step 324100 in nats: 0.108204\n",
      "Train Log likelihood, step 324150 in nats: 0.108208\n",
      "Train Log likelihood, step 324200 in nats: 0.108202\n",
      "Train epoch average loss: 0.10820358021506167\n",
      "\n",
      "\n",
      "Epoch: 1989\n",
      "Train Log likelihood, step 324250 in nats: 0.108201\n",
      "Train Log likelihood, step 324300 in nats: 0.108198\n",
      "Train Log likelihood, step 324350 in nats: 0.108199\n",
      "Train epoch average loss: 0.10820130055709552\n",
      "\n",
      "\n",
      "Epoch: 1990\n",
      "Train Log likelihood, step 324400 in nats: 0.108203\n",
      "Train Log likelihood, step 324450 in nats: 0.108211\n",
      "Train Log likelihood, step 324500 in nats: 0.108211\n",
      "Train epoch average loss: 0.1082120112939094\n",
      "\n",
      "\n",
      "Epoch: 1991\n",
      "Train Log likelihood, step 324550 in nats: 0.108213\n",
      "Train Log likelihood, step 324600 in nats: 0.108210\n",
      "Train Log likelihood, step 324650 in nats: 0.108211\n",
      "Train epoch average loss: 0.10821446906189076\n",
      "\n",
      "\n",
      "Epoch: 1992\n",
      "Train Log likelihood, step 324700 in nats: 0.108215\n",
      "Train Log likelihood, step 324750 in nats: 0.108217\n",
      "Train Log likelihood, step 324800 in nats: 0.108215\n",
      "Train Log likelihood, step 324850 in nats: 0.108216\n",
      "Train epoch average loss: 0.10821577201869546\n",
      "\n",
      "\n",
      "Epoch: 1993\n",
      "Train Log likelihood, step 324900 in nats: 0.108220\n",
      "Train Log likelihood, step 324950 in nats: 0.108227\n",
      "Train Log likelihood, step 325000 in nats: 0.108234\n",
      "Train epoch average loss: 0.10823461666529659\n",
      "\n",
      "\n",
      "Epoch: 1994\n",
      "Train Log likelihood, step 325050 in nats: 0.108239\n",
      "Train Log likelihood, step 325100 in nats: 0.108234\n",
      "Train Log likelihood, step 325150 in nats: 0.108234\n",
      "Train epoch average loss: 0.10823857180068681\n",
      "\n",
      "\n",
      "Epoch: 1995\n",
      "Train Log likelihood, step 325200 in nats: 0.108239\n",
      "Train Log likelihood, step 325250 in nats: 0.108244\n",
      "Train Log likelihood, step 325300 in nats: 0.108245\n",
      "Train epoch average loss: 0.10825209077650123\n",
      "\n",
      "\n",
      "Epoch: 1996\n",
      "Train Log likelihood, step 325350 in nats: 0.108253\n",
      "Train Log likelihood, step 325400 in nats: 0.108262\n",
      "Train Log likelihood, step 325450 in nats: 0.108270\n",
      "Train Log likelihood, step 325500 in nats: 0.108273\n",
      "Train epoch average loss: 0.10827344283864693\n",
      "\n",
      "\n",
      "Epoch: 1997\n",
      "Train Log likelihood, step 325550 in nats: 0.108280\n",
      "Train Log likelihood, step 325600 in nats: 0.108287\n",
      "Train Log likelihood, step 325650 in nats: 0.108294\n",
      "Train epoch average loss: 0.10829646191635343\n",
      "\n",
      "\n",
      "Epoch: 1998\n",
      "Train Log likelihood, step 325700 in nats: 0.108298\n",
      "Train Log likelihood, step 325750 in nats: 0.108302\n",
      "Train Log likelihood, step 325800 in nats: 0.108313\n",
      "Train epoch average loss: 0.10831647442202835\n",
      "\n",
      "\n",
      "Epoch: 1999\n",
      "Train Log likelihood, step 325850 in nats: 0.108319\n",
      "Train Log likelihood, step 325900 in nats: 0.108327\n",
      "Train Log likelihood, step 325950 in nats: 0.108331\n",
      "Train epoch average loss: 0.10833284998483995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond_enc.fit(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_samples(df, scaler, categorical_features, label_encoders):\n",
    "    aug_samples_df = pd.DataFrame(scaler.inverse_transform(df), columns=df.columns).astype(np.int64)\n",
    "    # clip negative values\n",
    "    aug_samples_df[aug_samples_df < 0] = 0\n",
    "    for j, feature in enumerate(categorical_features):\n",
    "        # clip out-of-category values\n",
    "        len_cls = len(list(label_encoders[j].classes_))\n",
    "        aug_samples_df.loc[aug_samples_df[feature] >= len_cls, feature] = len_cls - 1\n",
    "        aug_samples_df.loc[:, feature] = label_encoders[j].inverse_transform(aug_samples_df[feature])\n",
    "    return aug_samples_df\n",
    "\n",
    "def transform_samples(df, categorical_features, label_encoders):\n",
    "    dff = df.copy()\n",
    "    # encode object features to categorical integers\n",
    "    for j, feature in enumerate(categorical_features):\n",
    "        dff.loc[:, feature] = label_encoders[j].transform(dff[feature])\n",
    "    # fit a new scaler\n",
    "    aug_samples_df = pd.DataFrame(scaler.fit_transform(dff), columns=dff.columns)\n",
    "    return aug_samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gibbs sampling\n",
    "A practical challenge of the Gibbs sampler is that it's sensitive to initialization. Here, we initialize the sampler with original samples from the training set. Notice that `num_iter` should be multiplied by the size of the original training set. Meaning, `num_iter=5` and `len(pX_train)=1000` will generate 5k samples that can be used for distillation. In addition, one-round of Gibbs sampling is examined, based on the paper's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_samples = cond_enc.sample_gibbs(train_loader, rounds=1, num_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>70488</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-AF-spouse</td>\n",
       "      <td>Priv-house-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>188583</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-AF-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>Trinadad&amp;Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>62435</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>8</td>\n",
       "      <td>Married-AF-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>Trinadad&amp;Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>142365</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>8</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>Trinadad&amp;Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>96059</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>Trinadad&amp;Tobago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt    education  education.num  \\\n",
       "0   35      Never-worked   70488    Assoc-voc             12   \n",
       "1   41         Local-gov  188583    Bachelors             12   \n",
       "2   58      Never-worked   62435    Doctorate              8   \n",
       "3   58      Never-worked  142365    Doctorate              8   \n",
       "4   18  Self-emp-not-inc   96059  Prof-school              9   \n",
       "\n",
       "          marital.status         occupation    relationship   race     sex  \\\n",
       "0      Married-AF-spouse    Priv-house-serv         Husband  Other  Female   \n",
       "1      Married-AF-spouse    Protective-serv       Own-child  Other  Female   \n",
       "2      Married-AF-spouse  Handlers-cleaners         Husband  Other  Female   \n",
       "3  Married-spouse-absent    Protective-serv  Other-relative  Other  Female   \n",
       "4  Married-spouse-absent       Adm-clerical         Husband  Other  Female   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week   native.country  \n",
       "0           174             0              37         Thailand  \n",
       "1           171             0              48  Trinadad&Tobago  \n",
       "2           142             0              49  Trinadad&Tobago  \n",
       "3           176             0              58  Trinadad&Tobago  \n",
       "4           158             0              49  Trinadad&Tobago  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_samples_df = pd.DataFrame(aug_samples, columns=X.columns)\n",
    "gibbs_df = inverse_transform_samples(aug_samples_df, scaler, categorical, label_encoders)\n",
    "gibbs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditionals sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_cond_samples = cond_enc.sample_conditionals(train_loader, num_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>218164</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>160941</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-AF-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>3102</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>205152</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>115487</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-AF-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>151473</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     workclass  fnlwgt  education  education.num     marital.status  \\\n",
       "0   33  Never-worked  218164    HS-grad              9           Divorced   \n",
       "1   60  Never-worked  160941    HS-grad             14  Married-AF-spouse   \n",
       "2   32  Never-worked  205152  Assoc-voc             12      Never-married   \n",
       "3   33  Never-worked  115487    HS-grad              9  Married-AF-spouse   \n",
       "4   55  Never-worked  151473  Assoc-voc             12      Never-married   \n",
       "\n",
       "        occupation    relationship   race     sex  capital.gain  capital.loss  \\\n",
       "0     Armed-Forces       Own-child  Other  Female             0             1   \n",
       "1  Protective-serv         Husband  Other  Female          3102             0   \n",
       "2     Armed-Forces  Other-relative  Other  Female             0             2   \n",
       "3  Protective-serv         Husband  Other  Female             0             1   \n",
       "4     Tech-support  Other-relative  Other  Female             0             1   \n",
       "\n",
       "   hours.per.week native.country  \n",
       "0              44  United-States  \n",
       "1              49  United-States  \n",
       "2              40  United-States  \n",
       "3              40  United-States  \n",
       "4              38  United-States  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_cond_samples_df = pd.DataFrame(aug_cond_samples, columns=X.columns)\n",
    "cond_df = inverse_transform_samples(aug_cond_samples_df, scaler, categorical, label_encoders)\n",
    "cond_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label augmented features with the teacher model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distillation via Gibbs-sampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, process the sampled data for distillation in a similar manner to the pre-processing of the original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_gibbs_df = transform_samples(gibbs_df, categorical, label_encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict labels by the teacher model. The assumption here is that the teacher's accuracy is very high so we can actually count on it for labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_preds = predictor.predict_proba(proc_gibbs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_preds_np = teacher_preds.iloc[:, 1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.189439</td>\n",
       "      <td>-0.059037</td>\n",
       "      <td>-1.181389</td>\n",
       "      <td>-0.317863</td>\n",
       "      <td>1.171970</td>\n",
       "      <td>-0.625294</td>\n",
       "      <td>0.816614</td>\n",
       "      <td>-0.689595</td>\n",
       "      <td>0.358567</td>\n",
       "      <td>-0.087679</td>\n",
       "      <td>-0.164068</td>\n",
       "      <td>-0.189096</td>\n",
       "      <td>-0.174018</td>\n",
       "      <td>0.011348</td>\n",
       "      <td>0.410095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.220284</td>\n",
       "      <td>-1.062092</td>\n",
       "      <td>-0.056954</td>\n",
       "      <td>-0.056614</td>\n",
       "      <td>1.171970</td>\n",
       "      <td>-0.625294</td>\n",
       "      <td>1.359408</td>\n",
       "      <td>2.321456</td>\n",
       "      <td>0.358567</td>\n",
       "      <td>-0.087679</td>\n",
       "      <td>-0.165563</td>\n",
       "      <td>-0.189096</td>\n",
       "      <td>0.762145</td>\n",
       "      <td>0.241485</td>\n",
       "      <td>0.710511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.381165</td>\n",
       "      <td>-0.059037</td>\n",
       "      <td>-1.258065</td>\n",
       "      <td>0.204634</td>\n",
       "      <td>-0.418692</td>\n",
       "      <td>-0.625294</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>-0.689595</td>\n",
       "      <td>0.358567</td>\n",
       "      <td>-0.087679</td>\n",
       "      <td>-0.180013</td>\n",
       "      <td>-0.189096</td>\n",
       "      <td>0.847251</td>\n",
       "      <td>0.241485</td>\n",
       "      <td>0.187844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.381165</td>\n",
       "      <td>-0.059037</td>\n",
       "      <td>-0.497016</td>\n",
       "      <td>0.204634</td>\n",
       "      <td>-0.418692</td>\n",
       "      <td>1.036739</td>\n",
       "      <td>1.359408</td>\n",
       "      <td>1.317773</td>\n",
       "      <td>0.358567</td>\n",
       "      <td>-0.087679</td>\n",
       "      <td>-0.163071</td>\n",
       "      <td>-0.189096</td>\n",
       "      <td>1.613203</td>\n",
       "      <td>0.241485</td>\n",
       "      <td>0.051483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.350320</td>\n",
       "      <td>2.950126</td>\n",
       "      <td>-0.937916</td>\n",
       "      <td>1.249626</td>\n",
       "      <td>-0.021026</td>\n",
       "      <td>1.036739</td>\n",
       "      <td>-1.354560</td>\n",
       "      <td>-0.689595</td>\n",
       "      <td>0.358567</td>\n",
       "      <td>-0.087679</td>\n",
       "      <td>-0.172040</td>\n",
       "      <td>-0.189096</td>\n",
       "      <td>0.847251</td>\n",
       "      <td>0.241485</td>\n",
       "      <td>0.018493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education.num  marital.status  \\\n",
       "0 -0.189439  -0.059037 -1.181389  -0.317863       1.171970       -0.625294   \n",
       "1  0.220284  -1.062092 -0.056954  -0.056614       1.171970       -0.625294   \n",
       "2  1.381165  -0.059037 -1.258065   0.204634      -0.418692       -0.625294   \n",
       "3  1.381165  -0.059037 -0.497016   0.204634      -0.418692        1.036739   \n",
       "4 -1.350320   2.950126 -0.937916   1.249626      -0.021026        1.036739   \n",
       "\n",
       "   occupation  relationship      race       sex  capital.gain  capital.loss  \\\n",
       "0    0.816614     -0.689595  0.358567 -0.087679     -0.164068     -0.189096   \n",
       "1    1.359408      2.321456  0.358567 -0.087679     -0.165563     -0.189096   \n",
       "2    0.002424     -0.689595  0.358567 -0.087679     -0.180013     -0.189096   \n",
       "3    1.359408      1.317773  0.358567 -0.087679     -0.163071     -0.189096   \n",
       "4   -1.354560     -0.689595  0.358567 -0.087679     -0.172040     -0.189096   \n",
       "\n",
       "   hours.per.week  native.country    income  \n",
       "0       -0.174018        0.011348  0.410095  \n",
       "1        0.762145        0.241485  0.710511  \n",
       "2        0.847251        0.241485  0.187844  \n",
       "3        1.613203        0.241485  0.051483  \n",
       "4        0.847251        0.241485  0.018493  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug_gibbs_teacher_preds = proc_gibbs_df.copy()\n",
    "df_aug_gibbs_teacher_preds[label] = teacher_preds_np\n",
    "df_aug_gibbs_teacher_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the original training set and the augmented samples after being labeled by the teacher model. This forms the new training set for fitting the student model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size: 16280\n",
      "Augmeneted training set size: 81400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.189439</td>\n",
       "      <td>-0.059037</td>\n",
       "      <td>-1.181389</td>\n",
       "      <td>-0.317863</td>\n",
       "      <td>1.171970</td>\n",
       "      <td>-0.625294</td>\n",
       "      <td>0.816614</td>\n",
       "      <td>-0.689595</td>\n",
       "      <td>0.358567</td>\n",
       "      <td>-0.087679</td>\n",
       "      <td>-0.164068</td>\n",
       "      <td>-0.189096</td>\n",
       "      <td>-0.174018</td>\n",
       "      <td>0.011348</td>\n",
       "      <td>0.410095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.220284</td>\n",
       "      <td>-1.062092</td>\n",
       "      <td>-0.056954</td>\n",
       "      <td>-0.056614</td>\n",
       "      <td>1.171970</td>\n",
       "      <td>-0.625294</td>\n",
       "      <td>1.359408</td>\n",
       "      <td>2.321456</td>\n",
       "      <td>0.358567</td>\n",
       "      <td>-0.087679</td>\n",
       "      <td>-0.165563</td>\n",
       "      <td>-0.189096</td>\n",
       "      <td>0.762145</td>\n",
       "      <td>0.241485</td>\n",
       "      <td>0.710511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.381165</td>\n",
       "      <td>-0.059037</td>\n",
       "      <td>-1.258065</td>\n",
       "      <td>0.204634</td>\n",
       "      <td>-0.418692</td>\n",
       "      <td>-0.625294</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>-0.689595</td>\n",
       "      <td>0.358567</td>\n",
       "      <td>-0.087679</td>\n",
       "      <td>-0.180013</td>\n",
       "      <td>-0.189096</td>\n",
       "      <td>0.847251</td>\n",
       "      <td>0.241485</td>\n",
       "      <td>0.187844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.381165</td>\n",
       "      <td>-0.059037</td>\n",
       "      <td>-0.497016</td>\n",
       "      <td>0.204634</td>\n",
       "      <td>-0.418692</td>\n",
       "      <td>1.036739</td>\n",
       "      <td>1.359408</td>\n",
       "      <td>1.317773</td>\n",
       "      <td>0.358567</td>\n",
       "      <td>-0.087679</td>\n",
       "      <td>-0.163071</td>\n",
       "      <td>-0.189096</td>\n",
       "      <td>1.613203</td>\n",
       "      <td>0.241485</td>\n",
       "      <td>0.051483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.350320</td>\n",
       "      <td>2.950126</td>\n",
       "      <td>-0.937916</td>\n",
       "      <td>1.249626</td>\n",
       "      <td>-0.021026</td>\n",
       "      <td>1.036739</td>\n",
       "      <td>-1.354560</td>\n",
       "      <td>-0.689595</td>\n",
       "      <td>0.358567</td>\n",
       "      <td>-0.087679</td>\n",
       "      <td>-0.172040</td>\n",
       "      <td>-0.189096</td>\n",
       "      <td>0.847251</td>\n",
       "      <td>0.241485</td>\n",
       "      <td>0.018493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education.num  marital.status  \\\n",
       "0 -0.189439  -0.059037 -1.181389  -0.317863       1.171970       -0.625294   \n",
       "1  0.220284  -1.062092 -0.056954  -0.056614       1.171970       -0.625294   \n",
       "2  1.381165  -0.059037 -1.258065   0.204634      -0.418692       -0.625294   \n",
       "3  1.381165  -0.059037 -0.497016   0.204634      -0.418692        1.036739   \n",
       "4 -1.350320   2.950126 -0.937916   1.249626      -0.021026        1.036739   \n",
       "\n",
       "   occupation  relationship      race       sex  capital.gain  capital.loss  \\\n",
       "0    0.816614     -0.689595  0.358567 -0.087679     -0.164068     -0.189096   \n",
       "1    1.359408      2.321456  0.358567 -0.087679     -0.165563     -0.189096   \n",
       "2    0.002424     -0.689595  0.358567 -0.087679     -0.180013     -0.189096   \n",
       "3    1.359408      1.317773  0.358567 -0.087679     -0.163071     -0.189096   \n",
       "4   -1.354560     -0.689595  0.358567 -0.087679     -0.172040     -0.189096   \n",
       "\n",
       "   hours.per.week  native.country    income  \n",
       "0       -0.174018        0.011348  0.410095  \n",
       "1        0.762145        0.241485  0.710511  \n",
       "2        0.847251        0.241485  0.187844  \n",
       "3        1.613203        0.241485  0.051483  \n",
       "4        0.847251        0.241485  0.018493  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Original training set size: {len(df_train)}\\nAugmeneted training set size: {len(df_aug_gibbs_teacher_preds)}\")\n",
    "df_aug = pd.concat([df_aug_gibbs_teacher_preds, df_train])\n",
    "df_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug = df_aug.drop([label], axis=1)\n",
    "y_aug = df_aug[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestRegressor(random_state=0)\n",
    "clf.fit(X_aug, y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "test_probas = clf.predict(pX_test)\n",
    "test_preds = np.round(test_probas)\n",
    "print(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7885469091492391"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, test_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.903020760693811"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, test_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distillation via Conditinals-sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_cond_df = transform_samples(cond_df, categorical, label_encoders)\n",
    "teacher_preds = predictor.predict_proba(proc_cond_df)\n",
    "teacher_preds_np = teacher_preds.iloc[:, 1].to_numpy()\n",
    "df_aug_cond_teacher_preds = proc_cond_df.copy()\n",
    "df_aug_cond_teacher_preds[label] = teacher_preds_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size: 16280\n",
      "Augmeneted training set size: 81400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.372052</td>\n",
       "      <td>-0.255956</td>\n",
       "      <td>0.272900</td>\n",
       "      <td>0.332852</td>\n",
       "      <td>-0.223988</td>\n",
       "      <td>-1.268788</td>\n",
       "      <td>-1.121390</td>\n",
       "      <td>1.452792</td>\n",
       "      <td>0.399164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144256</td>\n",
       "      <td>-0.190852</td>\n",
       "      <td>0.305094</td>\n",
       "      <td>0.263627</td>\n",
       "      <td>0.174403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.596994</td>\n",
       "      <td>-0.255956</td>\n",
       "      <td>-0.268148</td>\n",
       "      <td>0.332852</td>\n",
       "      <td>1.805464</td>\n",
       "      <td>-0.662564</td>\n",
       "      <td>1.103020</td>\n",
       "      <td>-0.651992</td>\n",
       "      <td>0.399164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287178</td>\n",
       "      <td>-0.194372</td>\n",
       "      <td>0.710425</td>\n",
       "      <td>0.263627</td>\n",
       "      <td>0.872663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.444979</td>\n",
       "      <td>-0.255956</td>\n",
       "      <td>0.149870</td>\n",
       "      <td>-0.451576</td>\n",
       "      <td>0.993683</td>\n",
       "      <td>1.156108</td>\n",
       "      <td>-1.121390</td>\n",
       "      <td>0.751198</td>\n",
       "      <td>0.399164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144256</td>\n",
       "      <td>-0.187331</td>\n",
       "      <td>-0.019171</td>\n",
       "      <td>0.263627</td>\n",
       "      <td>0.027419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.372052</td>\n",
       "      <td>-0.255956</td>\n",
       "      <td>-0.697918</td>\n",
       "      <td>0.332852</td>\n",
       "      <td>-0.223988</td>\n",
       "      <td>-0.662564</td>\n",
       "      <td>1.103020</td>\n",
       "      <td>-0.651992</td>\n",
       "      <td>0.399164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144256</td>\n",
       "      <td>-0.190852</td>\n",
       "      <td>-0.019171</td>\n",
       "      <td>0.263627</td>\n",
       "      <td>0.270261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.232356</td>\n",
       "      <td>-0.255956</td>\n",
       "      <td>-0.357668</td>\n",
       "      <td>-0.451576</td>\n",
       "      <td>0.993683</td>\n",
       "      <td>1.156108</td>\n",
       "      <td>1.597334</td>\n",
       "      <td>0.751198</td>\n",
       "      <td>0.399164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144256</td>\n",
       "      <td>-0.190852</td>\n",
       "      <td>-0.181304</td>\n",
       "      <td>0.263627</td>\n",
       "      <td>0.125108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education.num  marital.status  \\\n",
       "0 -0.372052  -0.255956  0.272900   0.332852      -0.223988       -1.268788   \n",
       "1  1.596994  -0.255956 -0.268148   0.332852       1.805464       -0.662564   \n",
       "2 -0.444979  -0.255956  0.149870  -0.451576       0.993683        1.156108   \n",
       "3 -0.372052  -0.255956 -0.697918   0.332852      -0.223988       -0.662564   \n",
       "4  1.232356  -0.255956 -0.357668  -0.451576       0.993683        1.156108   \n",
       "\n",
       "   occupation  relationship      race  sex  capital.gain  capital.loss  \\\n",
       "0   -1.121390      1.452792  0.399164  0.0     -0.144256     -0.190852   \n",
       "1    1.103020     -0.651992  0.399164  0.0      0.287178     -0.194372   \n",
       "2   -1.121390      0.751198  0.399164  0.0     -0.144256     -0.187331   \n",
       "3    1.103020     -0.651992  0.399164  0.0     -0.144256     -0.190852   \n",
       "4    1.597334      0.751198  0.399164  0.0     -0.144256     -0.190852   \n",
       "\n",
       "   hours.per.week  native.country    income  \n",
       "0        0.305094        0.263627  0.174403  \n",
       "1        0.710425        0.263627  0.872663  \n",
       "2       -0.019171        0.263627  0.027419  \n",
       "3       -0.019171        0.263627  0.270261  \n",
       "4       -0.181304        0.263627  0.125108  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Original training set size: {len(df_train)}\\nAugmeneted training set size: {len(df_aug_cond_teacher_preds)}\")\n",
    "df_aug = pd.concat([df_aug_cond_teacher_preds, df_train])\n",
    "df_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug = df_aug.drop([label], axis=1)\n",
    "y_aug = df_aug[label]\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "clf.fit(X_aug, y_aug)\n",
    "\n",
    "test_probas = clf.predict(pX_test)\n",
    "test_preds = test_preds = np.round(test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7742540061903238"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, test_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710826898519566"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, test_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student with Teacher + Split Conformal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc.methods import SplitConformal\n",
    "from arc.black_boxes import TabularAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_prediction_sets(method, x, label):\n",
    "    s_sc = method.predict(x)\n",
    "    # given the binary classification case, we keep only prediction sets that include exactely one prediction.\n",
    "    filt_sc = [(xx, s_sc[i][0]) for i, xx in enumerate(x.to_numpy()) if len(s_sc[i]) == 1]\n",
    "    x_sc, y_sc = zip(*filt_sc)\n",
    "    sc_df = pd.DataFrame(x_sc, columns=x.columns)\n",
    "    sc_df[label] = y_sc\n",
    "    return sc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.850713</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>1.246786</td>\n",
       "      <td>-0.332697</td>\n",
       "      <td>1.135385</td>\n",
       "      <td>-1.742386</td>\n",
       "      <td>1.236648</td>\n",
       "      <td>-0.276827</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>-1.434521</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-2.885649</td>\n",
       "      <td>0.260859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.560269</td>\n",
       "      <td>-1.889076</td>\n",
       "      <td>-0.891714</td>\n",
       "      <td>0.185015</td>\n",
       "      <td>-0.421692</td>\n",
       "      <td>-1.742386</td>\n",
       "      <td>0.230318</td>\n",
       "      <td>1.590090</td>\n",
       "      <td>-4.327948</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.042075</td>\n",
       "      <td>0.260859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.998630</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>-1.370405</td>\n",
       "      <td>0.185015</td>\n",
       "      <td>-0.421692</td>\n",
       "      <td>0.921843</td>\n",
       "      <td>-0.272846</td>\n",
       "      <td>-0.276827</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.448300</td>\n",
       "      <td>0.260859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.121909</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>0.613637</td>\n",
       "      <td>-0.332697</td>\n",
       "      <td>1.135385</td>\n",
       "      <td>-0.410272</td>\n",
       "      <td>1.236648</td>\n",
       "      <td>-0.899132</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>0.770375</td>\n",
       "      <td>0.260859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.777653</td>\n",
       "      <td>-0.088376</td>\n",
       "      <td>0.456853</td>\n",
       "      <td>0.185015</td>\n",
       "      <td>-0.421692</td>\n",
       "      <td>-0.410272</td>\n",
       "      <td>-1.027593</td>\n",
       "      <td>-0.899132</td>\n",
       "      <td>0.393160</td>\n",
       "      <td>0.697097</td>\n",
       "      <td>-0.14426</td>\n",
       "      <td>-0.217063</td>\n",
       "      <td>-0.854525</td>\n",
       "      <td>0.260859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education.num  marital.status  \\\n",
       "0  1.850713  -0.088376  1.246786  -0.332697       1.135385       -1.742386   \n",
       "1 -0.560269  -1.889076 -0.891714   0.185015      -0.421692       -1.742386   \n",
       "2 -0.998630  -0.088376 -1.370405   0.185015      -0.421692        0.921843   \n",
       "3 -0.121909  -0.088376  0.613637  -0.332697       1.135385       -0.410272   \n",
       "4  1.777653  -0.088376  0.456853   0.185015      -0.421692       -0.410272   \n",
       "\n",
       "   occupation  relationship      race       sex  capital.gain  capital.loss  \\\n",
       "0    1.236648     -0.276827  0.393160 -1.434521      -0.14426     -0.217063   \n",
       "1    0.230318      1.590090 -4.327948  0.697097      -0.14426     -0.217063   \n",
       "2   -0.272846     -0.276827  0.393160  0.697097      -0.14426     -0.217063   \n",
       "3    1.236648     -0.899132  0.393160  0.697097      -0.14426     -0.217063   \n",
       "4   -1.027593     -0.899132  0.393160  0.697097      -0.14426     -0.217063   \n",
       "\n",
       "   hours.per.week  native.country  \n",
       "0       -2.885649        0.260859  \n",
       "1       -0.042075        0.260859  \n",
       "2       -0.448300        0.260859  \n",
       "3        0.770375        0.260859  \n",
       "4       -0.854525        0.260859  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pX_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210729_211112\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210729_211112\\\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    8140\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "Warning: Ignoring 6072 (out of 8140) training examples for which the label value in column 'income' is missing\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1.0, 0.0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1308.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.23 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['age', 'workclass', 'fnlwgt', 'education', 'education.num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['age', 'workclass', 'fnlwgt', 'education', 'education.num', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.23 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 39.94s of the 59.91s of remaining time.\n",
      "\t0.5053\t = Validation f1_macro score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 39.79s of the 59.77s of remaining time.\n",
      "\t0.4986\t = Validation f1_macro score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 39.64s of the 59.62s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 372. Best iteration is:\n",
      "\t[307]\ttrain_set's binary_logloss: 0.407799\ttrain_set's f1_macro: 0.769582\tvalid_set's binary_logloss: 0.677649\tvalid_set's f1_macro: 0.477273\n",
      "\tRan out of time, early stopping on iteration 223. Best iteration is:\n",
      "\t[207]\ttrain_set's binary_logloss: 0.447974\ttrain_set's f1_macro: 0.703209\tvalid_set's binary_logloss: 0.663998\tvalid_set's f1_macro: 0.486316\n",
      "\tRan out of time, early stopping on iteration 223. Best iteration is:\n",
      "\t[175]\ttrain_set's binary_logloss: 0.460679\ttrain_set's f1_macro: 0.680894\tvalid_set's binary_logloss: 0.689607\tvalid_set's f1_macro: 0.439773\n",
      "\tRan out of time, early stopping on iteration 397. Best iteration is:\n",
      "\t[396]\ttrain_set's binary_logloss: 0.374419\ttrain_set's f1_macro: 0.806253\tvalid_set's binary_logloss: 0.668731\tvalid_set's f1_macro: 0.504059\n",
      "\tRan out of time, early stopping on iteration 223. Best iteration is:\n",
      "\t[206]\ttrain_set's binary_logloss: 0.450903\ttrain_set's f1_macro: 0.678491\tvalid_set's binary_logloss: 0.617675\tvalid_set's f1_macro: 0.48708\n",
      "\tRan out of time, early stopping on iteration 230. Best iteration is:\n",
      "\t[205]\ttrain_set's binary_logloss: 0.449099\ttrain_set's f1_macro: 0.700535\tvalid_set's binary_logloss: 0.638122\tvalid_set's f1_macro: 0.495614\n",
      "\tRan out of time, early stopping on iteration 239. Best iteration is:\n",
      "\t[206]\ttrain_set's binary_logloss: 0.4514\ttrain_set's f1_macro: 0.701031\tvalid_set's binary_logloss: 0.637004\tvalid_set's f1_macro: 0.47345\n",
      "\tRan out of time, early stopping on iteration 258. Best iteration is:\n",
      "\t[257]\ttrain_set's binary_logloss: 0.428429\ttrain_set's f1_macro: 0.724544\tvalid_set's binary_logloss: 0.631072\tvalid_set's f1_macro: 0.488698\n",
      "\tRan out of time, early stopping on iteration 277. Best iteration is:\n",
      "\t[248]\ttrain_set's binary_logloss: 0.427217\ttrain_set's f1_macro: 0.728204\tvalid_set's binary_logloss: 0.673007\tvalid_set's f1_macro: 0.502829\n",
      "\tRan out of time, early stopping on iteration 321. Best iteration is:\n",
      "\t[289]\ttrain_set's binary_logloss: 0.410819\ttrain_set's f1_macro: 0.769242\tvalid_set's binary_logloss: 0.663209\tvalid_set's f1_macro: 0.470227\n",
      "\t0.4829\t = Validation f1_macro score\n",
      "\t37.95s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1.04s of the 21.02s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\ttrain_set's binary_logloss: 0.607743\ttrain_set's f1_macro: 0.411448\tvalid_set's binary_logloss: 0.61513\tvalid_set's f1_macro: 0.410256\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L1.\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 0.84s of the 20.81s of remaining time.\n",
      "\t0.4536\t = Validation f1_macro score\n",
      "\t1.55s\t = Training runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.92s of the 18.98s of remaining time.\n",
      "\t0.5059\t = Validation f1_macro score\n",
      "\t0.74s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsUnif_BAG_L2 ... Training model for up to 18.22s of the 18.22s of remaining time.\n",
      "\t0.5088\t = Validation f1_macro score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L2 ... Training model for up to 18.0s of the 17.99s of remaining time.\n",
      "\t0.5072\t = Validation f1_macro score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 17.78s of the 17.78s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 174. Best iteration is:\n",
      "\t[169]\ttrain_set's binary_logloss: 0.40019\ttrain_set's f1_macro: 0.774967\tvalid_set's binary_logloss: 0.594594\tvalid_set's f1_macro: 0.557692\n",
      "\tRan out of time, early stopping on iteration 89. Best iteration is:\n",
      "\t[1]\ttrain_set's binary_logloss: 0.609651\ttrain_set's f1_macro: 0.411448\tvalid_set's binary_logloss: 0.614288\tvalid_set's f1_macro: 0.410256\n",
      "\tRan out of time, early stopping on iteration 94. Best iteration is:\n",
      "\t[1]\ttrain_set's binary_logloss: 0.609584\ttrain_set's f1_macro: 0.411448\tvalid_set's binary_logloss: 0.614648\tvalid_set's f1_macro: 0.410256\n",
      "\tRan out of time, early stopping on iteration 94. Best iteration is:\n",
      "\t[80]\ttrain_set's binary_logloss: 0.486834\ttrain_set's f1_macro: 0.54222\tvalid_set's binary_logloss: 0.614536\tvalid_set's f1_macro: 0.427054\n",
      "\tRan out of time, early stopping on iteration 96. Best iteration is:\n",
      "\t[96]\ttrain_set's binary_logloss: 0.468497\ttrain_set's f1_macro: 0.605947\tvalid_set's binary_logloss: 0.608309\tvalid_set's f1_macro: 0.439073\n",
      "\tRan out of time, early stopping on iteration 102. Best iteration is:\n",
      "\t[57]\ttrain_set's binary_logloss: 0.51784\ttrain_set's f1_macro: 0.467425\tvalid_set's binary_logloss: 0.607124\tvalid_set's f1_macro: 0.445536\n",
      "\tRan out of time, early stopping on iteration 103. Best iteration is:\n",
      "\t[90]\ttrain_set's binary_logloss: 0.477767\ttrain_set's f1_macro: 0.586817\tvalid_set's binary_logloss: 0.605238\tvalid_set's f1_macro: 0.443377\n",
      "\tRan out of time, early stopping on iteration 105. Best iteration is:\n",
      "\t[101]\ttrain_set's binary_logloss: 0.465083\ttrain_set's f1_macro: 0.628147\tvalid_set's binary_logloss: 0.613615\tvalid_set's f1_macro: 0.436926\n",
      "\tRan out of time, early stopping on iteration 118. Best iteration is:\n",
      "\t[76]\ttrain_set's binary_logloss: 0.493044\ttrain_set's f1_macro: 0.53886\tvalid_set's binary_logloss: 0.612346\tvalid_set's f1_macro: 0.440708\n",
      "\tRan out of time, early stopping on iteration 145. Best iteration is:\n",
      "\t[109]\ttrain_set's binary_logloss: 0.45565\ttrain_set's f1_macro: 0.637729\tvalid_set's binary_logloss: 0.612008\tvalid_set's f1_macro: 0.476791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.451\t = Validation f1_macro score\n",
      "\t17.01s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 0.44s of the 0.44s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\ttrain_set's binary_logloss: 0.606302\ttrain_set's f1_macro: 0.411448\tvalid_set's binary_logloss: 0.614197\tvalid_set's f1_macro: 0.410256\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 0.25s of the 0.25s of remaining time.\n",
      "\t0.4478\t = Validation f1_macro score\n",
      "\t1.52s\t = Training runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 59.92s of the -1.75s of remaining time.\n",
      "\t0.5115\t = Validation f1_macro score\n",
      "\t0.9s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 62.69s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210729_211112\\\")\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "bb = TabularAutoML(label=label)\n",
    "method_sc = SplitConformal(pX_train, y_train, bb, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_gibbs_df_sc = filter_by_prediction_sets(method_sc, proc_gibbs_df, label)\n",
    "proc_cond_df_sc = filter_by_prediction_sets(method_sc, proc_cond_df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.259718</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>-1.480375</td>\n",
       "      <td>1.325252</td>\n",
       "      <td>-0.080571</td>\n",
       "      <td>0.878635</td>\n",
       "      <td>1.349306</td>\n",
       "      <td>-0.425635</td>\n",
       "      <td>0.409176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144238</td>\n",
       "      <td>-0.217057</td>\n",
       "      <td>-0.020654</td>\n",
       "      <td>0.263247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.396140</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>0.260226</td>\n",
       "      <td>0.125068</td>\n",
       "      <td>-0.509510</td>\n",
       "      <td>-0.762882</td>\n",
       "      <td>-0.568541</td>\n",
       "      <td>-0.425635</td>\n",
       "      <td>-2.487711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144238</td>\n",
       "      <td>-0.217057</td>\n",
       "      <td>-0.908772</td>\n",
       "      <td>0.263247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.072255</td>\n",
       "      <td>2.126398</td>\n",
       "      <td>-0.883462</td>\n",
       "      <td>0.125068</td>\n",
       "      <td>-0.509510</td>\n",
       "      <td>0.878635</td>\n",
       "      <td>-1.207823</td>\n",
       "      <td>-0.425635</td>\n",
       "      <td>0.409176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144238</td>\n",
       "      <td>-0.217057</td>\n",
       "      <td>-0.464713</td>\n",
       "      <td>0.263247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.093732</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>1.364832</td>\n",
       "      <td>0.125068</td>\n",
       "      <td>-0.509510</td>\n",
       "      <td>0.878635</td>\n",
       "      <td>-1.207823</td>\n",
       "      <td>-0.425635</td>\n",
       "      <td>0.409176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144238</td>\n",
       "      <td>-0.217057</td>\n",
       "      <td>0.068158</td>\n",
       "      <td>0.263247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.562127</td>\n",
       "      <td>-2.013443</td>\n",
       "      <td>-0.883830</td>\n",
       "      <td>1.325252</td>\n",
       "      <td>-0.080571</td>\n",
       "      <td>2.520152</td>\n",
       "      <td>0.710023</td>\n",
       "      <td>-0.425635</td>\n",
       "      <td>0.409176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144238</td>\n",
       "      <td>-0.217057</td>\n",
       "      <td>-3.040257</td>\n",
       "      <td>0.263247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education.num  marital.status  \\\n",
       "0 -1.259718   0.056478 -1.480375   1.325252      -0.080571        0.878635   \n",
       "1  1.396140   0.056478  0.260226   0.125068      -0.509510       -0.762882   \n",
       "2  1.072255   2.126398 -0.883462   0.125068      -0.509510        0.878635   \n",
       "3 -0.093732   0.056478  1.364832   0.125068      -0.509510        0.878635   \n",
       "4  2.562127  -2.013443 -0.883830   1.325252      -0.080571        2.520152   \n",
       "\n",
       "   occupation  relationship      race  sex  capital.gain  capital.loss  \\\n",
       "0    1.349306     -0.425635  0.409176  0.0     -0.144238     -0.217057   \n",
       "1   -0.568541     -0.425635 -2.487711  0.0     -0.144238     -0.217057   \n",
       "2   -1.207823     -0.425635  0.409176  0.0     -0.144238     -0.217057   \n",
       "3   -1.207823     -0.425635  0.409176  0.0     -0.144238     -0.217057   \n",
       "4    0.710023     -0.425635  0.409176  0.0     -0.144238     -0.217057   \n",
       "\n",
       "   hours.per.week  native.country  income  \n",
       "0       -0.020654        0.263247       0  \n",
       "1       -0.908772        0.263247       0  \n",
       "2       -0.464713        0.263247       0  \n",
       "3        0.068158        0.263247       0  \n",
       "4       -3.040257        0.263247       0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_sc_csv_path = r\"C:\\Users\\orrav\\Documents\\Datasets\\Adult Census Income\\adult_test_sc_roc_auc.csv\"\n",
    "df_sc = pd.read_csv(aug_sc_csv_path, index_col=0)\n",
    "df_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.259718</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>-1.480375</td>\n",
       "      <td>1.325252</td>\n",
       "      <td>-0.080571</td>\n",
       "      <td>0.878635</td>\n",
       "      <td>1.349306</td>\n",
       "      <td>-0.425635</td>\n",
       "      <td>0.409176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144238</td>\n",
       "      <td>-0.217057</td>\n",
       "      <td>-0.020654</td>\n",
       "      <td>0.263247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.396140</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>0.260226</td>\n",
       "      <td>0.125068</td>\n",
       "      <td>-0.509510</td>\n",
       "      <td>-0.762882</td>\n",
       "      <td>-0.568541</td>\n",
       "      <td>-0.425635</td>\n",
       "      <td>-2.487711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144238</td>\n",
       "      <td>-0.217057</td>\n",
       "      <td>-0.908772</td>\n",
       "      <td>0.263247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.072255</td>\n",
       "      <td>2.126398</td>\n",
       "      <td>-0.883462</td>\n",
       "      <td>0.125068</td>\n",
       "      <td>-0.509510</td>\n",
       "      <td>0.878635</td>\n",
       "      <td>-1.207823</td>\n",
       "      <td>-0.425635</td>\n",
       "      <td>0.409176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144238</td>\n",
       "      <td>-0.217057</td>\n",
       "      <td>-0.464713</td>\n",
       "      <td>0.263247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.093732</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>1.364832</td>\n",
       "      <td>0.125068</td>\n",
       "      <td>-0.509510</td>\n",
       "      <td>0.878635</td>\n",
       "      <td>-1.207823</td>\n",
       "      <td>-0.425635</td>\n",
       "      <td>0.409176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144238</td>\n",
       "      <td>-0.217057</td>\n",
       "      <td>0.068158</td>\n",
       "      <td>0.263247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.562127</td>\n",
       "      <td>-2.013443</td>\n",
       "      <td>-0.883830</td>\n",
       "      <td>1.325252</td>\n",
       "      <td>-0.080571</td>\n",
       "      <td>2.520152</td>\n",
       "      <td>0.710023</td>\n",
       "      <td>-0.425635</td>\n",
       "      <td>0.409176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144238</td>\n",
       "      <td>-0.217057</td>\n",
       "      <td>-3.040257</td>\n",
       "      <td>0.263247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education.num  marital.status  \\\n",
       "0 -1.259718   0.056478 -1.480375   1.325252      -0.080571        0.878635   \n",
       "1  1.396140   0.056478  0.260226   0.125068      -0.509510       -0.762882   \n",
       "2  1.072255   2.126398 -0.883462   0.125068      -0.509510        0.878635   \n",
       "3 -0.093732   0.056478  1.364832   0.125068      -0.509510        0.878635   \n",
       "4  2.562127  -2.013443 -0.883830   1.325252      -0.080571        2.520152   \n",
       "\n",
       "   occupation  relationship      race  sex  capital.gain  capital.loss  \\\n",
       "0    1.349306     -0.425635  0.409176  0.0     -0.144238     -0.217057   \n",
       "1   -0.568541     -0.425635 -2.487711  0.0     -0.144238     -0.217057   \n",
       "2   -1.207823     -0.425635  0.409176  0.0     -0.144238     -0.217057   \n",
       "3   -1.207823     -0.425635  0.409176  0.0     -0.144238     -0.217057   \n",
       "4    0.710023     -0.425635  0.409176  0.0     -0.144238     -0.217057   \n",
       "\n",
       "   hours.per.week  native.country  income  \n",
       "0       -0.020654        0.263247       0  \n",
       "1       -0.908772        0.263247       0  \n",
       "2       -0.464713        0.263247       0  \n",
       "3        0.068158        0.263247       0  \n",
       "4       -3.040257        0.263247       0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug_sc = pd.concat([df_sc, df_train])\n",
    "df_aug_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug_sc = df_aug_sc.drop([label], axis=1)\n",
    "y_aug_sc = df_aug_sc[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, max_depth=10, random_state=0)\n",
    "clf.fit(X_aug_sc, y_aug_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = clf.predict(pX_test)\n",
    "test_probas = clf.predict_proba(pX_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.772486612522792"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, test_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.907316691124066"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, test_probas)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP3m8Pu0NMNiNkpNfmY7d83",
   "mount_file_id": "1Gjc7Vg_2YfUKTW58vXv9RkpXWHlrcMct",
   "name": "adults-income.ipynb",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
